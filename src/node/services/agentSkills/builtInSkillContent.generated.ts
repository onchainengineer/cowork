// AUTO-GENERATED - DO NOT EDIT
// Run: bun scripts/gen_builtin_skills.ts
// Source: src/node/builtinSkills/*.md and docs/

export const BUILTIN_SKILL_FILES: Record<string, Record<string, string>> = {
  docx: {
    "SKILL.md": [
      "---",
      "name: docx",
      'description: "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. When Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks"',
      "license: Proprietary. LICENSE.txt has complete terms",
      "---",
      "",
      "# DOCX creation, editing, and analysis",
      "",
      "## Overview",
      "",
      "A user may ask you to create, edit, or analyze the contents of a .docx file. A .docx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.",
      "",
      "## Workflow Decision Tree",
      "",
      "### Reading/Analyzing Content",
      'Use "Text extraction" or "Raw XML access" sections below',
      "",
      "### Creating New Document",
      'Use "Creating a new Word document" workflow',
      "",
      "### Editing Existing Document",
      "- **Your own document + simple changes**",
      '  Use "Basic OOXML editing" workflow',
      "",
      "- **Someone else's document**",
      '  Use **"Redlining workflow"** (recommended default)',
      "",
      "- **Legal, academic, business, or government docs**",
      '  Use **"Redlining workflow"** (required)',
      "",
      "## Reading and analyzing content",
      "",
      "### Text extraction",
      "If you just need to read the text contents of a document, you should convert the document to markdown using pandoc. Pandoc provides excellent support for preserving document structure and can show tracked changes:",
      "",
      "```bash",
      "# Convert document to markdown with tracked changes",
      "pandoc --track-changes=all path-to-file.docx -o output.md",
      "# Options: --track-changes=accept/reject/all",
      "```",
      "",
      "### Raw XML access",
      "You need raw XML access for: comments, complex formatting, document structure, embedded media, and metadata. For any of these features, you'll need to unpack a document and read its raw XML contents.",
      "",
      "#### Unpacking a file",
      "`python ooxml/scripts/unpack.py <office_file> <output_directory>`",
      "",
      "#### Key file structures",
      "* `word/document.xml` - Main document contents",
      "* `word/comments.xml` - Comments referenced in document.xml",
      "* `word/media/` - Embedded images and media files",
      "* Tracked changes use `<w:ins>` (insertions) and `<w:del>` (deletions) tags",
      "",
      "## Creating a new Word document",
      "",
      "When creating a new Word document from scratch, use **docx-js**, which allows you to create Word documents using JavaScript/TypeScript.",
      "",
      "### Workflow",
      "1. **MANDATORY - READ ENTIRE FILE**: Read [`docx-js.md`](docx-js.md) (~500 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with document creation.",
      "2. Create a JavaScript/TypeScript file using Document, Paragraph, TextRun components (You can assume all dependencies are installed, but if not, refer to the dependencies section below)",
      "3. Export as .docx using Packer.toBuffer()",
      "",
      "## Editing an existing Word document",
      "",
      "When editing an existing Word document, use the **Document library** (a Python library for OOXML manipulation). The library automatically handles infrastructure setup and provides methods for document manipulation. For complex scenarios, you can access the underlying DOM directly through the library.",
      "",
      "### Workflow",
      "1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for the Document library API and XML patterns for directly editing document files.",
      "2. Unpack the document: `python ooxml/scripts/unpack.py <office_file> <output_directory>`",
      '3. Create and run a Python script using the Document library (see "Document Library" section in ooxml.md)',
      "4. Pack the final document: `python ooxml/scripts/pack.py <input_directory> <office_file>`",
      "",
      "The Document library provides both high-level methods for common operations and direct DOM access for complex scenarios.",
      "",
      "## Redlining workflow for document review",
      "",
      "This workflow allows you to plan comprehensive tracked changes using markdown before implementing them in OOXML. **CRITICAL**: For complete tracked changes, you must implement ALL changes systematically.",
      "",
      "**Batching Strategy**: Group related changes into batches of 3-10 changes. This makes debugging manageable while maintaining efficiency. Test each batch before moving to the next.",
      "",
      "**Principle: Minimal, Precise Edits**",
      "When implementing tracked changes, only mark text that actually changes. Repeating unchanged text makes edits harder to review and appears unprofessional. Break replacements into: [unchanged text] + [deletion] + [insertion] + [unchanged text]. Preserve the original run's RSID for unchanged text by extracting the `<w:r>` element from the original and reusing it.",
      "",
      'Example - Changing "30 days" to "60 days" in a sentence:',
      "```python",
      "# BAD - Replaces entire sentence",
      "'<w:del><w:r><w:delText>The term is 30 days.</w:delText></w:r></w:del><w:ins><w:r><w:t>The term is 60 days.</w:t></w:r></w:ins>'",
      "",
      "# GOOD - Only marks what changed, preserves original <w:r> for unchanged text",
      '\'<w:r w:rsidR="00AB12CD"><w:t>The term is </w:t></w:r><w:del><w:r><w:delText>30</w:delText></w:r></w:del><w:ins><w:r><w:t>60</w:t></w:r></w:ins><w:r w:rsidR="00AB12CD"><w:t> days.</w:t></w:r>\'',
      "```",
      "",
      "### Tracked changes workflow",
      "",
      "1. **Get markdown representation**: Convert document to markdown with tracked changes preserved:",
      "   ```bash",
      "   pandoc --track-changes=all path-to-file.docx -o current.md",
      "   ```",
      "",
      "2. **Identify and group changes**: Review the document and identify ALL changes needed, organizing them into logical batches:",
      "",
      "   **Location methods** (for finding changes in XML):",
      '   - Section/heading numbers (e.g., "Section 3.2", "Article IV")',
      "   - Paragraph identifiers if numbered",
      "   - Grep patterns with unique surrounding text",
      '   - Document structure (e.g., "first paragraph", "signature block")',
      "   - **DO NOT use markdown line numbers** - they don't map to XML structure",
      "",
      "   **Batch organization** (group 3-10 related changes per batch):",
      '   - By section: "Batch 1: Section 2 amendments", "Batch 2: Section 5 updates"',
      '   - By type: "Batch 1: Date corrections", "Batch 2: Party name changes"',
      "   - By complexity: Start with simple text replacements, then tackle complex structural changes",
      '   - Sequential: "Batch 1: Pages 1-3", "Batch 2: Pages 4-6"',
      "",
      "3. **Read documentation and unpack**:",
      '   - **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~600 lines) completely from start to finish. **NEVER set any range limits when reading this file.** Pay special attention to the "Document Library" and "Tracked Change Patterns" sections.',
      "   - **Unpack the document**: `python ooxml/scripts/unpack.py <file.docx> <dir>`",
      "   - **Note the suggested RSID**: The unpack script will suggest an RSID to use for your tracked changes. Copy this RSID for use in step 4b.",
      "",
      "4. **Implement changes in batches**: Group changes logically (by section, by type, or by proximity) and implement them together in a single script. This approach:",
      "   - Makes debugging easier (smaller batch = easier to isolate errors)",
      "   - Allows incremental progress",
      "   - Maintains efficiency (batch size of 3-10 changes works well)",
      "",
      "   **Suggested batch groupings:**",
      '   - By document section (e.g., "Section 3 changes", "Definitions", "Termination clause")',
      '   - By change type (e.g., "Date changes", "Party name updates", "Legal term replacements")',
      '   - By proximity (e.g., "Changes on pages 1-3", "Changes in first half of document")',
      "",
      "   For each batch of related changes:",
      "",
      "   **a. Map text to XML**: Grep for text in `word/document.xml` to verify how text is split across `<w:r>` elements.",
      "",
      '   **b. Create and run script**: Use `get_node` to find nodes, implement changes, then `doc.save()`. See **"Document Library"** section in ooxml.md for patterns.',
      "",
      "   **Note**: Always grep `word/document.xml` immediately before writing a script to get current line numbers and verify text content. Line numbers change after each script run.",
      "",
      "5. **Pack the document**: After all batches are complete, convert the unpacked directory back to .docx:",
      "   ```bash",
      "   python ooxml/scripts/pack.py unpacked reviewed-document.docx",
      "   ```",
      "",
      "6. **Final verification**: Do a comprehensive check of the complete document:",
      "   - Convert final document to markdown:",
      "     ```bash",
      "     pandoc --track-changes=all reviewed-document.docx -o verification.md",
      "     ```",
      "   - Verify ALL changes were applied correctly:",
      "     ```bash",
      '     grep "original phrase" verification.md  # Should NOT find it',
      '     grep "replacement phrase" verification.md  # Should find it',
      "     ```",
      "   - Check that no unintended changes were introduced",
      "",
      "",
      "## Converting Documents to Images",
      "",
      "To visually analyze Word documents, convert them to images using a two-step process:",
      "",
      "1. **Convert DOCX to PDF**:",
      "   ```bash",
      "   soffice --headless --convert-to pdf document.docx",
      "   ```",
      "",
      "2. **Convert PDF pages to JPEG images**:",
      "   ```bash",
      "   pdftoppm -jpeg -r 150 document.pdf page",
      "   ```",
      "   This creates files like `page-1.jpg`, `page-2.jpg`, etc.",
      "",
      "Options:",
      "- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)",
      "- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)",
      "- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)",
      "- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)",
      "- `page`: Prefix for output files",
      "",
      "Example for specific range:",
      "```bash",
      "pdftoppm -jpeg -r 150 -f 2 -l 5 document.pdf page  # Converts only pages 2-5",
      "```",
      "",
      "## Code Style Guidelines",
      "**IMPORTANT**: When generating code for DOCX operations:",
      "- Write concise code",
      "- Avoid verbose variable names and redundant operations",
      "- Avoid unnecessary print statements",
      "",
      "## Dependencies",
      "",
      "Required dependencies (install if not available):",
      "",
      "- **pandoc**: `sudo apt-get install pandoc` (for text extraction)",
      "- **docx**: `npm install -g docx` (for creating new documents)",
      "- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)",
      "- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)",
      "- **defusedxml**: `pip install defusedxml` (for secure XML parsing)",
    ].join("\n"),
  },
  init: {
    "SKILL.md": [
      "---",
      "name: init",
      "description: Bootstrap an AGENTS.md file in a new or existing project",
      "---",
      "",
      "<system>",
      "Use your tools to create or improve an AGENTS.md file in the root of the workspace which will serve as a contribution guide for AI agents.",
      "If an AGENTS.md file already exists, focus on additive improvement (preserve intent and useful information; refine, extend, and reorganize as needed) rather than replacing it wholesale.",
      "Inspect the workspace layout, code, documentation and git history to ensure correctness and accuracy.",
      "",
      "Ensure the following preamble exists at the top of the file before any other sections. Do not include the surrounding code fence backticks; only include the text.",
      "",
      "```md",
      "You are an experienced, pragmatic software engineering AI agent. Do not over-engineer a solution when a simple one is possible. Keep edits minimal. If you want an exception to ANY rule, you MUST stop and get permission first.",
      "```",
      "",
      "Recommended sections:",
      "",
      "- Project Overview (mandatory)",
      "  - Basic details about the project (e.g., high-level overview and goals).",
      "  - Technology choices (e.g., languages, databases, frameworks, libraries, build tools).",
      "- Reference (mandatory)",
      "  - List important code files.",
      "  - List important directories and basic code structure tips.",
      "  - Project architecture.",
      "- Essential commands (mandatory)",
      "  - build",
      "  - format",
      "  - lint",
      "  - test",
      "  - clean",
      "  - development server",
      "  - other _important_ scripts (use `find -type f -name '*.sh'` or similar)",
      "- Patterns (optional)",
      "  - List any important or uncommon patterns (compared to other similar codebases), with examples (e.g., how to authorize an HTTP request).",
      "  - List any important workflows and their steps (e.g., how to make a database migration).",
      "  - Testing patterns.",
      "- Anti-patterns (optional)",
      "  - Search git history and comments to find recurring mistakes or forbidden patterns.",
      "  - List each pattern and its reason.",
      "- Code style (optional)",
      "  - Style guide to follow (with link).",
      "- Commit and Pull Request Guidelines (mandatory)",
      "  - Required steps for validating changes before committing.",
      "  - Commit message conventions (read `git log`, or use `type: message` by default).",
      "  - Pull request description requirements.",
      "",
      "You can add other sections if they are necessary.",
      "If the information required for mandatory sections isn't available due to the workspace being empty or sparse, add TODO text in its place.",
      "Optional sections should be scrapped if the information is too thin.",
      "",
      "Some investigation tips:",
      "",
      "- Read existing lint configs, tsconfig, and CI workflows to find any style or layout rules.",
      '- Search for "TODO", "HACK", "FIXME", "don\'t", "never", "always" in comments.',
      "- Examine test files for patterns.",
      "- Read PR templates and issue templates if they exist.",
      "- Check for existing CONTRIBUTING.md, CODE_OF_CONDUCT.md, or similar documentation files.",
      "",
      "Some writing tips:",
      "",
      '- Each "do X" should have a corresponding "don\'t Y" where applicable.',
      "- Commands should be easily copy-pastable and tested.",
      "- Terms or phrases specific to this project should be explained on first use.",
      "- Anything that is against the norm should be explicitly highlighted and called out.",
      "",
      "Above all things:",
      "",
      "- The document must be clear and concise. Simple projects should need less than 400 words, but larger and more mature codebases will likely need 700+. Prioritize completeness over brevity.",
      "- Don't include useless fluff.",
      "- The document must be in Markdown format and use headings for structure.",
      "- Give examples where necessary or helpful (commands, directory paths, naming patterns).",
      "- Explanations and examples must be correct and specific to this codebase.",
      "- Maintain a professional, instructional tone.",
      "",
      "If the workspace is empty or sparse, ask the user for more information. Avoid hallucinating important decisions. You can provide suggestions to the user for language/technology/tool choices, but always respect the user's decision.",
      "",
      "- Project description and goals.",
      "- Language(s).",
      "- Technologies (database?), frameworks, libraries.",
      "- Tools.",
      "- Any other questions as you deem necessary.",
      "",
      "For empty or sparse workspaces ONLY, when finished writing/updating AGENTS.md, ask the user if they would like you to do the following:",
      "",
      "- initialize git IF it's not already set up (e.g., `git init`, `git remote add`, etc.)",
      "- write a concise README.md file",
      "- generate the bare minimum project scaffolding (e.g., initializing the package manager, writing a minimal build tool config)",
      "  </system>",
      "",
    ].join("\n"),
  },
  pdf: {
    "SKILL.md": [
      "---",
      "name: pdf",
      "description: Comprehensive PDF manipulation toolkit for extracting text and tables, creating new PDFs, merging/splitting documents, and handling forms. When Claude needs to fill in a PDF form or programmatically process, generate, or analyze PDF documents at scale.",
      "license: Proprietary. LICENSE.txt has complete terms",
      "---",
      "",
      "# PDF Processing Guide",
      "",
      "## Overview",
      "",
      "This guide covers essential PDF processing operations using Python libraries and command-line tools. For advanced features, JavaScript libraries, and detailed examples, see reference.md. If you need to fill out a PDF form, read forms.md and follow its instructions.",
      "",
      "## Quick Start",
      "",
      "```python",
      "from pypdf import PdfReader, PdfWriter",
      "",
      "# Read a PDF",
      'reader = PdfReader("document.pdf")',
      'print(f"Pages: {len(reader.pages)}")',
      "",
      "# Extract text",
      'text = ""',
      "for page in reader.pages:",
      "    text += page.extract_text()",
      "```",
      "",
      "## Python Libraries",
      "",
      "### pypdf - Basic Operations",
      "",
      "#### Merge PDFs",
      "```python",
      "from pypdf import PdfWriter, PdfReader",
      "",
      "writer = PdfWriter()",
      'for pdf_file in ["doc1.pdf", "doc2.pdf", "doc3.pdf"]:',
      "    reader = PdfReader(pdf_file)",
      "    for page in reader.pages:",
      "        writer.add_page(page)",
      "",
      'with open("merged.pdf", "wb") as output:',
      "    writer.write(output)",
      "```",
      "",
      "#### Split PDF",
      "```python",
      'reader = PdfReader("input.pdf")',
      "for i, page in enumerate(reader.pages):",
      "    writer = PdfWriter()",
      "    writer.add_page(page)",
      '    with open(f"page_{i+1}.pdf", "wb") as output:',
      "        writer.write(output)",
      "```",
      "",
      "#### Extract Metadata",
      "```python",
      'reader = PdfReader("document.pdf")',
      "meta = reader.metadata",
      'print(f"Title: {meta.title}")',
      'print(f"Author: {meta.author}")',
      'print(f"Subject: {meta.subject}")',
      'print(f"Creator: {meta.creator}")',
      "```",
      "",
      "#### Rotate Pages",
      "```python",
      'reader = PdfReader("input.pdf")',
      "writer = PdfWriter()",
      "",
      "page = reader.pages[0]",
      "page.rotate(90)  # Rotate 90 degrees clockwise",
      "writer.add_page(page)",
      "",
      'with open("rotated.pdf", "wb") as output:',
      "    writer.write(output)",
      "```",
      "",
      "### pdfplumber - Text and Table Extraction",
      "",
      "#### Extract Text with Layout",
      "```python",
      "import pdfplumber",
      "",
      'with pdfplumber.open("document.pdf") as pdf:',
      "    for page in pdf.pages:",
      "        text = page.extract_text()",
      "        print(text)",
      "```",
      "",
      "#### Extract Tables",
      "```python",
      'with pdfplumber.open("document.pdf") as pdf:',
      "    for i, page in enumerate(pdf.pages):",
      "        tables = page.extract_tables()",
      "        for j, table in enumerate(tables):",
      '            print(f"Table {j+1} on page {i+1}:")',
      "            for row in table:",
      "                print(row)",
      "```",
      "",
      "#### Advanced Table Extraction",
      "```python",
      "import pandas as pd",
      "",
      'with pdfplumber.open("document.pdf") as pdf:',
      "    all_tables = []",
      "    for page in pdf.pages:",
      "        tables = page.extract_tables()",
      "        for table in tables:",
      "            if table:  # Check if table is not empty",
      "                df = pd.DataFrame(table[1:], columns=table[0])",
      "                all_tables.append(df)",
      "",
      "# Combine all tables",
      "if all_tables:",
      "    combined_df = pd.concat(all_tables, ignore_index=True)",
      '    combined_df.to_excel("extracted_tables.xlsx", index=False)',
      "```",
      "",
      "### reportlab - Create PDFs",
      "",
      "#### Basic PDF Creation",
      "```python",
      "from reportlab.lib.pagesizes import letter",
      "from reportlab.pdfgen import canvas",
      "",
      'c = canvas.Canvas("hello.pdf", pagesize=letter)',
      "width, height = letter",
      "",
      "# Add text",
      'c.drawString(100, height - 100, "Hello World!")',
      'c.drawString(100, height - 120, "This is a PDF created with reportlab")',
      "",
      "# Add a line",
      "c.line(100, height - 140, 400, height - 140)",
      "",
      "# Save",
      "c.save()",
      "```",
      "",
      "#### Create PDF with Multiple Pages",
      "```python",
      "from reportlab.lib.pagesizes import letter",
      "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak",
      "from reportlab.lib.styles import getSampleStyleSheet",
      "",
      'doc = SimpleDocTemplate("report.pdf", pagesize=letter)',
      "styles = getSampleStyleSheet()",
      "story = []",
      "",
      "# Add content",
      "title = Paragraph(\"Report Title\", styles['Title'])",
      "story.append(title)",
      "story.append(Spacer(1, 12))",
      "",
      "body = Paragraph(\"This is the body of the report. \" * 20, styles['Normal'])",
      "story.append(body)",
      "story.append(PageBreak())",
      "",
      "# Page 2",
      "story.append(Paragraph(\"Page 2\", styles['Heading1']))",
      "story.append(Paragraph(\"Content for page 2\", styles['Normal']))",
      "",
      "# Build PDF",
      "doc.build(story)",
      "```",
      "",
      "## Command-Line Tools",
      "",
      "### pdftotext (poppler-utils)",
      "```bash",
      "# Extract text",
      "pdftotext input.pdf output.txt",
      "",
      "# Extract text preserving layout",
      "pdftotext -layout input.pdf output.txt",
      "",
      "# Extract specific pages",
      "pdftotext -f 1 -l 5 input.pdf output.txt  # Pages 1-5",
      "```",
      "",
      "### qpdf",
      "```bash",
      "# Merge PDFs",
      "qpdf --empty --pages file1.pdf file2.pdf -- merged.pdf",
      "",
      "# Split pages",
      "qpdf input.pdf --pages . 1-5 -- pages1-5.pdf",
      "qpdf input.pdf --pages . 6-10 -- pages6-10.pdf",
      "",
      "# Rotate pages",
      "qpdf input.pdf output.pdf --rotate=+90:1  # Rotate page 1 by 90 degrees",
      "",
      "# Remove password",
      "qpdf --password=mypassword --decrypt encrypted.pdf decrypted.pdf",
      "```",
      "",
      "### pdftk (if available)",
      "```bash",
      "# Merge",
      "pdftk file1.pdf file2.pdf cat output merged.pdf",
      "",
      "# Split",
      "pdftk input.pdf burst",
      "",
      "# Rotate",
      "pdftk input.pdf rotate 1east output rotated.pdf",
      "```",
      "",
      "## Common Tasks",
      "",
      "### Extract Text from Scanned PDFs",
      "```python",
      "# Requires: pip install pytesseract pdf2image",
      "import pytesseract",
      "from pdf2image import convert_from_path",
      "",
      "# Convert PDF to images",
      "images = convert_from_path('scanned.pdf')",
      "",
      "# OCR each page",
      'text = ""',
      "for i, image in enumerate(images):",
      '    text += f"Page {i+1}:\\n"',
      "    text += pytesseract.image_to_string(image)",
      '    text += "\\n\\n"',
      "",
      "print(text)",
      "```",
      "",
      "### Add Watermark",
      "```python",
      "from pypdf import PdfReader, PdfWriter",
      "",
      "# Create watermark (or load existing)",
      'watermark = PdfReader("watermark.pdf").pages[0]',
      "",
      "# Apply to all pages",
      'reader = PdfReader("document.pdf")',
      "writer = PdfWriter()",
      "",
      "for page in reader.pages:",
      "    page.merge_page(watermark)",
      "    writer.add_page(page)",
      "",
      'with open("watermarked.pdf", "wb") as output:',
      "    writer.write(output)",
      "```",
      "",
      "### Extract Images",
      "```bash",
      "# Using pdfimages (poppler-utils)",
      "pdfimages -j input.pdf output_prefix",
      "",
      "# This extracts all images as output_prefix-000.jpg, output_prefix-001.jpg, etc.",
      "```",
      "",
      "### Password Protection",
      "```python",
      "from pypdf import PdfReader, PdfWriter",
      "",
      'reader = PdfReader("input.pdf")',
      "writer = PdfWriter()",
      "",
      "for page in reader.pages:",
      "    writer.add_page(page)",
      "",
      "# Add password",
      'writer.encrypt("userpassword", "ownerpassword")',
      "",
      'with open("encrypted.pdf", "wb") as output:',
      "    writer.write(output)",
      "```",
      "",
      "## Quick Reference",
      "",
      "| Task | Best Tool | Command/Code |",
      "|------|-----------|--------------|",
      "| Merge PDFs | pypdf | `writer.add_page(page)` |",
      "| Split PDFs | pypdf | One page per file |",
      "| Extract text | pdfplumber | `page.extract_text()` |",
      "| Extract tables | pdfplumber | `page.extract_tables()` |",
      "| Create PDFs | reportlab | Canvas or Platypus |",
      "| Command line merge | qpdf | `qpdf --empty --pages ...` |",
      "| OCR scanned PDFs | pytesseract | Convert to image first |",
      "| Fill PDF forms | pdf-lib or pypdf (see forms.md) | See forms.md |",
      "",
      "## Next Steps",
      "",
      "- For advanced pypdfium2 usage, see reference.md",
      "- For JavaScript libraries (pdf-lib), see reference.md",
      "- If you need to fill out a PDF form, follow the instructions in forms.md",
      "- For troubleshooting guides, see reference.md",
      "",
    ].join("\n"),
  },
  pptx: {
    "SKILL.md": [
      "---",
      "name: pptx",
      'description: "Presentation creation, editing, and analysis. When Claude needs to work with presentations (.pptx files) for: (1) Creating new presentations, (2) Modifying or editing content, (3) Working with layouts, (4) Adding comments or speaker notes, or any other presentation tasks"',
      "license: Proprietary. LICENSE.txt has complete terms",
      "---",
      "",
      "# PPTX creation, editing, and analysis",
      "",
      "## Overview",
      "",
      "A user may ask you to create, edit, or analyze the contents of a .pptx file. A .pptx file is essentially a ZIP archive containing XML files and other resources that you can read or edit. You have different tools and workflows available for different tasks.",
      "",
      "## Reading and analyzing content",
      "",
      "### Text extraction",
      "If you just need to read the text contents of a presentation, you should convert the document to markdown:",
      "",
      "```bash",
      "# Convert document to markdown",
      "python -m markitdown path-to-file.pptx",
      "```",
      "",
      "### Raw XML access",
      "You need raw XML access for: comments, speaker notes, slide layouts, animations, design elements, and complex formatting. For any of these features, you'll need to unpack a presentation and read its raw XML contents.",
      "",
      "#### Unpacking a file",
      "`python ooxml/scripts/unpack.py <office_file> <output_dir>`",
      "",
      '**Note**: The unpack.py script is located at `skills/pptx/ooxml/scripts/unpack.py` relative to the project root. If the script doesn\'t exist at this path, use `find . -name "unpack.py"` to locate it.',
      "",
      "#### Key file structures",
      "* `ppt/presentation.xml` - Main presentation metadata and slide references",
      "* `ppt/slides/slide{N}.xml` - Individual slide contents (slide1.xml, slide2.xml, etc.)",
      "* `ppt/notesSlides/notesSlide{N}.xml` - Speaker notes for each slide",
      "* `ppt/comments/modernComment_*.xml` - Comments for specific slides",
      "* `ppt/slideLayouts/` - Layout templates for slides",
      "* `ppt/slideMasters/` - Master slide templates",
      "* `ppt/theme/` - Theme and styling information",
      "* `ppt/media/` - Images and other media files",
      "",
      "#### Typography and color extraction",
      "**When given an example design to emulate**: Always analyze the presentation's typography and colors first using the methods below:",
      "1. **Read theme file**: Check `ppt/theme/theme1.xml` for colors (`<a:clrScheme>`) and fonts (`<a:fontScheme>`)",
      "2. **Sample slide content**: Examine `ppt/slides/slide1.xml` for actual font usage (`<a:rPr>`) and colors",
      "3. **Search for patterns**: Use grep to find color (`<a:solidFill>`, `<a:srgbClr>`) and font references across all XML files",
      "",
      "## Creating a new PowerPoint presentation **without a template**",
      "",
      "When creating a new PowerPoint presentation from scratch, use the **html2pptx** workflow to convert HTML slides to PowerPoint with accurate positioning.",
      "",
      "### Design Principles",
      "",
      "**CRITICAL**: Before creating any presentation, analyze the content and choose appropriate design elements:",
      "1. **Consider the subject matter**: What is this presentation about? What tone, industry, or mood does it suggest?",
      "2. **Check for branding**: If the user mentions a company/organization, consider their brand colors and identity",
      "3. **Match palette to content**: Select colors that reflect the subject",
      "4. **State your approach**: Explain your design choices before writing code",
      "",
      "**Requirements**:",
      "- ✅ State your content-informed design approach BEFORE writing code",
      "- ✅ Use web-safe fonts only: Arial, Helvetica, Times New Roman, Georgia, Courier New, Verdana, Tahoma, Trebuchet MS, Impact",
      "- ✅ Create clear visual hierarchy through size, weight, and color",
      "- ✅ Ensure readability: strong contrast, appropriately sized text, clean alignment",
      "- ✅ Be consistent: repeat patterns, spacing, and visual language across slides",
      "",
      "#### Color Palette Selection",
      "",
      "**Choosing colors creatively**:",
      "- **Think beyond defaults**: What colors genuinely match this specific topic? Avoid autopilot choices.",
      "- **Consider multiple angles**: Topic, industry, mood, energy level, target audience, brand identity (if mentioned)",
      "- **Be adventurous**: Try unexpected combinations - a healthcare presentation doesn't have to be green, finance doesn't have to be navy",
      "- **Build your palette**: Pick 3-5 colors that work together (dominant colors + supporting tones + accent)",
      "- **Ensure contrast**: Text must be clearly readable on backgrounds",
      "",
      "**Example color palettes** (use these to spark creativity - choose one, adapt it, or create your own):",
      "",
      "1. **Classic Blue**: Deep navy (#1C2833), slate gray (#2E4053), silver (#AAB7B8), off-white (#F4F6F6)",
      "2. **Teal & Coral**: Teal (#5EA8A7), deep teal (#277884), coral (#FE4447), white (#FFFFFF)",
      "3. **Bold Red**: Red (#C0392B), bright red (#E74C3C), orange (#F39C12), yellow (#F1C40F), green (#2ECC71)",
      "4. **Warm Blush**: Mauve (#A49393), blush (#EED6D3), rose (#E8B4B8), cream (#FAF7F2)",
      "5. **Burgundy Luxury**: Burgundy (#5D1D2E), crimson (#951233), rust (#C15937), gold (#997929)",
      "6. **Deep Purple & Emerald**: Purple (#B165FB), dark blue (#181B24), emerald (#40695B), white (#FFFFFF)",
      "7. **Cream & Forest Green**: Cream (#FFE1C7), forest green (#40695B), white (#FCFCFC)",
      "8. **Pink & Purple**: Pink (#F8275B), coral (#FF574A), rose (#FF737D), purple (#3D2F68)",
      "9. **Lime & Plum**: Lime (#C5DE82), plum (#7C3A5F), coral (#FD8C6E), blue-gray (#98ACB5)",
      "10. **Black & Gold**: Gold (#BF9A4A), black (#000000), cream (#F4F6F6)",
      "11. **Sage & Terracotta**: Sage (#87A96B), terracotta (#E07A5F), cream (#F4F1DE), charcoal (#2C2C2C)",
      "12. **Charcoal & Red**: Charcoal (#292929), red (#E33737), light gray (#CCCBCB)",
      "13. **Vibrant Orange**: Orange (#F96D00), light gray (#F2F2F2), charcoal (#222831)",
      "14. **Forest Green**: Black (#191A19), green (#4E9F3D), dark green (#1E5128), white (#FFFFFF)",
      "15. **Retro Rainbow**: Purple (#722880), pink (#D72D51), orange (#EB5C18), amber (#F08800), gold (#DEB600)",
      "16. **Vintage Earthy**: Mustard (#E3B448), sage (#CBD18F), forest green (#3A6B35), cream (#F4F1DE)",
      "17. **Coastal Rose**: Old rose (#AD7670), beaver (#B49886), eggshell (#F3ECDC), ash gray (#BFD5BE)",
      "18. **Orange & Turquoise**: Light orange (#FC993E), grayish turquoise (#667C6F), white (#FCFCFC)",
      "",
      "#### Visual Details Options",
      "",
      "**Geometric Patterns**:",
      "- Diagonal section dividers instead of horizontal",
      "- Asymmetric column widths (30/70, 40/60, 25/75)",
      "- Rotated text headers at 90° or 270°",
      "- Circular/hexagonal frames for images",
      "- Triangular accent shapes in corners",
      "- Overlapping shapes for depth",
      "",
      "**Border & Frame Treatments**:",
      "- Thick single-color borders (10-20pt) on one side only",
      "- Double-line borders with contrasting colors",
      "- Corner brackets instead of full frames",
      "- L-shaped borders (top+left or bottom+right)",
      "- Underline accents beneath headers (3-5pt thick)",
      "",
      "**Typography Treatments**:",
      "- Extreme size contrast (72pt headlines vs 11pt body)",
      "- All-caps headers with wide letter spacing",
      "- Numbered sections in oversized display type",
      "- Monospace (Courier New) for data/stats/technical content",
      "- Condensed fonts (Arial Narrow) for dense information",
      "- Outlined text for emphasis",
      "",
      "**Chart & Data Styling**:",
      "- Monochrome charts with single accent color for key data",
      "- Horizontal bar charts instead of vertical",
      "- Dot plots instead of bar charts",
      "- Minimal gridlines or none at all",
      "- Data labels directly on elements (no legends)",
      "- Oversized numbers for key metrics",
      "",
      "**Layout Innovations**:",
      "- Full-bleed images with text overlays",
      "- Sidebar column (20-30% width) for navigation/context",
      "- Modular grid systems (3×3, 4×4 blocks)",
      "- Z-pattern or F-pattern content flow",
      "- Floating text boxes over colored shapes",
      "- Magazine-style multi-column layouts",
      "",
      "**Background Treatments**:",
      "- Solid color blocks occupying 40-60% of slide",
      "- Gradient fills (vertical or diagonal only)",
      "- Split backgrounds (two colors, diagonal or vertical)",
      "- Edge-to-edge color bands",
      "- Negative space as a design element",
      "",
      "### Layout Tips",
      "**When creating slides with charts or tables:**",
      "- **Two-column layout (PREFERRED)**: Use a header spanning the full width, then two columns below - text/bullets in one column and the featured content in the other. This provides better balance and makes charts/tables more readable. Use flexbox with unequal column widths (e.g., 40%/60% split) to optimize space for each content type.",
      "- **Full-slide layout**: Let the featured content (chart/table) take up the entire slide for maximum impact and readability",
      "- **NEVER vertically stack**: Do not place charts/tables below text in a single column - this causes poor readability and layout issues",
      "",
      "### Workflow",
      "1. **MANDATORY - READ ENTIRE FILE**: Read [`html2pptx.md`](html2pptx.md) completely from start to finish. **NEVER set any range limits when reading this file.** Read the full file content for detailed syntax, critical formatting rules, and best practices before proceeding with presentation creation.",
      "2. Create an HTML file for each slide with proper dimensions (e.g., 720pt × 405pt for 16:9)",
      "   - Use `<p>`, `<h1>`-`<h6>`, `<ul>`, `<ol>` for all text content",
      '   - Use `class="placeholder"` for areas where charts/tables will be added (render with gray background for visibility)',
      "   - **CRITICAL**: Rasterize gradients and icons as PNG images FIRST using Sharp, then reference in HTML",
      "   - **LAYOUT**: For slides with charts/tables/images, use either full-slide layout or two-column layout for better readability",
      "3. Create and run a JavaScript file using the [`html2pptx.js`](scripts/html2pptx.js) library to convert HTML slides to PowerPoint and save the presentation",
      "   - Use the `html2pptx()` function to process each HTML file",
      "   - Add charts and tables to placeholder areas using PptxGenJS API",
      "   - Save the presentation using `pptx.writeFile()`",
      "4. **Visual validation**: Generate thumbnails and inspect for layout issues",
      "   - Create thumbnail grid: `python scripts/thumbnail.py output.pptx workspace/thumbnails --cols 4`",
      "   - Read and carefully examine the thumbnail image for:",
      "     - **Text cutoff**: Text being cut off by header bars, shapes, or slide edges",
      "     - **Text overlap**: Text overlapping with other text or shapes",
      "     - **Positioning issues**: Content too close to slide boundaries or other elements",
      "     - **Contrast issues**: Insufficient contrast between text and backgrounds",
      "   - If issues found, adjust HTML margins/spacing/colors and regenerate the presentation",
      "   - Repeat until all slides are visually correct",
      "",
      "## Editing an existing PowerPoint presentation",
      "",
      "When edit slides in an existing PowerPoint presentation, you need to work with the raw Office Open XML (OOXML) format. This involves unpacking the .pptx file, editing the XML content, and repacking it.",
      "",
      "### Workflow",
      "1. **MANDATORY - READ ENTIRE FILE**: Read [`ooxml.md`](ooxml.md) (~500 lines) completely from start to finish.  **NEVER set any range limits when reading this file.**  Read the full file content for detailed guidance on OOXML structure and editing workflows before any presentation editing.",
      "2. Unpack the presentation: `python ooxml/scripts/unpack.py <office_file> <output_dir>`",
      "3. Edit the XML files (primarily `ppt/slides/slide{N}.xml` and related files)",
      "4. **CRITICAL**: Validate immediately after each edit and fix any validation errors before proceeding: `python ooxml/scripts/validate.py <dir> --original <file>`",
      "5. Pack the final presentation: `python ooxml/scripts/pack.py <input_directory> <office_file>`",
      "",
      "## Creating a new PowerPoint presentation **using a template**",
      "",
      "When you need to create a presentation that follows an existing template's design, you'll need to duplicate and re-arrange template slides before then replacing placeholder context.",
      "",
      "### Workflow",
      "1. **Extract template text AND create visual thumbnail grid**:",
      "   * Extract text: `python -m markitdown template.pptx > template-content.md`",
      "   * Read `template-content.md`: Read the entire file to understand the contents of the template presentation. **NEVER set any range limits when reading this file.**",
      "   * Create thumbnail grids: `python scripts/thumbnail.py template.pptx`",
      "   * See [Creating Thumbnail Grids](#creating-thumbnail-grids) section for more details",
      "",
      "2. **Analyze template and save inventory to a file**:",
      "   * **Visual Analysis**: Review thumbnail grid(s) to understand slide layouts, design patterns, and visual structure",
      "   * Create and save a template inventory file at `template-inventory.md` containing:",
      "     ```markdown",
      "     # Template Inventory Analysis",
      "     **Total Slides: [count]**",
      "     **IMPORTANT: Slides are 0-indexed (first slide = 0, last slide = count-1)**",
      "",
      "     ## [Category Name]",
      "     - Slide 0: [Layout code if available] - Description/purpose",
      "     - Slide 1: [Layout code] - Description/purpose",
      "     - Slide 2: [Layout code] - Description/purpose",
      "     [... EVERY slide must be listed individually with its index ...]",
      "     ```",
      "   * **Using the thumbnail grid**: Reference the visual thumbnails to identify:",
      "     - Layout patterns (title slides, content layouts, section dividers)",
      "     - Image placeholder locations and counts",
      "     - Design consistency across slide groups",
      "     - Visual hierarchy and structure",
      "   * This inventory file is REQUIRED for selecting appropriate templates in the next step",
      "",
      "3. **Create presentation outline based on template inventory**:",
      "   * Review available templates from step 2.",
      "   * Choose an intro or title template for the first slide. This should be one of the first templates.",
      "   * Choose safe, text-based layouts for the other slides.",
      "   * **CRITICAL: Match layout structure to actual content**:",
      "     - Single-column layouts: Use for unified narrative or single topic",
      "     - Two-column layouts: Use ONLY when you have exactly 2 distinct items/concepts",
      "     - Three-column layouts: Use ONLY when you have exactly 3 distinct items/concepts",
      "     - Image + text layouts: Use ONLY when you have actual images to insert",
      "     - Quote layouts: Use ONLY for actual quotes from people (with attribution), never for emphasis",
      "     - Never use layouts with more placeholders than you have content",
      "     - If you have 2 items, don't force them into a 3-column layout",
      "     - If you have 4+ items, consider breaking into multiple slides or using a list format",
      "   * Count your actual content pieces BEFORE selecting the layout",
      "   * Verify each placeholder in the chosen layout will be filled with meaningful content",
      "   * Select one option representing the **best** layout for each content section.",
      "   * Save `outline.md` with content AND template mapping that leverages available designs",
      "   * Example template mapping:",
      "      ```",
      "      # Template slides to use (0-based indexing)",
      "      # WARNING: Verify indices are within range! Template with 73 slides has indices 0-72",
      "      # Mapping: slide numbers from outline -> template slide indices",
      "      template_mapping = [",
      "          0,   # Use slide 0 (Title/Cover)",
      "          34,  # Use slide 34 (B1: Title and body)",
      "          34,  # Use slide 34 again (duplicate for second B1)",
      "          50,  # Use slide 50 (E1: Quote)",
      "          54,  # Use slide 54 (F2: Closing + Text)",
      "      ]",
      "      ```",
      "",
      "4. **Duplicate, reorder, and delete slides using `rearrange.py`**:",
      "   * Use the `scripts/rearrange.py` script to create a new presentation with slides in the desired order:",
      "     ```bash",
      "     python scripts/rearrange.py template.pptx working.pptx 0,34,34,50,52",
      "     ```",
      "   * The script handles duplicating repeated slides, deleting unused slides, and reordering automatically",
      "   * Slide indices are 0-based (first slide is 0, second is 1, etc.)",
      "   * The same slide index can appear multiple times to duplicate that slide",
      "",
      "5. **Extract ALL text using the `inventory.py` script**:",
      "   * **Run inventory extraction**:",
      "     ```bash",
      "     python scripts/inventory.py working.pptx text-inventory.json",
      "     ```",
      "   * **Read text-inventory.json**: Read the entire text-inventory.json file to understand all shapes and their properties. **NEVER set any range limits when reading this file.**",
      "",
      "   * The inventory JSON structure:",
      "      ```json",
      "        {",
      '          "slide-0": {',
      '            "shape-0": {',
      '              "placeholder_type": "TITLE",  // or null for non-placeholders',
      '              "left": 1.5,                  // position in inches',
      '              "top": 2.0,',
      '              "width": 7.5,',
      '              "height": 1.2,',
      '              "paragraphs": [',
      "                {",
      '                  "text": "Paragraph text",',
      "                  // Optional properties (only included when non-default):",
      '                  "bullet": true,           // explicit bullet detected',
      '                  "level": 0,               // only included when bullet is true',
      '                  "alignment": "CENTER",    // CENTER, RIGHT (not LEFT)',
      '                  "space_before": 10.0,     // space before paragraph in points',
      '                  "space_after": 6.0,       // space after paragraph in points',
      '                  "line_spacing": 22.4,     // line spacing in points',
      '                  "font_name": "Arial",     // from first run',
      '                  "font_size": 14.0,        // in points',
      '                  "bold": true,',
      '                  "italic": false,',
      '                  "underline": false,',
      '                  "color": "FF0000"         // RGB color',
      "                }",
      "              ]",
      "            }",
      "          }",
      "        }",
      "      ```",
      "",
      "   * Key features:",
      '     - **Slides**: Named as "slide-0", "slide-1", etc.',
      '     - **Shapes**: Ordered by visual position (top-to-bottom, left-to-right) as "shape-0", "shape-1", etc.',
      "     - **Placeholder types**: TITLE, CENTER_TITLE, SUBTITLE, BODY, OBJECT, or null",
      "     - **Default font size**: `default_font_size` in points extracted from layout placeholders (when available)",
      "     - **Slide numbers are filtered**: Shapes with SLIDE_NUMBER placeholder type are automatically excluded from inventory",
      "     - **Bullets**: When `bullet: true`, `level` is always included (even if 0)",
      "     - **Spacing**: `space_before`, `space_after`, and `line_spacing` in points (only included when set)",
      '     - **Colors**: `color` for RGB (e.g., "FF0000"), `theme_color` for theme colors (e.g., "DARK_1")',
      "     - **Properties**: Only non-default values are included in the output",
      "",
      "6. **Generate replacement text and save the data to a JSON file**",
      "   Based on the text inventory from the previous step:",
      "   - **CRITICAL**: First verify which shapes exist in the inventory - only reference shapes that are actually present",
      "   - **VALIDATION**: The replace.py script will validate that all shapes in your replacement JSON exist in the inventory",
      "     - If you reference a non-existent shape, you'll get an error showing available shapes",
      "     - If you reference a non-existent slide, you'll get an error indicating the slide doesn't exist",
      "     - All validation errors are shown at once before the script exits",
      "   - **IMPORTANT**: The replace.py script uses inventory.py internally to identify ALL text shapes",
      '   - **AUTOMATIC CLEARING**: ALL text shapes from the inventory will be cleared unless you provide "paragraphs" for them',
      '   - Add a "paragraphs" field to shapes that need content (not "replacement_paragraphs")',
      '   - Shapes without "paragraphs" in the replacement JSON will have their text cleared automatically',
      '   - Paragraphs with bullets will be automatically left aligned. Don\'t set the `alignment` property on when `"bullet": true`',
      "   - Generate appropriate replacement content for placeholder text",
      "   - Use shape size to determine appropriate content length",
      "   - **CRITICAL**: Include paragraph properties from the original inventory - don't just provide text",
      "   - **IMPORTANT**: When bullet: true, do NOT include bullet symbols (•, -, *) in text - they're added automatically",
      "   - **ESSENTIAL FORMATTING RULES**:",
      '     - Headers/titles should typically have `"bold": true`',
      '     - List items should have `"bullet": true, "level": 0` (level is required when bullet is true)',
      '     - Preserve any alignment properties (e.g., `"alignment": "CENTER"` for centered text)',
      '     - Include font properties when different from default (e.g., `"font_size": 14.0`, `"font_name": "Lora"`)',
      '     - Colors: Use `"color": "FF0000"` for RGB or `"theme_color": "DARK_1"` for theme colors',
      "     - The replacement script expects **properly formatted paragraphs**, not just text strings",
      "     - **Overlapping shapes**: Prefer shapes with larger default_font_size or more appropriate placeholder_type",
      "   - Save the updated inventory with replacements to `replacement-text.json`",
      "   - **WARNING**: Different template layouts have different shape counts - always check the actual inventory before creating replacements",
      "",
      "   Example paragraphs field showing proper formatting:",
      "   ```json",
      '   "paragraphs": [',
      "     {",
      '       "text": "New presentation title text",',
      '       "alignment": "CENTER",',
      '       "bold": true',
      "     },",
      "     {",
      '       "text": "Section Header",',
      '       "bold": true',
      "     },",
      "     {",
      '       "text": "First bullet point without bullet symbol",',
      '       "bullet": true,',
      '       "level": 0',
      "     },",
      "     {",
      '       "text": "Red colored text",',
      '       "color": "FF0000"',
      "     },",
      "     {",
      '       "text": "Theme colored text",',
      '       "theme_color": "DARK_1"',
      "     },",
      "     {",
      '       "text": "Regular paragraph text without special formatting"',
      "     }",
      "   ]",
      "   ```",
      "",
      "   **Shapes not listed in the replacement JSON are automatically cleared**:",
      "   ```json",
      "   {",
      '     "slide-0": {',
      '       "shape-0": {',
      '         "paragraphs": [...] // This shape gets new text',
      "       }",
      "       // shape-1 and shape-2 from inventory will be cleared automatically",
      "     }",
      "   }",
      "   ```",
      "",
      "   **Common formatting patterns for presentations**:",
      "   - Title slides: Bold text, sometimes centered",
      "   - Section headers within slides: Bold text",
      '   - Bullet lists: Each item needs `"bullet": true, "level": 0`',
      "   - Body text: Usually no special properties needed",
      "   - Quotes: May have special alignment or font properties",
      "",
      "7. **Apply replacements using the `replace.py` script**",
      "   ```bash",
      "   python scripts/replace.py working.pptx replacement-text.json output.pptx",
      "   ```",
      "",
      "   The script will:",
      "   - First extract the inventory of ALL text shapes using functions from inventory.py",
      "   - Validate that all shapes in the replacement JSON exist in the inventory",
      "   - Clear text from ALL shapes identified in the inventory",
      '   - Apply new text only to shapes with "paragraphs" defined in the replacement JSON',
      "   - Preserve formatting by applying paragraph properties from the JSON",
      "   - Handle bullets, alignment, font properties, and colors automatically",
      "   - Save the updated presentation",
      "",
      "   Example validation errors:",
      "   ```",
      "   ERROR: Invalid shapes in replacement JSON:",
      "     - Shape 'shape-99' not found on 'slide-0'. Available shapes: shape-0, shape-1, shape-4",
      "     - Slide 'slide-999' not found in inventory",
      "   ```",
      "",
      "   ```",
      "   ERROR: Replacement text made overflow worse in these shapes:",
      '     - slide-0/shape-2: overflow worsened by 1.25" (was 0.00", now 1.25")',
      "   ```",
      "",
      "## Creating Thumbnail Grids",
      "",
      "To create visual thumbnail grids of PowerPoint slides for quick analysis and reference:",
      "",
      "```bash",
      "python scripts/thumbnail.py template.pptx [output_prefix]",
      "```",
      "",
      "**Features**:",
      "- Creates: `thumbnails.jpg` (or `thumbnails-1.jpg`, `thumbnails-2.jpg`, etc. for large decks)",
      "- Default: 5 columns, max 30 slides per grid (5×6)",
      "- Custom prefix: `python scripts/thumbnail.py template.pptx my-grid`",
      "  - Note: The output prefix should include the path if you want output in a specific directory (e.g., `workspace/my-grid`)",
      "- Adjust columns: `--cols 4` (range: 3-6, affects slides per grid)",
      "- Grid limits: 3 cols = 12 slides/grid, 4 cols = 20, 5 cols = 30, 6 cols = 42",
      "- Slides are zero-indexed (Slide 0, Slide 1, etc.)",
      "",
      "**Use cases**:",
      "- Template analysis: Quickly understand slide layouts and design patterns",
      "- Content review: Visual overview of entire presentation",
      "- Navigation reference: Find specific slides by their visual appearance",
      "- Quality check: Verify all slides are properly formatted",
      "",
      "**Examples**:",
      "```bash",
      "# Basic usage",
      "python scripts/thumbnail.py presentation.pptx",
      "",
      "# Combine options: custom name, columns",
      "python scripts/thumbnail.py template.pptx analysis --cols 4",
      "```",
      "",
      "## Converting Slides to Images",
      "",
      "To visually analyze PowerPoint slides, convert them to images using a two-step process:",
      "",
      "1. **Convert PPTX to PDF**:",
      "   ```bash",
      "   soffice --headless --convert-to pdf template.pptx",
      "   ```",
      "",
      "2. **Convert PDF pages to JPEG images**:",
      "   ```bash",
      "   pdftoppm -jpeg -r 150 template.pdf slide",
      "   ```",
      "   This creates files like `slide-1.jpg`, `slide-2.jpg`, etc.",
      "",
      "Options:",
      "- `-r 150`: Sets resolution to 150 DPI (adjust for quality/size balance)",
      "- `-jpeg`: Output JPEG format (use `-png` for PNG if preferred)",
      "- `-f N`: First page to convert (e.g., `-f 2` starts from page 2)",
      "- `-l N`: Last page to convert (e.g., `-l 5` stops at page 5)",
      "- `slide`: Prefix for output files",
      "",
      "Example for specific range:",
      "```bash",
      "pdftoppm -jpeg -r 150 -f 2 -l 5 template.pdf slide  # Converts only pages 2-5",
      "```",
      "",
      "## Code Style Guidelines",
      "**IMPORTANT**: When generating code for PPTX operations:",
      "- Write concise code",
      "- Avoid verbose variable names and redundant operations",
      "- Avoid unnecessary print statements",
      "",
      "## Dependencies",
      "",
      "Required dependencies (should already be installed):",
      "",
      '- **markitdown**: `pip install "markitdown[pptx]"` (for text extraction from presentations)',
      "- **pptxgenjs**: `npm install -g pptxgenjs` (for creating presentations via html2pptx)",
      "- **playwright**: `npm install -g playwright` (for HTML rendering in html2pptx)",
      "- **react-icons**: `npm install -g react-icons react react-dom` (for icons)",
      "- **sharp**: `npm install -g sharp` (for SVG rasterization and image processing)",
      "- **LibreOffice**: `sudo apt-get install libreoffice` (for PDF conversion)",
      "- **Poppler**: `sudo apt-get install poppler-utils` (for pdftoppm to convert PDF to images)",
      "- **defusedxml**: `pip install defusedxml` (for secure XML parsing)",
    ].join("\n"),
  },
  "skill-creator": {
    "SKILL.md": [
      "---",
      "name: skill-creator",
      "description: Guide for creating effective skills. This skill should be used when users want to create a new skill (or update an existing skill) that extends Claude's capabilities with specialized knowledge, workflows, or tool integrations.",
      "license: Complete terms in LICENSE.txt",
      "---",
      "",
      "# Skill Creator",
      "",
      "This skill provides guidance for creating effective skills.",
      "",
      "## About Skills",
      "",
      "Skills are modular, self-contained packages that extend Claude's capabilities by providing",
      'specialized knowledge, workflows, and tools. Think of them as "onboarding guides" for specific',
      "domains or tasks—they transform Claude from a general-purpose agent into a specialized agent",
      "equipped with procedural knowledge that no model can fully possess.",
      "",
      "### What Skills Provide",
      "",
      "1. Specialized workflows - Multi-step procedures for specific domains",
      "2. Tool integrations - Instructions for working with specific file formats or APIs",
      "3. Domain expertise - Company-specific knowledge, schemas, business logic",
      "4. Bundled resources - Scripts, references, and assets for complex and repetitive tasks",
      "",
      "## Core Principles",
      "",
      "### Concise is Key",
      "",
      "The context window is a public good. Skills share the context window with everything else Claude needs: system prompt, conversation history, other Skills' metadata, and the actual user request.",
      "",
      '**Default assumption: Claude is already very smart.** Only add context Claude doesn\'t already have. Challenge each piece of information: "Does Claude really need this explanation?" and "Does this paragraph justify its token cost?"',
      "",
      "Prefer concise examples over verbose explanations.",
      "",
      "### Set Appropriate Degrees of Freedom",
      "",
      "Match the level of specificity to the task's fragility and variability:",
      "",
      "**High freedom (text-based instructions)**: Use when multiple approaches are valid, decisions depend on context, or heuristics guide the approach.",
      "",
      "**Medium freedom (pseudocode or scripts with parameters)**: Use when a preferred pattern exists, some variation is acceptable, or configuration affects behavior.",
      "",
      "**Low freedom (specific scripts, few parameters)**: Use when operations are fragile and error-prone, consistency is critical, or a specific sequence must be followed.",
      "",
      "Think of Claude as exploring a path: a narrow bridge with cliffs needs specific guardrails (low freedom), while an open field allows many routes (high freedom).",
      "",
      "### Anatomy of a Skill",
      "",
      "Every skill consists of a required SKILL.md file and optional bundled resources:",
      "",
      "```",
      "skill-name/",
      "├── SKILL.md (required)",
      "│   ├── YAML frontmatter metadata (required)",
      "│   │   ├── name: (required)",
      "│   │   └── description: (required)",
      "│   └── Markdown instructions (required)",
      "└── Bundled Resources (optional)",
      "    ├── scripts/          - Executable code (Python/Bash/etc.)",
      "    ├── references/       - Documentation intended to be loaded into context as needed",
      "    └── assets/           - Files used in output (templates, icons, fonts, etc.)",
      "```",
      "",
      "#### SKILL.md (required)",
      "",
      "Every SKILL.md consists of:",
      "",
      "- **Frontmatter** (YAML): Contains `name` and `description` fields. These are the only fields that Claude reads to determine when the skill gets used, thus it is very important to be clear and comprehensive in describing what the skill is, and when it should be used.",
      "- **Body** (Markdown): Instructions and guidance for using the skill. Only loaded AFTER the skill triggers (if at all).",
      "",
      "#### Bundled Resources (optional)",
      "",
      "##### Scripts (`scripts/`)",
      "",
      "Executable code (Python/Bash/etc.) for tasks that require deterministic reliability or are repeatedly rewritten.",
      "",
      "- **When to include**: When the same code is being rewritten repeatedly or deterministic reliability is needed",
      "- **Example**: `scripts/rotate_pdf.py` for PDF rotation tasks",
      "- **Benefits**: Token efficient, deterministic, may be executed without loading into context",
      "- **Note**: Scripts may still need to be read by Claude for patching or environment-specific adjustments",
      "",
      "##### References (`references/`)",
      "",
      "Documentation and reference material intended to be loaded as needed into context to inform Claude's process and thinking.",
      "",
      "- **When to include**: For documentation that Claude should reference while working",
      "- **Examples**: `references/finance.md` for financial schemas, `references/mnda.md` for company NDA template, `references/policies.md` for company policies, `references/api_docs.md` for API specifications",
      "- **Use cases**: Database schemas, API documentation, domain knowledge, company policies, detailed workflow guides",
      "- **Benefits**: Keeps SKILL.md lean, loaded only when Claude determines it's needed",
      "- **Best practice**: If files are large (>10k words), include grep search patterns in SKILL.md",
      "- **Avoid duplication**: Information should live in either SKILL.md or references files, not both. Prefer references files for detailed information unless it's truly core to the skill—this keeps SKILL.md lean while making information discoverable without hogging the context window. Keep only essential procedural instructions and workflow guidance in SKILL.md; move detailed reference material, schemas, and examples to references files.",
      "",
      "##### Assets (`assets/`)",
      "",
      "Files not intended to be loaded into context, but rather used within the output Claude produces.",
      "",
      "- **When to include**: When the skill needs files that will be used in the final output",
      "- **Examples**: `assets/logo.png` for brand assets, `assets/slides.pptx` for PowerPoint templates, `assets/frontend-template/` for HTML/React boilerplate, `assets/font.ttf` for typography",
      "- **Use cases**: Templates, images, icons, boilerplate code, fonts, sample documents that get copied or modified",
      "- **Benefits**: Separates output resources from documentation, enables Claude to use files without loading them into context",
      "",
      "#### What to Not Include in a Skill",
      "",
      "A skill should only contain essential files that directly support its functionality. Do NOT create extraneous documentation or auxiliary files, including:",
      "",
      "- README.md",
      "- INSTALLATION_GUIDE.md",
      "- QUICK_REFERENCE.md",
      "- CHANGELOG.md",
      "- etc.",
      "",
      "The skill should only contain the information needed for an AI agent to do the job at hand. It should not contain auxilary context about the process that went into creating it, setup and testing procedures, user-facing documentation, etc. Creating additional documentation files just adds clutter and confusion.",
      "",
      "### Progressive Disclosure Design Principle",
      "",
      "Skills use a three-level loading system to manage context efficiently:",
      "",
      "1. **Metadata (name + description)** - Always in context (~100 words)",
      "2. **SKILL.md body** - When skill triggers (<5k words)",
      "3. **Bundled resources** - As needed by Claude (Unlimited because scripts can be executed without reading into context window)",
      "",
      "#### Progressive Disclosure Patterns",
      "",
      "Keep SKILL.md body to the essentials and under 500 lines to minimize context bloat. Split content into separate files when approaching this limit. When splitting out content into other files, it is very important to reference them from SKILL.md and describe clearly when to read them, to ensure the reader of the skill knows they exist and when to use them.",
      "",
      "**Key principle:** When a skill supports multiple variations, frameworks, or options, keep only the core workflow and selection guidance in SKILL.md. Move variant-specific details (patterns, examples, configuration) into separate reference files.",
      "",
      "**Pattern 1: High-level guide with references**",
      "",
      "```markdown",
      "# PDF Processing",
      "",
      "## Quick start",
      "",
      "Extract text with pdfplumber:",
      "[code example]",
      "",
      "## Advanced features",
      "",
      "- **Form filling**: See [FORMS.md](FORMS.md) for complete guide",
      "- **API reference**: See [REFERENCE.md](REFERENCE.md) for all methods",
      "- **Examples**: See [EXAMPLES.md](EXAMPLES.md) for common patterns",
      "```",
      "",
      "Claude loads FORMS.md, REFERENCE.md, or EXAMPLES.md only when needed.",
      "",
      "**Pattern 2: Domain-specific organization**",
      "",
      "For Skills with multiple domains, organize content by domain to avoid loading irrelevant context:",
      "",
      "```",
      "bigquery-skill/",
      "├── SKILL.md (overview and navigation)",
      "└── reference/",
      "    ├── finance.md (revenue, billing metrics)",
      "    ├── sales.md (opportunities, pipeline)",
      "    ├── product.md (API usage, features)",
      "    └── marketing.md (campaigns, attribution)",
      "```",
      "",
      "When a user asks about sales metrics, Claude only reads sales.md.",
      "",
      "Similarly, for skills supporting multiple frameworks or variants, organize by variant:",
      "",
      "```",
      "cloud-deploy/",
      "├── SKILL.md (workflow + provider selection)",
      "└── references/",
      "    ├── aws.md (AWS deployment patterns)",
      "    ├── gcp.md (GCP deployment patterns)",
      "    └── azure.md (Azure deployment patterns)",
      "```",
      "",
      "When the user chooses AWS, Claude only reads aws.md.",
      "",
      "**Pattern 3: Conditional details**",
      "",
      "Show basic content, link to advanced content:",
      "",
      "```markdown",
      "# DOCX Processing",
      "",
      "## Creating documents",
      "",
      "Use docx-js for new documents. See [DOCX-JS.md](DOCX-JS.md).",
      "",
      "## Editing documents",
      "",
      "For simple edits, modify the XML directly.",
      "",
      "**For tracked changes**: See [REDLINING.md](REDLINING.md)",
      "**For OOXML details**: See [OOXML.md](OOXML.md)",
      "```",
      "",
      "Claude reads REDLINING.md or OOXML.md only when the user needs those features.",
      "",
      "**Important guidelines:**",
      "",
      "- **Avoid deeply nested references** - Keep references one level deep from SKILL.md. All reference files should link directly from SKILL.md.",
      "- **Structure longer reference files** - For files longer than 100 lines, include a table of contents at the top so Claude can see the full scope when previewing.",
      "",
      "## Skill Creation Process",
      "",
      "Skill creation involves these steps:",
      "",
      "1. Understand the skill with concrete examples",
      "2. Plan reusable skill contents (scripts, references, assets)",
      "3. Initialize the skill (run init_skill.py)",
      "4. Edit the skill (implement resources and write SKILL.md)",
      "5. Package the skill (run package_skill.py)",
      "6. Iterate based on real usage",
      "",
      "Follow these steps in order, skipping only if there is a clear reason why they are not applicable.",
      "",
      "### Step 1: Understanding the Skill with Concrete Examples",
      "",
      "Skip this step only when the skill's usage patterns are already clearly understood. It remains valuable even when working with an existing skill.",
      "",
      "To create an effective skill, clearly understand concrete examples of how the skill will be used. This understanding can come from either direct user examples or generated examples that are validated with user feedback.",
      "",
      "For example, when building an image-editor skill, relevant questions include:",
      "",
      '- "What functionality should the image-editor skill support? Editing, rotating, anything else?"',
      '- "Can you give some examples of how this skill would be used?"',
      "- \"I can imagine users asking for things like 'Remove the red-eye from this image' or 'Rotate this image'. Are there other ways you imagine this skill being used?\"",
      '- "What would a user say that should trigger this skill?"',
      "",
      "To avoid overwhelming users, avoid asking too many questions in a single message. Start with the most important questions and follow up as needed for better effectiveness.",
      "",
      "Conclude this step when there is a clear sense of the functionality the skill should support.",
      "",
      "### Step 2: Planning the Reusable Skill Contents",
      "",
      "To turn concrete examples into an effective skill, analyze each example by:",
      "",
      "1. Considering how to execute on the example from scratch",
      "2. Identifying what scripts, references, and assets would be helpful when executing these workflows repeatedly",
      "",
      'Example: When building a `pdf-editor` skill to handle queries like "Help me rotate this PDF," the analysis shows:',
      "",
      "1. Rotating a PDF requires re-writing the same code each time",
      "2. A `scripts/rotate_pdf.py` script would be helpful to store in the skill",
      "",
      'Example: When designing a `frontend-webapp-builder` skill for queries like "Build me a todo app" or "Build me a dashboard to track my steps," the analysis shows:',
      "",
      "1. Writing a frontend webapp requires the same boilerplate HTML/React each time",
      "2. An `assets/hello-world/` template containing the boilerplate HTML/React project files would be helpful to store in the skill",
      "",
      'Example: When building a `big-query` skill to handle queries like "How many users have logged in today?" the analysis shows:',
      "",
      "1. Querying BigQuery requires re-discovering the table schemas and relationships each time",
      "2. A `references/schema.md` file documenting the table schemas would be helpful to store in the skill",
      "",
      "To establish the skill's contents, analyze each concrete example to create a list of the reusable resources to include: scripts, references, and assets.",
      "",
      "### Step 3: Initializing the Skill",
      "",
      "At this point, it is time to actually create the skill.",
      "",
      "Skip this step only if the skill being developed already exists, and iteration or packaging is needed. In this case, continue to the next step.",
      "",
      "When creating a new skill from scratch, always run the `init_skill.py` script. The script conveniently generates a new template skill directory that automatically includes everything a skill requires, making the skill creation process much more efficient and reliable.",
      "",
      "Usage:",
      "",
      "```bash",
      "scripts/init_skill.py <skill-name> --path <output-directory>",
      "```",
      "",
      "The script:",
      "",
      "- Creates the skill directory at the specified path",
      "- Generates a SKILL.md template with proper frontmatter and TODO placeholders",
      "- Creates example resource directories: `scripts/`, `references/`, and `assets/`",
      "- Adds example files in each directory that can be customized or deleted",
      "",
      "After initialization, customize or remove the generated SKILL.md and example files as needed.",
      "",
      "### Step 4: Edit the Skill",
      "",
      "When editing the (newly-generated or existing) skill, remember that the skill is being created for another instance of Claude to use. Include information that would be beneficial and non-obvious to Claude. Consider what procedural knowledge, domain-specific details, or reusable assets would help another Claude instance execute these tasks more effectively.",
      "",
      "#### Learn Proven Design Patterns",
      "",
      "Consult these helpful guides based on your skill's needs:",
      "",
      "- **Multi-step processes**: See references/workflows.md for sequential workflows and conditional logic",
      "- **Specific output formats or quality standards**: See references/output-patterns.md for template and example patterns",
      "",
      "These files contain established best practices for effective skill design.",
      "",
      "#### Start with Reusable Skill Contents",
      "",
      "To begin implementation, start with the reusable resources identified above: `scripts/`, `references/`, and `assets/` files. Note that this step may require user input. For example, when implementing a `brand-guidelines` skill, the user may need to provide brand assets or templates to store in `assets/`, or documentation to store in `references/`.",
      "",
      "Added scripts must be tested by actually running them to ensure there are no bugs and that the output matches what is expected. If there are many similar scripts, only a representative sample needs to be tested to ensure confidence that they all work while balancing time to completion.",
      "",
      "Any example files and directories not needed for the skill should be deleted. The initialization script creates example files in `scripts/`, `references/`, and `assets/` to demonstrate structure, but most skills won't need all of them.",
      "",
      "#### Update SKILL.md",
      "",
      "**Writing Guidelines:** Always use imperative/infinitive form.",
      "",
      "##### Frontmatter",
      "",
      "Write the YAML frontmatter with `name` and `description`:",
      "",
      "- `name`: The skill name",
      "- `description`: This is the primary triggering mechanism for your skill, and helps Claude understand when to use the skill.",
      "  - Include both what the Skill does and specific triggers/contexts for when to use it.",
      '  - Include all "when to use" information here - Not in the body. The body is only loaded after triggering, so "When to Use This Skill" sections in the body are not helpful to Claude.',
      '  - Example description for a `docx` skill: "Comprehensive document creation, editing, and analysis with support for tracked changes, comments, formatting preservation, and text extraction. Use when Claude needs to work with professional documents (.docx files) for: (1) Creating new documents, (2) Modifying or editing content, (3) Working with tracked changes, (4) Adding comments, or any other document tasks"',
      "",
      "Do not include any other fields in YAML frontmatter.",
      "",
      "##### Body",
      "",
      "Write instructions for using the skill and its bundled resources.",
      "",
      "### Step 5: Packaging a Skill",
      "",
      "Once development of the skill is complete, it must be packaged into a distributable .skill file that gets shared with the user. The packaging process automatically validates the skill first to ensure it meets all requirements:",
      "",
      "```bash",
      "scripts/package_skill.py <path/to/skill-folder>",
      "```",
      "",
      "Optional output directory specification:",
      "",
      "```bash",
      "scripts/package_skill.py <path/to/skill-folder> ./dist",
      "```",
      "",
      "The packaging script will:",
      "",
      "1. **Validate** the skill automatically, checking:",
      "",
      "   - YAML frontmatter format and required fields",
      "   - Skill naming conventions and directory structure",
      "   - Description completeness and quality",
      "   - File organization and resource references",
      "",
      "2. **Package** the skill if validation passes, creating a .skill file named after the skill (e.g., `my-skill.skill`) that includes all files and maintains the proper directory structure for distribution. The .skill file is a zip file with a .skill extension.",
      "",
      "If validation fails, the script will report the errors and exit without creating a package. Fix any validation errors and run the packaging command again.",
      "",
      "### Step 6: Iterate",
      "",
      "After testing the skill, users may request improvements. Often this happens right after using the skill, with fresh context of how the skill performed.",
      "",
      "**Iteration workflow:**",
      "",
      "1. Use the skill on real tasks",
      "2. Notice struggles or inefficiencies",
      "3. Identify how SKILL.md or bundled resources should be updated",
      "4. Implement changes and test again",
      "",
    ].join("\n"),
  },
  "unix-docs": {
    "SKILL.md": [
      "---",
      "name: unix-docs",
      "description: Index + offline snapshot of unix documentation (progressive disclosure).",
      "---",
      "",
      "# unix docs",
      "",
      "This built-in skill helps the agent answer questions about **unix** (Coding Agent Multiplexer) without dumping the entire docs into context.",
      "",
      "## How to use",
      "",
      "### Prefer: read the bundled docs snapshot (recommended)",
      "",
      "This skill bundles an **offline snapshot of the unix docs** under `references/docs/`.",
      "",
      "Why prefer the bundled snapshot?",
      "",
      "1. The docs tree below is guaranteed to match what’s embedded.",
      "2. It’s more likely to match *your installed unix version* (the live site may be ahead).",
      "",
      "To read a specific page:",
      "",
      "```ts",
      "agent_skill_read_file({",
      '  name: "unix-docs",',
      '  filePath: "references/docs/config/models.mdx",',
      "});",
      "```",
      "",
      "### Fallback: bundled docs",
      "",
      "If the bundled docs don't mention something, refer to the local documentation in the `docs/` directory.",
      "",
      "#### Docs tree (auto-generated)",
      "",
      "Use this index to find a page's:",
      "",
      "- **Docs route** (for `web_fetch`)",
      "- **Embedded file path** (for `agent_skill_read_file`)",
      "",
      "<!-- BEGIN DOCS_TREE -->",
      "- **Documentation**",
      "  - **Getting Started**",
      "    - Introduction (`/`) → `references/docs/index.mdx`",
      "    - Install (`/install`) → `references/docs/install.mdx` — Download and install Unix for macOS, Linux, and Windows",
      "    - **Models**",
      "      - Models (`/config/models`) → `references/docs/config/models.mdx` — Select and configure AI models in Unix",
      "      - Providers (`/config/providers`) → `references/docs/config/providers.mdx` — Configure API keys and settings for AI providers",
      "    - Why Parallelize? (`/getting-started/why-parallelize`) → `references/docs/getting-started/why-parallelize.mdx` — Use cases for running multiple AI agents in parallel",
      "    - Unix Codes (`/getting-started/unix-codes`) → `references/docs/getting-started/unix-codes.mdx` — Redeem free LLM token credits for evaluating Unix",
      "    - CLI (`/reference/cli`) → `references/docs/reference/cli.mdx` — Run one-off agent tasks from the command line with `unix run`",
      "  - **Workspaces**",
      "    - Workspaces (`/workspaces`) → `references/docs/workspaces/index.mdx` — Isolated development environments for parallel agent work",
      "    - Forking Workspaces (`/workspaces/fork`) → `references/docs/workspaces/fork.mdx` — Clone workspaces with conversation history to explore alternatives",
      "    - Message Sharing (`/workspaces/sharing`) → `references/docs/workspaces/sharing.mdx` — Share encrypted messages with cryptographic signatures via Unix",
      "    - **Compaction**",
      "      - Compaction (`/workspaces/compaction`) → `references/docs/workspaces/compaction/index.mdx` — Managing conversation context size with compaction",
      "      - Manual Compaction (`/workspaces/compaction/manual`) → `references/docs/workspaces/compaction/manual.mdx` — Commands for manually managing conversation context",
      "      - Automatic Compaction (`/workspaces/compaction/automatic`) → `references/docs/workspaces/compaction/automatic.mdx` — Let Unix automatically compact your conversations based on usage or idle time",
      "      - Customization (`/workspaces/compaction/customization`) → `references/docs/workspaces/compaction/customization.mdx` — Customize the compaction system prompt",
      "    - **Runtimes**",
      "      - Runtimes (`/runtime`) → `references/docs/runtime/index.mdx` — Configure where and how Unix executes agent workspaces",
      "      - Local Runtime (`/runtime/local`) → `references/docs/runtime/local.mdx` — Run agents directly in your project directory",
      "      - Worktree Runtime (`/runtime/worktree`) → `references/docs/runtime/worktree.mdx` — Isolated git worktree environments for parallel agent work",
      "      - SSH Runtime (`/runtime/ssh`) → `references/docs/runtime/ssh.mdx` — Run agents on remote hosts over SSH for security and performance",
      "      - Coder Runtime (`/runtime/coder`) → `references/docs/runtime/coder.mdx` — Run agents on Coder workspaces",
      "      - Docker Runtime (`/runtime/docker`) → `references/docs/runtime/docker.mdx` — Run agents in isolated Docker containers",
      "      - Dev Container Runtime (`/runtime/devcontainer`) → `references/docs/runtime/devcontainer.mdx` — Run agents in containers defined by devcontainer.json",
      "    - **Hooks**",
      "      - Init Hooks (`/hooks/init`) → `references/docs/hooks/init.mdx` — Run setup commands automatically when creating new workspaces",
      "      - Tool Hooks (`/hooks/tools`) → `references/docs/hooks/tools.mdx` — Block dangerous commands, lint after edits, and set up your environment",
      "      - Environment Variables (`/hooks/environment-variables`) → `references/docs/hooks/environment-variables.mdx` — Environment variables available in agent bash commands and hooks",
      "  - **Agents**",
      "    - Agents (`/agents`) → `references/docs/agents/index.mdx` — Define custom agents (modes + subagents) with Markdown files",
      "    - Instruction Files (`/agents/instruction-files`) → `references/docs/agents/instruction-files.mdx` — Configure agent behavior with AGENTS.md files",
      "    - Agent Skills (`/agents/agent-skills`) → `references/docs/agents/agent-skills.mdx` — Share reusable workflows and references with skills",
      "    - Plan Mode (`/agents/plan-mode`) → `references/docs/agents/plan-mode.mdx` — Review and collaborate on plans before execution",
      "    - System Prompt (`/agents/system-prompt`) → `references/docs/agents/system-prompt.mdx` — How Unix constructs the system prompt for AI models",
      "    - Prompting Tips (`/agents/prompting-tips`) → `references/docs/agents/prompting-tips.mdx` — Tips and tricks for getting the most out of your AI agents",
      "  - **Configuration**",
      "    - MCP Servers (`/config/mcp-servers`) → `references/docs/config/mcp-servers.mdx` — Extend agent capabilities with Model Context Protocol servers",
      "    - Project Secrets (`/config/project-secrets`) → `references/docs/config/project-secrets.mdx` — Manage environment variables and API keys for your projects",
      "    - Agentic Git Identity (`/config/agentic-git-identity`) → `references/docs/config/agentic-git-identity.mdx` — Configure a separate Git identity for AI-generated commits",
      "    - Keyboard Shortcuts (`/config/keybinds`) → `references/docs/config/keybinds.mdx` — Complete keyboard shortcut reference for Unix",
      "    - Notifications (`/config/notifications`) → `references/docs/config/notifications.mdx` — Configure how agents notify you about important events",
      "    - Vim Mode (`/config/vim-mode`) → `references/docs/config/vim-mode.mdx` — Vim-style editing in the Unix chat input",
      "  - **Guides**",
      "    - GitHub Actions (`/guides/github-actions`) → `references/docs/guides/github-actions.mdx` — Automate your workflows with unix run in GitHub Actions",
      "    - Agentic Git Identity (`/config/agentic-git-identity`) → `references/docs/config/agentic-git-identity.mdx` — Configure a separate Git identity for AI-generated commits",
      "    - Prompting Tips (`/agents/prompting-tips`) → `references/docs/agents/prompting-tips.mdx` — Tips and tricks for getting the most out of your AI agents",
      "  - **Integrations**",
      "    - VS Code Extension (`/integrations/vscode-extension`) → `references/docs/integrations/vscode-extension.mdx` — Pair Unix workspaces with VS Code and Cursor editors",
      "  - **Reference**",
      "    - Telemetry (`/reference/telemetry`) → `references/docs/reference/telemetry.mdx` — What Unix collects, what it doesn’t, and how to disable it",
      "    - Storybook (`/reference/storybook`) → `references/docs/reference/storybook.mdx` — Develop and test Unix UI states in isolation",
      "    - Terminal Benchmarking (`/reference/benchmarking`) → `references/docs/reference/benchmarking.mdx` — Run Terminal-Bench benchmarks with the Unix adapter",
      "    - AGENTS.md (`/AGENTS`) → `references/docs/AGENTS.md` — Agent instructions for AI assistants working on the Unix codebase",
      "<!-- END DOCS_TREE -->",
      "",
      "1. Read the docs navigation (source of truth for which pages exist):",
      "",
      "```ts",
      'agent_skill_read_file({ name: "unix-docs", filePath: "references/docs/docs.json" });',
      "```",
      "",
      "2. Read a specific page by path (mirrors `docs/` in the unix repo):",
      "",
      "- `/agents` → `references/docs/agents/index.mdx`",
      "- `/config/models` → `references/docs/config/models.mdx`",
      "- `/runtime` → `references/docs/runtime/index.mdx`",
      "",
      "```ts",
      "agent_skill_read_file({",
      '  name: "unix-docs",',
      '  filePath: "references/docs/config/models.mdx",',
      "});",
      "```",
      "",
      "Notes:",
      "",
      "- Many pages are `.mdx`; some are `.../index.mdx`.",
      "- Images are not embedded; you may see `/img/...` references.",
      "",
      "## When to use",
      "",
      "Use this skill when the user asks how unix works (workspaces, runtimes, agents, models, hooks, keybinds, etc.).",
      "",
      "## About",
      "",
      "LATTICE WORKBENCH - runtime enforcement and identity infrastructure for autonomous ai agents for internal use.",
      "",
    ].join("\n"),
  },
  xlsx: {
    "SKILL.md": [
      "---",
      "name: xlsx",
      'description: "Comprehensive spreadsheet creation, editing, and analysis with support for formulas, formatting, data analysis, and visualization. When Claude needs to work with spreadsheets (.xlsx, .xlsm, .csv, .tsv, etc) for: (1) Creating new spreadsheets with formulas and formatting, (2) Reading or analyzing data, (3) Modify existing spreadsheets while preserving formulas, (4) Data analysis and visualization in spreadsheets, or (5) Recalculating formulas"',
      "license: Proprietary. LICENSE.txt has complete terms",
      "---",
      "",
      "# Requirements for Outputs",
      "",
      "## All Excel files",
      "",
      "### Zero Formula Errors",
      "- Every Excel model MUST be delivered with ZERO formula errors (#REF!, #DIV/0!, #VALUE!, #N/A, #NAME?)",
      "",
      "### Preserve Existing Templates (when updating templates)",
      "- Study and EXACTLY match existing format, style, and conventions when modifying files",
      "- Never impose standardized formatting on files with established patterns",
      "- Existing template conventions ALWAYS override these guidelines",
      "",
      "## Financial models",
      "",
      "### Color Coding Standards",
      "Unless otherwise stated by the user or existing template",
      "",
      "#### Industry-Standard Color Conventions",
      "- **Blue text (RGB: 0,0,255)**: Hardcoded inputs, and numbers users will change for scenarios",
      "- **Black text (RGB: 0,0,0)**: ALL formulas and calculations",
      "- **Green text (RGB: 0,128,0)**: Links pulling from other worksheets within same workbook",
      "- **Red text (RGB: 255,0,0)**: External links to other files",
      "- **Yellow background (RGB: 255,255,0)**: Key assumptions needing attention or cells that need to be updated",
      "",
      "### Number Formatting Standards",
      "",
      "#### Required Format Rules",
      '- **Years**: Format as text strings (e.g., "2024" not "2,024")',
      '- **Currency**: Use $#,##0 format; ALWAYS specify units in headers ("Revenue ($mm)")',
      '- **Zeros**: Use number formatting to make all zeros "-", including percentages (e.g., "$#,##0;($#,##0);-")',
      "- **Percentages**: Default to 0.0% format (one decimal)",
      "- **Multiples**: Format as 0.0x for valuation multiples (EV/EBITDA, P/E)",
      "- **Negative numbers**: Use parentheses (123) not minus -123",
      "",
      "### Formula Construction Rules",
      "",
      "#### Assumptions Placement",
      "- Place ALL assumptions (growth rates, margins, multiples, etc.) in separate assumption cells",
      "- Use cell references instead of hardcoded values in formulas",
      "- Example: Use =B5*(1+$B$6) instead of =B5*1.05",
      "",
      "#### Formula Error Prevention",
      "- Verify all cell references are correct",
      "- Check for off-by-one errors in ranges",
      "- Ensure consistent formulas across all projection periods",
      "- Test with edge cases (zero values, negative numbers)",
      "- Verify no unintended circular references",
      "",
      "#### Documentation Requirements for Hardcodes",
      '- Comment or in cells beside (if end of table). Format: "Source: [System/Document], [Date], [Specific Reference], [URL if applicable]"',
      "- Examples:",
      '  - "Source: Company 10-K, FY2024, Page 45, Revenue Note, [SEC EDGAR URL]"',
      '  - "Source: Company 10-Q, Q2 2025, Exhibit 99.1, [SEC EDGAR URL]"',
      '  - "Source: Bloomberg Terminal, 8/15/2025, AAPL US Equity"',
      '  - "Source: FactSet, 8/20/2025, Consensus Estimates Screen"',
      "",
      "# XLSX creation, editing, and analysis",
      "",
      "## Overview",
      "",
      "A user may ask you to create, edit, or analyze the contents of an .xlsx file. You have different tools and workflows available for different tasks.",
      "",
      "## Important Requirements",
      "",
      "**LibreOffice Required for Formula Recalculation**: You can assume LibreOffice is installed for recalculating formula values using the `recalc.py` script. The script automatically configures LibreOffice on first run",
      "",
      "## Reading and analyzing data",
      "",
      "### Data analysis with pandas",
      "For data analysis, visualization, and basic operations, use **pandas** which provides powerful data manipulation capabilities:",
      "",
      "```python",
      "import pandas as pd",
      "",
      "# Read Excel",
      "df = pd.read_excel('file.xlsx')  # Default: first sheet",
      "all_sheets = pd.read_excel('file.xlsx', sheet_name=None)  # All sheets as dict",
      "",
      "# Analyze",
      "df.head()      # Preview data",
      "df.info()      # Column info",
      "df.describe()  # Statistics",
      "",
      "# Write Excel",
      "df.to_excel('output.xlsx', index=False)",
      "```",
      "",
      "## Excel File Workflows",
      "",
      "## CRITICAL: Use Formulas, Not Hardcoded Values",
      "",
      "**Always use Excel formulas instead of calculating values in Python and hardcoding them.** This ensures the spreadsheet remains dynamic and updateable.",
      "",
      "### ❌ WRONG - Hardcoding Calculated Values",
      "```python",
      "# Bad: Calculating in Python and hardcoding result",
      "total = df['Sales'].sum()",
      "sheet['B10'] = total  # Hardcodes 5000",
      "",
      "# Bad: Computing growth rate in Python",
      "growth = (df.iloc[-1]['Revenue'] - df.iloc[0]['Revenue']) / df.iloc[0]['Revenue']",
      "sheet['C5'] = growth  # Hardcodes 0.15",
      "",
      "# Bad: Python calculation for average",
      "avg = sum(values) / len(values)",
      "sheet['D20'] = avg  # Hardcodes 42.5",
      "```",
      "",
      "### ✅ CORRECT - Using Excel Formulas",
      "```python",
      "# Good: Let Excel calculate the sum",
      "sheet['B10'] = '=SUM(B2:B9)'",
      "",
      "# Good: Growth rate as Excel formula",
      "sheet['C5'] = '=(C4-C2)/C2'",
      "",
      "# Good: Average using Excel function",
      "sheet['D20'] = '=AVERAGE(D2:D19)'",
      "```",
      "",
      "This applies to ALL calculations - totals, percentages, ratios, differences, etc. The spreadsheet should be able to recalculate when source data changes.",
      "",
      "## Common Workflow",
      "1. **Choose tool**: pandas for data, openpyxl for formulas/formatting",
      "2. **Create/Load**: Create new workbook or load existing file",
      "3. **Modify**: Add/edit data, formulas, and formatting",
      "4. **Save**: Write to file",
      "5. **Recalculate formulas (MANDATORY IF USING FORMULAS)**: Use the recalc.py script",
      "   ```bash",
      "   python recalc.py output.xlsx",
      "   ```",
      "6. **Verify and fix any errors**: ",
      "   - The script returns JSON with error details",
      "   - If `status` is `errors_found`, check `error_summary` for specific error types and locations",
      "   - Fix the identified errors and recalculate again",
      "   - Common errors to fix:",
      "     - `#REF!`: Invalid cell references",
      "     - `#DIV/0!`: Division by zero",
      "     - `#VALUE!`: Wrong data type in formula",
      "     - `#NAME?`: Unrecognized formula name",
      "",
      "### Creating new Excel files",
      "",
      "```python",
      "# Using openpyxl for formulas and formatting",
      "from openpyxl import Workbook",
      "from openpyxl.styles import Font, PatternFill, Alignment",
      "",
      "wb = Workbook()",
      "sheet = wb.active",
      "",
      "# Add data",
      "sheet['A1'] = 'Hello'",
      "sheet['B1'] = 'World'",
      "sheet.append(['Row', 'of', 'data'])",
      "",
      "# Add formula",
      "sheet['B2'] = '=SUM(A1:A10)'",
      "",
      "# Formatting",
      "sheet['A1'].font = Font(bold=True, color='FF0000')",
      "sheet['A1'].fill = PatternFill('solid', start_color='FFFF00')",
      "sheet['A1'].alignment = Alignment(horizontal='center')",
      "",
      "# Column width",
      "sheet.column_dimensions['A'].width = 20",
      "",
      "wb.save('output.xlsx')",
      "```",
      "",
      "### Editing existing Excel files",
      "",
      "```python",
      "# Using openpyxl to preserve formulas and formatting",
      "from openpyxl import load_workbook",
      "",
      "# Load existing file",
      "wb = load_workbook('existing.xlsx')",
      "sheet = wb.active  # or wb['SheetName'] for specific sheet",
      "",
      "# Working with multiple sheets",
      "for sheet_name in wb.sheetnames:",
      "    sheet = wb[sheet_name]",
      '    print(f"Sheet: {sheet_name}")',
      "",
      "# Modify cells",
      "sheet['A1'] = 'New Value'",
      "sheet.insert_rows(2)  # Insert row at position 2",
      "sheet.delete_cols(3)  # Delete column 3",
      "",
      "# Add new sheet",
      "new_sheet = wb.create_sheet('NewSheet')",
      "new_sheet['A1'] = 'Data'",
      "",
      "wb.save('modified.xlsx')",
      "```",
      "",
      "## Recalculating formulas",
      "",
      "Excel files created or modified by openpyxl contain formulas as strings but not calculated values. Use the provided `recalc.py` script to recalculate formulas:",
      "",
      "```bash",
      "python recalc.py <excel_file> [timeout_seconds]",
      "```",
      "",
      "Example:",
      "```bash",
      "python recalc.py output.xlsx 30",
      "```",
      "",
      "The script:",
      "- Automatically sets up LibreOffice macro on first run",
      "- Recalculates all formulas in all sheets",
      "- Scans ALL cells for Excel errors (#REF!, #DIV/0!, etc.)",
      "- Returns JSON with detailed error locations and counts",
      "- Works on both Linux and macOS",
      "",
      "## Formula Verification Checklist",
      "",
      "Quick checks to ensure formulas work correctly:",
      "",
      "### Essential Verification",
      "- [ ] **Test 2-3 sample references**: Verify they pull correct values before building full model",
      "- [ ] **Column mapping**: Confirm Excel columns match (e.g., column 64 = BL, not BK)",
      "- [ ] **Row offset**: Remember Excel rows are 1-indexed (DataFrame row 5 = Excel row 6)",
      "",
      "### Common Pitfalls",
      "- [ ] **NaN handling**: Check for null values with `pd.notna()`",
      "- [ ] **Far-right columns**: FY data often in columns 50+ ",
      "- [ ] **Multiple matches**: Search all occurrences, not just first",
      "- [ ] **Division by zero**: Check denominators before using `/` in formulas (#DIV/0!)",
      "- [ ] **Wrong references**: Verify all cell references point to intended cells (#REF!)",
      "- [ ] **Cross-sheet references**: Use correct format (Sheet1!A1) for linking sheets",
      "",
      "### Formula Testing Strategy",
      "- [ ] **Start small**: Test formulas on 2-3 cells before applying broadly",
      "- [ ] **Verify dependencies**: Check all cells referenced in formulas exist",
      "- [ ] **Test edge cases**: Include zero, negative, and very large values",
      "",
      "### Interpreting recalc.py Output",
      "The script returns JSON with error details:",
      "```json",
      "{",
      '  "status": "success",           // or "errors_found"',
      '  "total_errors": 0,              // Total error count',
      '  "total_formulas": 42,           // Number of formulas in file',
      '  "error_summary": {              // Only present if errors found',
      '    "#REF!": {',
      '      "count": 2,',
      '      "locations": ["Sheet1!B5", "Sheet1!C10"]',
      "    }",
      "  }",
      "}",
      "```",
      "",
      "## Best Practices",
      "",
      "### Library Selection",
      "- **pandas**: Best for data analysis, bulk operations, and simple data export",
      "- **openpyxl**: Best for complex formatting, formulas, and Excel-specific features",
      "",
      "### Working with openpyxl",
      "- Cell indices are 1-based (row=1, column=1 refers to cell A1)",
      "- Use `data_only=True` to read calculated values: `load_workbook('file.xlsx', data_only=True)`",
      "- **Warning**: If opened with `data_only=True` and saved, formulas are replaced with values and permanently lost",
      "- For large files: Use `read_only=True` for reading or `write_only=True` for writing",
      "- Formulas are preserved but not evaluated - use recalc.py to update values",
      "",
      "### Working with pandas",
      "- Specify data types to avoid inference issues: `pd.read_excel('file.xlsx', dtype={'id': str})`",
      "- For large files, read specific columns: `pd.read_excel('file.xlsx', usecols=['A', 'C', 'E'])`",
      "- Handle dates properly: `pd.read_excel('file.xlsx', parse_dates=['date_column'])`",
      "",
      "## Code Style Guidelines",
      "**IMPORTANT**: When generating Python code for Excel operations:",
      "- Write minimal, concise Python code without unnecessary comments",
      "- Avoid verbose variable names and redundant operations",
      "- Avoid unnecessary print statements",
      "",
      "**For Excel files themselves**:",
      "- Add comments to cells with complex formulas or important assumptions",
      "- Document data sources for hardcoded values",
      "- Include notes for key calculations and model sections",
    ].join("\n"),
  },
};
