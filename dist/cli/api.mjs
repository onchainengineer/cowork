import{createRequire}from'module';globalThis.require=createRequire(import.meta.url);
var __create = Object.create;
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getProtoOf = Object.getPrototypeOf;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __knownSymbol = (name16, symbol17) => (symbol17 = Symbol[name16]) ? symbol17 : Symbol.for("Symbol." + name16);
var __typeError = (msg) => {
  throw TypeError(msg);
};
var __require = /* @__PURE__ */ ((x) => typeof require !== "undefined" ? require : typeof Proxy !== "undefined" ? new Proxy(x, {
  get: (a, b) => (typeof require !== "undefined" ? require : a)[b]
}) : x)(function(x) {
  if (typeof require !== "undefined") return require.apply(this, arguments);
  throw Error('Dynamic require of "' + x + '" is not supported');
});
var __esm = (fn, res) => function __init() {
  return fn && (res = (0, fn[__getOwnPropNames(fn)[0]])(fn = 0)), res;
};
var __commonJS = (cb, mod) => function __require2() {
  return mod || (0, cb[__getOwnPropNames(cb)[0]])((mod = { exports: {} }).exports, mod), mod.exports;
};
var __export = (target, all) => {
  for (var name16 in all)
    __defProp(target, name16, { get: all[name16], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toESM = (mod, isNodeMode, target) => (target = mod != null ? __create(__getProtoOf(mod)) : {}, __copyProps(
  // If the importer is in node compatibility mode or this is not an ESM
  // file that has been converted to a CommonJS file using a Babel-
  // compatible transform (i.e. "__esModule" has not been set), then set
  // "default" to the CommonJS "module.exports" for node compatibility.
  isNodeMode || !mod || !mod.__esModule ? __defProp(target, "default", { value: mod, enumerable: true }) : target,
  mod
));
var __using = (stack, value2, async) => {
  if (value2 != null) {
    if (typeof value2 !== "object" && typeof value2 !== "function") __typeError("Object expected");
    var dispose, inner;
    if (async) dispose = value2[__knownSymbol("asyncDispose")];
    if (dispose === void 0) {
      dispose = value2[__knownSymbol("dispose")];
      if (async) inner = dispose;
    }
    if (typeof dispose !== "function") __typeError("Object not disposable");
    if (inner) dispose = function() {
      try {
        inner.call(this);
      } catch (e) {
        return Promise.reject(e);
      }
    };
    stack.push([async, dispose, value2]);
  } else if (async) {
    stack.push([async]);
  }
  return value2;
};
var __callDispose = (stack, error, hasError) => {
  var E = typeof SuppressedError === "function" ? SuppressedError : function(e, s, m, _) {
    return _ = Error(m), _.name = "SuppressedError", _.error = e, _.suppressed = s, _;
  };
  var fail = (e) => error = hasError ? new E(e, error, "An error was suppressed during disposal") : (hasError = true, e);
  var next = (it) => {
    while (it = stack.pop()) {
      try {
        var result = it[1] && it[1].call(it[2]);
        if (it[0]) return Promise.resolve(result).then(next, (e) => (fail(e), next()));
      } catch (e) {
        fail(e);
      }
    }
    if (hasError) throw error;
  };
  return next();
};

// node_modules/@orpc/shared/dist/index.mjs
function resolveMaybeOptionalOptions(rest) {
  return rest[0] ?? {};
}
function toArray(value2) {
  return Array.isArray(value2) ? value2 : value2 === void 0 || value2 === null ? [] : [value2];
}
function once(fn) {
  let cached;
  return () => {
    if (cached) {
      return cached.result;
    }
    const result = fn();
    cached = { result };
    return result;
  };
}
function sequential(fn) {
  let lastOperationPromise = Promise.resolve();
  return (...args2) => {
    return lastOperationPromise = lastOperationPromise.catch(() => {
    }).then(() => {
      return fn(...args2);
    });
  };
}
function getGlobalOtelConfig() {
  return globalThis[GLOBAL_OTEL_CONFIG_KEY];
}
function startSpan(name16, options = {}, context) {
  const tracer = getGlobalOtelConfig()?.tracer;
  return tracer?.startSpan(name16, options, context);
}
function setSpanError(span, error, options = {}) {
  if (!span) {
    return;
  }
  const exception = toOtelException(error);
  span.recordException(exception);
  if (!options.signal?.aborted || options.signal.reason !== error) {
    span.setStatus({
      code: SPAN_ERROR_STATUS,
      message: exception.message
    });
  }
}
function toOtelException(error) {
  if (error instanceof Error) {
    const exception = {
      message: error.message,
      name: error.name,
      stack: error.stack
    };
    if ("code" in error && (typeof error.code === "string" || typeof error.code === "number")) {
      exception.code = error.code;
    }
    return exception;
  }
  return { message: String(error) };
}
async function runWithSpan({ name: name16, context, ...options }, fn) {
  const tracer = getGlobalOtelConfig()?.tracer;
  if (!tracer) {
    return fn();
  }
  const callback = async (span) => {
    try {
      return await fn(span);
    } catch (e) {
      setSpanError(span, e, options);
      throw e;
    } finally {
      span.end();
    }
  };
  if (context) {
    return tracer.startActiveSpan(name16, options, context, callback);
  } else {
    return tracer.startActiveSpan(name16, options, callback);
  }
}
async function runInSpanContext(span, fn) {
  const otelConfig = getGlobalOtelConfig();
  if (!span || !otelConfig) {
    return fn();
  }
  const ctx = otelConfig.trace.setSpan(otelConfig.context.active(), span);
  return otelConfig.context.with(ctx, fn);
}
function isAsyncIteratorObject(maybe) {
  if (!maybe || typeof maybe !== "object") {
    return false;
  }
  return "next" in maybe && typeof maybe.next === "function" && Symbol.asyncIterator in maybe && typeof maybe[Symbol.asyncIterator] === "function";
}
function asyncIteratorWithSpan({ name: name16, ...options }, iterator) {
  let span;
  return new AsyncIteratorClass(
    async () => {
      span ??= startSpan(name16);
      try {
        const result = await runInSpanContext(span, () => iterator.next());
        span?.addEvent(result.done ? "completed" : "yielded");
        return result;
      } catch (err) {
        setSpanError(span, err, options);
        throw err;
      }
    },
    async (reason) => {
      try {
        if (reason !== "next") {
          await runInSpanContext(span, () => iterator.return?.());
        }
      } catch (err) {
        setSpanError(span, err, options);
        throw err;
      } finally {
        span?.end();
      }
    }
  );
}
function onStart(callback) {
  return async (options, ...rest) => {
    await callback(options, ...rest);
    return await options.next();
  };
}
function onSuccess(callback) {
  return async (options, ...rest) => {
    const result = await options.next();
    await callback(result, options, ...rest);
    return result;
  };
}
function onError(callback) {
  return async (options, ...rest) => {
    try {
      return await options.next();
    } catch (error) {
      await callback(error, options, ...rest);
      throw error;
    }
  };
}
function onFinish(callback) {
  let state;
  return async (options, ...rest) => {
    try {
      const result = await options.next();
      state = [null, result, true];
      return result;
    } catch (error) {
      state = [error, void 0, false];
      throw error;
    } finally {
      await callback(state, options, ...rest);
    }
  };
}
function intercept(interceptors, options, main) {
  const next = (options2, index) => {
    const interceptor = interceptors[index];
    if (!interceptor) {
      return main(options2);
    }
    return interceptor({
      ...options2,
      next: (newOptions = options2) => next(newOptions, index + 1)
    });
  };
  return next(options, 0);
}
function parseEmptyableJSON(text2) {
  if (!text2) {
    return void 0;
  }
  return JSON.parse(text2);
}
function stringifyJSON(value2) {
  return JSON.stringify(value2);
}
function getConstructor(value2) {
  if (!isTypescriptObject(value2)) {
    return null;
  }
  return Object.getPrototypeOf(value2)?.constructor;
}
function isObject(value2) {
  if (!value2 || typeof value2 !== "object") {
    return false;
  }
  const proto2 = Object.getPrototypeOf(value2);
  return proto2 === Object.prototype || !proto2 || !proto2.constructor;
}
function isTypescriptObject(value2) {
  return !!value2 && (typeof value2 === "object" || typeof value2 === "function");
}
function value(value2, ...args2) {
  if (typeof value2 === "function") {
    return value2(...args2);
  }
  return value2;
}
function preventNativeAwait(target) {
  return new Proxy(target, {
    get(target2, prop, receiver) {
      const value2 = Reflect.get(target2, prop, receiver);
      if (prop !== "then" || typeof value2 !== "function") {
        return value2;
      }
      return new Proxy(value2, {
        apply(targetFn, thisArg, args2) {
          if (args2.length !== 2 || args2.some((arg) => !isNativeFunction(arg))) {
            return Reflect.apply(targetFn, thisArg, args2);
          }
          let shouldOmit = true;
          args2[0].call(thisArg, preventNativeAwait(new Proxy(target2, {
            get: (target3, prop2, receiver2) => {
              if (shouldOmit && prop2 === "then") {
                shouldOmit = false;
                return void 0;
              }
              return Reflect.get(target3, prop2, receiver2);
            }
          })));
        }
      });
    }
  });
}
function isNativeFunction(fn) {
  return typeof fn === "function" && NATIVE_FUNCTION_REGEX.test(fn.toString());
}
function overlayProxy(target, partial) {
  const proxy = new Proxy(typeof target === "function" ? partial : target, {
    get(_, prop) {
      const targetValue = prop in partial ? partial : value(target);
      const v = Reflect.get(targetValue, prop);
      return typeof v === "function" ? v.bind(targetValue) : v;
    },
    has(_, prop) {
      return Reflect.has(partial, prop) || Reflect.has(value(target), prop);
    }
  });
  return proxy;
}
function streamToAsyncIteratorClass(stream) {
  const reader = stream.getReader();
  return new AsyncIteratorClass(
    async () => {
      return reader.read();
    },
    async () => {
      await reader.cancel();
    }
  );
}
function asyncIteratorToStream(iterator) {
  return new ReadableStream({
    async pull(controller) {
      const { done, value: value2 } = await iterator.next();
      if (done) {
        controller.close();
      } else {
        controller.enqueue(value2);
      }
    },
    async cancel() {
      await iterator.return?.();
    }
  });
}
function asyncIteratorToUnproxiedDataStream(iterator) {
  return new ReadableStream({
    async pull(controller) {
      const { done, value: value2 } = await iterator.next();
      if (done) {
        controller.close();
      } else {
        const unproxied = isObject(value2) ? { ...value2 } : Array.isArray(value2) ? value2.map((i) => i) : value2;
        controller.enqueue(unproxied);
      }
    },
    async cancel() {
      await iterator.return?.();
    }
  });
}
function tryDecodeURIComponent(value2) {
  try {
    return decodeURIComponent(value2);
  } catch {
    return value2;
  }
}
var ORPC_NAME, ORPC_SHARED_PACKAGE_NAME, ORPC_SHARED_PACKAGE_VERSION, AbortError, SPAN_ERROR_STATUS, GLOBAL_OTEL_CONFIG_KEY, fallbackAsyncDisposeSymbol, asyncDisposeSymbol, AsyncIteratorClass, EventPublisher, NATIVE_FUNCTION_REGEX;
var init_dist = __esm({
  "node_modules/@orpc/shared/dist/index.mjs"() {
    ORPC_NAME = "orpc";
    ORPC_SHARED_PACKAGE_NAME = "@orpc/shared";
    ORPC_SHARED_PACKAGE_VERSION = "1.12.2";
    AbortError = class extends Error {
      constructor(...rest) {
        super(...rest);
        this.name = "AbortError";
      }
    };
    SPAN_ERROR_STATUS = 2;
    GLOBAL_OTEL_CONFIG_KEY = `__${ORPC_SHARED_PACKAGE_NAME}@${ORPC_SHARED_PACKAGE_VERSION}/otel/config__`;
    fallbackAsyncDisposeSymbol = Symbol.for("asyncDispose");
    asyncDisposeSymbol = Symbol.asyncDispose ?? fallbackAsyncDisposeSymbol;
    AsyncIteratorClass = class {
      #isDone = false;
      #isExecuteComplete = false;
      #cleanup;
      #next;
      constructor(next, cleanup) {
        this.#cleanup = cleanup;
        this.#next = sequential(async () => {
          if (this.#isDone) {
            return { done: true, value: void 0 };
          }
          try {
            const result = await next();
            if (result.done) {
              this.#isDone = true;
            }
            return result;
          } catch (err) {
            this.#isDone = true;
            throw err;
          } finally {
            if (this.#isDone && !this.#isExecuteComplete) {
              this.#isExecuteComplete = true;
              await this.#cleanup("next");
            }
          }
        });
      }
      next() {
        return this.#next();
      }
      async return(value2) {
        this.#isDone = true;
        if (!this.#isExecuteComplete) {
          this.#isExecuteComplete = true;
          await this.#cleanup("return");
        }
        return { done: true, value: value2 };
      }
      async throw(err) {
        this.#isDone = true;
        if (!this.#isExecuteComplete) {
          this.#isExecuteComplete = true;
          await this.#cleanup("throw");
        }
        throw err;
      }
      /**
       * asyncDispose symbol only available in esnext, we should fallback to Symbol.for('asyncDispose')
       */
      async [asyncDisposeSymbol]() {
        this.#isDone = true;
        if (!this.#isExecuteComplete) {
          this.#isExecuteComplete = true;
          await this.#cleanup("dispose");
        }
      }
      [Symbol.asyncIterator]() {
        return this;
      }
    };
    EventPublisher = class {
      #listenersMap = /* @__PURE__ */ new Map();
      #maxBufferedEvents;
      constructor(options = {}) {
        this.#maxBufferedEvents = options.maxBufferedEvents ?? 100;
      }
      get size() {
        return this.#listenersMap.size;
      }
      /**
       * Emits an event and delivers the payload to all subscribed listeners.
       */
      publish(event, payload) {
        const listeners = this.#listenersMap.get(event);
        if (!listeners) {
          return;
        }
        for (const listener of listeners) {
          listener(payload);
        }
      }
      subscribe(event, listenerOrOptions) {
        if (typeof listenerOrOptions === "function") {
          let listeners = this.#listenersMap.get(event);
          if (!listeners) {
            this.#listenersMap.set(event, listeners = []);
          }
          listeners.push(listenerOrOptions);
          return once(() => {
            listeners.splice(listeners.indexOf(listenerOrOptions), 1);
            if (listeners.length === 0) {
              this.#listenersMap.delete(event);
            }
          });
        }
        const signal = listenerOrOptions?.signal;
        const maxBufferedEvents = listenerOrOptions?.maxBufferedEvents ?? this.#maxBufferedEvents;
        signal?.throwIfAborted();
        const bufferedEvents = [];
        const pullResolvers = [];
        const unsubscribe = this.subscribe(event, (payload) => {
          const resolver = pullResolvers.shift();
          if (resolver) {
            resolver[0]({ done: false, value: payload });
          } else {
            bufferedEvents.push(payload);
            if (bufferedEvents.length > maxBufferedEvents) {
              bufferedEvents.shift();
            }
          }
        });
        const abortListener = (event2) => {
          unsubscribe();
          pullResolvers.forEach((resolver) => resolver[1](event2.target.reason));
          pullResolvers.length = 0;
          bufferedEvents.length = 0;
        };
        signal?.addEventListener("abort", abortListener, { once: true });
        return new AsyncIteratorClass(async () => {
          if (signal?.aborted) {
            throw signal.reason;
          }
          if (bufferedEvents.length > 0) {
            return { done: false, value: bufferedEvents.shift() };
          }
          return new Promise((resolve3, reject) => {
            pullResolvers.push([resolve3, reject]);
          });
        }, async () => {
          unsubscribe();
          signal?.removeEventListener("abort", abortListener);
          pullResolvers.forEach((resolver) => resolver[0]({ done: true, value: void 0 }));
          pullResolvers.length = 0;
          bufferedEvents.length = 0;
        });
      }
    };
    NATIVE_FUNCTION_REGEX = /^\s*function\s*\(\)\s*\{\s*\[native code\]\s*\}\s*$/;
  }
});

// node_modules/@orpc/client/dist/shared/client.J7pEE4Uw.mjs
function fallbackORPCErrorStatus(code, status) {
  return status ?? COMMON_ORPC_ERROR_DEFS[code]?.status ?? 500;
}
function fallbackORPCErrorMessage(code, message) {
  return message || COMMON_ORPC_ERROR_DEFS[code]?.message || code;
}
function isDefinedError(error) {
  return error instanceof ORPCError && error.defined;
}
function toORPCError(error) {
  return error instanceof ORPCError ? error : new ORPCError("INTERNAL_SERVER_ERROR", {
    message: "Internal server error",
    cause: error
  });
}
function isORPCErrorStatus(status) {
  return status < 200 || status >= 400;
}
function isORPCErrorJson(json) {
  if (!isObject(json)) {
    return false;
  }
  const validKeys = ["defined", "code", "status", "message", "data"];
  if (Object.keys(json).some((k) => !validKeys.includes(k))) {
    return false;
  }
  return "defined" in json && typeof json.defined === "boolean" && "code" in json && typeof json.code === "string" && "status" in json && typeof json.status === "number" && isORPCErrorStatus(json.status) && "message" in json && typeof json.message === "string";
}
function createORPCErrorFromJson(json, options = {}) {
  return new ORPCError(json.code, {
    ...options,
    ...json
  });
}
var ORPC_CLIENT_PACKAGE_NAME, ORPC_CLIENT_PACKAGE_VERSION, COMMON_ORPC_ERROR_DEFS, GLOBAL_ORPC_ERROR_CONSTRUCTORS_SYMBOL, globalORPCErrorConstructors, ORPCError;
var init_client_J7pEE4Uw = __esm({
  "node_modules/@orpc/client/dist/shared/client.J7pEE4Uw.mjs"() {
    init_dist();
    ORPC_CLIENT_PACKAGE_NAME = "@orpc/client";
    ORPC_CLIENT_PACKAGE_VERSION = "1.12.2";
    COMMON_ORPC_ERROR_DEFS = {
      BAD_REQUEST: {
        status: 400,
        message: "Bad Request"
      },
      UNAUTHORIZED: {
        status: 401,
        message: "Unauthorized"
      },
      FORBIDDEN: {
        status: 403,
        message: "Forbidden"
      },
      NOT_FOUND: {
        status: 404,
        message: "Not Found"
      },
      METHOD_NOT_SUPPORTED: {
        status: 405,
        message: "Method Not Supported"
      },
      NOT_ACCEPTABLE: {
        status: 406,
        message: "Not Acceptable"
      },
      TIMEOUT: {
        status: 408,
        message: "Request Timeout"
      },
      CONFLICT: {
        status: 409,
        message: "Conflict"
      },
      PRECONDITION_FAILED: {
        status: 412,
        message: "Precondition Failed"
      },
      PAYLOAD_TOO_LARGE: {
        status: 413,
        message: "Payload Too Large"
      },
      UNSUPPORTED_MEDIA_TYPE: {
        status: 415,
        message: "Unsupported Media Type"
      },
      UNPROCESSABLE_CONTENT: {
        status: 422,
        message: "Unprocessable Content"
      },
      TOO_MANY_REQUESTS: {
        status: 429,
        message: "Too Many Requests"
      },
      CLIENT_CLOSED_REQUEST: {
        status: 499,
        message: "Client Closed Request"
      },
      INTERNAL_SERVER_ERROR: {
        status: 500,
        message: "Internal Server Error"
      },
      NOT_IMPLEMENTED: {
        status: 501,
        message: "Not Implemented"
      },
      BAD_GATEWAY: {
        status: 502,
        message: "Bad Gateway"
      },
      SERVICE_UNAVAILABLE: {
        status: 503,
        message: "Service Unavailable"
      },
      GATEWAY_TIMEOUT: {
        status: 504,
        message: "Gateway Timeout"
      }
    };
    GLOBAL_ORPC_ERROR_CONSTRUCTORS_SYMBOL = Symbol.for(`__${ORPC_CLIENT_PACKAGE_NAME}@${ORPC_CLIENT_PACKAGE_VERSION}/error/ORPC_ERROR_CONSTRUCTORS__`);
    void (globalThis[GLOBAL_ORPC_ERROR_CONSTRUCTORS_SYMBOL] ??= /* @__PURE__ */ new WeakSet());
    globalORPCErrorConstructors = globalThis[GLOBAL_ORPC_ERROR_CONSTRUCTORS_SYMBOL];
    ORPCError = class extends Error {
      defined;
      code;
      status;
      data;
      constructor(code, ...rest) {
        const options = resolveMaybeOptionalOptions(rest);
        if (options.status !== void 0 && !isORPCErrorStatus(options.status)) {
          throw new Error("[ORPCError] Invalid error status code.");
        }
        const message = fallbackORPCErrorMessage(code, options.message);
        super(message, options);
        this.code = code;
        this.status = fallbackORPCErrorStatus(code, options.status);
        this.defined = options.defined ?? false;
        this.data = options.data;
      }
      toJSON() {
        return {
          defined: this.defined,
          code: this.code,
          status: this.status,
          message: this.message,
          data: this.data
        };
      }
      /**
       * Workaround for Next.js where different contexts use separate
       * dependency graphs, causing multiple ORPCError constructors existing and breaking
       * `instanceof` checks across contexts.
       *
       * This is particularly problematic with "Optimized SSR", where orpc-client
       * executes in one context but is invoked from another. When an error is thrown
       * in the execution context, `instanceof ORPCError` checks fail in the
       * invocation context due to separate class constructors.
       *
       * @todo Remove this and related code if Next.js resolves the multiple dependency graph issue.
       */
      static [Symbol.hasInstance](instance) {
        if (globalORPCErrorConstructors.has(this)) {
          const constructor = getConstructor(instance);
          if (constructor && globalORPCErrorConstructors.has(constructor)) {
            return true;
          }
        }
        return super[Symbol.hasInstance](instance);
      }
    };
    globalORPCErrorConstructors.add(ORPCError);
  }
});

// node_modules/@orpc/standard-server/dist/index.mjs
function decodeEventMessage(encoded) {
  const lines = encoded.replace(/\n+$/, "").split(/\n/);
  const message = {
    data: void 0,
    event: void 0,
    id: void 0,
    retry: void 0,
    comments: []
  };
  for (const line of lines) {
    const index = line.indexOf(":");
    const key = index === -1 ? line : line.slice(0, index);
    const value2 = index === -1 ? "" : line.slice(index + 1).replace(/^\s/, "");
    if (index === 0) {
      message.comments.push(value2);
    } else if (key === "data") {
      message.data ??= "";
      message.data += `${value2}
`;
    } else if (key === "event") {
      message.event = value2;
    } else if (key === "id") {
      message.id = value2;
    } else if (key === "retry") {
      const maybeInteger = Number.parseInt(value2);
      if (Number.isInteger(maybeInteger) && maybeInteger >= 0 && maybeInteger.toString() === value2) {
        message.retry = maybeInteger;
      }
    }
  }
  message.data = message.data?.replace(/\n$/, "");
  return message;
}
function assertEventId(id) {
  if (id.includes("\n")) {
    throw new EventEncoderError("Event's id must not contain a newline character");
  }
}
function assertEventName(event) {
  if (event.includes("\n")) {
    throw new EventEncoderError("Event's event must not contain a newline character");
  }
}
function assertEventRetry(retry) {
  if (!Number.isInteger(retry) || retry < 0) {
    throw new EventEncoderError("Event's retry must be a integer and >= 0");
  }
}
function assertEventComment(comment) {
  if (comment.includes("\n")) {
    throw new EventEncoderError("Event's comment must not contain a newline character");
  }
}
function encodeEventData(data) {
  const lines = data?.split(/\n/) ?? [];
  let output = "";
  for (const line of lines) {
    output += `data: ${line}
`;
  }
  return output;
}
function encodeEventComments(comments) {
  let output = "";
  for (const comment of comments ?? []) {
    assertEventComment(comment);
    output += `: ${comment}
`;
  }
  return output;
}
function encodeEventMessage(message) {
  let output = "";
  output += encodeEventComments(message.comments);
  if (message.event !== void 0) {
    assertEventName(message.event);
    output += `event: ${message.event}
`;
  }
  if (message.retry !== void 0) {
    assertEventRetry(message.retry);
    output += `retry: ${message.retry}
`;
  }
  if (message.id !== void 0) {
    assertEventId(message.id);
    output += `id: ${message.id}
`;
  }
  output += encodeEventData(message.data);
  output += "\n";
  return output;
}
function withEventMeta(container, meta) {
  if (meta.id === void 0 && meta.retry === void 0 && !meta.comments?.length) {
    return container;
  }
  if (meta.id !== void 0) {
    assertEventId(meta.id);
  }
  if (meta.retry !== void 0) {
    assertEventRetry(meta.retry);
  }
  if (meta.comments !== void 0) {
    for (const comment of meta.comments) {
      assertEventComment(comment);
    }
  }
  return new Proxy(container, {
    get(target, prop, receiver) {
      if (prop === EVENT_SOURCE_META_SYMBOL) {
        return meta;
      }
      return Reflect.get(target, prop, receiver);
    }
  });
}
function getEventMeta(container) {
  return isTypescriptObject(container) ? Reflect.get(container, EVENT_SOURCE_META_SYMBOL) : void 0;
}
function generateContentDisposition(filename) {
  const escapedFileName = filename.replace(/"/g, '\\"');
  const encodedFilenameStar = encodeURIComponent(filename).replace(/['()*]/g, (c) => `%${c.charCodeAt(0).toString(16).toUpperCase()}`).replace(/%(7C|60|5E)/g, (str, hex) => String.fromCharCode(Number.parseInt(hex, 16)));
  return `inline; filename="${escapedFileName}"; filename*=utf-8''${encodedFilenameStar}`;
}
function getFilenameFromContentDisposition(contentDisposition) {
  const encodedFilenameStarMatch = contentDisposition.match(/filename\*=(UTF-8'')?([^;]*)/i);
  if (encodedFilenameStarMatch && typeof encodedFilenameStarMatch[2] === "string") {
    return tryDecodeURIComponent(encodedFilenameStarMatch[2]);
  }
  const encodedFilenameMatch = contentDisposition.match(/filename="((?:\\"|[^"])*)"/i);
  if (encodedFilenameMatch && typeof encodedFilenameMatch[1] === "string") {
    return encodedFilenameMatch[1].replace(/\\"/g, '"');
  }
}
function mergeStandardHeaders(a, b) {
  const merged = { ...a };
  for (const key in b) {
    if (Array.isArray(b[key])) {
      merged[key] = [...toArray(merged[key]), ...b[key]];
    } else if (b[key] !== void 0) {
      if (Array.isArray(merged[key])) {
        merged[key] = [...merged[key], b[key]];
      } else if (merged[key] !== void 0) {
        merged[key] = [merged[key], b[key]];
      } else {
        merged[key] = b[key];
      }
    }
  }
  return merged;
}
var EventEncoderError, EventDecoderError, ErrorEvent, EventDecoder, EventDecoderStream, EVENT_SOURCE_META_SYMBOL, HibernationEventIterator;
var init_dist2 = __esm({
  "node_modules/@orpc/standard-server/dist/index.mjs"() {
    init_dist();
    EventEncoderError = class extends TypeError {
    };
    EventDecoderError = class extends TypeError {
    };
    ErrorEvent = class extends Error {
      data;
      constructor(options) {
        super(options?.message ?? "An error event was received", options);
        this.data = options?.data;
      }
    };
    EventDecoder = class {
      constructor(options = {}) {
        this.options = options;
      }
      incomplete = "";
      feed(chunk) {
        this.incomplete += chunk;
        const lastCompleteIndex = this.incomplete.lastIndexOf("\n\n");
        if (lastCompleteIndex === -1) {
          return;
        }
        const completes = this.incomplete.slice(0, lastCompleteIndex).split(/\n\n/);
        this.incomplete = this.incomplete.slice(lastCompleteIndex + 2);
        for (const encoded of completes) {
          const message = decodeEventMessage(`${encoded}

`);
          if (this.options.onEvent) {
            this.options.onEvent(message);
          }
        }
        this.incomplete = "";
      }
      end() {
        if (this.incomplete) {
          throw new EventDecoderError("Event Iterator ended before complete");
        }
      }
    };
    EventDecoderStream = class extends TransformStream {
      constructor() {
        let decoder;
        super({
          start(controller) {
            decoder = new EventDecoder({
              onEvent: (event) => {
                controller.enqueue(event);
              }
            });
          },
          transform(chunk) {
            decoder.feed(chunk);
          },
          flush() {
            decoder.end();
          }
        });
      }
    };
    EVENT_SOURCE_META_SYMBOL = Symbol("ORPC_EVENT_SOURCE_META");
    HibernationEventIterator = class extends AsyncIteratorClass {
      /**
       * this property is not transferred to the client, so it should be optional for type safety
       */
      hibernationCallback;
      constructor(hibernationCallback) {
        super(async () => {
          throw new Error("Cannot iterate over hibernating iterator directly");
        }, async (reason) => {
          if (reason !== "next") {
            throw new Error("Cannot cleanup hibernating iterator directly");
          }
        });
        this.hibernationCallback = hibernationCallback;
      }
    };
  }
});

// node_modules/@orpc/client/dist/shared/client.BLtwTQUg.mjs
function mapEventIterator(iterator, maps) {
  const mapError = async (error) => {
    let mappedError = await maps.error(error);
    if (mappedError !== error) {
      const meta = getEventMeta(error);
      if (meta && isTypescriptObject(mappedError)) {
        mappedError = withEventMeta(mappedError, meta);
      }
    }
    return mappedError;
  };
  return new AsyncIteratorClass(async () => {
    const { done, value: value2 } = await (async () => {
      try {
        return await iterator.next();
      } catch (error) {
        throw await mapError(error);
      }
    })();
    let mappedValue = await maps.value(value2, done);
    if (mappedValue !== value2) {
      const meta = getEventMeta(value2);
      if (meta && isTypescriptObject(mappedValue)) {
        mappedValue = withEventMeta(mappedValue, meta);
      }
    }
    return { done, value: mappedValue };
  }, async () => {
    try {
      await iterator.return?.();
    } catch (error) {
      throw await mapError(error);
    }
  });
}
var init_client_BLtwTQUg = __esm({
  "node_modules/@orpc/client/dist/shared/client.BLtwTQUg.mjs"() {
    init_dist();
    init_dist2();
  }
});

// node_modules/@orpc/client/dist/index.mjs
async function safe(promise) {
  try {
    const output = await promise;
    return Object.assign(
      [null, output, false, true],
      { error: null, data: output, isDefined: false, isSuccess: true }
    );
  } catch (e) {
    const error = e;
    if (isDefinedError(error)) {
      return Object.assign(
        [error, void 0, true, false],
        { error, data: void 0, isDefined: true, isSuccess: false }
      );
    }
    return Object.assign(
      [error, void 0, false, false],
      { error, data: void 0, isDefined: false, isSuccess: false }
    );
  }
}
function resolveFriendlyClientOptions(options) {
  return {
    ...options,
    context: options.context ?? {}
    // Context only optional if all fields are optional
  };
}
function createORPCClient(link, options = {}) {
  const path21 = options.path ?? [];
  const procedureClient = async (...[input, options2 = {}]) => {
    return await link.call(path21, input, resolveFriendlyClientOptions(options2));
  };
  const recursive = new Proxy(procedureClient, {
    get(target, key) {
      if (typeof key !== "string") {
        return Reflect.get(target, key);
      }
      return createORPCClient(link, {
        ...options,
        path: [...path21, key]
      });
    }
  });
  return preventNativeAwait(recursive);
}
var init_dist3 = __esm({
  "node_modules/@orpc/client/dist/index.mjs"() {
    init_dist();
    init_dist();
    init_client_J7pEE4Uw();
    init_client_J7pEE4Uw();
    init_client_BLtwTQUg();
    init_dist2();
  }
});

// node_modules/@orpc/contract/dist/shared/contract.D_dZrO__.mjs
function mergeErrorMap(errorMap1, errorMap2) {
  return { ...errorMap1, ...errorMap2 };
}
async function validateORPCError(map, error) {
  const { code, status, message, data, cause, defined } = error;
  const config2 = map?.[error.code];
  if (!config2 || fallbackORPCErrorStatus(error.code, config2.status) !== error.status) {
    return defined ? new ORPCError(code, { defined: false, status, message, data, cause }) : error;
  }
  if (!config2.data) {
    return defined ? error : new ORPCError(code, { defined: true, status, message, data, cause });
  }
  const validated = await config2.data["~standard"].validate(error.data);
  if (validated.issues) {
    return defined ? new ORPCError(code, { defined: false, status, message, data, cause }) : error;
  }
  return new ORPCError(code, { defined: true, status, message, data: validated.value, cause });
}
function isContractProcedure(item) {
  if (item instanceof ContractProcedure) {
    return true;
  }
  return (typeof item === "object" || typeof item === "function") && item !== null && "~orpc" in item && typeof item["~orpc"] === "object" && item["~orpc"] !== null && "errorMap" in item["~orpc"] && "route" in item["~orpc"] && "meta" in item["~orpc"];
}
var ValidationError, ContractProcedure;
var init_contract_D_dZrO = __esm({
  "node_modules/@orpc/contract/dist/shared/contract.D_dZrO__.mjs"() {
    init_dist3();
    ValidationError = class extends Error {
      issues;
      data;
      constructor(options) {
        super(options.message, options);
        this.issues = options.issues;
        this.data = options.data;
      }
    };
    ContractProcedure = class {
      /**
       * This property holds the defined options for the contract procedure.
       */
      "~orpc";
      constructor(def) {
        if (def.route?.successStatus && isORPCErrorStatus(def.route.successStatus)) {
          throw new Error("[ContractProcedure] Invalid successStatus.");
        }
        if (Object.values(def.errorMap).some((val) => val && val.status && !isORPCErrorStatus(val.status))) {
          throw new Error("[ContractProcedure] Invalid error status code.");
        }
        this["~orpc"] = def;
      }
    };
  }
});

// node_modules/@orpc/contract/dist/index.mjs
function mergeMeta(meta1, meta2) {
  return { ...meta1, ...meta2 };
}
function mergeRoute(a, b) {
  return { ...a, ...b };
}
function prefixRoute(route, prefix) {
  if (!route.path) {
    return route;
  }
  return {
    ...route,
    path: `${prefix}${route.path}`
  };
}
function unshiftTagRoute(route, tags) {
  return {
    ...route,
    tags: [...tags, ...route.tags ?? []]
  };
}
function mergePrefix(a, b) {
  return a ? `${a}${b}` : b;
}
function mergeTags(a, b) {
  return a ? [...a, ...b] : b;
}
function enhanceRoute(route, options) {
  let router2 = route;
  if (options.prefix) {
    router2 = prefixRoute(router2, options.prefix);
  }
  if (options.tags?.length) {
    router2 = unshiftTagRoute(router2, options.tags);
  }
  return router2;
}
function getContractRouter(router2, path21) {
  let current = router2;
  for (let i = 0; i < path21.length; i++) {
    const segment = path21[i];
    if (!current) {
      return void 0;
    }
    if (isContractProcedure(current)) {
      return void 0;
    }
    current = current[segment];
  }
  return current;
}
function enhanceContractRouter(router2, options) {
  if (isContractProcedure(router2)) {
    const enhanced2 = new ContractProcedure({
      ...router2["~orpc"],
      errorMap: mergeErrorMap(options.errorMap, router2["~orpc"].errorMap),
      route: enhanceRoute(router2["~orpc"].route, options)
    });
    return enhanced2;
  }
  const enhanced = {};
  for (const key in router2) {
    enhanced[key] = enhanceContractRouter(router2[key], options);
  }
  return enhanced;
}
function fallbackContractConfig(key, value2) {
  if (value2 === void 0) {
    return DEFAULT_CONFIG[key];
  }
  return value2;
}
function eventIterator(yields, returns) {
  return {
    "~standard": {
      [EVENT_ITERATOR_DETAILS_SYMBOL]: { yields, returns },
      vendor: "orpc",
      version: 1,
      validate(iterator) {
        if (!isAsyncIteratorObject(iterator)) {
          return { issues: [{ message: "Expect event iterator", path: [] }] };
        }
        const mapped = mapEventIterator(iterator, {
          async value(value2, done) {
            const schema = done ? returns : yields;
            if (!schema) {
              return value2;
            }
            const result = await schema["~standard"].validate(value2);
            if (result.issues) {
              throw new ORPCError("EVENT_ITERATOR_VALIDATION_FAILED", {
                message: "Event iterator validation failed",
                cause: new ValidationError({
                  issues: result.issues,
                  message: "Event iterator validation failed",
                  data: value2
                })
              });
            }
            return result.value;
          },
          error: async (error) => error
        });
        return { value: mapped };
      }
    }
  };
}
function type(...[map]) {
  return {
    "~standard": {
      vendor: "custom",
      version: 1,
      async validate(value2) {
        if (map) {
          return { value: await map(value2) };
        }
        return { value: value2 };
      }
    }
  };
}
var ContractBuilder, oc, DEFAULT_CONFIG, EVENT_ITERATOR_DETAILS_SYMBOL;
var init_dist4 = __esm({
  "node_modules/@orpc/contract/dist/index.mjs"() {
    init_contract_D_dZrO();
    init_contract_D_dZrO();
    init_dist3();
    init_dist3();
    init_dist();
    init_dist();
    ContractBuilder = class _ContractBuilder extends ContractProcedure {
      constructor(def) {
        super(def);
        this["~orpc"].prefix = def.prefix;
        this["~orpc"].tags = def.tags;
      }
      /**
       * Sets or overrides the initial meta.
       *
       * @see {@link https://orpc.dev/docs/metadata Metadata Docs}
       */
      $meta(initialMeta) {
        return new _ContractBuilder({
          ...this["~orpc"],
          meta: initialMeta
        });
      }
      /**
       * Sets or overrides the initial route.
       * This option is typically relevant when integrating with OpenAPI.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing OpenAPI Routing Docs}
       * @see {@link https://orpc.dev/docs/openapi/input-output-structure OpenAPI Input/Output Structure Docs}
       */
      $route(initialRoute) {
        return new _ContractBuilder({
          ...this["~orpc"],
          route: initialRoute
        });
      }
      /**
       * Adds type-safe custom errors to the contract.
       * The provided errors are spared-merged with any existing errors in the contract.
       *
       * @see {@link https://orpc.dev/docs/error-handling#type%E2%80%90safe-error-handling Type-Safe Error Handling Docs}
       */
      errors(errors) {
        return new _ContractBuilder({
          ...this["~orpc"],
          errorMap: mergeErrorMap(this["~orpc"].errorMap, errors)
        });
      }
      /**
       * Sets or updates the metadata for the contract.
       * The provided metadata is spared-merged with any existing metadata in the contract.
       *
       * @see {@link https://orpc.dev/docs/metadata Metadata Docs}
       */
      meta(meta) {
        return new _ContractBuilder({
          ...this["~orpc"],
          meta: mergeMeta(this["~orpc"].meta, meta)
        });
      }
      /**
       * Sets or updates the route definition for the contract.
       * The provided route is spared-merged with any existing route in the contract.
       * This option is typically relevant when integrating with OpenAPI.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing OpenAPI Routing Docs}
       * @see {@link https://orpc.dev/docs/openapi/input-output-structure OpenAPI Input/Output Structure Docs}
       */
      route(route) {
        return new _ContractBuilder({
          ...this["~orpc"],
          route: mergeRoute(this["~orpc"].route, route)
        });
      }
      /**
       * Defines the input validation schema for the contract.
       *
       * @see {@link https://orpc.dev/docs/procedure#input-output-validation Input Validation Docs}
       */
      input(schema) {
        return new _ContractBuilder({
          ...this["~orpc"],
          inputSchema: schema
        });
      }
      /**
       * Defines the output validation schema for the contract.
       *
       * @see {@link https://orpc.dev/docs/procedure#input-output-validation Output Validation Docs}
       */
      output(schema) {
        return new _ContractBuilder({
          ...this["~orpc"],
          outputSchema: schema
        });
      }
      /**
       * Prefixes all procedures in the contract router.
       * The provided prefix is post-appended to any existing router prefix.
       *
       * @note This option does not affect procedures that do not define a path in their route definition.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing#route-prefixes OpenAPI Route Prefixes Docs}
       */
      prefix(prefix) {
        return new _ContractBuilder({
          ...this["~orpc"],
          prefix: mergePrefix(this["~orpc"].prefix, prefix)
        });
      }
      /**
       * Adds tags to all procedures in the contract router.
       * This helpful when you want to group procedures together in the OpenAPI specification.
       *
       * @see {@link https://orpc.dev/docs/openapi/openapi-specification#operation-metadata OpenAPI Operation Metadata Docs}
       */
      tag(...tags) {
        return new _ContractBuilder({
          ...this["~orpc"],
          tags: mergeTags(this["~orpc"].tags, tags)
        });
      }
      /**
       * Applies all of the previously defined options to the specified contract router.
       *
       * @see {@link https://orpc.dev/docs/router#extending-router Extending Router Docs}
       */
      router(router2) {
        return enhanceContractRouter(router2, this["~orpc"]);
      }
    };
    oc = new ContractBuilder({
      errorMap: {},
      route: {},
      meta: {}
    });
    DEFAULT_CONFIG = {
      defaultMethod: "POST",
      defaultSuccessStatus: 200,
      defaultSuccessDescription: "OK",
      defaultInputStructure: "compact",
      defaultOutputStructure: "compact"
    };
    EVENT_ITERATOR_DETAILS_SYMBOL = Symbol("ORPC_EVENT_ITERATOR_DETAILS");
  }
});

// node_modules/@orpc/server/dist/shared/server.Ds4HPpvH.mjs
function lazy(loader, meta = {}) {
  return {
    [LAZY_SYMBOL]: {
      loader,
      meta
    }
  };
}
function isLazy(item) {
  return (typeof item === "object" || typeof item === "function") && item !== null && LAZY_SYMBOL in item;
}
function getLazyMeta(lazied) {
  return lazied[LAZY_SYMBOL].meta;
}
function unlazy(lazied) {
  return isLazy(lazied) ? lazied[LAZY_SYMBOL].loader() : Promise.resolve({ default: lazied });
}
function isStartWithMiddlewares(middlewares, compare) {
  if (compare.length > middlewares.length) {
    return false;
  }
  for (let i = 0; i < middlewares.length; i++) {
    if (compare[i] === void 0) {
      return true;
    }
    if (middlewares[i] !== compare[i]) {
      return false;
    }
  }
  return true;
}
function mergeMiddlewares(first, second, options) {
  if (options.dedupeLeading && isStartWithMiddlewares(second, first)) {
    return second;
  }
  return [...first, ...second];
}
function addMiddleware(middlewares, addition) {
  return [...middlewares, addition];
}
function isProcedure(item) {
  if (item instanceof Procedure) {
    return true;
  }
  return isContractProcedure(item) && "middlewares" in item["~orpc"] && "inputValidationIndex" in item["~orpc"] && "outputValidationIndex" in item["~orpc"] && "handler" in item["~orpc"];
}
function mergeCurrentContext(context, other) {
  return { ...context, ...other };
}
function createORPCErrorConstructorMap(errors) {
  const proxy = new Proxy(errors, {
    get(target, code) {
      if (typeof code !== "string") {
        return Reflect.get(target, code);
      }
      const item = (...rest) => {
        const options = resolveMaybeOptionalOptions(rest);
        const config2 = errors[code];
        return new ORPCError(code, {
          defined: Boolean(config2),
          status: config2?.status,
          message: options.message ?? config2?.message,
          data: options.data,
          cause: options.cause
        });
      };
      return item;
    }
  });
  return proxy;
}
function middlewareOutputFn(output) {
  return { output, context: {} };
}
function createProcedureClient(lazyableProcedure, ...rest) {
  const options = resolveMaybeOptionalOptions(rest);
  return async (...[input, callerOptions]) => {
    const path21 = toArray(options.path);
    const { default: procedure } = await unlazy(lazyableProcedure);
    const clientContext = callerOptions?.context ?? {};
    const context = await value(options.context ?? {}, clientContext);
    const errors = createORPCErrorConstructorMap(procedure["~orpc"].errorMap);
    const validateError = async (e) => {
      if (e instanceof ORPCError) {
        return await validateORPCError(procedure["~orpc"].errorMap, e);
      }
      return e;
    };
    try {
      const output = await runWithSpan(
        { name: "call_procedure", signal: callerOptions?.signal },
        (span) => {
          span?.setAttribute("procedure.path", [...path21]);
          return intercept(
            toArray(options.interceptors),
            {
              context,
              input,
              // input only optional when it undefinable so we can safely cast it
              errors,
              path: path21,
              procedure,
              signal: callerOptions?.signal,
              lastEventId: callerOptions?.lastEventId
            },
            (interceptorOptions) => executeProcedureInternal(interceptorOptions.procedure, interceptorOptions)
          );
        }
      );
      if (isAsyncIteratorObject(output)) {
        if (output instanceof HibernationEventIterator) {
          return output;
        }
        return overlayProxy(output, mapEventIterator(
          asyncIteratorWithSpan(
            { name: "consume_event_iterator_output", signal: callerOptions?.signal },
            output
          ),
          {
            value: (v) => v,
            error: (e) => validateError(e)
          }
        ));
      }
      return output;
    } catch (e) {
      throw await validateError(e);
    }
  };
}
async function validateInput(procedure, input) {
  const schema = procedure["~orpc"].inputSchema;
  if (!schema) {
    return input;
  }
  return runWithSpan(
    { name: "validate_input" },
    async () => {
      const result = await schema["~standard"].validate(input);
      if (result.issues) {
        throw new ORPCError("BAD_REQUEST", {
          message: "Input validation failed",
          data: {
            issues: result.issues
          },
          cause: new ValidationError({
            message: "Input validation failed",
            issues: result.issues,
            data: input
          })
        });
      }
      return result.value;
    }
  );
}
async function validateOutput(procedure, output) {
  const schema = procedure["~orpc"].outputSchema;
  if (!schema) {
    return output;
  }
  return runWithSpan(
    { name: "validate_output" },
    async () => {
      const result = await schema["~standard"].validate(output);
      if (result.issues) {
        throw new ORPCError("INTERNAL_SERVER_ERROR", {
          message: "Output validation failed",
          cause: new ValidationError({
            message: "Output validation failed",
            issues: result.issues,
            data: output
          })
        });
      }
      return result.value;
    }
  );
}
async function executeProcedureInternal(procedure, options) {
  const middlewares = procedure["~orpc"].middlewares;
  const inputValidationIndex = Math.min(Math.max(0, procedure["~orpc"].inputValidationIndex), middlewares.length);
  const outputValidationIndex = Math.min(Math.max(0, procedure["~orpc"].outputValidationIndex), middlewares.length);
  const next = async (index, context, input) => {
    let currentInput = input;
    if (index === inputValidationIndex) {
      currentInput = await validateInput(procedure, currentInput);
    }
    const mid = middlewares[index];
    const output = mid ? await runWithSpan(
      { name: `middleware.${mid.name}`, signal: options.signal },
      async (span) => {
        span?.setAttribute("middleware.index", index);
        span?.setAttribute("middleware.name", mid.name);
        const result = await mid({
          ...options,
          context,
          next: async (...[nextOptions]) => {
            const nextContext = nextOptions?.context ?? {};
            return {
              output: await next(index + 1, mergeCurrentContext(context, nextContext), currentInput),
              context: nextContext
            };
          }
        }, currentInput, middlewareOutputFn);
        return result.output;
      }
    ) : await runWithSpan(
      { name: "handler", signal: options.signal },
      () => procedure["~orpc"].handler({ ...options, context, input: currentInput })
    );
    if (index === outputValidationIndex) {
      return await validateOutput(procedure, output);
    }
    return output;
  };
  return next(0, options.context, options.input);
}
function setHiddenRouterContract(router2, contract) {
  return new Proxy(router2, {
    get(target, key) {
      if (key === HIDDEN_ROUTER_CONTRACT_SYMBOL) {
        return contract;
      }
      return Reflect.get(target, key);
    }
  });
}
function getHiddenRouterContract(router2) {
  return router2[HIDDEN_ROUTER_CONTRACT_SYMBOL];
}
function getRouter(router2, path21) {
  let current = router2;
  for (let i = 0; i < path21.length; i++) {
    const segment = path21[i];
    if (!current) {
      return void 0;
    }
    if (isProcedure(current)) {
      return void 0;
    }
    if (!isLazy(current)) {
      current = current[segment];
      continue;
    }
    const lazied = current;
    const rest = path21.slice(i);
    return lazy(async () => {
      const unwrapped = await unlazy(lazied);
      const next = getRouter(unwrapped.default, rest);
      return unlazy(next);
    }, getLazyMeta(lazied));
  }
  return current;
}
function createAccessibleLazyRouter(lazied) {
  const recursive = new Proxy(lazied, {
    get(target, key) {
      if (typeof key !== "string") {
        return Reflect.get(target, key);
      }
      const next = getRouter(lazied, [key]);
      return createAccessibleLazyRouter(next);
    }
  });
  return recursive;
}
function enhanceRouter(router2, options) {
  if (isLazy(router2)) {
    const laziedMeta = getLazyMeta(router2);
    const enhancedPrefix = laziedMeta?.prefix ? mergePrefix(options.prefix, laziedMeta?.prefix) : options.prefix;
    const enhanced2 = lazy(async () => {
      const { default: unlaziedRouter } = await unlazy(router2);
      const enhanced3 = enhanceRouter(unlaziedRouter, options);
      return unlazy(enhanced3);
    }, {
      ...laziedMeta,
      prefix: enhancedPrefix
    });
    const accessible = createAccessibleLazyRouter(enhanced2);
    return accessible;
  }
  if (isProcedure(router2)) {
    const newMiddlewares = mergeMiddlewares(options.middlewares, router2["~orpc"].middlewares, { dedupeLeading: options.dedupeLeadingMiddlewares });
    const newMiddlewareAdded = newMiddlewares.length - router2["~orpc"].middlewares.length;
    const enhanced2 = new Procedure({
      ...router2["~orpc"],
      route: enhanceRoute(router2["~orpc"].route, options),
      errorMap: mergeErrorMap(options.errorMap, router2["~orpc"].errorMap),
      middlewares: newMiddlewares,
      inputValidationIndex: router2["~orpc"].inputValidationIndex + newMiddlewareAdded,
      outputValidationIndex: router2["~orpc"].outputValidationIndex + newMiddlewareAdded
    });
    return enhanced2;
  }
  const enhanced = {};
  for (const key in router2) {
    enhanced[key] = enhanceRouter(router2[key], options);
  }
  return enhanced;
}
function traverseContractProcedures(options, callback, lazyOptions = []) {
  let currentRouter = options.router;
  const hiddenContract = getHiddenRouterContract(options.router);
  if (hiddenContract !== void 0) {
    currentRouter = hiddenContract;
  }
  if (isLazy(currentRouter)) {
    lazyOptions.push({
      router: currentRouter,
      path: options.path
    });
  } else if (isContractProcedure(currentRouter)) {
    callback({
      contract: currentRouter,
      path: options.path
    });
  } else {
    for (const key in currentRouter) {
      traverseContractProcedures(
        {
          router: currentRouter[key],
          path: [...options.path, key]
        },
        callback,
        lazyOptions
      );
    }
  }
  return lazyOptions;
}
async function resolveContractProcedures(options, callback) {
  const pending = [options];
  for (const options2 of pending) {
    const lazyOptions = traverseContractProcedures(options2, callback);
    for (const options3 of lazyOptions) {
      const { default: router2 } = await unlazy(options3.router);
      pending.push({
        router: router2,
        path: options3.path
      });
    }
  }
}
async function unlazyRouter(router2) {
  if (isProcedure(router2)) {
    return router2;
  }
  const unlazied = {};
  for (const key in router2) {
    const item = router2[key];
    const { default: unlaziedRouter } = await unlazy(item);
    unlazied[key] = await unlazyRouter(unlaziedRouter);
  }
  return unlazied;
}
function createAssertedLazyProcedure(lazied) {
  const lazyProcedure = lazy(async () => {
    const { default: maybeProcedure } = await unlazy(lazied);
    if (!isProcedure(maybeProcedure)) {
      throw new Error(`
            Expected a lazy<procedure> but got lazy<unknown>.
            This should be caught by TypeScript compilation.
            Please report this issue if this makes you feel uncomfortable.
        `);
    }
    return { default: maybeProcedure };
  }, getLazyMeta(lazied));
  return lazyProcedure;
}
function createContractedProcedure(procedure, contract) {
  return new Procedure({
    ...procedure["~orpc"],
    errorMap: contract["~orpc"].errorMap,
    route: contract["~orpc"].route,
    meta: contract["~orpc"].meta
  });
}
function call(procedure, input, ...rest) {
  const options = resolveMaybeOptionalOptions(rest);
  return createProcedureClient(procedure, options)(input, options);
}
var LAZY_SYMBOL, Procedure, HIDDEN_ROUTER_CONTRACT_SYMBOL;
var init_server_Ds4HPpvH = __esm({
  "node_modules/@orpc/server/dist/shared/server.Ds4HPpvH.mjs"() {
    init_dist4();
    init_dist();
    init_dist3();
    init_dist2();
    LAZY_SYMBOL = Symbol("ORPC_LAZY_SYMBOL");
    Procedure = class {
      /**
       * This property holds the defined options.
       */
      "~orpc";
      constructor(def) {
        this["~orpc"] = def;
      }
    };
    HIDDEN_ROUTER_CONTRACT_SYMBOL = Symbol("ORPC_HIDDEN_ROUTER_CONTRACT");
  }
});

// node_modules/@orpc/server/dist/index.mjs
var dist_exports = {};
__export(dist_exports, {
  AsyncIteratorClass: () => AsyncIteratorClass,
  Builder: () => Builder,
  DecoratedProcedure: () => DecoratedProcedure,
  EventPublisher: () => EventPublisher,
  LAZY_SYMBOL: () => LAZY_SYMBOL,
  ORPCError: () => ORPCError,
  Procedure: () => Procedure,
  ValidationError: () => ValidationError,
  addMiddleware: () => addMiddleware,
  call: () => call,
  createAccessibleLazyRouter: () => createAccessibleLazyRouter,
  createActionableClient: () => createActionableClient,
  createAssertedLazyProcedure: () => createAssertedLazyProcedure,
  createContractedProcedure: () => createContractedProcedure,
  createORPCErrorConstructorMap: () => createORPCErrorConstructorMap,
  createProcedureClient: () => createProcedureClient,
  createRouterClient: () => createRouterClient,
  decorateMiddleware: () => decorateMiddleware,
  enhanceRouter: () => enhanceRouter,
  eventIterator: () => eventIterator,
  eventIteratorToStream: () => asyncIteratorToStream,
  eventIteratorToUnproxiedDataStream: () => asyncIteratorToUnproxiedDataStream,
  fallbackConfig: () => fallbackConfig,
  getEventMeta: () => getEventMeta,
  getHiddenRouterContract: () => getHiddenRouterContract,
  getLazyMeta: () => getLazyMeta,
  getRouter: () => getRouter,
  implement: () => implement,
  implementerInternal: () => implementerInternal,
  inferRPCMethodFromRouter: () => inferRPCMethodFromRouter,
  isDefinedError: () => isDefinedError,
  isLazy: () => isLazy,
  isProcedure: () => isProcedure,
  isStartWithMiddlewares: () => isStartWithMiddlewares,
  lazy: () => lazy,
  mergeCurrentContext: () => mergeCurrentContext,
  mergeMiddlewares: () => mergeMiddlewares,
  middlewareOutputFn: () => middlewareOutputFn,
  onError: () => onError,
  onFinish: () => onFinish,
  onStart: () => onStart,
  onSuccess: () => onSuccess,
  os: () => os,
  resolveContractProcedures: () => resolveContractProcedures,
  safe: () => safe,
  setHiddenRouterContract: () => setHiddenRouterContract,
  streamToEventIterator: () => streamToAsyncIteratorClass,
  traverseContractProcedures: () => traverseContractProcedures,
  type: () => type,
  unlazy: () => unlazy,
  unlazyRouter: () => unlazyRouter,
  validateORPCError: () => validateORPCError,
  withEventMeta: () => withEventMeta
});
function fallbackConfig(key, value2) {
  if (value2 === void 0) {
    return DEFAULT_CONFIG2[key];
  }
  return value2;
}
function decorateMiddleware(middleware) {
  const decorated = ((...args2) => middleware(...args2));
  decorated.mapInput = (mapInput) => {
    const mapped = decorateMiddleware(
      (options, input, ...rest) => middleware(options, mapInput(input), ...rest)
    );
    return mapped;
  };
  decorated.concat = (concatMiddleware, mapInput) => {
    const mapped = mapInput ? decorateMiddleware(concatMiddleware).mapInput(mapInput) : concatMiddleware;
    const concatted = decorateMiddleware((options, input, output, ...rest) => {
      const merged = middleware({
        ...options,
        next: (...[nextOptions1]) => mapped({
          ...options,
          context: { ...options.context, ...nextOptions1?.context },
          next: (...[nextOptions2]) => options.next({ context: { ...nextOptions1?.context, ...nextOptions2?.context } })
        }, input, output, ...rest)
      }, input, output, ...rest);
      return merged;
    });
    return concatted;
  };
  return decorated;
}
function createActionableClient(client) {
  const action = async (input) => {
    try {
      return [null, await client(input)];
    } catch (error) {
      if (error instanceof Error && "digest" in error && typeof error.digest === "string" && error.digest.startsWith("NEXT_")) {
        throw error;
      }
      if (error instanceof Response && "options" in error && isObject(error.options) || isObject(error) && error.isNotFound === true) {
        throw error;
      }
      return [toORPCError(error).toJSON(), void 0];
    }
  };
  return action;
}
function implementerInternal(contract, config2, middlewares) {
  if (isContractProcedure(contract)) {
    const impl2 = new Builder({
      ...contract["~orpc"],
      config: config2,
      middlewares,
      inputValidationIndex: fallbackConfig("initialInputValidationIndex", config2?.initialInputValidationIndex) + middlewares.length,
      outputValidationIndex: fallbackConfig("initialOutputValidationIndex", config2?.initialOutputValidationIndex) + middlewares.length,
      dedupeLeadingMiddlewares: fallbackConfig("dedupeLeadingMiddlewares", config2.dedupeLeadingMiddlewares)
    });
    return impl2;
  }
  const impl = new Proxy(contract, {
    get: (target, key) => {
      if (typeof key !== "string") {
        return Reflect.get(target, key);
      }
      let method;
      if (key === "middleware") {
        method = (mid) => decorateMiddleware(mid);
      } else if (key === "use") {
        method = (mid) => {
          return implementerInternal(
            contract,
            config2,
            addMiddleware(middlewares, mid)
          );
        };
      } else if (key === "router") {
        method = (router2) => {
          const adapted = enhanceRouter(router2, {
            middlewares,
            errorMap: {},
            prefix: void 0,
            tags: void 0,
            dedupeLeadingMiddlewares: fallbackConfig("dedupeLeadingMiddlewares", config2.dedupeLeadingMiddlewares)
          });
          return setHiddenRouterContract(adapted, contract);
        };
      } else if (key === "lazy") {
        method = (loader) => {
          const adapted = enhanceRouter(lazy(loader), {
            middlewares,
            errorMap: {},
            prefix: void 0,
            tags: void 0,
            dedupeLeadingMiddlewares: fallbackConfig("dedupeLeadingMiddlewares", config2.dedupeLeadingMiddlewares)
          });
          return setHiddenRouterContract(adapted, contract);
        };
      }
      const next = getContractRouter(target, [key]);
      if (!next) {
        return method ?? next;
      }
      const nextImpl = implementerInternal(next, config2, middlewares);
      if (method) {
        return new Proxy(method, {
          get(_, key2) {
            return Reflect.get(nextImpl, key2);
          }
        });
      }
      return nextImpl;
    }
  });
  return impl;
}
function implement(contract, config2 = {}) {
  const implInternal = implementerInternal(contract, config2, []);
  const impl = new Proxy(implInternal, {
    get: (target, key) => {
      let method;
      if (key === "$context") {
        method = () => impl;
      } else if (key === "$config") {
        method = (config22) => implement(contract, config22);
      }
      const next = Reflect.get(target, key);
      if (!method || !next || typeof next !== "function" && typeof next !== "object") {
        return method || next;
      }
      return new Proxy(method, {
        get(_, key2) {
          return Reflect.get(next, key2);
        }
      });
    }
  });
  return impl;
}
function inferRPCMethodFromRouter(router2) {
  return async (_, path21) => {
    const { default: procedure } = await unlazy(getRouter(router2, path21));
    if (!isProcedure(procedure)) {
      throw new Error(
        `[inferRPCMethodFromRouter] No valid procedure found at path "${path21.join(".")}". This may happen when the router is not properly configured.`
      );
    }
    const method = fallbackContractConfig("defaultMethod", procedure["~orpc"].route.method);
    return method === "HEAD" ? "GET" : method;
  };
}
function createRouterClient(router2, ...rest) {
  const options = resolveMaybeOptionalOptions(rest);
  if (isProcedure(router2)) {
    const caller = createProcedureClient(router2, options);
    return caller;
  }
  const procedureCaller = isLazy(router2) ? createProcedureClient(createAssertedLazyProcedure(router2), options) : {};
  const recursive = new Proxy(procedureCaller, {
    get(target, key) {
      if (typeof key !== "string") {
        return Reflect.get(target, key);
      }
      const next = getRouter(router2, [key]);
      if (!next) {
        return Reflect.get(target, key);
      }
      return createRouterClient(next, {
        ...rest[0],
        path: [...rest[0]?.path ?? [], key]
      });
    }
  });
  return recursive;
}
var DEFAULT_CONFIG2, DecoratedProcedure, Builder, os;
var init_dist5 = __esm({
  "node_modules/@orpc/server/dist/index.mjs"() {
    init_dist4();
    init_dist4();
    init_server_Ds4HPpvH();
    init_server_Ds4HPpvH();
    init_dist3();
    init_dist3();
    init_dist();
    init_dist();
    init_dist2();
    DEFAULT_CONFIG2 = {
      initialInputValidationIndex: 0,
      initialOutputValidationIndex: 0,
      dedupeLeadingMiddlewares: true
    };
    DecoratedProcedure = class _DecoratedProcedure extends Procedure {
      /**
       * Adds type-safe custom errors.
       * The provided errors are spared-merged with any existing errors.
       *
       * @see {@link https://orpc.dev/docs/error-handling#type%E2%80%90safe-error-handling Type-Safe Error Handling Docs}
       */
      errors(errors) {
        return new _DecoratedProcedure({
          ...this["~orpc"],
          errorMap: mergeErrorMap(this["~orpc"].errorMap, errors)
        });
      }
      /**
       * Sets or updates the metadata.
       * The provided metadata is spared-merged with any existing metadata.
       *
       * @see {@link https://orpc.dev/docs/metadata Metadata Docs}
       */
      meta(meta) {
        return new _DecoratedProcedure({
          ...this["~orpc"],
          meta: mergeMeta(this["~orpc"].meta, meta)
        });
      }
      /**
       * Sets or updates the route definition.
       * The provided route is spared-merged with any existing route.
       * This option is typically relevant when integrating with OpenAPI.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing OpenAPI Routing Docs}
       * @see {@link https://orpc.dev/docs/openapi/input-output-structure OpenAPI Input/Output Structure Docs}
       */
      route(route) {
        return new _DecoratedProcedure({
          ...this["~orpc"],
          route: mergeRoute(this["~orpc"].route, route)
        });
      }
      use(middleware, mapInput) {
        const mapped = mapInput ? decorateMiddleware(middleware).mapInput(mapInput) : middleware;
        return new _DecoratedProcedure({
          ...this["~orpc"],
          middlewares: addMiddleware(this["~orpc"].middlewares, mapped)
        });
      }
      /**
       * Make this procedure callable (works like a function while still being a procedure).
       *
       * @see {@link https://orpc.dev/docs/client/server-side Server-side Client Docs}
       */
      callable(...rest) {
        const client = createProcedureClient(this, ...rest);
        return new Proxy(client, {
          get: (target, key) => {
            return Reflect.has(this, key) ? Reflect.get(this, key) : Reflect.get(target, key);
          },
          has: (target, key) => {
            return Reflect.has(this, key) || Reflect.has(target, key);
          }
        });
      }
      /**
       * Make this procedure compatible with server action.
       *
       * @see {@link https://orpc.dev/docs/server-action Server Action Docs}
       */
      actionable(...rest) {
        const action = createActionableClient(createProcedureClient(this, ...rest));
        return new Proxy(action, {
          get: (target, key) => {
            return Reflect.has(this, key) ? Reflect.get(this, key) : Reflect.get(target, key);
          },
          has: (target, key) => {
            return Reflect.has(this, key) || Reflect.has(target, key);
          }
        });
      }
    };
    Builder = class _Builder {
      /**
       * This property holds the defined options.
       */
      "~orpc";
      constructor(def) {
        this["~orpc"] = def;
      }
      /**
       * Sets or overrides the config.
       *
       * @see {@link https://orpc.dev/docs/client/server-side#middlewares-order Middlewares Order Docs}
       * @see {@link https://orpc.dev/docs/best-practices/dedupe-middleware#configuration Dedupe Middleware Docs}
       */
      $config(config2) {
        const inputValidationCount = this["~orpc"].inputValidationIndex - fallbackConfig("initialInputValidationIndex", this["~orpc"].config.initialInputValidationIndex);
        const outputValidationCount = this["~orpc"].outputValidationIndex - fallbackConfig("initialOutputValidationIndex", this["~orpc"].config.initialOutputValidationIndex);
        return new _Builder({
          ...this["~orpc"],
          config: config2,
          dedupeLeadingMiddlewares: fallbackConfig("dedupeLeadingMiddlewares", config2.dedupeLeadingMiddlewares),
          inputValidationIndex: fallbackConfig("initialInputValidationIndex", config2.initialInputValidationIndex) + inputValidationCount,
          outputValidationIndex: fallbackConfig("initialOutputValidationIndex", config2.initialOutputValidationIndex) + outputValidationCount
        });
      }
      /**
       * Set or override the initial context.
       *
       * @see {@link https://orpc.dev/docs/context Context Docs}
       */
      $context() {
        return new _Builder({
          ...this["~orpc"],
          middlewares: [],
          inputValidationIndex: fallbackConfig("initialInputValidationIndex", this["~orpc"].config.initialInputValidationIndex),
          outputValidationIndex: fallbackConfig("initialOutputValidationIndex", this["~orpc"].config.initialOutputValidationIndex)
        });
      }
      /**
       * Sets or overrides the initial meta.
       *
       * @see {@link https://orpc.dev/docs/metadata Metadata Docs}
       */
      $meta(initialMeta) {
        return new _Builder({
          ...this["~orpc"],
          meta: initialMeta
        });
      }
      /**
       * Sets or overrides the initial route.
       * This option is typically relevant when integrating with OpenAPI.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing OpenAPI Routing Docs}
       * @see {@link https://orpc.dev/docs/openapi/input-output-structure OpenAPI Input/Output Structure Docs}
       */
      $route(initialRoute) {
        return new _Builder({
          ...this["~orpc"],
          route: initialRoute
        });
      }
      /**
       * Sets or overrides the initial input schema.
       *
       * @see {@link https://orpc.dev/docs/procedure#initial-configuration Initial Procedure Configuration Docs}
       */
      $input(initialInputSchema) {
        return new _Builder({
          ...this["~orpc"],
          inputSchema: initialInputSchema
        });
      }
      /**
       * Creates a middleware.
       *
       * @see {@link https://orpc.dev/docs/middleware Middleware Docs}
       */
      middleware(middleware) {
        return decorateMiddleware(middleware);
      }
      /**
       * Adds type-safe custom errors.
       * The provided errors are spared-merged with any existing errors.
       *
       * @see {@link https://orpc.dev/docs/error-handling#type%E2%80%90safe-error-handling Type-Safe Error Handling Docs}
       */
      errors(errors) {
        return new _Builder({
          ...this["~orpc"],
          errorMap: mergeErrorMap(this["~orpc"].errorMap, errors)
        });
      }
      use(middleware, mapInput) {
        const mapped = mapInput ? decorateMiddleware(middleware).mapInput(mapInput) : middleware;
        return new _Builder({
          ...this["~orpc"],
          middlewares: addMiddleware(this["~orpc"].middlewares, mapped)
        });
      }
      /**
       * Sets or updates the metadata.
       * The provided metadata is spared-merged with any existing metadata.
       *
       * @see {@link https://orpc.dev/docs/metadata Metadata Docs}
       */
      meta(meta) {
        return new _Builder({
          ...this["~orpc"],
          meta: mergeMeta(this["~orpc"].meta, meta)
        });
      }
      /**
       * Sets or updates the route definition.
       * The provided route is spared-merged with any existing route.
       * This option is typically relevant when integrating with OpenAPI.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing OpenAPI Routing Docs}
       * @see {@link https://orpc.dev/docs/openapi/input-output-structure OpenAPI Input/Output Structure Docs}
       */
      route(route) {
        return new _Builder({
          ...this["~orpc"],
          route: mergeRoute(this["~orpc"].route, route)
        });
      }
      /**
       * Defines the input validation schema.
       *
       * @see {@link https://orpc.dev/docs/procedure#input-output-validation Input Validation Docs}
       */
      input(schema) {
        return new _Builder({
          ...this["~orpc"],
          inputSchema: schema,
          inputValidationIndex: fallbackConfig("initialInputValidationIndex", this["~orpc"].config.initialInputValidationIndex) + this["~orpc"].middlewares.length
        });
      }
      /**
       * Defines the output validation schema.
       *
       * @see {@link https://orpc.dev/docs/procedure#input-output-validation Output Validation Docs}
       */
      output(schema) {
        return new _Builder({
          ...this["~orpc"],
          outputSchema: schema,
          outputValidationIndex: fallbackConfig("initialOutputValidationIndex", this["~orpc"].config.initialOutputValidationIndex) + this["~orpc"].middlewares.length
        });
      }
      /**
       * Defines the handler of the procedure.
       *
       * @see {@link https://orpc.dev/docs/procedure Procedure Docs}
       */
      handler(handler) {
        return new DecoratedProcedure({
          ...this["~orpc"],
          handler
        });
      }
      /**
       * Prefixes all procedures in the router.
       * The provided prefix is post-appended to any existing router prefix.
       *
       * @note This option does not affect procedures that do not define a path in their route definition.
       *
       * @see {@link https://orpc.dev/docs/openapi/routing#route-prefixes OpenAPI Route Prefixes Docs}
       */
      prefix(prefix) {
        return new _Builder({
          ...this["~orpc"],
          prefix: mergePrefix(this["~orpc"].prefix, prefix)
        });
      }
      /**
       * Adds tags to all procedures in the router.
       * This helpful when you want to group procedures together in the OpenAPI specification.
       *
       * @see {@link https://orpc.dev/docs/openapi/openapi-specification#operation-metadata OpenAPI Operation Metadata Docs}
       */
      tag(...tags) {
        return new _Builder({
          ...this["~orpc"],
          tags: mergeTags(this["~orpc"].tags, tags)
        });
      }
      /**
       * Applies all of the previously defined options to the specified router.
       *
       * @see {@link https://orpc.dev/docs/router#extending-router Extending Router Docs}
       */
      router(router2) {
        return enhanceRouter(router2, this["~orpc"]);
      }
      /**
       * Create a lazy router
       * And applies all of the previously defined options to the specified router.
       *
       * @see {@link https://orpc.dev/docs/router#extending-router Extending Router Docs}
       */
      lazy(loader) {
        return enhanceRouter(lazy(loader), this["~orpc"]);
      }
    };
    os = new Builder({
      config: {},
      route: {},
      meta: {},
      errorMap: {},
      inputValidationIndex: fallbackConfig("initialInputValidationIndex"),
      outputValidationIndex: fallbackConfig("initialOutputValidationIndex"),
      middlewares: [],
      dedupeLeadingMiddlewares: true
    });
  }
});

// node_modules/@vercel/oidc/dist/get-context.js
var require_get_context = __commonJS({
  "node_modules/@vercel/oidc/dist/get-context.js"(exports, module) {
    "use strict";
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var get_context_exports = {};
    __export3(get_context_exports, {
      SYMBOL_FOR_REQ_CONTEXT: () => SYMBOL_FOR_REQ_CONTEXT,
      getContext: () => getContext3
    });
    module.exports = __toCommonJS(get_context_exports);
    var SYMBOL_FOR_REQ_CONTEXT = Symbol.for("@vercel/request-context");
    function getContext3() {
      const fromSymbol = globalThis;
      return fromSymbol[SYMBOL_FOR_REQ_CONTEXT]?.get?.() ?? {};
    }
  }
});

// node_modules/@vercel/oidc/dist/token-error.js
var require_token_error = __commonJS({
  "node_modules/@vercel/oidc/dist/token-error.js"(exports, module) {
    "use strict";
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var token_error_exports = {};
    __export3(token_error_exports, {
      VercelOidcTokenError: () => VercelOidcTokenError
    });
    module.exports = __toCommonJS(token_error_exports);
    var VercelOidcTokenError = class extends Error {
      constructor(message, cause) {
        super(message);
        this.name = "VercelOidcTokenError";
        this.cause = cause;
      }
      toString() {
        if (this.cause) {
          return `${this.name}: ${this.message}: ${this.cause}`;
        }
        return `${this.name}: ${this.message}`;
      }
    };
  }
});

// node_modules/@vercel/oidc/dist/token-io.js
var require_token_io = __commonJS({
  "node_modules/@vercel/oidc/dist/token-io.js"(exports, module) {
    "use strict";
    var __create2 = Object.create;
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __getProtoOf2 = Object.getPrototypeOf;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toESM2 = (mod, isNodeMode, target) => (target = mod != null ? __create2(__getProtoOf2(mod)) : {}, __copyProps2(
      // If the importer is in node compatibility mode or this is not an ESM
      // file that has been converted to a CommonJS file using a Babel-
      // compatible transform (i.e. "__esModule" has not been set), then set
      // "default" to the CommonJS "module.exports" for node compatibility.
      isNodeMode || !mod || !mod.__esModule ? __defProp3(target, "default", { value: mod, enumerable: true }) : target,
      mod
    ));
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var token_io_exports = {};
    __export3(token_io_exports, {
      findRootDir: () => findRootDir,
      getUserDataDir: () => getUserDataDir
    });
    module.exports = __toCommonJS(token_io_exports);
    var import_path4 = __toESM2(__require("path"));
    var import_fs3 = __toESM2(__require("fs"));
    var import_os2 = __toESM2(__require("os"));
    var import_token_error = require_token_error();
    function findRootDir() {
      try {
        let dir = process.cwd();
        while (dir !== import_path4.default.dirname(dir)) {
          const pkgPath = import_path4.default.join(dir, ".vercel");
          if (import_fs3.default.existsSync(pkgPath)) {
            return dir;
          }
          dir = import_path4.default.dirname(dir);
        }
      } catch (e) {
        throw new import_token_error.VercelOidcTokenError(
          "Token refresh only supported in node server environments"
        );
      }
      throw new import_token_error.VercelOidcTokenError("Unable to find root directory");
    }
    function getUserDataDir() {
      if (process.env.XDG_DATA_HOME) {
        return process.env.XDG_DATA_HOME;
      }
      switch (import_os2.default.platform()) {
        case "darwin":
          return import_path4.default.join(import_os2.default.homedir(), "Library/Application Support");
        case "linux":
          return import_path4.default.join(import_os2.default.homedir(), ".local/share");
        case "win32":
          if (process.env.LOCALAPPDATA) {
            return process.env.LOCALAPPDATA;
          }
          return null;
        default:
          return null;
      }
    }
  }
});

// node_modules/@vercel/oidc/dist/token-util.js
var require_token_util = __commonJS({
  "node_modules/@vercel/oidc/dist/token-util.js"(exports, module) {
    "use strict";
    var __create2 = Object.create;
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __getProtoOf2 = Object.getPrototypeOf;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toESM2 = (mod, isNodeMode, target) => (target = mod != null ? __create2(__getProtoOf2(mod)) : {}, __copyProps2(
      // If the importer is in node compatibility mode or this is not an ESM
      // file that has been converted to a CommonJS file using a Babel-
      // compatible transform (i.e. "__esModule" has not been set), then set
      // "default" to the CommonJS "module.exports" for node compatibility.
      isNodeMode || !mod || !mod.__esModule ? __defProp3(target, "default", { value: mod, enumerable: true }) : target,
      mod
    ));
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var token_util_exports = {};
    __export3(token_util_exports, {
      assertVercelOidcTokenResponse: () => assertVercelOidcTokenResponse,
      findProjectInfo: () => findProjectInfo,
      getTokenPayload: () => getTokenPayload,
      getVercelCliToken: () => getVercelCliToken,
      getVercelDataDir: () => getVercelDataDir,
      getVercelOidcToken: () => getVercelOidcToken3,
      isExpired: () => isExpired,
      loadToken: () => loadToken,
      saveToken: () => saveToken
    });
    module.exports = __toCommonJS(token_util_exports);
    var path21 = __toESM2(__require("path"));
    var fs14 = __toESM2(__require("fs"));
    var import_token_error = require_token_error();
    var import_token_io = require_token_io();
    function getVercelDataDir() {
      const vercelFolder = "com.vercel.cli";
      const dataDir = (0, import_token_io.getUserDataDir)();
      if (!dataDir) {
        return null;
      }
      return path21.join(dataDir, vercelFolder);
    }
    function getVercelCliToken() {
      const dataDir = getVercelDataDir();
      if (!dataDir) {
        return null;
      }
      const tokenPath = path21.join(dataDir, "auth.json");
      if (!fs14.existsSync(tokenPath)) {
        return null;
      }
      const token = fs14.readFileSync(tokenPath, "utf8");
      if (!token) {
        return null;
      }
      return JSON.parse(token).token;
    }
    async function getVercelOidcToken3(authToken, projectId, teamId) {
      try {
        const url = `https://api.vercel.com/v1/projects/${projectId}/token?source=vercel-oidc-refresh${teamId ? `&teamId=${teamId}` : ""}`;
        const res = await fetch(url, {
          method: "POST",
          headers: {
            Authorization: `Bearer ${authToken}`
          }
        });
        if (!res.ok) {
          throw new import_token_error.VercelOidcTokenError(
            `Failed to refresh OIDC token: ${res.statusText}`
          );
        }
        const tokenRes = await res.json();
        assertVercelOidcTokenResponse(tokenRes);
        return tokenRes;
      } catch (e) {
        throw new import_token_error.VercelOidcTokenError(`Failed to refresh OIDC token`, e);
      }
    }
    function assertVercelOidcTokenResponse(res) {
      if (!res || typeof res !== "object") {
        throw new TypeError("Expected an object");
      }
      if (!("token" in res) || typeof res.token !== "string") {
        throw new TypeError("Expected a string-valued token property");
      }
    }
    function findProjectInfo() {
      const dir = (0, import_token_io.findRootDir)();
      if (!dir) {
        throw new import_token_error.VercelOidcTokenError("Unable to find root directory");
      }
      try {
        const prjPath = path21.join(dir, ".vercel", "project.json");
        if (!fs14.existsSync(prjPath)) {
          throw new import_token_error.VercelOidcTokenError("project.json not found");
        }
        const prj = JSON.parse(fs14.readFileSync(prjPath, "utf8"));
        if (typeof prj.projectId !== "string" && typeof prj.orgId !== "string") {
          throw new TypeError("Expected a string-valued projectId property");
        }
        return { projectId: prj.projectId, teamId: prj.orgId };
      } catch (e) {
        throw new import_token_error.VercelOidcTokenError(`Unable to find project ID`, e);
      }
    }
    function saveToken(token, projectId) {
      try {
        const dir = (0, import_token_io.getUserDataDir)();
        if (!dir) {
          throw new import_token_error.VercelOidcTokenError("Unable to find user data directory");
        }
        const tokenPath = path21.join(dir, "com.vercel.token", `${projectId}.json`);
        const tokenJson = JSON.stringify(token);
        fs14.mkdirSync(path21.dirname(tokenPath), { mode: 504, recursive: true });
        fs14.writeFileSync(tokenPath, tokenJson);
        fs14.chmodSync(tokenPath, 432);
        return;
      } catch (e) {
        throw new import_token_error.VercelOidcTokenError(`Failed to save token`, e);
      }
    }
    function loadToken(projectId) {
      try {
        const dir = (0, import_token_io.getUserDataDir)();
        if (!dir) {
          return null;
        }
        const tokenPath = path21.join(dir, "com.vercel.token", `${projectId}.json`);
        if (!fs14.existsSync(tokenPath)) {
          return null;
        }
        const token = JSON.parse(fs14.readFileSync(tokenPath, "utf8"));
        assertVercelOidcTokenResponse(token);
        return token;
      } catch (e) {
        throw new import_token_error.VercelOidcTokenError(`Failed to load token`, e);
      }
    }
    function getTokenPayload(token) {
      const tokenParts = token.split(".");
      if (tokenParts.length !== 3) {
        throw new import_token_error.VercelOidcTokenError("Invalid token");
      }
      const base64 = tokenParts[1].replace(/-/g, "+").replace(/_/g, "/");
      const padded = base64.padEnd(
        base64.length + (4 - base64.length % 4) % 4,
        "="
      );
      return JSON.parse(Buffer.from(padded, "base64").toString("utf8"));
    }
    function isExpired(token) {
      return token.exp * 1e3 < Date.now();
    }
  }
});

// node_modules/@vercel/oidc/dist/token.js
var require_token = __commonJS({
  "node_modules/@vercel/oidc/dist/token.js"(exports, module) {
    "use strict";
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var token_exports = {};
    __export3(token_exports, {
      refreshToken: () => refreshToken
    });
    module.exports = __toCommonJS(token_exports);
    var import_token_error = require_token_error();
    var import_token_util = require_token_util();
    async function refreshToken() {
      const { projectId, teamId } = (0, import_token_util.findProjectInfo)();
      let maybeToken = (0, import_token_util.loadToken)(projectId);
      if (!maybeToken || (0, import_token_util.isExpired)((0, import_token_util.getTokenPayload)(maybeToken.token))) {
        const authToken = (0, import_token_util.getVercelCliToken)();
        if (!authToken) {
          throw new import_token_error.VercelOidcTokenError(
            "Failed to refresh OIDC token: login to vercel cli"
          );
        }
        if (!projectId) {
          throw new import_token_error.VercelOidcTokenError(
            "Failed to refresh OIDC token: project id not found"
          );
        }
        maybeToken = await (0, import_token_util.getVercelOidcToken)(authToken, projectId, teamId);
        if (!maybeToken) {
          throw new import_token_error.VercelOidcTokenError("Failed to refresh OIDC token");
        }
        (0, import_token_util.saveToken)(maybeToken, projectId);
      }
      process.env.VERCEL_OIDC_TOKEN = maybeToken.token;
      return;
    }
  }
});

// node_modules/@vercel/oidc/dist/get-vercel-oidc-token.js
var require_get_vercel_oidc_token = __commonJS({
  "node_modules/@vercel/oidc/dist/get-vercel-oidc-token.js"(exports, module) {
    "use strict";
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var get_vercel_oidc_token_exports = {};
    __export3(get_vercel_oidc_token_exports, {
      getVercelOidcToken: () => getVercelOidcToken3,
      getVercelOidcTokenSync: () => getVercelOidcTokenSync2
    });
    module.exports = __toCommonJS(get_vercel_oidc_token_exports);
    var import_get_context = require_get_context();
    var import_token_error = require_token_error();
    async function getVercelOidcToken3() {
      let token = "";
      let err;
      try {
        token = getVercelOidcTokenSync2();
      } catch (error) {
        err = error;
      }
      try {
        const [{ getTokenPayload, isExpired }, { refreshToken }] = await Promise.all([
          await Promise.resolve().then(() => __toESM(require_token_util())),
          await Promise.resolve().then(() => __toESM(require_token()))
        ]);
        if (!token || isExpired(getTokenPayload(token))) {
          await refreshToken();
          token = getVercelOidcTokenSync2();
        }
      } catch (error) {
        if (err?.message && error instanceof Error) {
          error.message = `${err.message}
${error.message}`;
        }
        throw new import_token_error.VercelOidcTokenError(`Failed to refresh OIDC token`, error);
      }
      return token;
    }
    function getVercelOidcTokenSync2() {
      const token = (0, import_get_context.getContext)().headers?.["x-vercel-oidc-token"] ?? process.env.VERCEL_OIDC_TOKEN;
      if (!token) {
        throw new Error(
          `The 'x-vercel-oidc-token' header is missing from the request. Do you have the OIDC option enabled in the Vercel project settings?`
        );
      }
      return token;
    }
  }
});

// node_modules/@vercel/oidc/dist/index.js
var require_dist = __commonJS({
  "node_modules/@vercel/oidc/dist/index.js"(exports, module) {
    "use strict";
    var __defProp3 = Object.defineProperty;
    var __getOwnPropDesc2 = Object.getOwnPropertyDescriptor;
    var __getOwnPropNames2 = Object.getOwnPropertyNames;
    var __hasOwnProp2 = Object.prototype.hasOwnProperty;
    var __export3 = (target, all) => {
      for (var name16 in all)
        __defProp3(target, name16, { get: all[name16], enumerable: true });
    };
    var __copyProps2 = (to, from, except, desc) => {
      if (from && typeof from === "object" || typeof from === "function") {
        for (let key of __getOwnPropNames2(from))
          if (!__hasOwnProp2.call(to, key) && key !== except)
            __defProp3(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc2(from, key)) || desc.enumerable });
      }
      return to;
    };
    var __toCommonJS = (mod) => __copyProps2(__defProp3({}, "__esModule", { value: true }), mod);
    var src_exports = {};
    __export3(src_exports, {
      getContext: () => import_get_context.getContext,
      getVercelOidcToken: () => import_get_vercel_oidc_token.getVercelOidcToken,
      getVercelOidcTokenSync: () => import_get_vercel_oidc_token.getVercelOidcTokenSync
    });
    module.exports = __toCommonJS(src_exports);
    var import_get_vercel_oidc_token = require_get_vercel_oidc_token();
    var import_get_context = require_get_context();
  }
});

// node_modules/.pnpm/ssh-config@5.0.4/node_modules/ssh-config/dist/glob.js
var require_glob = __commonJS({
  "node_modules/.pnpm/ssh-config@5.0.4/node_modules/ssh-config/dist/glob.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    function escapeChars(text2, chars) {
      for (let char of chars) {
        text2 = text2.replace(new RegExp("\\" + char, "g"), "\\" + char);
      }
      return text2;
    }
    function match(pattern, text2) {
      pattern = escapeChars(pattern, "\\()[]{}.+^$|");
      pattern = pattern.replace(/\*/g, ".*").replace(/\?/g, ".?");
      return new RegExp("^(?:" + pattern + ")$").test(text2);
    }
    function glob2(patternList, text2) {
      const patterns = Array.isArray(patternList) ? patternList : patternList.split(/,/);
      let result = false;
      for (const pattern of patterns) {
        const negate = pattern[0] == "!";
        if (negate && match(pattern.slice(1), text2)) {
          return false;
        } else if (match(pattern, text2)) {
          result = true;
        }
      }
      return result;
    }
    exports.default = glob2;
  }
});

// node_modules/.pnpm/ssh-config@5.0.4/node_modules/ssh-config/dist/ssh-config.js
var require_ssh_config = __commonJS({
  "node_modules/.pnpm/ssh-config@5.0.4/node_modules/ssh-config/dist/ssh-config.js"(exports) {
    "use strict";
    var __importDefault = exports && exports.__importDefault || function(mod) {
      return mod && mod.__esModule ? mod : { "default": mod };
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.glob = exports.LineType = void 0;
    exports.parse = parse3;
    exports.stringify = stringify;
    var glob_1 = __importDefault(require_glob());
    exports.glob = glob_1.default;
    var child_process_1 = __require("child_process");
    var os_1 = __importDefault(__require("os"));
    var RE_SPACE = /\s/;
    var RE_LINE_BREAK = /\r|\n/;
    var RE_SECTION_DIRECTIVE = /^(Host|Match)$/i;
    var RE_MULTI_VALUE_DIRECTIVE = /^(GlobalKnownHostsFile|Host|IPQoS|SendEnv|UserKnownHostsFile|ProxyCommand|Match|CanonicalDomains)$/i;
    var RE_QUOTE_DIRECTIVE = /^(?:CertificateFile|IdentityFile|IdentityAgent|User)$/i;
    var RE_SINGLE_LINE_DIRECTIVE = /^(Include|IdentityFile)$/i;
    var LineType;
    (function(LineType2) {
      LineType2[LineType2["DIRECTIVE"] = 1] = "DIRECTIVE";
      LineType2[LineType2["COMMENT"] = 2] = "COMMENT";
      LineType2[LineType2["EMPTY"] = 3] = "EMPTY";
    })(LineType || (exports.LineType = LineType = {}));
    var REPEATABLE_DIRECTIVES = [
      "IdentityFile",
      "LocalForward",
      "RemoteForward",
      "DynamicForward",
      "CertificateFile"
    ];
    function compare(line, opts) {
      return opts.hasOwnProperty(line.param) && opts[line.param] === line.value;
    }
    function getIndent(config2) {
      for (const line of config2) {
        if (line.type === LineType.DIRECTIVE && "config" in line) {
          for (const subline of line.config) {
            if (subline.before) {
              return subline.before;
            }
          }
        }
      }
      return "  ";
    }
    function match(criteria, context) {
      const testCriterion = (key, criterion) => {
        switch (key.toLowerCase()) {
          case "all":
            return true;
          case "final":
            if (context.inFinalPass) {
              return true;
            }
            context.doFinalPass = true;
            return false;
          case "exec":
            const command = `function main {
          ${criterion}
        }
        main`;
            return (0, child_process_1.spawnSync)(command, { shell: true }).status === 0;
          case "host":
            return (0, glob_1.default)(criterion, context.params.HostName);
          case "originalhost":
            return (0, glob_1.default)(criterion, context.params.OriginalHost);
          case "user":
            return (0, glob_1.default)(criterion, context.params.User);
          case "localuser":
            return (0, glob_1.default)(criterion, context.params.LocalUser);
        }
      };
      for (const key in criteria) {
        const criterion = criteria[key];
        const values = Array.isArray(criterion) ? criterion.map(({ val }) => val) : criterion;
        if (!testCriterion(key, values)) {
          return false;
        }
      }
      return true;
    }
    var SSHConfig2 = class _SSHConfig extends Array {
      /**
       * Parse SSH config text into structured object.
       */
      static parse(text2) {
        return parse3(text2);
      }
      /**
       * Stringify structured object into SSH config text.
       */
      static stringify(config2) {
        return stringify(config2);
      }
      compute(opts) {
        if (typeof opts === "string")
          opts = { Host: opts };
        let userInfo4;
        try {
          userInfo4 = os_1.default.userInfo();
        } catch (_a17) {
          userInfo4 = { username: process.env.USER || process.env.USERNAME || "" };
        }
        const context = {
          params: {
            Host: opts.Host,
            HostName: opts.Host,
            OriginalHost: opts.Host,
            User: userInfo4.username,
            LocalUser: userInfo4.username
          },
          inFinalPass: false,
          doFinalPass: false
        };
        const obj = {};
        const setProperty = (name16, value2) => {
          let val;
          if (Array.isArray(value2)) {
            if (/ProxyCommand/i.test(name16)) {
              val = value2.map(({ val: val2, separator, quoted }) => {
                return `${separator}${quoted ? `"${val2.replace(/"/g, '\\"')}"` : val2}`;
              }).join("").trim();
            } else {
              val = value2.map(({ val: val2 }) => val2);
            }
          } else {
            val = value2;
          }
          const val0 = Array.isArray(val) ? val[0] : val;
          if (REPEATABLE_DIRECTIVES.includes(name16)) {
            const list = obj[name16] || (obj[name16] = []);
            list.push(...[].concat(val));
          } else if (obj[name16] == null) {
            if (name16 === "HostName") {
              context.params.HostName = val0;
            } else if (name16 === "User") {
              context.params.User = val0;
            }
            obj[name16] = val;
          }
        };
        if (opts.User !== void 0) {
          setProperty("User", opts.User);
        }
        const doPass = () => {
          for (const line of this) {
            if (line.type !== LineType.DIRECTIVE)
              continue;
            if (line.param === "Host" && (0, glob_1.default)(Array.isArray(line.value) ? line.value.map(({ val }) => val) : line.value, context.params.Host)) {
              let canonicalizeHostName = false;
              let canonicalDomains = [];
              setProperty(line.param, line.value);
              for (const subline of line.config) {
                if (subline.type === LineType.DIRECTIVE) {
                  setProperty(subline.param, subline.value);
                  if (/^CanonicalizeHostName$/i.test(subline.param) && subline.value === "yes") {
                    canonicalizeHostName = true;
                  }
                  if (/^CanonicalDomains$/i.test(subline.param) && Array.isArray(subline.value)) {
                    canonicalDomains = subline.value.map(({ val }) => val);
                  }
                }
              }
              if (canonicalDomains.length > 0 && canonicalizeHostName && context.params.Host === context.params.OriginalHost) {
                for (const domain of canonicalDomains) {
                  const host = `${context.params.OriginalHost}.${domain}`;
                  const { status, stderr } = (0, child_process_1.spawnSync)("nslookup", [host]);
                  if (status === 0 && !/can't find/.test(stderr.toString())) {
                    context.params.Host = host;
                    setProperty("Host", host);
                    doPass();
                    break;
                  }
                }
              }
            } else if (line.param === "Match" && "criteria" in line && match(line.criteria, context)) {
              for (const subline of line.config) {
                if (subline.type === LineType.DIRECTIVE) {
                  setProperty(subline.param, subline.value);
                }
              }
            } else if (line.param !== "Host" && line.param !== "Match") {
              setProperty(line.param, line.value);
            }
          }
        };
        doPass();
        if (context.doFinalPass) {
          context.inFinalPass = true;
          context.params.Host = context.params.HostName;
          doPass();
        }
        return obj;
      }
      find(opts) {
        if (typeof opts === "function")
          return super.find(opts);
        if (!(opts && ("Host" in opts || "Match" in opts))) {
          throw new Error("Can only find by Host or Match");
        }
        return super.find((line) => compare(line, opts));
      }
      remove(opts) {
        let index;
        if (typeof opts === "function") {
          index = super.findIndex(opts);
        } else if (!(opts && ("Host" in opts || "Match" in opts))) {
          throw new Error("Can only remove by Host or Match");
        } else {
          index = super.findIndex((line) => compare(line, opts));
        }
        if (index >= 0)
          return this.splice(index, 1);
      }
      toString() {
        return stringify(this);
      }
      /**
       * Append new section to existing SSH config.
       */
      append(opts) {
        const indent = getIndent(this);
        const lastEntry = this.length > 0 ? this[this.length - 1] : null;
        let config2 = lastEntry && lastEntry.config || this;
        let configWas = this;
        let lastLine = config2.length > 0 ? config2[config2.length - 1] : lastEntry;
        if (lastLine && !lastLine.after)
          lastLine.after = "\n";
        let sectionLineFound = config2 !== configWas;
        for (const param in opts) {
          const value2 = opts[param];
          const line = {
            type: LineType.DIRECTIVE,
            param,
            separator: " ",
            value: Array.isArray(value2) ? value2.map((val, i) => ({ val, separator: i === 0 ? "" : " " })) : value2,
            before: sectionLineFound ? indent : indent.replace(/  |\t/, ""),
            after: "\n"
          };
          if (RE_SECTION_DIRECTIVE.test(param)) {
            sectionLineFound = true;
            line.before = indent.replace(/  |\t/, "");
            config2 = configWas;
            if (lastLine && lastLine.after === "\n")
              lastLine.after += "\n";
            config2.push(line);
            config2 = line.config = new _SSHConfig();
          } else {
            config2.push(line);
          }
          lastLine = line;
        }
        return configWas;
      }
      /**
       * Prepend new section to existing SSH config.
       */
      prepend(opts, beforeFirstSection = false) {
        const indent = getIndent(this);
        let config2 = this;
        let i = 0;
        if (beforeFirstSection) {
          while (i < this.length && !("config" in this[i])) {
            i += 1;
          }
          if (i >= this.length) {
            return this.append(opts);
          }
        }
        let sectionLineFound = false;
        let processedLines = 0;
        for (const param in opts) {
          processedLines += 1;
          const value2 = opts[param];
          const line = {
            type: LineType.DIRECTIVE,
            param,
            separator: " ",
            value: Array.isArray(value2) ? value2.map((val, i2) => ({ val, separator: i2 === 0 ? "" : " " })) : value2,
            before: "",
            after: "\n"
          };
          if (RE_SECTION_DIRECTIVE.test(param)) {
            line.before = indent.replace(/  |\t/, "");
            config2.splice(i, 0, line);
            config2 = line.config = new _SSHConfig();
            sectionLineFound = true;
            continue;
          }
          if (processedLines === Object.keys(opts).length) {
            line.after += "\n";
          }
          if (!sectionLineFound) {
            config2.splice(i, 0, line);
            i += 1;
            if (RE_SINGLE_LINE_DIRECTIVE.test(param)) {
              line.after += "\n";
            }
            continue;
          }
          line.before = indent;
          config2.push(line);
        }
        return config2;
      }
    };
    SSHConfig2.DIRECTIVE = LineType.DIRECTIVE;
    SSHConfig2.COMMENT = LineType.COMMENT;
    exports.default = SSHConfig2;
    function parse3(text2) {
      let i = 0;
      let chr = next();
      let config2 = new SSHConfig2();
      let configWas = config2;
      function next() {
        return text2[i++];
      }
      function space() {
        let spaces = "";
        while (RE_SPACE.test(chr)) {
          spaces += chr;
          chr = next();
        }
        return spaces;
      }
      function linebreak() {
        let breaks = "";
        while (RE_LINE_BREAK.test(chr)) {
          breaks += chr;
          chr = next();
        }
        return breaks;
      }
      function parameter() {
        let param = "";
        while (chr && /[^ \t=]/.test(chr)) {
          param += chr;
          chr = next();
        }
        return param;
      }
      function separator() {
        let sep = space();
        if (chr === "=") {
          sep += chr;
          chr = next();
        }
        return sep + space();
      }
      function value2() {
        let val = "";
        let quoted = false;
        let escaped = false;
        while (chr && !RE_LINE_BREAK.test(chr)) {
          if (escaped) {
            val += chr === '"' ? chr : `\\${chr}`;
            escaped = false;
          } else if (chr === '"' && (!val || quoted)) {
            quoted = !quoted;
          } else if (chr === "\\") {
            escaped = true;
          } else if (chr === "#" && !quoted) {
            break;
          } else {
            val += chr;
          }
          chr = next();
        }
        if (quoted || escaped) {
          throw new Error(`Unexpected line break at ${val}`);
        }
        return val.trim();
      }
      function comment() {
        const type2 = LineType.COMMENT;
        let content = "";
        while (chr && !RE_LINE_BREAK.test(chr)) {
          content += chr;
          chr = next();
        }
        return { type: type2, content, before: "", after: "" };
      }
      function values() {
        const results = [];
        let val = "";
        let valQuoted = false;
        let valSeparator = " ";
        let quoted = false;
        let escaped = false;
        while (chr && !RE_LINE_BREAK.test(chr)) {
          if (escaped) {
            val += chr === '"' ? chr : `\\${chr}`;
            escaped = false;
          } else if (chr === '"') {
            quoted = !quoted;
          } else if (chr === "\\") {
            escaped = true;
          } else if (quoted) {
            val += chr;
            valQuoted = true;
          } else if (/[ \t=]/.test(chr)) {
            if (val) {
              results.push({ val, separator: valSeparator, quoted: valQuoted });
              val = "";
              valQuoted = false;
              valSeparator = chr;
            }
          } else if (chr === "#" && results.length > 0) {
            break;
          } else {
            val += chr;
          }
          chr = next();
        }
        if (quoted || escaped) {
          throw new Error(`Unexpected line break at ${results.map(({ val: val2 }) => val2).concat(val).join(" ")}`);
        }
        if (val)
          results.push({ val, separator: valSeparator, quoted: valQuoted });
        return results.length > 1 ? results : results[0].val;
      }
      function directive() {
        const type2 = LineType.DIRECTIVE;
        const param = parameter();
        const multiple = RE_MULTI_VALUE_DIRECTIVE.test(param);
        const result = {
          type: type2,
          param,
          separator: separator(),
          quoted: !multiple && chr === '"',
          value: multiple ? values() : value2(),
          before: "",
          after: ""
        };
        if (!result.quoted)
          delete result.quoted;
        if (/^Match$/i.test(param)) {
          const criteria = {};
          if (typeof result.value === "string") {
            result.value = [{ val: result.value, separator: "", quoted: result.quoted }];
          }
          let i2 = 0;
          while (i2 < result.value.length) {
            const { val: keyword } = result.value[i2];
            switch (keyword.toLowerCase()) {
              case "all":
              case "canonical":
              case "final":
                criteria[keyword] = [];
                i2 += 1;
                break;
              default:
                if (i2 + 1 >= result.value.length) {
                  throw new Error(`Missing value for match criteria ${keyword}`);
                }
                criteria[keyword] = result.value[i2 + 1].val;
                i2 += 2;
                break;
            }
          }
          result.criteria = criteria;
        }
        return result;
      }
      function line() {
        const before = space();
        const node = chr === "#" ? comment() : directive();
        const after = linebreak();
        node.before = before;
        node.after = after;
        return node;
      }
      while (chr) {
        let node = line();
        if (node.type === LineType.DIRECTIVE && RE_SECTION_DIRECTIVE.test(node.param)) {
          config2 = configWas;
          config2.push(node);
          config2 = node.config = new SSHConfig2();
        } else if (node.type === LineType.DIRECTIVE && !node.param) {
          if (config2.length === 0) {
            if (configWas.length === 0) {
              configWas.push({ type: LineType.EMPTY, before: "", after: node.before });
            } else {
              configWas[configWas.length - 1].after += node.before;
            }
          } else {
            config2[config2.length - 1].after += node.before;
          }
        } else {
          config2.push(node);
        }
      }
      return configWas;
    }
    function stringify(config2) {
      let str = "";
      function formatValue(value2, quoted) {
        if (Array.isArray(value2)) {
          let result = "";
          for (const { val, separator, quoted: quoted2 } of value2) {
            result += (result ? separator : "") + formatValue(val, quoted2 || RE_SPACE.test(val));
          }
          return result;
        }
        return quoted ? `"${value2}"` : value2;
      }
      function formatDirective(line) {
        const quoted = line.quoted || RE_QUOTE_DIRECTIVE.test(line.param) && RE_SPACE.test(line.value);
        const value2 = formatValue(line.value, quoted);
        return `${line.param}${line.separator}${value2}`;
      }
      const format = (line) => {
        str += line.before;
        if (line.type === LineType.COMMENT) {
          str += line.content;
        } else if (line.type === LineType.DIRECTIVE && REPEATABLE_DIRECTIVES.includes(line.param)) {
          (Array.isArray(line.value) ? line.value : [line.value]).forEach((value2, i, values) => {
            str += formatDirective({ ...line, value: typeof value2 !== "string" ? value2.val : value2 });
            if (i < values.length - 1)
              str += `
${line.before}`;
          });
        } else if (line.type === LineType.DIRECTIVE) {
          str += formatDirective(line);
        }
        str += line.after;
        if ("config" in line) {
          line.config.forEach(format);
        }
      };
      config2.forEach(format);
      return str;
    }
  }
});

// node_modules/.pnpm/ssh-config@5.0.4/node_modules/ssh-config/dist/index.js
var require_dist2 = __commonJS({
  "node_modules/.pnpm/ssh-config@5.0.4/node_modules/ssh-config/dist/index.js"(exports) {
    "use strict";
    var __createBinding = exports && exports.__createBinding || (Object.create ? (function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      var desc = Object.getOwnPropertyDescriptor(m, k);
      if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
        desc = { enumerable: true, get: function() {
          return m[k];
        } };
      }
      Object.defineProperty(o, k2, desc);
    }) : (function(o, m, k, k2) {
      if (k2 === void 0) k2 = k;
      o[k2] = m[k];
    }));
    var __exportStar = exports && exports.__exportStar || function(m, exports2) {
      for (var p in m) if (p !== "default" && !Object.prototype.hasOwnProperty.call(exports2, p)) __createBinding(exports2, m, p);
    };
    var __importDefault = exports && exports.__importDefault || function(mod) {
      return mod && mod.__esModule ? mod : { "default": mod };
    };
    Object.defineProperty(exports, "__esModule", { value: true });
    var ssh_config_1 = __importDefault(require_ssh_config());
    __exportStar(require_ssh_config(), exports);
    exports.default = ssh_config_1.default;
  }
});

// node_modules/.pnpm/imurmurhash@0.1.4/node_modules/imurmurhash/imurmurhash.js
var require_imurmurhash = __commonJS({
  "node_modules/.pnpm/imurmurhash@0.1.4/node_modules/imurmurhash/imurmurhash.js"(exports, module) {
    (function() {
      var cache;
      function MurmurHash3(key, seed) {
        var m = this instanceof MurmurHash3 ? this : cache;
        m.reset(seed);
        if (typeof key === "string" && key.length > 0) {
          m.hash(key);
        }
        if (m !== this) {
          return m;
        }
      }
      ;
      MurmurHash3.prototype.hash = function(key) {
        var h1, k1, i, top, len;
        len = key.length;
        this.len += len;
        k1 = this.k1;
        i = 0;
        switch (this.rem) {
          case 0:
            k1 ^= len > i ? key.charCodeAt(i++) & 65535 : 0;
          case 1:
            k1 ^= len > i ? (key.charCodeAt(i++) & 65535) << 8 : 0;
          case 2:
            k1 ^= len > i ? (key.charCodeAt(i++) & 65535) << 16 : 0;
          case 3:
            k1 ^= len > i ? (key.charCodeAt(i) & 255) << 24 : 0;
            k1 ^= len > i ? (key.charCodeAt(i++) & 65280) >> 8 : 0;
        }
        this.rem = len + this.rem & 3;
        len -= this.rem;
        if (len > 0) {
          h1 = this.h1;
          while (1) {
            k1 = k1 * 11601 + (k1 & 65535) * 3432906752 & 4294967295;
            k1 = k1 << 15 | k1 >>> 17;
            k1 = k1 * 13715 + (k1 & 65535) * 461832192 & 4294967295;
            h1 ^= k1;
            h1 = h1 << 13 | h1 >>> 19;
            h1 = h1 * 5 + 3864292196 & 4294967295;
            if (i >= len) {
              break;
            }
            k1 = key.charCodeAt(i++) & 65535 ^ (key.charCodeAt(i++) & 65535) << 8 ^ (key.charCodeAt(i++) & 65535) << 16;
            top = key.charCodeAt(i++);
            k1 ^= (top & 255) << 24 ^ (top & 65280) >> 8;
          }
          k1 = 0;
          switch (this.rem) {
            case 3:
              k1 ^= (key.charCodeAt(i + 2) & 65535) << 16;
            case 2:
              k1 ^= (key.charCodeAt(i + 1) & 65535) << 8;
            case 1:
              k1 ^= key.charCodeAt(i) & 65535;
          }
          this.h1 = h1;
        }
        this.k1 = k1;
        return this;
      };
      MurmurHash3.prototype.result = function() {
        var k1, h1;
        k1 = this.k1;
        h1 = this.h1;
        if (k1 > 0) {
          k1 = k1 * 11601 + (k1 & 65535) * 3432906752 & 4294967295;
          k1 = k1 << 15 | k1 >>> 17;
          k1 = k1 * 13715 + (k1 & 65535) * 461832192 & 4294967295;
          h1 ^= k1;
        }
        h1 ^= this.len;
        h1 ^= h1 >>> 16;
        h1 = h1 * 51819 + (h1 & 65535) * 2246770688 & 4294967295;
        h1 ^= h1 >>> 13;
        h1 = h1 * 44597 + (h1 & 65535) * 3266445312 & 4294967295;
        h1 ^= h1 >>> 16;
        return h1 >>> 0;
      };
      MurmurHash3.prototype.reset = function(seed) {
        this.h1 = typeof seed === "number" ? seed : 0;
        this.rem = this.k1 = this.len = 0;
        return this;
      };
      cache = new MurmurHash3();
      if (typeof module != "undefined") {
        module.exports = MurmurHash3;
      } else {
        this.MurmurHash3 = MurmurHash3;
      }
    })();
  }
});

// node_modules/.pnpm/signal-exit@4.1.0/node_modules/signal-exit/dist/cjs/signals.js
var require_signals = __commonJS({
  "node_modules/.pnpm/signal-exit@4.1.0/node_modules/signal-exit/dist/cjs/signals.js"(exports) {
    "use strict";
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.signals = void 0;
    exports.signals = [];
    exports.signals.push("SIGHUP", "SIGINT", "SIGTERM");
    if (process.platform !== "win32") {
      exports.signals.push(
        "SIGALRM",
        "SIGABRT",
        "SIGVTALRM",
        "SIGXCPU",
        "SIGXFSZ",
        "SIGUSR2",
        "SIGTRAP",
        "SIGSYS",
        "SIGQUIT",
        "SIGIOT"
        // should detect profiler and enable/disable accordingly.
        // see #21
        // 'SIGPROF'
      );
    }
    if (process.platform === "linux") {
      exports.signals.push("SIGIO", "SIGPOLL", "SIGPWR", "SIGSTKFLT");
    }
  }
});

// node_modules/.pnpm/signal-exit@4.1.0/node_modules/signal-exit/dist/cjs/index.js
var require_cjs = __commonJS({
  "node_modules/.pnpm/signal-exit@4.1.0/node_modules/signal-exit/dist/cjs/index.js"(exports) {
    "use strict";
    var _a17;
    Object.defineProperty(exports, "__esModule", { value: true });
    exports.unload = exports.load = exports.onExit = exports.signals = void 0;
    var signals_js_1 = require_signals();
    Object.defineProperty(exports, "signals", { enumerable: true, get: function() {
      return signals_js_1.signals;
    } });
    var processOk = (process4) => !!process4 && typeof process4 === "object" && typeof process4.removeListener === "function" && typeof process4.emit === "function" && typeof process4.reallyExit === "function" && typeof process4.listeners === "function" && typeof process4.kill === "function" && typeof process4.pid === "number" && typeof process4.on === "function";
    var kExitEmitter = Symbol.for("signal-exit emitter");
    var global2 = globalThis;
    var ObjectDefineProperty = Object.defineProperty.bind(Object);
    var Emitter = class {
      emitted = {
        afterExit: false,
        exit: false
      };
      listeners = {
        afterExit: [],
        exit: []
      };
      count = 0;
      id = Math.random();
      constructor() {
        if (global2[kExitEmitter]) {
          return global2[kExitEmitter];
        }
        ObjectDefineProperty(global2, kExitEmitter, {
          value: this,
          writable: false,
          enumerable: false,
          configurable: false
        });
      }
      on(ev, fn) {
        this.listeners[ev].push(fn);
      }
      removeListener(ev, fn) {
        const list = this.listeners[ev];
        const i = list.indexOf(fn);
        if (i === -1) {
          return;
        }
        if (i === 0 && list.length === 1) {
          list.length = 0;
        } else {
          list.splice(i, 1);
        }
      }
      emit(ev, code, signal) {
        if (this.emitted[ev]) {
          return false;
        }
        this.emitted[ev] = true;
        let ret = false;
        for (const fn of this.listeners[ev]) {
          ret = fn(code, signal) === true || ret;
        }
        if (ev === "exit") {
          ret = this.emit("afterExit", code, signal) || ret;
        }
        return ret;
      }
    };
    var SignalExitBase = class {
    };
    var signalExitWrap = (handler) => {
      return {
        onExit(cb, opts) {
          return handler.onExit(cb, opts);
        },
        load() {
          return handler.load();
        },
        unload() {
          return handler.unload();
        }
      };
    };
    var SignalExitFallback = class extends SignalExitBase {
      onExit() {
        return () => {
        };
      }
      load() {
      }
      unload() {
      }
    };
    var SignalExit = class extends SignalExitBase {
      // "SIGHUP" throws an `ENOSYS` error on Windows,
      // so use a supported signal instead
      /* c8 ignore start */
      #hupSig = process3.platform === "win32" ? "SIGINT" : "SIGHUP";
      /* c8 ignore stop */
      #emitter = new Emitter();
      #process;
      #originalProcessEmit;
      #originalProcessReallyExit;
      #sigListeners = {};
      #loaded = false;
      constructor(process4) {
        super();
        this.#process = process4;
        this.#sigListeners = {};
        for (const sig of signals_js_1.signals) {
          this.#sigListeners[sig] = () => {
            const listeners = this.#process.listeners(sig);
            let { count } = this.#emitter;
            const p = process4;
            if (typeof p.__signal_exit_emitter__ === "object" && typeof p.__signal_exit_emitter__.count === "number") {
              count += p.__signal_exit_emitter__.count;
            }
            if (listeners.length === count) {
              this.unload();
              const ret = this.#emitter.emit("exit", null, sig);
              const s = sig === "SIGHUP" ? this.#hupSig : sig;
              if (!ret)
                process4.kill(process4.pid, s);
            }
          };
        }
        this.#originalProcessReallyExit = process4.reallyExit;
        this.#originalProcessEmit = process4.emit;
      }
      onExit(cb, opts) {
        if (!processOk(this.#process)) {
          return () => {
          };
        }
        if (this.#loaded === false) {
          this.load();
        }
        const ev = opts?.alwaysLast ? "afterExit" : "exit";
        this.#emitter.on(ev, cb);
        return () => {
          this.#emitter.removeListener(ev, cb);
          if (this.#emitter.listeners["exit"].length === 0 && this.#emitter.listeners["afterExit"].length === 0) {
            this.unload();
          }
        };
      }
      load() {
        if (this.#loaded) {
          return;
        }
        this.#loaded = true;
        this.#emitter.count += 1;
        for (const sig of signals_js_1.signals) {
          try {
            const fn = this.#sigListeners[sig];
            if (fn)
              this.#process.on(sig, fn);
          } catch (_) {
          }
        }
        this.#process.emit = (ev, ...a) => {
          return this.#processEmit(ev, ...a);
        };
        this.#process.reallyExit = (code) => {
          return this.#processReallyExit(code);
        };
      }
      unload() {
        if (!this.#loaded) {
          return;
        }
        this.#loaded = false;
        signals_js_1.signals.forEach((sig) => {
          const listener = this.#sigListeners[sig];
          if (!listener) {
            throw new Error("Listener not defined for signal: " + sig);
          }
          try {
            this.#process.removeListener(sig, listener);
          } catch (_) {
          }
        });
        this.#process.emit = this.#originalProcessEmit;
        this.#process.reallyExit = this.#originalProcessReallyExit;
        this.#emitter.count -= 1;
      }
      #processReallyExit(code) {
        if (!processOk(this.#process)) {
          return 0;
        }
        this.#process.exitCode = code || 0;
        this.#emitter.emit("exit", this.#process.exitCode, null);
        return this.#originalProcessReallyExit.call(this.#process, this.#process.exitCode);
      }
      #processEmit(ev, ...args2) {
        const og = this.#originalProcessEmit;
        if (ev === "exit" && processOk(this.#process)) {
          if (typeof args2[0] === "number") {
            this.#process.exitCode = args2[0];
          }
          const ret = og.call(this.#process, ev, ...args2);
          this.#emitter.emit("exit", this.#process.exitCode, null);
          return ret;
        } else {
          return og.call(this.#process, ev, ...args2);
        }
      }
    };
    var process3 = globalThis.process;
    _a17 = signalExitWrap(processOk(process3) ? new SignalExit(process3) : new SignalExitFallback()), /**
     * Called when the process is exiting, whether via signal, explicit
     * exit, or running out of stuff to do.
     *
     * If the global process object is not suitable for instrumentation,
     * then this will be a no-op.
     *
     * Returns a function that may be used to unload signal-exit.
     */
    exports.onExit = _a17.onExit, /**
     * Load the listeners.  Likely you never need to call this, unless
     * doing a rather deep integration with signal-exit functionality.
     * Mostly exposed for the benefit of testing.
     *
     * @internal
     */
    exports.load = _a17.load, /**
     * Unload the listeners.  Likely you never need to call this, unless
     * doing a rather deep integration with signal-exit functionality.
     * Mostly exposed for the benefit of testing.
     *
     * @internal
     */
    exports.unload = _a17.unload;
  }
});

// node_modules/.pnpm/write-file-atomic@6.0.0/node_modules/write-file-atomic/lib/index.js
var require_lib = __commonJS({
  "node_modules/.pnpm/write-file-atomic@6.0.0/node_modules/write-file-atomic/lib/index.js"(exports, module) {
    "use strict";
    module.exports = writeFile2;
    module.exports.sync = writeFileSync3;
    module.exports._getTmpname = getTmpname;
    module.exports._cleanupOnExit = cleanupOnExit;
    var fs14 = __require("fs");
    var MurmurHash3 = require_imurmurhash();
    var { onExit } = require_cjs();
    var path21 = __require("path");
    var { promisify } = __require("util");
    var activeFiles = {};
    var threadId = (function getId() {
      try {
        const workerThreads = __require("worker_threads");
        return workerThreads.threadId;
      } catch (e) {
        return 0;
      }
    })();
    var invocations = 0;
    function getTmpname(filename) {
      return filename + "." + MurmurHash3(__filename).hash(String(process.pid)).hash(String(threadId)).hash(String(++invocations)).result();
    }
    function cleanupOnExit(tmpfile) {
      return () => {
        try {
          fs14.unlinkSync(typeof tmpfile === "function" ? tmpfile() : tmpfile);
        } catch {
        }
      };
    }
    function serializeActiveFile(absoluteName) {
      return new Promise((resolve3) => {
        if (!activeFiles[absoluteName]) {
          activeFiles[absoluteName] = [];
        }
        activeFiles[absoluteName].push(resolve3);
        if (activeFiles[absoluteName].length === 1) {
          resolve3();
        }
      });
    }
    function isChownErrOk(err) {
      if (err.code === "ENOSYS") {
        return true;
      }
      const nonroot = !process.getuid || process.getuid() !== 0;
      if (nonroot) {
        if (err.code === "EINVAL" || err.code === "EPERM") {
          return true;
        }
      }
      return false;
    }
    async function writeFileAsync(filename, data, options = {}) {
      if (typeof options === "string") {
        options = { encoding: options };
      }
      let fd;
      let tmpfile;
      const removeOnExitHandler = onExit(cleanupOnExit(() => tmpfile));
      const absoluteName = path21.resolve(filename);
      try {
        await serializeActiveFile(absoluteName);
        const truename = await promisify(fs14.realpath)(filename).catch(() => filename);
        tmpfile = getTmpname(truename);
        if (!options.mode || !options.chown) {
          const stats = await promisify(fs14.stat)(truename).catch(() => {
          });
          if (stats) {
            if (options.mode == null) {
              options.mode = stats.mode;
            }
            if (options.chown == null && process.getuid) {
              options.chown = { uid: stats.uid, gid: stats.gid };
            }
          }
        }
        fd = await promisify(fs14.open)(tmpfile, "w", options.mode);
        if (options.tmpfileCreated) {
          await options.tmpfileCreated(tmpfile);
        }
        if (ArrayBuffer.isView(data)) {
          await promisify(fs14.write)(fd, data, 0, data.length, 0);
        } else if (data != null) {
          await promisify(fs14.write)(fd, String(data), 0, String(options.encoding || "utf8"));
        }
        if (options.fsync !== false) {
          await promisify(fs14.fsync)(fd);
        }
        await promisify(fs14.close)(fd);
        fd = null;
        if (options.chown) {
          await promisify(fs14.chown)(tmpfile, options.chown.uid, options.chown.gid).catch((err) => {
            if (!isChownErrOk(err)) {
              throw err;
            }
          });
        }
        if (options.mode) {
          await promisify(fs14.chmod)(tmpfile, options.mode).catch((err) => {
            if (!isChownErrOk(err)) {
              throw err;
            }
          });
        }
        await promisify(fs14.rename)(tmpfile, truename);
      } finally {
        if (fd) {
          await promisify(fs14.close)(fd).catch(
            /* istanbul ignore next */
            () => {
            }
          );
        }
        removeOnExitHandler();
        await promisify(fs14.unlink)(tmpfile).catch(() => {
        });
        activeFiles[absoluteName].shift();
        if (activeFiles[absoluteName].length > 0) {
          activeFiles[absoluteName][0]();
        } else {
          delete activeFiles[absoluteName];
        }
      }
    }
    async function writeFile2(filename, data, options, callback) {
      if (options instanceof Function) {
        callback = options;
        options = {};
      }
      const promise = writeFileAsync(filename, data, options);
      if (callback) {
        try {
          const result = await promise;
          return callback(result);
        } catch (err) {
          return callback(err);
        }
      }
      return promise;
    }
    function writeFileSync3(filename, data, options) {
      if (typeof options === "string") {
        options = { encoding: options };
      } else if (!options) {
        options = {};
      }
      try {
        filename = fs14.realpathSync(filename);
      } catch (ex) {
      }
      const tmpfile = getTmpname(filename);
      if (!options.mode || !options.chown) {
        try {
          const stats = fs14.statSync(filename);
          options = Object.assign({}, options);
          if (!options.mode) {
            options.mode = stats.mode;
          }
          if (!options.chown && process.getuid) {
            options.chown = { uid: stats.uid, gid: stats.gid };
          }
        } catch (ex) {
        }
      }
      let fd;
      const cleanup = cleanupOnExit(tmpfile);
      const removeOnExitHandler = onExit(cleanup);
      let threw = true;
      try {
        fd = fs14.openSync(tmpfile, "w", options.mode || 438);
        if (options.tmpfileCreated) {
          options.tmpfileCreated(tmpfile);
        }
        if (ArrayBuffer.isView(data)) {
          fs14.writeSync(fd, data, 0, data.length, 0);
        } else if (data != null) {
          fs14.writeSync(fd, String(data), 0, String(options.encoding || "utf8"));
        }
        if (options.fsync !== false) {
          fs14.fsyncSync(fd);
        }
        fs14.closeSync(fd);
        fd = null;
        if (options.chown) {
          try {
            fs14.chownSync(tmpfile, options.chown.uid, options.chown.gid);
          } catch (err) {
            if (!isChownErrOk(err)) {
              throw err;
            }
          }
        }
        if (options.mode) {
          try {
            fs14.chmodSync(tmpfile, options.mode);
          } catch (err) {
            if (!isChownErrOk(err)) {
              throw err;
            }
          }
        }
        fs14.renameSync(tmpfile, filename);
        threw = false;
      } finally {
        if (fd) {
          try {
            fs14.closeSync(fd);
          } catch (ex) {
          }
        }
        removeOnExitHandler();
        if (threw) {
          cleanup();
        }
      }
    }
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/identity.js
var require_identity = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/identity.js"(exports) {
    "use strict";
    var ALIAS = Symbol.for("yaml.alias");
    var DOC = Symbol.for("yaml.document");
    var MAP = Symbol.for("yaml.map");
    var PAIR = Symbol.for("yaml.pair");
    var SCALAR = Symbol.for("yaml.scalar");
    var SEQ = Symbol.for("yaml.seq");
    var NODE_TYPE = Symbol.for("yaml.node.type");
    var isAlias = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === ALIAS;
    var isDocument = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === DOC;
    var isMap = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === MAP;
    var isPair = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === PAIR;
    var isScalar = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === SCALAR;
    var isSeq = (node) => !!node && typeof node === "object" && node[NODE_TYPE] === SEQ;
    function isCollection(node) {
      if (node && typeof node === "object")
        switch (node[NODE_TYPE]) {
          case MAP:
          case SEQ:
            return true;
        }
      return false;
    }
    function isNode(node) {
      if (node && typeof node === "object")
        switch (node[NODE_TYPE]) {
          case ALIAS:
          case MAP:
          case SCALAR:
          case SEQ:
            return true;
        }
      return false;
    }
    var hasAnchor = (node) => (isScalar(node) || isCollection(node)) && !!node.anchor;
    exports.ALIAS = ALIAS;
    exports.DOC = DOC;
    exports.MAP = MAP;
    exports.NODE_TYPE = NODE_TYPE;
    exports.PAIR = PAIR;
    exports.SCALAR = SCALAR;
    exports.SEQ = SEQ;
    exports.hasAnchor = hasAnchor;
    exports.isAlias = isAlias;
    exports.isCollection = isCollection;
    exports.isDocument = isDocument;
    exports.isMap = isMap;
    exports.isNode = isNode;
    exports.isPair = isPair;
    exports.isScalar = isScalar;
    exports.isSeq = isSeq;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/visit.js
var require_visit = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/visit.js"(exports) {
    "use strict";
    var identity = require_identity();
    var BREAK = Symbol("break visit");
    var SKIP = Symbol("skip children");
    var REMOVE = Symbol("remove node");
    function visit(node, visitor) {
      const visitor_ = initVisitor(visitor);
      if (identity.isDocument(node)) {
        const cd = visit_(null, node.contents, visitor_, Object.freeze([node]));
        if (cd === REMOVE)
          node.contents = null;
      } else
        visit_(null, node, visitor_, Object.freeze([]));
    }
    visit.BREAK = BREAK;
    visit.SKIP = SKIP;
    visit.REMOVE = REMOVE;
    function visit_(key, node, visitor, path21) {
      const ctrl = callVisitor(key, node, visitor, path21);
      if (identity.isNode(ctrl) || identity.isPair(ctrl)) {
        replaceNode(key, path21, ctrl);
        return visit_(key, ctrl, visitor, path21);
      }
      if (typeof ctrl !== "symbol") {
        if (identity.isCollection(node)) {
          path21 = Object.freeze(path21.concat(node));
          for (let i = 0; i < node.items.length; ++i) {
            const ci = visit_(i, node.items[i], visitor, path21);
            if (typeof ci === "number")
              i = ci - 1;
            else if (ci === BREAK)
              return BREAK;
            else if (ci === REMOVE) {
              node.items.splice(i, 1);
              i -= 1;
            }
          }
        } else if (identity.isPair(node)) {
          path21 = Object.freeze(path21.concat(node));
          const ck = visit_("key", node.key, visitor, path21);
          if (ck === BREAK)
            return BREAK;
          else if (ck === REMOVE)
            node.key = null;
          const cv = visit_("value", node.value, visitor, path21);
          if (cv === BREAK)
            return BREAK;
          else if (cv === REMOVE)
            node.value = null;
        }
      }
      return ctrl;
    }
    async function visitAsync(node, visitor) {
      const visitor_ = initVisitor(visitor);
      if (identity.isDocument(node)) {
        const cd = await visitAsync_(null, node.contents, visitor_, Object.freeze([node]));
        if (cd === REMOVE)
          node.contents = null;
      } else
        await visitAsync_(null, node, visitor_, Object.freeze([]));
    }
    visitAsync.BREAK = BREAK;
    visitAsync.SKIP = SKIP;
    visitAsync.REMOVE = REMOVE;
    async function visitAsync_(key, node, visitor, path21) {
      const ctrl = await callVisitor(key, node, visitor, path21);
      if (identity.isNode(ctrl) || identity.isPair(ctrl)) {
        replaceNode(key, path21, ctrl);
        return visitAsync_(key, ctrl, visitor, path21);
      }
      if (typeof ctrl !== "symbol") {
        if (identity.isCollection(node)) {
          path21 = Object.freeze(path21.concat(node));
          for (let i = 0; i < node.items.length; ++i) {
            const ci = await visitAsync_(i, node.items[i], visitor, path21);
            if (typeof ci === "number")
              i = ci - 1;
            else if (ci === BREAK)
              return BREAK;
            else if (ci === REMOVE) {
              node.items.splice(i, 1);
              i -= 1;
            }
          }
        } else if (identity.isPair(node)) {
          path21 = Object.freeze(path21.concat(node));
          const ck = await visitAsync_("key", node.key, visitor, path21);
          if (ck === BREAK)
            return BREAK;
          else if (ck === REMOVE)
            node.key = null;
          const cv = await visitAsync_("value", node.value, visitor, path21);
          if (cv === BREAK)
            return BREAK;
          else if (cv === REMOVE)
            node.value = null;
        }
      }
      return ctrl;
    }
    function initVisitor(visitor) {
      if (typeof visitor === "object" && (visitor.Collection || visitor.Node || visitor.Value)) {
        return Object.assign({
          Alias: visitor.Node,
          Map: visitor.Node,
          Scalar: visitor.Node,
          Seq: visitor.Node
        }, visitor.Value && {
          Map: visitor.Value,
          Scalar: visitor.Value,
          Seq: visitor.Value
        }, visitor.Collection && {
          Map: visitor.Collection,
          Seq: visitor.Collection
        }, visitor);
      }
      return visitor;
    }
    function callVisitor(key, node, visitor, path21) {
      if (typeof visitor === "function")
        return visitor(key, node, path21);
      if (identity.isMap(node))
        return visitor.Map?.(key, node, path21);
      if (identity.isSeq(node))
        return visitor.Seq?.(key, node, path21);
      if (identity.isPair(node))
        return visitor.Pair?.(key, node, path21);
      if (identity.isScalar(node))
        return visitor.Scalar?.(key, node, path21);
      if (identity.isAlias(node))
        return visitor.Alias?.(key, node, path21);
      return void 0;
    }
    function replaceNode(key, path21, node) {
      const parent = path21[path21.length - 1];
      if (identity.isCollection(parent)) {
        parent.items[key] = node;
      } else if (identity.isPair(parent)) {
        if (key === "key")
          parent.key = node;
        else
          parent.value = node;
      } else if (identity.isDocument(parent)) {
        parent.contents = node;
      } else {
        const pt = identity.isAlias(parent) ? "alias" : "scalar";
        throw new Error(`Cannot replace node with ${pt} parent`);
      }
    }
    exports.visit = visit;
    exports.visitAsync = visitAsync;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/directives.js
var require_directives = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/directives.js"(exports) {
    "use strict";
    var identity = require_identity();
    var visit = require_visit();
    var escapeChars = {
      "!": "%21",
      ",": "%2C",
      "[": "%5B",
      "]": "%5D",
      "{": "%7B",
      "}": "%7D"
    };
    var escapeTagName = (tn) => tn.replace(/[!,[\]{}]/g, (ch) => escapeChars[ch]);
    var Directives = class _Directives {
      constructor(yaml, tags) {
        this.docStart = null;
        this.docEnd = false;
        this.yaml = Object.assign({}, _Directives.defaultYaml, yaml);
        this.tags = Object.assign({}, _Directives.defaultTags, tags);
      }
      clone() {
        const copy = new _Directives(this.yaml, this.tags);
        copy.docStart = this.docStart;
        return copy;
      }
      /**
       * During parsing, get a Directives instance for the current document and
       * update the stream state according to the current version's spec.
       */
      atDocument() {
        const res = new _Directives(this.yaml, this.tags);
        switch (this.yaml.version) {
          case "1.1":
            this.atNextDocument = true;
            break;
          case "1.2":
            this.atNextDocument = false;
            this.yaml = {
              explicit: _Directives.defaultYaml.explicit,
              version: "1.2"
            };
            this.tags = Object.assign({}, _Directives.defaultTags);
            break;
        }
        return res;
      }
      /**
       * @param onError - May be called even if the action was successful
       * @returns `true` on success
       */
      add(line, onError2) {
        if (this.atNextDocument) {
          this.yaml = { explicit: _Directives.defaultYaml.explicit, version: "1.1" };
          this.tags = Object.assign({}, _Directives.defaultTags);
          this.atNextDocument = false;
        }
        const parts = line.trim().split(/[ \t]+/);
        const name16 = parts.shift();
        switch (name16) {
          case "%TAG": {
            if (parts.length !== 2) {
              onError2(0, "%TAG directive should contain exactly two parts");
              if (parts.length < 2)
                return false;
            }
            const [handle, prefix] = parts;
            this.tags[handle] = prefix;
            return true;
          }
          case "%YAML": {
            this.yaml.explicit = true;
            if (parts.length !== 1) {
              onError2(0, "%YAML directive should contain exactly one part");
              return false;
            }
            const [version] = parts;
            if (version === "1.1" || version === "1.2") {
              this.yaml.version = version;
              return true;
            } else {
              const isValid = /^\d+\.\d+$/.test(version);
              onError2(6, `Unsupported YAML version ${version}`, isValid);
              return false;
            }
          }
          default:
            onError2(0, `Unknown directive ${name16}`, true);
            return false;
        }
      }
      /**
       * Resolves a tag, matching handles to those defined in %TAG directives.
       *
       * @returns Resolved tag, which may also be the non-specific tag `'!'` or a
       *   `'!local'` tag, or `null` if unresolvable.
       */
      tagName(source, onError2) {
        if (source === "!")
          return "!";
        if (source[0] !== "!") {
          onError2(`Not a valid tag: ${source}`);
          return null;
        }
        if (source[1] === "<") {
          const verbatim = source.slice(2, -1);
          if (verbatim === "!" || verbatim === "!!") {
            onError2(`Verbatim tags aren't resolved, so ${source} is invalid.`);
            return null;
          }
          if (source[source.length - 1] !== ">")
            onError2("Verbatim tags must end with a >");
          return verbatim;
        }
        const [, handle, suffix] = source.match(/^(.*!)([^!]*)$/s);
        if (!suffix)
          onError2(`The ${source} tag has no suffix`);
        const prefix = this.tags[handle];
        if (prefix) {
          try {
            return prefix + decodeURIComponent(suffix);
          } catch (error) {
            onError2(String(error));
            return null;
          }
        }
        if (handle === "!")
          return source;
        onError2(`Could not resolve tag: ${source}`);
        return null;
      }
      /**
       * Given a fully resolved tag, returns its printable string form,
       * taking into account current tag prefixes and defaults.
       */
      tagString(tag) {
        for (const [handle, prefix] of Object.entries(this.tags)) {
          if (tag.startsWith(prefix))
            return handle + escapeTagName(tag.substring(prefix.length));
        }
        return tag[0] === "!" ? tag : `!<${tag}>`;
      }
      toString(doc) {
        const lines = this.yaml.explicit ? [`%YAML ${this.yaml.version || "1.2"}`] : [];
        const tagEntries = Object.entries(this.tags);
        let tagNames;
        if (doc && tagEntries.length > 0 && identity.isNode(doc.contents)) {
          const tags = {};
          visit.visit(doc.contents, (_key, node) => {
            if (identity.isNode(node) && node.tag)
              tags[node.tag] = true;
          });
          tagNames = Object.keys(tags);
        } else
          tagNames = [];
        for (const [handle, prefix] of tagEntries) {
          if (handle === "!!" && prefix === "tag:yaml.org,2002:")
            continue;
          if (!doc || tagNames.some((tn) => tn.startsWith(prefix)))
            lines.push(`%TAG ${handle} ${prefix}`);
        }
        return lines.join("\n");
      }
    };
    Directives.defaultYaml = { explicit: false, version: "1.2" };
    Directives.defaultTags = { "!!": "tag:yaml.org,2002:" };
    exports.Directives = Directives;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/anchors.js
var require_anchors = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/anchors.js"(exports) {
    "use strict";
    var identity = require_identity();
    var visit = require_visit();
    function anchorIsValid(anchor) {
      if (/[\x00-\x19\s,[\]{}]/.test(anchor)) {
        const sa = JSON.stringify(anchor);
        const msg = `Anchor must not contain whitespace or control characters: ${sa}`;
        throw new Error(msg);
      }
      return true;
    }
    function anchorNames(root) {
      const anchors = /* @__PURE__ */ new Set();
      visit.visit(root, {
        Value(_key, node) {
          if (node.anchor)
            anchors.add(node.anchor);
        }
      });
      return anchors;
    }
    function findNewAnchor(prefix, exclude) {
      for (let i = 1; true; ++i) {
        const name16 = `${prefix}${i}`;
        if (!exclude.has(name16))
          return name16;
      }
    }
    function createNodeAnchors(doc, prefix) {
      const aliasObjects = [];
      const sourceObjects = /* @__PURE__ */ new Map();
      let prevAnchors = null;
      return {
        onAnchor: (source) => {
          aliasObjects.push(source);
          prevAnchors ?? (prevAnchors = anchorNames(doc));
          const anchor = findNewAnchor(prefix, prevAnchors);
          prevAnchors.add(anchor);
          return anchor;
        },
        /**
         * With circular references, the source node is only resolved after all
         * of its child nodes are. This is why anchors are set only after all of
         * the nodes have been created.
         */
        setAnchors: () => {
          for (const source of aliasObjects) {
            const ref = sourceObjects.get(source);
            if (typeof ref === "object" && ref.anchor && (identity.isScalar(ref.node) || identity.isCollection(ref.node))) {
              ref.node.anchor = ref.anchor;
            } else {
              const error = new Error("Failed to resolve repeated object (this should not happen)");
              error.source = source;
              throw error;
            }
          }
        },
        sourceObjects
      };
    }
    exports.anchorIsValid = anchorIsValid;
    exports.anchorNames = anchorNames;
    exports.createNodeAnchors = createNodeAnchors;
    exports.findNewAnchor = findNewAnchor;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/applyReviver.js
var require_applyReviver = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/applyReviver.js"(exports) {
    "use strict";
    function applyReviver(reviver, obj, key, val) {
      if (val && typeof val === "object") {
        if (Array.isArray(val)) {
          for (let i = 0, len = val.length; i < len; ++i) {
            const v0 = val[i];
            const v1 = applyReviver(reviver, val, String(i), v0);
            if (v1 === void 0)
              delete val[i];
            else if (v1 !== v0)
              val[i] = v1;
          }
        } else if (val instanceof Map) {
          for (const k of Array.from(val.keys())) {
            const v0 = val.get(k);
            const v1 = applyReviver(reviver, val, k, v0);
            if (v1 === void 0)
              val.delete(k);
            else if (v1 !== v0)
              val.set(k, v1);
          }
        } else if (val instanceof Set) {
          for (const v0 of Array.from(val)) {
            const v1 = applyReviver(reviver, val, v0, v0);
            if (v1 === void 0)
              val.delete(v0);
            else if (v1 !== v0) {
              val.delete(v0);
              val.add(v1);
            }
          }
        } else {
          for (const [k, v0] of Object.entries(val)) {
            const v1 = applyReviver(reviver, val, k, v0);
            if (v1 === void 0)
              delete val[k];
            else if (v1 !== v0)
              val[k] = v1;
          }
        }
      }
      return reviver.call(obj, key, val);
    }
    exports.applyReviver = applyReviver;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/toJS.js
var require_toJS = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/toJS.js"(exports) {
    "use strict";
    var identity = require_identity();
    function toJS(value2, arg, ctx) {
      if (Array.isArray(value2))
        return value2.map((v, i) => toJS(v, String(i), ctx));
      if (value2 && typeof value2.toJSON === "function") {
        if (!ctx || !identity.hasAnchor(value2))
          return value2.toJSON(arg, ctx);
        const data = { aliasCount: 0, count: 1, res: void 0 };
        ctx.anchors.set(value2, data);
        ctx.onCreate = (res2) => {
          data.res = res2;
          delete ctx.onCreate;
        };
        const res = value2.toJSON(arg, ctx);
        if (ctx.onCreate)
          ctx.onCreate(res);
        return res;
      }
      if (typeof value2 === "bigint" && !ctx?.keep)
        return Number(value2);
      return value2;
    }
    exports.toJS = toJS;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Node.js
var require_Node = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Node.js"(exports) {
    "use strict";
    var applyReviver = require_applyReviver();
    var identity = require_identity();
    var toJS = require_toJS();
    var NodeBase = class {
      constructor(type2) {
        Object.defineProperty(this, identity.NODE_TYPE, { value: type2 });
      }
      /** Create a copy of this node.  */
      clone() {
        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));
        if (this.range)
          copy.range = this.range.slice();
        return copy;
      }
      /** A plain JavaScript representation of this node. */
      toJS(doc, { mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
        if (!identity.isDocument(doc))
          throw new TypeError("A document argument is required");
        const ctx = {
          anchors: /* @__PURE__ */ new Map(),
          doc,
          keep: true,
          mapAsMap: mapAsMap === true,
          mapKeyWarned: false,
          maxAliasCount: typeof maxAliasCount === "number" ? maxAliasCount : 100
        };
        const res = toJS.toJS(this, "", ctx);
        if (typeof onAnchor === "function")
          for (const { count, res: res2 } of ctx.anchors.values())
            onAnchor(res2, count);
        return typeof reviver === "function" ? applyReviver.applyReviver(reviver, { "": res }, "", res) : res;
      }
    };
    exports.NodeBase = NodeBase;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Alias.js
var require_Alias = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Alias.js"(exports) {
    "use strict";
    var anchors = require_anchors();
    var visit = require_visit();
    var identity = require_identity();
    var Node = require_Node();
    var toJS = require_toJS();
    var Alias = class extends Node.NodeBase {
      constructor(source) {
        super(identity.ALIAS);
        this.source = source;
        Object.defineProperty(this, "tag", {
          set() {
            throw new Error("Alias nodes cannot have tags");
          }
        });
      }
      /**
       * Resolve the value of this alias within `doc`, finding the last
       * instance of the `source` anchor before this node.
       */
      resolve(doc, ctx) {
        let nodes;
        if (ctx?.aliasResolveCache) {
          nodes = ctx.aliasResolveCache;
        } else {
          nodes = [];
          visit.visit(doc, {
            Node: (_key, node) => {
              if (identity.isAlias(node) || identity.hasAnchor(node))
                nodes.push(node);
            }
          });
          if (ctx)
            ctx.aliasResolveCache = nodes;
        }
        let found = void 0;
        for (const node of nodes) {
          if (node === this)
            break;
          if (node.anchor === this.source)
            found = node;
        }
        return found;
      }
      toJSON(_arg, ctx) {
        if (!ctx)
          return { source: this.source };
        const { anchors: anchors2, doc, maxAliasCount } = ctx;
        const source = this.resolve(doc, ctx);
        if (!source) {
          const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;
          throw new ReferenceError(msg);
        }
        let data = anchors2.get(source);
        if (!data) {
          toJS.toJS(source, null, ctx);
          data = anchors2.get(source);
        }
        if (data?.res === void 0) {
          const msg = "This should not happen: Alias anchor was not resolved?";
          throw new ReferenceError(msg);
        }
        if (maxAliasCount >= 0) {
          data.count += 1;
          if (data.aliasCount === 0)
            data.aliasCount = getAliasCount(doc, source, anchors2);
          if (data.count * data.aliasCount > maxAliasCount) {
            const msg = "Excessive alias count indicates a resource exhaustion attack";
            throw new ReferenceError(msg);
          }
        }
        return data.res;
      }
      toString(ctx, _onComment, _onChompKeep) {
        const src = `*${this.source}`;
        if (ctx) {
          anchors.anchorIsValid(this.source);
          if (ctx.options.verifyAliasOrder && !ctx.anchors.has(this.source)) {
            const msg = `Unresolved alias (the anchor must be set before the alias): ${this.source}`;
            throw new Error(msg);
          }
          if (ctx.implicitKey)
            return `${src} `;
        }
        return src;
      }
    };
    function getAliasCount(doc, node, anchors2) {
      if (identity.isAlias(node)) {
        const source = node.resolve(doc);
        const anchor = anchors2 && source && anchors2.get(source);
        return anchor ? anchor.count * anchor.aliasCount : 0;
      } else if (identity.isCollection(node)) {
        let count = 0;
        for (const item of node.items) {
          const c = getAliasCount(doc, item, anchors2);
          if (c > count)
            count = c;
        }
        return count;
      } else if (identity.isPair(node)) {
        const kc = getAliasCount(doc, node.key, anchors2);
        const vc = getAliasCount(doc, node.value, anchors2);
        return Math.max(kc, vc);
      }
      return 1;
    }
    exports.Alias = Alias;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Scalar.js
var require_Scalar = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Scalar.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Node = require_Node();
    var toJS = require_toJS();
    var isScalarValue = (value2) => !value2 || typeof value2 !== "function" && typeof value2 !== "object";
    var Scalar = class extends Node.NodeBase {
      constructor(value2) {
        super(identity.SCALAR);
        this.value = value2;
      }
      toJSON(arg, ctx) {
        return ctx?.keep ? this.value : toJS.toJS(this.value, arg, ctx);
      }
      toString() {
        return String(this.value);
      }
    };
    Scalar.BLOCK_FOLDED = "BLOCK_FOLDED";
    Scalar.BLOCK_LITERAL = "BLOCK_LITERAL";
    Scalar.PLAIN = "PLAIN";
    Scalar.QUOTE_DOUBLE = "QUOTE_DOUBLE";
    Scalar.QUOTE_SINGLE = "QUOTE_SINGLE";
    exports.Scalar = Scalar;
    exports.isScalarValue = isScalarValue;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/createNode.js
var require_createNode = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/createNode.js"(exports) {
    "use strict";
    var Alias = require_Alias();
    var identity = require_identity();
    var Scalar = require_Scalar();
    var defaultTagPrefix = "tag:yaml.org,2002:";
    function findTagObject(value2, tagName, tags) {
      if (tagName) {
        const match = tags.filter((t) => t.tag === tagName);
        const tagObj = match.find((t) => !t.format) ?? match[0];
        if (!tagObj)
          throw new Error(`Tag ${tagName} not found`);
        return tagObj;
      }
      return tags.find((t) => t.identify?.(value2) && !t.format);
    }
    function createNode(value2, tagName, ctx) {
      if (identity.isDocument(value2))
        value2 = value2.contents;
      if (identity.isNode(value2))
        return value2;
      if (identity.isPair(value2)) {
        const map = ctx.schema[identity.MAP].createNode?.(ctx.schema, null, ctx);
        map.items.push(value2);
        return map;
      }
      if (value2 instanceof String || value2 instanceof Number || value2 instanceof Boolean || typeof BigInt !== "undefined" && value2 instanceof BigInt) {
        value2 = value2.valueOf();
      }
      const { aliasDuplicateObjects, onAnchor, onTagObj, schema, sourceObjects } = ctx;
      let ref = void 0;
      if (aliasDuplicateObjects && value2 && typeof value2 === "object") {
        ref = sourceObjects.get(value2);
        if (ref) {
          ref.anchor ?? (ref.anchor = onAnchor(value2));
          return new Alias.Alias(ref.anchor);
        } else {
          ref = { anchor: null, node: null };
          sourceObjects.set(value2, ref);
        }
      }
      if (tagName?.startsWith("!!"))
        tagName = defaultTagPrefix + tagName.slice(2);
      let tagObj = findTagObject(value2, tagName, schema.tags);
      if (!tagObj) {
        if (value2 && typeof value2.toJSON === "function") {
          value2 = value2.toJSON();
        }
        if (!value2 || typeof value2 !== "object") {
          const node2 = new Scalar.Scalar(value2);
          if (ref)
            ref.node = node2;
          return node2;
        }
        tagObj = value2 instanceof Map ? schema[identity.MAP] : Symbol.iterator in Object(value2) ? schema[identity.SEQ] : schema[identity.MAP];
      }
      if (onTagObj) {
        onTagObj(tagObj);
        delete ctx.onTagObj;
      }
      const node = tagObj?.createNode ? tagObj.createNode(ctx.schema, value2, ctx) : typeof tagObj?.nodeClass?.from === "function" ? tagObj.nodeClass.from(ctx.schema, value2, ctx) : new Scalar.Scalar(value2);
      if (tagName)
        node.tag = tagName;
      else if (!tagObj.default)
        node.tag = tagObj.tag;
      if (ref)
        ref.node = node;
      return node;
    }
    exports.createNode = createNode;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Collection.js
var require_Collection = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Collection.js"(exports) {
    "use strict";
    var createNode = require_createNode();
    var identity = require_identity();
    var Node = require_Node();
    function collectionFromPath(schema, path21, value2) {
      let v = value2;
      for (let i = path21.length - 1; i >= 0; --i) {
        const k = path21[i];
        if (typeof k === "number" && Number.isInteger(k) && k >= 0) {
          const a = [];
          a[k] = v;
          v = a;
        } else {
          v = /* @__PURE__ */ new Map([[k, v]]);
        }
      }
      return createNode.createNode(v, void 0, {
        aliasDuplicateObjects: false,
        keepUndefined: false,
        onAnchor: () => {
          throw new Error("This should not happen, please report a bug.");
        },
        schema,
        sourceObjects: /* @__PURE__ */ new Map()
      });
    }
    var isEmptyPath = (path21) => path21 == null || typeof path21 === "object" && !!path21[Symbol.iterator]().next().done;
    var Collection = class extends Node.NodeBase {
      constructor(type2, schema) {
        super(type2);
        Object.defineProperty(this, "schema", {
          value: schema,
          configurable: true,
          enumerable: false,
          writable: true
        });
      }
      /**
       * Create a copy of this collection.
       *
       * @param schema - If defined, overwrites the original's schema
       */
      clone(schema) {
        const copy = Object.create(Object.getPrototypeOf(this), Object.getOwnPropertyDescriptors(this));
        if (schema)
          copy.schema = schema;
        copy.items = copy.items.map((it) => identity.isNode(it) || identity.isPair(it) ? it.clone(schema) : it);
        if (this.range)
          copy.range = this.range.slice();
        return copy;
      }
      /**
       * Adds a value to the collection. For `!!map` and `!!omap` the value must
       * be a Pair instance or a `{ key, value }` object, which may not have a key
       * that already exists in the map.
       */
      addIn(path21, value2) {
        if (isEmptyPath(path21))
          this.add(value2);
        else {
          const [key, ...rest] = path21;
          const node = this.get(key, true);
          if (identity.isCollection(node))
            node.addIn(rest, value2);
          else if (node === void 0 && this.schema)
            this.set(key, collectionFromPath(this.schema, rest, value2));
          else
            throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
        }
      }
      /**
       * Removes a value from the collection.
       * @returns `true` if the item was found and removed.
       */
      deleteIn(path21) {
        const [key, ...rest] = path21;
        if (rest.length === 0)
          return this.delete(key);
        const node = this.get(key, true);
        if (identity.isCollection(node))
          return node.deleteIn(rest);
        else
          throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
      }
      /**
       * Returns item at `key`, or `undefined` if not found. By default unwraps
       * scalar values from their surrounding node; to disable set `keepScalar` to
       * `true` (collections are always returned intact).
       */
      getIn(path21, keepScalar) {
        const [key, ...rest] = path21;
        const node = this.get(key, true);
        if (rest.length === 0)
          return !keepScalar && identity.isScalar(node) ? node.value : node;
        else
          return identity.isCollection(node) ? node.getIn(rest, keepScalar) : void 0;
      }
      hasAllNullValues(allowScalar) {
        return this.items.every((node) => {
          if (!identity.isPair(node))
            return false;
          const n = node.value;
          return n == null || allowScalar && identity.isScalar(n) && n.value == null && !n.commentBefore && !n.comment && !n.tag;
        });
      }
      /**
       * Checks if the collection includes a value with the key `key`.
       */
      hasIn(path21) {
        const [key, ...rest] = path21;
        if (rest.length === 0)
          return this.has(key);
        const node = this.get(key, true);
        return identity.isCollection(node) ? node.hasIn(rest) : false;
      }
      /**
       * Sets a value in this collection. For `!!set`, `value` needs to be a
       * boolean to add/remove the item from the set.
       */
      setIn(path21, value2) {
        const [key, ...rest] = path21;
        if (rest.length === 0) {
          this.set(key, value2);
        } else {
          const node = this.get(key, true);
          if (identity.isCollection(node))
            node.setIn(rest, value2);
          else if (node === void 0 && this.schema)
            this.set(key, collectionFromPath(this.schema, rest, value2));
          else
            throw new Error(`Expected YAML collection at ${key}. Remaining path: ${rest}`);
        }
      }
    };
    exports.Collection = Collection;
    exports.collectionFromPath = collectionFromPath;
    exports.isEmptyPath = isEmptyPath;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyComment.js
var require_stringifyComment = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyComment.js"(exports) {
    "use strict";
    var stringifyComment = (str) => str.replace(/^(?!$)(?: $)?/gm, "#");
    function indentComment(comment, indent) {
      if (/^\n+$/.test(comment))
        return comment.substring(1);
      return indent ? comment.replace(/^(?! *$)/gm, indent) : comment;
    }
    var lineComment = (str, indent, comment) => str.endsWith("\n") ? indentComment(comment, indent) : comment.includes("\n") ? "\n" + indentComment(comment, indent) : (str.endsWith(" ") ? "" : " ") + comment;
    exports.indentComment = indentComment;
    exports.lineComment = lineComment;
    exports.stringifyComment = stringifyComment;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/foldFlowLines.js
var require_foldFlowLines = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/foldFlowLines.js"(exports) {
    "use strict";
    var FOLD_FLOW = "flow";
    var FOLD_BLOCK = "block";
    var FOLD_QUOTED = "quoted";
    function foldFlowLines(text2, indent, mode = "flow", { indentAtStart, lineWidth = 80, minContentWidth = 20, onFold, onOverflow } = {}) {
      if (!lineWidth || lineWidth < 0)
        return text2;
      if (lineWidth < minContentWidth)
        minContentWidth = 0;
      const endStep = Math.max(1 + minContentWidth, 1 + lineWidth - indent.length);
      if (text2.length <= endStep)
        return text2;
      const folds = [];
      const escapedFolds = {};
      let end = lineWidth - indent.length;
      if (typeof indentAtStart === "number") {
        if (indentAtStart > lineWidth - Math.max(2, minContentWidth))
          folds.push(0);
        else
          end = lineWidth - indentAtStart;
      }
      let split = void 0;
      let prev = void 0;
      let overflow = false;
      let i = -1;
      let escStart = -1;
      let escEnd = -1;
      if (mode === FOLD_BLOCK) {
        i = consumeMoreIndentedLines(text2, i, indent.length);
        if (i !== -1)
          end = i + endStep;
      }
      for (let ch; ch = text2[i += 1]; ) {
        if (mode === FOLD_QUOTED && ch === "\\") {
          escStart = i;
          switch (text2[i + 1]) {
            case "x":
              i += 3;
              break;
            case "u":
              i += 5;
              break;
            case "U":
              i += 9;
              break;
            default:
              i += 1;
          }
          escEnd = i;
        }
        if (ch === "\n") {
          if (mode === FOLD_BLOCK)
            i = consumeMoreIndentedLines(text2, i, indent.length);
          end = i + indent.length + endStep;
          split = void 0;
        } else {
          if (ch === " " && prev && prev !== " " && prev !== "\n" && prev !== "	") {
            const next = text2[i + 1];
            if (next && next !== " " && next !== "\n" && next !== "	")
              split = i;
          }
          if (i >= end) {
            if (split) {
              folds.push(split);
              end = split + endStep;
              split = void 0;
            } else if (mode === FOLD_QUOTED) {
              while (prev === " " || prev === "	") {
                prev = ch;
                ch = text2[i += 1];
                overflow = true;
              }
              const j = i > escEnd + 1 ? i - 2 : escStart - 1;
              if (escapedFolds[j])
                return text2;
              folds.push(j);
              escapedFolds[j] = true;
              end = j + endStep;
              split = void 0;
            } else {
              overflow = true;
            }
          }
        }
        prev = ch;
      }
      if (overflow && onOverflow)
        onOverflow();
      if (folds.length === 0)
        return text2;
      if (onFold)
        onFold();
      let res = text2.slice(0, folds[0]);
      for (let i2 = 0; i2 < folds.length; ++i2) {
        const fold = folds[i2];
        const end2 = folds[i2 + 1] || text2.length;
        if (fold === 0)
          res = `
${indent}${text2.slice(0, end2)}`;
        else {
          if (mode === FOLD_QUOTED && escapedFolds[fold])
            res += `${text2[fold]}\\`;
          res += `
${indent}${text2.slice(fold + 1, end2)}`;
        }
      }
      return res;
    }
    function consumeMoreIndentedLines(text2, i, indent) {
      let end = i;
      let start = i + 1;
      let ch = text2[start];
      while (ch === " " || ch === "	") {
        if (i < start + indent) {
          ch = text2[++i];
        } else {
          do {
            ch = text2[++i];
          } while (ch && ch !== "\n");
          end = i;
          start = i + 1;
          ch = text2[start];
        }
      }
      return end;
    }
    exports.FOLD_BLOCK = FOLD_BLOCK;
    exports.FOLD_FLOW = FOLD_FLOW;
    exports.FOLD_QUOTED = FOLD_QUOTED;
    exports.foldFlowLines = foldFlowLines;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyString.js
var require_stringifyString = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyString.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var foldFlowLines = require_foldFlowLines();
    var getFoldOptions = (ctx, isBlock) => ({
      indentAtStart: isBlock ? ctx.indent.length : ctx.indentAtStart,
      lineWidth: ctx.options.lineWidth,
      minContentWidth: ctx.options.minContentWidth
    });
    var containsDocumentMarker = (str) => /^(%|---|\.\.\.)/m.test(str);
    function lineLengthOverLimit(str, lineWidth, indentLength) {
      if (!lineWidth || lineWidth < 0)
        return false;
      const limit = lineWidth - indentLength;
      const strLen = str.length;
      if (strLen <= limit)
        return false;
      for (let i = 0, start = 0; i < strLen; ++i) {
        if (str[i] === "\n") {
          if (i - start > limit)
            return true;
          start = i + 1;
          if (strLen - start <= limit)
            return false;
        }
      }
      return true;
    }
    function doubleQuotedString(value2, ctx) {
      const json = JSON.stringify(value2);
      if (ctx.options.doubleQuotedAsJSON)
        return json;
      const { implicitKey } = ctx;
      const minMultiLineLength = ctx.options.doubleQuotedMinMultiLineLength;
      const indent = ctx.indent || (containsDocumentMarker(value2) ? "  " : "");
      let str = "";
      let start = 0;
      for (let i = 0, ch = json[i]; ch; ch = json[++i]) {
        if (ch === " " && json[i + 1] === "\\" && json[i + 2] === "n") {
          str += json.slice(start, i) + "\\ ";
          i += 1;
          start = i;
          ch = "\\";
        }
        if (ch === "\\")
          switch (json[i + 1]) {
            case "u":
              {
                str += json.slice(start, i);
                const code = json.substr(i + 2, 4);
                switch (code) {
                  case "0000":
                    str += "\\0";
                    break;
                  case "0007":
                    str += "\\a";
                    break;
                  case "000b":
                    str += "\\v";
                    break;
                  case "001b":
                    str += "\\e";
                    break;
                  case "0085":
                    str += "\\N";
                    break;
                  case "00a0":
                    str += "\\_";
                    break;
                  case "2028":
                    str += "\\L";
                    break;
                  case "2029":
                    str += "\\P";
                    break;
                  default:
                    if (code.substr(0, 2) === "00")
                      str += "\\x" + code.substr(2);
                    else
                      str += json.substr(i, 6);
                }
                i += 5;
                start = i + 1;
              }
              break;
            case "n":
              if (implicitKey || json[i + 2] === '"' || json.length < minMultiLineLength) {
                i += 1;
              } else {
                str += json.slice(start, i) + "\n\n";
                while (json[i + 2] === "\\" && json[i + 3] === "n" && json[i + 4] !== '"') {
                  str += "\n";
                  i += 2;
                }
                str += indent;
                if (json[i + 2] === " ")
                  str += "\\";
                i += 1;
                start = i + 1;
              }
              break;
            default:
              i += 1;
          }
      }
      str = start ? str + json.slice(start) : json;
      return implicitKey ? str : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_QUOTED, getFoldOptions(ctx, false));
    }
    function singleQuotedString(value2, ctx) {
      if (ctx.options.singleQuote === false || ctx.implicitKey && value2.includes("\n") || /[ \t]\n|\n[ \t]/.test(value2))
        return doubleQuotedString(value2, ctx);
      const indent = ctx.indent || (containsDocumentMarker(value2) ? "  " : "");
      const res = "'" + value2.replace(/'/g, "''").replace(/\n+/g, `$&
${indent}`) + "'";
      return ctx.implicitKey ? res : foldFlowLines.foldFlowLines(res, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));
    }
    function quotedString(value2, ctx) {
      const { singleQuote } = ctx.options;
      let qs;
      if (singleQuote === false)
        qs = doubleQuotedString;
      else {
        const hasDouble = value2.includes('"');
        const hasSingle = value2.includes("'");
        if (hasDouble && !hasSingle)
          qs = singleQuotedString;
        else if (hasSingle && !hasDouble)
          qs = doubleQuotedString;
        else
          qs = singleQuote ? singleQuotedString : doubleQuotedString;
      }
      return qs(value2, ctx);
    }
    var blockEndNewlines;
    try {
      blockEndNewlines = new RegExp("(^|(?<!\n))\n+(?!\n|$)", "g");
    } catch {
      blockEndNewlines = /\n+(?!\n|$)/g;
    }
    function blockString({ comment, type: type2, value: value2 }, ctx, onComment, onChompKeep) {
      const { blockQuote, commentString, lineWidth } = ctx.options;
      if (!blockQuote || /\n[\t ]+$/.test(value2)) {
        return quotedString(value2, ctx);
      }
      const indent = ctx.indent || (ctx.forceBlockIndent || containsDocumentMarker(value2) ? "  " : "");
      const literal = blockQuote === "literal" ? true : blockQuote === "folded" || type2 === Scalar.Scalar.BLOCK_FOLDED ? false : type2 === Scalar.Scalar.BLOCK_LITERAL ? true : !lineLengthOverLimit(value2, lineWidth, indent.length);
      if (!value2)
        return literal ? "|\n" : ">\n";
      let chomp;
      let endStart;
      for (endStart = value2.length; endStart > 0; --endStart) {
        const ch = value2[endStart - 1];
        if (ch !== "\n" && ch !== "	" && ch !== " ")
          break;
      }
      let end = value2.substring(endStart);
      const endNlPos = end.indexOf("\n");
      if (endNlPos === -1) {
        chomp = "-";
      } else if (value2 === end || endNlPos !== end.length - 1) {
        chomp = "+";
        if (onChompKeep)
          onChompKeep();
      } else {
        chomp = "";
      }
      if (end) {
        value2 = value2.slice(0, -end.length);
        if (end[end.length - 1] === "\n")
          end = end.slice(0, -1);
        end = end.replace(blockEndNewlines, `$&${indent}`);
      }
      let startWithSpace = false;
      let startEnd;
      let startNlPos = -1;
      for (startEnd = 0; startEnd < value2.length; ++startEnd) {
        const ch = value2[startEnd];
        if (ch === " ")
          startWithSpace = true;
        else if (ch === "\n")
          startNlPos = startEnd;
        else
          break;
      }
      let start = value2.substring(0, startNlPos < startEnd ? startNlPos + 1 : startEnd);
      if (start) {
        value2 = value2.substring(start.length);
        start = start.replace(/\n+/g, `$&${indent}`);
      }
      const indentSize = indent ? "2" : "1";
      let header = (startWithSpace ? indentSize : "") + chomp;
      if (comment) {
        header += " " + commentString(comment.replace(/ ?[\r\n]+/g, " "));
        if (onComment)
          onComment();
      }
      if (!literal) {
        const foldedValue = value2.replace(/\n+/g, "\n$&").replace(/(?:^|\n)([\t ].*)(?:([\n\t ]*)\n(?![\n\t ]))?/g, "$1$2").replace(/\n+/g, `$&${indent}`);
        let literalFallback = false;
        const foldOptions = getFoldOptions(ctx, true);
        if (blockQuote !== "folded" && type2 !== Scalar.Scalar.BLOCK_FOLDED) {
          foldOptions.onOverflow = () => {
            literalFallback = true;
          };
        }
        const body = foldFlowLines.foldFlowLines(`${start}${foldedValue}${end}`, indent, foldFlowLines.FOLD_BLOCK, foldOptions);
        if (!literalFallback)
          return `>${header}
${indent}${body}`;
      }
      value2 = value2.replace(/\n+/g, `$&${indent}`);
      return `|${header}
${indent}${start}${value2}${end}`;
    }
    function plainString(item, ctx, onComment, onChompKeep) {
      const { type: type2, value: value2 } = item;
      const { actualString, implicitKey, indent, indentStep, inFlow } = ctx;
      if (implicitKey && value2.includes("\n") || inFlow && /[[\]{},]/.test(value2)) {
        return quotedString(value2, ctx);
      }
      if (/^[\n\t ,[\]{}#&*!|>'"%@`]|^[?-]$|^[?-][ \t]|[\n:][ \t]|[ \t]\n|[\n\t ]#|[\n\t :]$/.test(value2)) {
        return implicitKey || inFlow || !value2.includes("\n") ? quotedString(value2, ctx) : blockString(item, ctx, onComment, onChompKeep);
      }
      if (!implicitKey && !inFlow && type2 !== Scalar.Scalar.PLAIN && value2.includes("\n")) {
        return blockString(item, ctx, onComment, onChompKeep);
      }
      if (containsDocumentMarker(value2)) {
        if (indent === "") {
          ctx.forceBlockIndent = true;
          return blockString(item, ctx, onComment, onChompKeep);
        } else if (implicitKey && indent === indentStep) {
          return quotedString(value2, ctx);
        }
      }
      const str = value2.replace(/\n+/g, `$&
${indent}`);
      if (actualString) {
        const test = (tag) => tag.default && tag.tag !== "tag:yaml.org,2002:str" && tag.test?.test(str);
        const { compat, tags } = ctx.doc.schema;
        if (tags.some(test) || compat?.some(test))
          return quotedString(value2, ctx);
      }
      return implicitKey ? str : foldFlowLines.foldFlowLines(str, indent, foldFlowLines.FOLD_FLOW, getFoldOptions(ctx, false));
    }
    function stringifyString(item, ctx, onComment, onChompKeep) {
      const { implicitKey, inFlow } = ctx;
      const ss = typeof item.value === "string" ? item : Object.assign({}, item, { value: String(item.value) });
      let { type: type2 } = item;
      if (type2 !== Scalar.Scalar.QUOTE_DOUBLE) {
        if (/[\x00-\x08\x0b-\x1f\x7f-\x9f\u{D800}-\u{DFFF}]/u.test(ss.value))
          type2 = Scalar.Scalar.QUOTE_DOUBLE;
      }
      const _stringify = (_type) => {
        switch (_type) {
          case Scalar.Scalar.BLOCK_FOLDED:
          case Scalar.Scalar.BLOCK_LITERAL:
            return implicitKey || inFlow ? quotedString(ss.value, ctx) : blockString(ss, ctx, onComment, onChompKeep);
          case Scalar.Scalar.QUOTE_DOUBLE:
            return doubleQuotedString(ss.value, ctx);
          case Scalar.Scalar.QUOTE_SINGLE:
            return singleQuotedString(ss.value, ctx);
          case Scalar.Scalar.PLAIN:
            return plainString(ss, ctx, onComment, onChompKeep);
          default:
            return null;
        }
      };
      let res = _stringify(type2);
      if (res === null) {
        const { defaultKeyType, defaultStringType } = ctx.options;
        const t = implicitKey && defaultKeyType || defaultStringType;
        res = _stringify(t);
        if (res === null)
          throw new Error(`Unsupported default string type ${t}`);
      }
      return res;
    }
    exports.stringifyString = stringifyString;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringify.js
var require_stringify = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringify.js"(exports) {
    "use strict";
    var anchors = require_anchors();
    var identity = require_identity();
    var stringifyComment = require_stringifyComment();
    var stringifyString = require_stringifyString();
    function createStringifyContext(doc, options) {
      const opt = Object.assign({
        blockQuote: true,
        commentString: stringifyComment.stringifyComment,
        defaultKeyType: null,
        defaultStringType: "PLAIN",
        directives: null,
        doubleQuotedAsJSON: false,
        doubleQuotedMinMultiLineLength: 40,
        falseStr: "false",
        flowCollectionPadding: true,
        indentSeq: true,
        lineWidth: 80,
        minContentWidth: 20,
        nullStr: "null",
        simpleKeys: false,
        singleQuote: null,
        trueStr: "true",
        verifyAliasOrder: true
      }, doc.schema.toStringOptions, options);
      let inFlow;
      switch (opt.collectionStyle) {
        case "block":
          inFlow = false;
          break;
        case "flow":
          inFlow = true;
          break;
        default:
          inFlow = null;
      }
      return {
        anchors: /* @__PURE__ */ new Set(),
        doc,
        flowCollectionPadding: opt.flowCollectionPadding ? " " : "",
        indent: "",
        indentStep: typeof opt.indent === "number" ? " ".repeat(opt.indent) : "  ",
        inFlow,
        options: opt
      };
    }
    function getTagObject(tags, item) {
      if (item.tag) {
        const match = tags.filter((t) => t.tag === item.tag);
        if (match.length > 0)
          return match.find((t) => t.format === item.format) ?? match[0];
      }
      let tagObj = void 0;
      let obj;
      if (identity.isScalar(item)) {
        obj = item.value;
        let match = tags.filter((t) => t.identify?.(obj));
        if (match.length > 1) {
          const testMatch = match.filter((t) => t.test);
          if (testMatch.length > 0)
            match = testMatch;
        }
        tagObj = match.find((t) => t.format === item.format) ?? match.find((t) => !t.format);
      } else {
        obj = item;
        tagObj = tags.find((t) => t.nodeClass && obj instanceof t.nodeClass);
      }
      if (!tagObj) {
        const name16 = obj?.constructor?.name ?? (obj === null ? "null" : typeof obj);
        throw new Error(`Tag not resolved for ${name16} value`);
      }
      return tagObj;
    }
    function stringifyProps(node, tagObj, { anchors: anchors$1, doc }) {
      if (!doc.directives)
        return "";
      const props = [];
      const anchor = (identity.isScalar(node) || identity.isCollection(node)) && node.anchor;
      if (anchor && anchors.anchorIsValid(anchor)) {
        anchors$1.add(anchor);
        props.push(`&${anchor}`);
      }
      const tag = node.tag ?? (tagObj.default ? null : tagObj.tag);
      if (tag)
        props.push(doc.directives.tagString(tag));
      return props.join(" ");
    }
    function stringify(item, ctx, onComment, onChompKeep) {
      if (identity.isPair(item))
        return item.toString(ctx, onComment, onChompKeep);
      if (identity.isAlias(item)) {
        if (ctx.doc.directives)
          return item.toString(ctx);
        if (ctx.resolvedAliases?.has(item)) {
          throw new TypeError(`Cannot stringify circular structure without alias nodes`);
        } else {
          if (ctx.resolvedAliases)
            ctx.resolvedAliases.add(item);
          else
            ctx.resolvedAliases = /* @__PURE__ */ new Set([item]);
          item = item.resolve(ctx.doc);
        }
      }
      let tagObj = void 0;
      const node = identity.isNode(item) ? item : ctx.doc.createNode(item, { onTagObj: (o) => tagObj = o });
      tagObj ?? (tagObj = getTagObject(ctx.doc.schema.tags, node));
      const props = stringifyProps(node, tagObj, ctx);
      if (props.length > 0)
        ctx.indentAtStart = (ctx.indentAtStart ?? 0) + props.length + 1;
      const str = typeof tagObj.stringify === "function" ? tagObj.stringify(node, ctx, onComment, onChompKeep) : identity.isScalar(node) ? stringifyString.stringifyString(node, ctx, onComment, onChompKeep) : node.toString(ctx, onComment, onChompKeep);
      if (!props)
        return str;
      return identity.isScalar(node) || str[0] === "{" || str[0] === "[" ? `${props} ${str}` : `${props}
${ctx.indent}${str}`;
    }
    exports.createStringifyContext = createStringifyContext;
    exports.stringify = stringify;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyPair.js
var require_stringifyPair = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyPair.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Scalar = require_Scalar();
    var stringify = require_stringify();
    var stringifyComment = require_stringifyComment();
    function stringifyPair({ key, value: value2 }, ctx, onComment, onChompKeep) {
      const { allNullValues, doc, indent, indentStep, options: { commentString, indentSeq, simpleKeys } } = ctx;
      let keyComment = identity.isNode(key) && key.comment || null;
      if (simpleKeys) {
        if (keyComment) {
          throw new Error("With simple keys, key nodes cannot have comments");
        }
        if (identity.isCollection(key) || !identity.isNode(key) && typeof key === "object") {
          const msg = "With simple keys, collection cannot be used as a key value";
          throw new Error(msg);
        }
      }
      let explicitKey = !simpleKeys && (!key || keyComment && value2 == null && !ctx.inFlow || identity.isCollection(key) || (identity.isScalar(key) ? key.type === Scalar.Scalar.BLOCK_FOLDED || key.type === Scalar.Scalar.BLOCK_LITERAL : typeof key === "object"));
      ctx = Object.assign({}, ctx, {
        allNullValues: false,
        implicitKey: !explicitKey && (simpleKeys || !allNullValues),
        indent: indent + indentStep
      });
      let keyCommentDone = false;
      let chompKeep = false;
      let str = stringify.stringify(key, ctx, () => keyCommentDone = true, () => chompKeep = true);
      if (!explicitKey && !ctx.inFlow && str.length > 1024) {
        if (simpleKeys)
          throw new Error("With simple keys, single line scalar must not span more than 1024 characters");
        explicitKey = true;
      }
      if (ctx.inFlow) {
        if (allNullValues || value2 == null) {
          if (keyCommentDone && onComment)
            onComment();
          return str === "" ? "?" : explicitKey ? `? ${str}` : str;
        }
      } else if (allNullValues && !simpleKeys || value2 == null && explicitKey) {
        str = `? ${str}`;
        if (keyComment && !keyCommentDone) {
          str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));
        } else if (chompKeep && onChompKeep)
          onChompKeep();
        return str;
      }
      if (keyCommentDone)
        keyComment = null;
      if (explicitKey) {
        if (keyComment)
          str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));
        str = `? ${str}
${indent}:`;
      } else {
        str = `${str}:`;
        if (keyComment)
          str += stringifyComment.lineComment(str, ctx.indent, commentString(keyComment));
      }
      let vsb, vcb, valueComment;
      if (identity.isNode(value2)) {
        vsb = !!value2.spaceBefore;
        vcb = value2.commentBefore;
        valueComment = value2.comment;
      } else {
        vsb = false;
        vcb = null;
        valueComment = null;
        if (value2 && typeof value2 === "object")
          value2 = doc.createNode(value2);
      }
      ctx.implicitKey = false;
      if (!explicitKey && !keyComment && identity.isScalar(value2))
        ctx.indentAtStart = str.length + 1;
      chompKeep = false;
      if (!indentSeq && indentStep.length >= 2 && !ctx.inFlow && !explicitKey && identity.isSeq(value2) && !value2.flow && !value2.tag && !value2.anchor) {
        ctx.indent = ctx.indent.substring(2);
      }
      let valueCommentDone = false;
      const valueStr = stringify.stringify(value2, ctx, () => valueCommentDone = true, () => chompKeep = true);
      let ws = " ";
      if (keyComment || vsb || vcb) {
        ws = vsb ? "\n" : "";
        if (vcb) {
          const cs = commentString(vcb);
          ws += `
${stringifyComment.indentComment(cs, ctx.indent)}`;
        }
        if (valueStr === "" && !ctx.inFlow) {
          if (ws === "\n" && valueComment)
            ws = "\n\n";
        } else {
          ws += `
${ctx.indent}`;
        }
      } else if (!explicitKey && identity.isCollection(value2)) {
        const vs0 = valueStr[0];
        const nl0 = valueStr.indexOf("\n");
        const hasNewline = nl0 !== -1;
        const flow = ctx.inFlow ?? value2.flow ?? value2.items.length === 0;
        if (hasNewline || !flow) {
          let hasPropsLine = false;
          if (hasNewline && (vs0 === "&" || vs0 === "!")) {
            let sp0 = valueStr.indexOf(" ");
            if (vs0 === "&" && sp0 !== -1 && sp0 < nl0 && valueStr[sp0 + 1] === "!") {
              sp0 = valueStr.indexOf(" ", sp0 + 1);
            }
            if (sp0 === -1 || nl0 < sp0)
              hasPropsLine = true;
          }
          if (!hasPropsLine)
            ws = `
${ctx.indent}`;
        }
      } else if (valueStr === "" || valueStr[0] === "\n") {
        ws = "";
      }
      str += ws + valueStr;
      if (ctx.inFlow) {
        if (valueCommentDone && onComment)
          onComment();
      } else if (valueComment && !valueCommentDone) {
        str += stringifyComment.lineComment(str, ctx.indent, commentString(valueComment));
      } else if (chompKeep && onChompKeep) {
        onChompKeep();
      }
      return str;
    }
    exports.stringifyPair = stringifyPair;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/log.js
var require_log = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/log.js"(exports) {
    "use strict";
    var node_process = __require("process");
    function debug2(logLevel, ...messages) {
      if (logLevel === "debug")
        console.log(...messages);
    }
    function warn(logLevel, warning) {
      if (logLevel === "debug" || logLevel === "warn") {
        if (typeof node_process.emitWarning === "function")
          node_process.emitWarning(warning);
        else
          console.warn(warning);
      }
    }
    exports.debug = debug2;
    exports.warn = warn;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/merge.js
var require_merge = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/merge.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Scalar = require_Scalar();
    var MERGE_KEY = "<<";
    var merge = {
      identify: (value2) => value2 === MERGE_KEY || typeof value2 === "symbol" && value2.description === MERGE_KEY,
      default: "key",
      tag: "tag:yaml.org,2002:merge",
      test: /^<<$/,
      resolve: () => Object.assign(new Scalar.Scalar(Symbol(MERGE_KEY)), {
        addToJSMap: addMergeToJSMap
      }),
      stringify: () => MERGE_KEY
    };
    var isMergeKey = (ctx, key) => (merge.identify(key) || identity.isScalar(key) && (!key.type || key.type === Scalar.Scalar.PLAIN) && merge.identify(key.value)) && ctx?.doc.schema.tags.some((tag) => tag.tag === merge.tag && tag.default);
    function addMergeToJSMap(ctx, map, value2) {
      value2 = ctx && identity.isAlias(value2) ? value2.resolve(ctx.doc) : value2;
      if (identity.isSeq(value2))
        for (const it of value2.items)
          mergeValue(ctx, map, it);
      else if (Array.isArray(value2))
        for (const it of value2)
          mergeValue(ctx, map, it);
      else
        mergeValue(ctx, map, value2);
    }
    function mergeValue(ctx, map, value2) {
      const source = ctx && identity.isAlias(value2) ? value2.resolve(ctx.doc) : value2;
      if (!identity.isMap(source))
        throw new Error("Merge sources must be maps or map aliases");
      const srcMap = source.toJSON(null, ctx, Map);
      for (const [key, value3] of srcMap) {
        if (map instanceof Map) {
          if (!map.has(key))
            map.set(key, value3);
        } else if (map instanceof Set) {
          map.add(key);
        } else if (!Object.prototype.hasOwnProperty.call(map, key)) {
          Object.defineProperty(map, key, {
            value: value3,
            writable: true,
            enumerable: true,
            configurable: true
          });
        }
      }
      return map;
    }
    exports.addMergeToJSMap = addMergeToJSMap;
    exports.isMergeKey = isMergeKey;
    exports.merge = merge;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/addPairToJSMap.js
var require_addPairToJSMap = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/addPairToJSMap.js"(exports) {
    "use strict";
    var log2 = require_log();
    var merge = require_merge();
    var stringify = require_stringify();
    var identity = require_identity();
    var toJS = require_toJS();
    function addPairToJSMap(ctx, map, { key, value: value2 }) {
      if (identity.isNode(key) && key.addToJSMap)
        key.addToJSMap(ctx, map, value2);
      else if (merge.isMergeKey(ctx, key))
        merge.addMergeToJSMap(ctx, map, value2);
      else {
        const jsKey = toJS.toJS(key, "", ctx);
        if (map instanceof Map) {
          map.set(jsKey, toJS.toJS(value2, jsKey, ctx));
        } else if (map instanceof Set) {
          map.add(jsKey);
        } else {
          const stringKey = stringifyKey(key, jsKey, ctx);
          const jsValue = toJS.toJS(value2, stringKey, ctx);
          if (stringKey in map)
            Object.defineProperty(map, stringKey, {
              value: jsValue,
              writable: true,
              enumerable: true,
              configurable: true
            });
          else
            map[stringKey] = jsValue;
        }
      }
      return map;
    }
    function stringifyKey(key, jsKey, ctx) {
      if (jsKey === null)
        return "";
      if (typeof jsKey !== "object")
        return String(jsKey);
      if (identity.isNode(key) && ctx?.doc) {
        const strCtx = stringify.createStringifyContext(ctx.doc, {});
        strCtx.anchors = /* @__PURE__ */ new Set();
        for (const node of ctx.anchors.keys())
          strCtx.anchors.add(node.anchor);
        strCtx.inFlow = true;
        strCtx.inStringifyKey = true;
        const strKey = key.toString(strCtx);
        if (!ctx.mapKeyWarned) {
          let jsonStr = JSON.stringify(strKey);
          if (jsonStr.length > 40)
            jsonStr = jsonStr.substring(0, 36) + '..."';
          log2.warn(ctx.doc.options.logLevel, `Keys with collection values will be stringified due to JS Object restrictions: ${jsonStr}. Set mapAsMap: true to use object keys.`);
          ctx.mapKeyWarned = true;
        }
        return strKey;
      }
      return JSON.stringify(jsKey);
    }
    exports.addPairToJSMap = addPairToJSMap;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Pair.js
var require_Pair = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/Pair.js"(exports) {
    "use strict";
    var createNode = require_createNode();
    var stringifyPair = require_stringifyPair();
    var addPairToJSMap = require_addPairToJSMap();
    var identity = require_identity();
    function createPair(key, value2, ctx) {
      const k = createNode.createNode(key, void 0, ctx);
      const v = createNode.createNode(value2, void 0, ctx);
      return new Pair(k, v);
    }
    var Pair = class _Pair {
      constructor(key, value2 = null) {
        Object.defineProperty(this, identity.NODE_TYPE, { value: identity.PAIR });
        this.key = key;
        this.value = value2;
      }
      clone(schema) {
        let { key, value: value2 } = this;
        if (identity.isNode(key))
          key = key.clone(schema);
        if (identity.isNode(value2))
          value2 = value2.clone(schema);
        return new _Pair(key, value2);
      }
      toJSON(_, ctx) {
        const pair = ctx?.mapAsMap ? /* @__PURE__ */ new Map() : {};
        return addPairToJSMap.addPairToJSMap(ctx, pair, this);
      }
      toString(ctx, onComment, onChompKeep) {
        return ctx?.doc ? stringifyPair.stringifyPair(this, ctx, onComment, onChompKeep) : JSON.stringify(this);
      }
    };
    exports.Pair = Pair;
    exports.createPair = createPair;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyCollection.js
var require_stringifyCollection = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyCollection.js"(exports) {
    "use strict";
    var identity = require_identity();
    var stringify = require_stringify();
    var stringifyComment = require_stringifyComment();
    function stringifyCollection(collection, ctx, options) {
      const flow = ctx.inFlow ?? collection.flow;
      const stringify2 = flow ? stringifyFlowCollection : stringifyBlockCollection;
      return stringify2(collection, ctx, options);
    }
    function stringifyBlockCollection({ comment, items }, ctx, { blockItemPrefix, flowChars, itemIndent, onChompKeep, onComment }) {
      const { indent, options: { commentString } } = ctx;
      const itemCtx = Object.assign({}, ctx, { indent: itemIndent, type: null });
      let chompKeep = false;
      const lines = [];
      for (let i = 0; i < items.length; ++i) {
        const item = items[i];
        let comment2 = null;
        if (identity.isNode(item)) {
          if (!chompKeep && item.spaceBefore)
            lines.push("");
          addCommentBefore(ctx, lines, item.commentBefore, chompKeep);
          if (item.comment)
            comment2 = item.comment;
        } else if (identity.isPair(item)) {
          const ik = identity.isNode(item.key) ? item.key : null;
          if (ik) {
            if (!chompKeep && ik.spaceBefore)
              lines.push("");
            addCommentBefore(ctx, lines, ik.commentBefore, chompKeep);
          }
        }
        chompKeep = false;
        let str2 = stringify.stringify(item, itemCtx, () => comment2 = null, () => chompKeep = true);
        if (comment2)
          str2 += stringifyComment.lineComment(str2, itemIndent, commentString(comment2));
        if (chompKeep && comment2)
          chompKeep = false;
        lines.push(blockItemPrefix + str2);
      }
      let str;
      if (lines.length === 0) {
        str = flowChars.start + flowChars.end;
      } else {
        str = lines[0];
        for (let i = 1; i < lines.length; ++i) {
          const line = lines[i];
          str += line ? `
${indent}${line}` : "\n";
        }
      }
      if (comment) {
        str += "\n" + stringifyComment.indentComment(commentString(comment), indent);
        if (onComment)
          onComment();
      } else if (chompKeep && onChompKeep)
        onChompKeep();
      return str;
    }
    function stringifyFlowCollection({ items }, ctx, { flowChars, itemIndent }) {
      const { indent, indentStep, flowCollectionPadding: fcPadding, options: { commentString } } = ctx;
      itemIndent += indentStep;
      const itemCtx = Object.assign({}, ctx, {
        indent: itemIndent,
        inFlow: true,
        type: null
      });
      let reqNewline = false;
      let linesAtValue = 0;
      const lines = [];
      for (let i = 0; i < items.length; ++i) {
        const item = items[i];
        let comment = null;
        if (identity.isNode(item)) {
          if (item.spaceBefore)
            lines.push("");
          addCommentBefore(ctx, lines, item.commentBefore, false);
          if (item.comment)
            comment = item.comment;
        } else if (identity.isPair(item)) {
          const ik = identity.isNode(item.key) ? item.key : null;
          if (ik) {
            if (ik.spaceBefore)
              lines.push("");
            addCommentBefore(ctx, lines, ik.commentBefore, false);
            if (ik.comment)
              reqNewline = true;
          }
          const iv = identity.isNode(item.value) ? item.value : null;
          if (iv) {
            if (iv.comment)
              comment = iv.comment;
            if (iv.commentBefore)
              reqNewline = true;
          } else if (item.value == null && ik?.comment) {
            comment = ik.comment;
          }
        }
        if (comment)
          reqNewline = true;
        let str = stringify.stringify(item, itemCtx, () => comment = null);
        if (i < items.length - 1)
          str += ",";
        if (comment)
          str += stringifyComment.lineComment(str, itemIndent, commentString(comment));
        if (!reqNewline && (lines.length > linesAtValue || str.includes("\n")))
          reqNewline = true;
        lines.push(str);
        linesAtValue = lines.length;
      }
      const { start, end } = flowChars;
      if (lines.length === 0) {
        return start + end;
      } else {
        if (!reqNewline) {
          const len = lines.reduce((sum, line) => sum + line.length + 2, 2);
          reqNewline = ctx.options.lineWidth > 0 && len > ctx.options.lineWidth;
        }
        if (reqNewline) {
          let str = start;
          for (const line of lines)
            str += line ? `
${indentStep}${indent}${line}` : "\n";
          return `${str}
${indent}${end}`;
        } else {
          return `${start}${fcPadding}${lines.join(" ")}${fcPadding}${end}`;
        }
      }
    }
    function addCommentBefore({ indent, options: { commentString } }, lines, comment, chompKeep) {
      if (comment && chompKeep)
        comment = comment.replace(/^\n+/, "");
      if (comment) {
        const ic = stringifyComment.indentComment(commentString(comment), indent);
        lines.push(ic.trimStart());
      }
    }
    exports.stringifyCollection = stringifyCollection;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/YAMLMap.js
var require_YAMLMap = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/YAMLMap.js"(exports) {
    "use strict";
    var stringifyCollection = require_stringifyCollection();
    var addPairToJSMap = require_addPairToJSMap();
    var Collection = require_Collection();
    var identity = require_identity();
    var Pair = require_Pair();
    var Scalar = require_Scalar();
    function findPair(items, key) {
      const k = identity.isScalar(key) ? key.value : key;
      for (const it of items) {
        if (identity.isPair(it)) {
          if (it.key === key || it.key === k)
            return it;
          if (identity.isScalar(it.key) && it.key.value === k)
            return it;
        }
      }
      return void 0;
    }
    var YAMLMap = class extends Collection.Collection {
      static get tagName() {
        return "tag:yaml.org,2002:map";
      }
      constructor(schema) {
        super(identity.MAP, schema);
        this.items = [];
      }
      /**
       * A generic collection parsing method that can be extended
       * to other node classes that inherit from YAMLMap
       */
      static from(schema, obj, ctx) {
        const { keepUndefined, replacer } = ctx;
        const map = new this(schema);
        const add = (key, value2) => {
          if (typeof replacer === "function")
            value2 = replacer.call(obj, key, value2);
          else if (Array.isArray(replacer) && !replacer.includes(key))
            return;
          if (value2 !== void 0 || keepUndefined)
            map.items.push(Pair.createPair(key, value2, ctx));
        };
        if (obj instanceof Map) {
          for (const [key, value2] of obj)
            add(key, value2);
        } else if (obj && typeof obj === "object") {
          for (const key of Object.keys(obj))
            add(key, obj[key]);
        }
        if (typeof schema.sortMapEntries === "function") {
          map.items.sort(schema.sortMapEntries);
        }
        return map;
      }
      /**
       * Adds a value to the collection.
       *
       * @param overwrite - If not set `true`, using a key that is already in the
       *   collection will throw. Otherwise, overwrites the previous value.
       */
      add(pair, overwrite) {
        let _pair;
        if (identity.isPair(pair))
          _pair = pair;
        else if (!pair || typeof pair !== "object" || !("key" in pair)) {
          _pair = new Pair.Pair(pair, pair?.value);
        } else
          _pair = new Pair.Pair(pair.key, pair.value);
        const prev = findPair(this.items, _pair.key);
        const sortEntries = this.schema?.sortMapEntries;
        if (prev) {
          if (!overwrite)
            throw new Error(`Key ${_pair.key} already set`);
          if (identity.isScalar(prev.value) && Scalar.isScalarValue(_pair.value))
            prev.value.value = _pair.value;
          else
            prev.value = _pair.value;
        } else if (sortEntries) {
          const i = this.items.findIndex((item) => sortEntries(_pair, item) < 0);
          if (i === -1)
            this.items.push(_pair);
          else
            this.items.splice(i, 0, _pair);
        } else {
          this.items.push(_pair);
        }
      }
      delete(key) {
        const it = findPair(this.items, key);
        if (!it)
          return false;
        const del = this.items.splice(this.items.indexOf(it), 1);
        return del.length > 0;
      }
      get(key, keepScalar) {
        const it = findPair(this.items, key);
        const node = it?.value;
        return (!keepScalar && identity.isScalar(node) ? node.value : node) ?? void 0;
      }
      has(key) {
        return !!findPair(this.items, key);
      }
      set(key, value2) {
        this.add(new Pair.Pair(key, value2), true);
      }
      /**
       * @param ctx - Conversion context, originally set in Document#toJS()
       * @param {Class} Type - If set, forces the returned collection type
       * @returns Instance of Type, Map, or Object
       */
      toJSON(_, ctx, Type) {
        const map = Type ? new Type() : ctx?.mapAsMap ? /* @__PURE__ */ new Map() : {};
        if (ctx?.onCreate)
          ctx.onCreate(map);
        for (const item of this.items)
          addPairToJSMap.addPairToJSMap(ctx, map, item);
        return map;
      }
      toString(ctx, onComment, onChompKeep) {
        if (!ctx)
          return JSON.stringify(this);
        for (const item of this.items) {
          if (!identity.isPair(item))
            throw new Error(`Map items must all be pairs; found ${JSON.stringify(item)} instead`);
        }
        if (!ctx.allNullValues && this.hasAllNullValues(false))
          ctx = Object.assign({}, ctx, { allNullValues: true });
        return stringifyCollection.stringifyCollection(this, ctx, {
          blockItemPrefix: "",
          flowChars: { start: "{", end: "}" },
          itemIndent: ctx.indent || "",
          onChompKeep,
          onComment
        });
      }
    };
    exports.YAMLMap = YAMLMap;
    exports.findPair = findPair;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/map.js
var require_map = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/map.js"(exports) {
    "use strict";
    var identity = require_identity();
    var YAMLMap = require_YAMLMap();
    var map = {
      collection: "map",
      default: true,
      nodeClass: YAMLMap.YAMLMap,
      tag: "tag:yaml.org,2002:map",
      resolve(map2, onError2) {
        if (!identity.isMap(map2))
          onError2("Expected a mapping for this tag");
        return map2;
      },
      createNode: (schema, obj, ctx) => YAMLMap.YAMLMap.from(schema, obj, ctx)
    };
    exports.map = map;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/YAMLSeq.js
var require_YAMLSeq = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/nodes/YAMLSeq.js"(exports) {
    "use strict";
    var createNode = require_createNode();
    var stringifyCollection = require_stringifyCollection();
    var Collection = require_Collection();
    var identity = require_identity();
    var Scalar = require_Scalar();
    var toJS = require_toJS();
    var YAMLSeq = class extends Collection.Collection {
      static get tagName() {
        return "tag:yaml.org,2002:seq";
      }
      constructor(schema) {
        super(identity.SEQ, schema);
        this.items = [];
      }
      add(value2) {
        this.items.push(value2);
      }
      /**
       * Removes a value from the collection.
       *
       * `key` must contain a representation of an integer for this to succeed.
       * It may be wrapped in a `Scalar`.
       *
       * @returns `true` if the item was found and removed.
       */
      delete(key) {
        const idx = asItemIndex(key);
        if (typeof idx !== "number")
          return false;
        const del = this.items.splice(idx, 1);
        return del.length > 0;
      }
      get(key, keepScalar) {
        const idx = asItemIndex(key);
        if (typeof idx !== "number")
          return void 0;
        const it = this.items[idx];
        return !keepScalar && identity.isScalar(it) ? it.value : it;
      }
      /**
       * Checks if the collection includes a value with the key `key`.
       *
       * `key` must contain a representation of an integer for this to succeed.
       * It may be wrapped in a `Scalar`.
       */
      has(key) {
        const idx = asItemIndex(key);
        return typeof idx === "number" && idx < this.items.length;
      }
      /**
       * Sets a value in this collection. For `!!set`, `value` needs to be a
       * boolean to add/remove the item from the set.
       *
       * If `key` does not contain a representation of an integer, this will throw.
       * It may be wrapped in a `Scalar`.
       */
      set(key, value2) {
        const idx = asItemIndex(key);
        if (typeof idx !== "number")
          throw new Error(`Expected a valid index, not ${key}.`);
        const prev = this.items[idx];
        if (identity.isScalar(prev) && Scalar.isScalarValue(value2))
          prev.value = value2;
        else
          this.items[idx] = value2;
      }
      toJSON(_, ctx) {
        const seq = [];
        if (ctx?.onCreate)
          ctx.onCreate(seq);
        let i = 0;
        for (const item of this.items)
          seq.push(toJS.toJS(item, String(i++), ctx));
        return seq;
      }
      toString(ctx, onComment, onChompKeep) {
        if (!ctx)
          return JSON.stringify(this);
        return stringifyCollection.stringifyCollection(this, ctx, {
          blockItemPrefix: "- ",
          flowChars: { start: "[", end: "]" },
          itemIndent: (ctx.indent || "") + "  ",
          onChompKeep,
          onComment
        });
      }
      static from(schema, obj, ctx) {
        const { replacer } = ctx;
        const seq = new this(schema);
        if (obj && Symbol.iterator in Object(obj)) {
          let i = 0;
          for (let it of obj) {
            if (typeof replacer === "function") {
              const key = obj instanceof Set ? it : String(i++);
              it = replacer.call(obj, key, it);
            }
            seq.items.push(createNode.createNode(it, void 0, ctx));
          }
        }
        return seq;
      }
    };
    function asItemIndex(key) {
      let idx = identity.isScalar(key) ? key.value : key;
      if (idx && typeof idx === "string")
        idx = Number(idx);
      return typeof idx === "number" && Number.isInteger(idx) && idx >= 0 ? idx : null;
    }
    exports.YAMLSeq = YAMLSeq;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/seq.js
var require_seq = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/seq.js"(exports) {
    "use strict";
    var identity = require_identity();
    var YAMLSeq = require_YAMLSeq();
    var seq = {
      collection: "seq",
      default: true,
      nodeClass: YAMLSeq.YAMLSeq,
      tag: "tag:yaml.org,2002:seq",
      resolve(seq2, onError2) {
        if (!identity.isSeq(seq2))
          onError2("Expected a sequence for this tag");
        return seq2;
      },
      createNode: (schema, obj, ctx) => YAMLSeq.YAMLSeq.from(schema, obj, ctx)
    };
    exports.seq = seq;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/string.js
var require_string = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/string.js"(exports) {
    "use strict";
    var stringifyString = require_stringifyString();
    var string = {
      identify: (value2) => typeof value2 === "string",
      default: true,
      tag: "tag:yaml.org,2002:str",
      resolve: (str) => str,
      stringify(item, ctx, onComment, onChompKeep) {
        ctx = Object.assign({ actualString: true }, ctx);
        return stringifyString.stringifyString(item, ctx, onComment, onChompKeep);
      }
    };
    exports.string = string;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/null.js
var require_null = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/common/null.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var nullTag = {
      identify: (value2) => value2 == null,
      createNode: () => new Scalar.Scalar(null),
      default: true,
      tag: "tag:yaml.org,2002:null",
      test: /^(?:~|[Nn]ull|NULL)?$/,
      resolve: () => new Scalar.Scalar(null),
      stringify: ({ source }, ctx) => typeof source === "string" && nullTag.test.test(source) ? source : ctx.options.nullStr
    };
    exports.nullTag = nullTag;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/bool.js
var require_bool = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/bool.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var boolTag = {
      identify: (value2) => typeof value2 === "boolean",
      default: true,
      tag: "tag:yaml.org,2002:bool",
      test: /^(?:[Tt]rue|TRUE|[Ff]alse|FALSE)$/,
      resolve: (str) => new Scalar.Scalar(str[0] === "t" || str[0] === "T"),
      stringify({ source, value: value2 }, ctx) {
        if (source && boolTag.test.test(source)) {
          const sv = source[0] === "t" || source[0] === "T";
          if (value2 === sv)
            return source;
        }
        return value2 ? ctx.options.trueStr : ctx.options.falseStr;
      }
    };
    exports.boolTag = boolTag;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyNumber.js
var require_stringifyNumber = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyNumber.js"(exports) {
    "use strict";
    function stringifyNumber({ format, minFractionDigits, tag, value: value2 }) {
      if (typeof value2 === "bigint")
        return String(value2);
      const num = typeof value2 === "number" ? value2 : Number(value2);
      if (!isFinite(num))
        return isNaN(num) ? ".nan" : num < 0 ? "-.inf" : ".inf";
      let n = Object.is(value2, -0) ? "-0" : JSON.stringify(value2);
      if (!format && minFractionDigits && (!tag || tag === "tag:yaml.org,2002:float") && /^\d/.test(n)) {
        let i = n.indexOf(".");
        if (i < 0) {
          i = n.length;
          n += ".";
        }
        let d = minFractionDigits - (n.length - i - 1);
        while (d-- > 0)
          n += "0";
      }
      return n;
    }
    exports.stringifyNumber = stringifyNumber;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/float.js
var require_float = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/float.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var stringifyNumber = require_stringifyNumber();
    var floatNaN = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      test: /^(?:[-+]?\.(?:inf|Inf|INF)|\.nan|\.NaN|\.NAN)$/,
      resolve: (str) => str.slice(-3).toLowerCase() === "nan" ? NaN : str[0] === "-" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
      stringify: stringifyNumber.stringifyNumber
    };
    var floatExp = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      format: "EXP",
      test: /^[-+]?(?:\.[0-9]+|[0-9]+(?:\.[0-9]*)?)[eE][-+]?[0-9]+$/,
      resolve: (str) => parseFloat(str),
      stringify(node) {
        const num = Number(node.value);
        return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);
      }
    };
    var float = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      test: /^[-+]?(?:\.[0-9]+|[0-9]+\.[0-9]*)$/,
      resolve(str) {
        const node = new Scalar.Scalar(parseFloat(str));
        const dot = str.indexOf(".");
        if (dot !== -1 && str[str.length - 1] === "0")
          node.minFractionDigits = str.length - dot - 1;
        return node;
      },
      stringify: stringifyNumber.stringifyNumber
    };
    exports.float = float;
    exports.floatExp = floatExp;
    exports.floatNaN = floatNaN;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/int.js
var require_int = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/int.js"(exports) {
    "use strict";
    var stringifyNumber = require_stringifyNumber();
    var intIdentify = (value2) => typeof value2 === "bigint" || Number.isInteger(value2);
    var intResolve = (str, offset, radix, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str.substring(offset), radix);
    function intStringify(node, radix, prefix) {
      const { value: value2 } = node;
      if (intIdentify(value2) && value2 >= 0)
        return prefix + value2.toString(radix);
      return stringifyNumber.stringifyNumber(node);
    }
    var intOct = {
      identify: (value2) => intIdentify(value2) && value2 >= 0,
      default: true,
      tag: "tag:yaml.org,2002:int",
      format: "OCT",
      test: /^0o[0-7]+$/,
      resolve: (str, _onError, opt) => intResolve(str, 2, 8, opt),
      stringify: (node) => intStringify(node, 8, "0o")
    };
    var int = {
      identify: intIdentify,
      default: true,
      tag: "tag:yaml.org,2002:int",
      test: /^[-+]?[0-9]+$/,
      resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
      stringify: stringifyNumber.stringifyNumber
    };
    var intHex = {
      identify: (value2) => intIdentify(value2) && value2 >= 0,
      default: true,
      tag: "tag:yaml.org,2002:int",
      format: "HEX",
      test: /^0x[0-9a-fA-F]+$/,
      resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
      stringify: (node) => intStringify(node, 16, "0x")
    };
    exports.int = int;
    exports.intHex = intHex;
    exports.intOct = intOct;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/schema.js
var require_schema = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/core/schema.js"(exports) {
    "use strict";
    var map = require_map();
    var _null = require_null();
    var seq = require_seq();
    var string = require_string();
    var bool = require_bool();
    var float = require_float();
    var int = require_int();
    var schema = [
      map.map,
      seq.seq,
      string.string,
      _null.nullTag,
      bool.boolTag,
      int.intOct,
      int.int,
      int.intHex,
      float.floatNaN,
      float.floatExp,
      float.float
    ];
    exports.schema = schema;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/json/schema.js
var require_schema2 = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/json/schema.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var map = require_map();
    var seq = require_seq();
    function intIdentify(value2) {
      return typeof value2 === "bigint" || Number.isInteger(value2);
    }
    var stringifyJSON2 = ({ value: value2 }) => JSON.stringify(value2);
    var jsonScalars = [
      {
        identify: (value2) => typeof value2 === "string",
        default: true,
        tag: "tag:yaml.org,2002:str",
        resolve: (str) => str,
        stringify: stringifyJSON2
      },
      {
        identify: (value2) => value2 == null,
        createNode: () => new Scalar.Scalar(null),
        default: true,
        tag: "tag:yaml.org,2002:null",
        test: /^null$/,
        resolve: () => null,
        stringify: stringifyJSON2
      },
      {
        identify: (value2) => typeof value2 === "boolean",
        default: true,
        tag: "tag:yaml.org,2002:bool",
        test: /^true$|^false$/,
        resolve: (str) => str === "true",
        stringify: stringifyJSON2
      },
      {
        identify: intIdentify,
        default: true,
        tag: "tag:yaml.org,2002:int",
        test: /^-?(?:0|[1-9][0-9]*)$/,
        resolve: (str, _onError, { intAsBigInt }) => intAsBigInt ? BigInt(str) : parseInt(str, 10),
        stringify: ({ value: value2 }) => intIdentify(value2) ? value2.toString() : JSON.stringify(value2)
      },
      {
        identify: (value2) => typeof value2 === "number",
        default: true,
        tag: "tag:yaml.org,2002:float",
        test: /^-?(?:0|[1-9][0-9]*)(?:\.[0-9]*)?(?:[eE][-+]?[0-9]+)?$/,
        resolve: (str) => parseFloat(str),
        stringify: stringifyJSON2
      }
    ];
    var jsonError = {
      default: true,
      tag: "",
      test: /^/,
      resolve(str, onError2) {
        onError2(`Unresolved plain scalar ${JSON.stringify(str)}`);
        return str;
      }
    };
    var schema = [map.map, seq.seq].concat(jsonScalars, jsonError);
    exports.schema = schema;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/binary.js
var require_binary = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/binary.js"(exports) {
    "use strict";
    var node_buffer = __require("buffer");
    var Scalar = require_Scalar();
    var stringifyString = require_stringifyString();
    var binary = {
      identify: (value2) => value2 instanceof Uint8Array,
      // Buffer inherits from Uint8Array
      default: false,
      tag: "tag:yaml.org,2002:binary",
      /**
       * Returns a Buffer in node and an Uint8Array in browsers
       *
       * To use the resulting buffer as an image, you'll want to do something like:
       *
       *   const blob = new Blob([buffer], { type: 'image/jpeg' })
       *   document.querySelector('#photo').src = URL.createObjectURL(blob)
       */
      resolve(src, onError2) {
        if (typeof node_buffer.Buffer === "function") {
          return node_buffer.Buffer.from(src, "base64");
        } else if (typeof atob === "function") {
          const str = atob(src.replace(/[\n\r]/g, ""));
          const buffer = new Uint8Array(str.length);
          for (let i = 0; i < str.length; ++i)
            buffer[i] = str.charCodeAt(i);
          return buffer;
        } else {
          onError2("This environment does not support reading binary tags; either Buffer or atob is required");
          return src;
        }
      },
      stringify({ comment, type: type2, value: value2 }, ctx, onComment, onChompKeep) {
        if (!value2)
          return "";
        const buf = value2;
        let str;
        if (typeof node_buffer.Buffer === "function") {
          str = buf instanceof node_buffer.Buffer ? buf.toString("base64") : node_buffer.Buffer.from(buf.buffer).toString("base64");
        } else if (typeof btoa === "function") {
          let s = "";
          for (let i = 0; i < buf.length; ++i)
            s += String.fromCharCode(buf[i]);
          str = btoa(s);
        } else {
          throw new Error("This environment does not support writing binary tags; either Buffer or btoa is required");
        }
        type2 ?? (type2 = Scalar.Scalar.BLOCK_LITERAL);
        if (type2 !== Scalar.Scalar.QUOTE_DOUBLE) {
          const lineWidth = Math.max(ctx.options.lineWidth - ctx.indent.length, ctx.options.minContentWidth);
          const n = Math.ceil(str.length / lineWidth);
          const lines = new Array(n);
          for (let i = 0, o = 0; i < n; ++i, o += lineWidth) {
            lines[i] = str.substr(o, lineWidth);
          }
          str = lines.join(type2 === Scalar.Scalar.BLOCK_LITERAL ? "\n" : " ");
        }
        return stringifyString.stringifyString({ comment, type: type2, value: str }, ctx, onComment, onChompKeep);
      }
    };
    exports.binary = binary;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/pairs.js
var require_pairs = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/pairs.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Pair = require_Pair();
    var Scalar = require_Scalar();
    var YAMLSeq = require_YAMLSeq();
    function resolvePairs(seq, onError2) {
      if (identity.isSeq(seq)) {
        for (let i = 0; i < seq.items.length; ++i) {
          let item = seq.items[i];
          if (identity.isPair(item))
            continue;
          else if (identity.isMap(item)) {
            if (item.items.length > 1)
              onError2("Each pair must have its own sequence indicator");
            const pair = item.items[0] || new Pair.Pair(new Scalar.Scalar(null));
            if (item.commentBefore)
              pair.key.commentBefore = pair.key.commentBefore ? `${item.commentBefore}
${pair.key.commentBefore}` : item.commentBefore;
            if (item.comment) {
              const cn = pair.value ?? pair.key;
              cn.comment = cn.comment ? `${item.comment}
${cn.comment}` : item.comment;
            }
            item = pair;
          }
          seq.items[i] = identity.isPair(item) ? item : new Pair.Pair(item);
        }
      } else
        onError2("Expected a sequence for this tag");
      return seq;
    }
    function createPairs(schema, iterable, ctx) {
      const { replacer } = ctx;
      const pairs2 = new YAMLSeq.YAMLSeq(schema);
      pairs2.tag = "tag:yaml.org,2002:pairs";
      let i = 0;
      if (iterable && Symbol.iterator in Object(iterable))
        for (let it of iterable) {
          if (typeof replacer === "function")
            it = replacer.call(iterable, String(i++), it);
          let key, value2;
          if (Array.isArray(it)) {
            if (it.length === 2) {
              key = it[0];
              value2 = it[1];
            } else
              throw new TypeError(`Expected [key, value] tuple: ${it}`);
          } else if (it && it instanceof Object) {
            const keys = Object.keys(it);
            if (keys.length === 1) {
              key = keys[0];
              value2 = it[key];
            } else {
              throw new TypeError(`Expected tuple with one key, not ${keys.length} keys`);
            }
          } else {
            key = it;
          }
          pairs2.items.push(Pair.createPair(key, value2, ctx));
        }
      return pairs2;
    }
    var pairs = {
      collection: "seq",
      default: false,
      tag: "tag:yaml.org,2002:pairs",
      resolve: resolvePairs,
      createNode: createPairs
    };
    exports.createPairs = createPairs;
    exports.pairs = pairs;
    exports.resolvePairs = resolvePairs;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/omap.js
var require_omap = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/omap.js"(exports) {
    "use strict";
    var identity = require_identity();
    var toJS = require_toJS();
    var YAMLMap = require_YAMLMap();
    var YAMLSeq = require_YAMLSeq();
    var pairs = require_pairs();
    var YAMLOMap = class _YAMLOMap extends YAMLSeq.YAMLSeq {
      constructor() {
        super();
        this.add = YAMLMap.YAMLMap.prototype.add.bind(this);
        this.delete = YAMLMap.YAMLMap.prototype.delete.bind(this);
        this.get = YAMLMap.YAMLMap.prototype.get.bind(this);
        this.has = YAMLMap.YAMLMap.prototype.has.bind(this);
        this.set = YAMLMap.YAMLMap.prototype.set.bind(this);
        this.tag = _YAMLOMap.tag;
      }
      /**
       * If `ctx` is given, the return type is actually `Map<unknown, unknown>`,
       * but TypeScript won't allow widening the signature of a child method.
       */
      toJSON(_, ctx) {
        if (!ctx)
          return super.toJSON(_);
        const map = /* @__PURE__ */ new Map();
        if (ctx?.onCreate)
          ctx.onCreate(map);
        for (const pair of this.items) {
          let key, value2;
          if (identity.isPair(pair)) {
            key = toJS.toJS(pair.key, "", ctx);
            value2 = toJS.toJS(pair.value, key, ctx);
          } else {
            key = toJS.toJS(pair, "", ctx);
          }
          if (map.has(key))
            throw new Error("Ordered maps must not include duplicate keys");
          map.set(key, value2);
        }
        return map;
      }
      static from(schema, iterable, ctx) {
        const pairs$1 = pairs.createPairs(schema, iterable, ctx);
        const omap2 = new this();
        omap2.items = pairs$1.items;
        return omap2;
      }
    };
    YAMLOMap.tag = "tag:yaml.org,2002:omap";
    var omap = {
      collection: "seq",
      identify: (value2) => value2 instanceof Map,
      nodeClass: YAMLOMap,
      default: false,
      tag: "tag:yaml.org,2002:omap",
      resolve(seq, onError2) {
        const pairs$1 = pairs.resolvePairs(seq, onError2);
        const seenKeys = [];
        for (const { key } of pairs$1.items) {
          if (identity.isScalar(key)) {
            if (seenKeys.includes(key.value)) {
              onError2(`Ordered maps must not include duplicate keys: ${key.value}`);
            } else {
              seenKeys.push(key.value);
            }
          }
        }
        return Object.assign(new YAMLOMap(), pairs$1);
      },
      createNode: (schema, iterable, ctx) => YAMLOMap.from(schema, iterable, ctx)
    };
    exports.YAMLOMap = YAMLOMap;
    exports.omap = omap;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/bool.js
var require_bool2 = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/bool.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    function boolStringify({ value: value2, source }, ctx) {
      const boolObj = value2 ? trueTag : falseTag;
      if (source && boolObj.test.test(source))
        return source;
      return value2 ? ctx.options.trueStr : ctx.options.falseStr;
    }
    var trueTag = {
      identify: (value2) => value2 === true,
      default: true,
      tag: "tag:yaml.org,2002:bool",
      test: /^(?:Y|y|[Yy]es|YES|[Tt]rue|TRUE|[Oo]n|ON)$/,
      resolve: () => new Scalar.Scalar(true),
      stringify: boolStringify
    };
    var falseTag = {
      identify: (value2) => value2 === false,
      default: true,
      tag: "tag:yaml.org,2002:bool",
      test: /^(?:N|n|[Nn]o|NO|[Ff]alse|FALSE|[Oo]ff|OFF)$/,
      resolve: () => new Scalar.Scalar(false),
      stringify: boolStringify
    };
    exports.falseTag = falseTag;
    exports.trueTag = trueTag;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/float.js
var require_float2 = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/float.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var stringifyNumber = require_stringifyNumber();
    var floatNaN = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      test: /^(?:[-+]?\.(?:inf|Inf|INF)|\.nan|\.NaN|\.NAN)$/,
      resolve: (str) => str.slice(-3).toLowerCase() === "nan" ? NaN : str[0] === "-" ? Number.NEGATIVE_INFINITY : Number.POSITIVE_INFINITY,
      stringify: stringifyNumber.stringifyNumber
    };
    var floatExp = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      format: "EXP",
      test: /^[-+]?(?:[0-9][0-9_]*)?(?:\.[0-9_]*)?[eE][-+]?[0-9]+$/,
      resolve: (str) => parseFloat(str.replace(/_/g, "")),
      stringify(node) {
        const num = Number(node.value);
        return isFinite(num) ? num.toExponential() : stringifyNumber.stringifyNumber(node);
      }
    };
    var float = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      test: /^[-+]?(?:[0-9][0-9_]*)?\.[0-9_]*$/,
      resolve(str) {
        const node = new Scalar.Scalar(parseFloat(str.replace(/_/g, "")));
        const dot = str.indexOf(".");
        if (dot !== -1) {
          const f = str.substring(dot + 1).replace(/_/g, "");
          if (f[f.length - 1] === "0")
            node.minFractionDigits = f.length;
        }
        return node;
      },
      stringify: stringifyNumber.stringifyNumber
    };
    exports.float = float;
    exports.floatExp = floatExp;
    exports.floatNaN = floatNaN;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/int.js
var require_int2 = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/int.js"(exports) {
    "use strict";
    var stringifyNumber = require_stringifyNumber();
    var intIdentify = (value2) => typeof value2 === "bigint" || Number.isInteger(value2);
    function intResolve(str, offset, radix, { intAsBigInt }) {
      const sign = str[0];
      if (sign === "-" || sign === "+")
        offset += 1;
      str = str.substring(offset).replace(/_/g, "");
      if (intAsBigInt) {
        switch (radix) {
          case 2:
            str = `0b${str}`;
            break;
          case 8:
            str = `0o${str}`;
            break;
          case 16:
            str = `0x${str}`;
            break;
        }
        const n2 = BigInt(str);
        return sign === "-" ? BigInt(-1) * n2 : n2;
      }
      const n = parseInt(str, radix);
      return sign === "-" ? -1 * n : n;
    }
    function intStringify(node, radix, prefix) {
      const { value: value2 } = node;
      if (intIdentify(value2)) {
        const str = value2.toString(radix);
        return value2 < 0 ? "-" + prefix + str.substr(1) : prefix + str;
      }
      return stringifyNumber.stringifyNumber(node);
    }
    var intBin = {
      identify: intIdentify,
      default: true,
      tag: "tag:yaml.org,2002:int",
      format: "BIN",
      test: /^[-+]?0b[0-1_]+$/,
      resolve: (str, _onError, opt) => intResolve(str, 2, 2, opt),
      stringify: (node) => intStringify(node, 2, "0b")
    };
    var intOct = {
      identify: intIdentify,
      default: true,
      tag: "tag:yaml.org,2002:int",
      format: "OCT",
      test: /^[-+]?0[0-7_]+$/,
      resolve: (str, _onError, opt) => intResolve(str, 1, 8, opt),
      stringify: (node) => intStringify(node, 8, "0")
    };
    var int = {
      identify: intIdentify,
      default: true,
      tag: "tag:yaml.org,2002:int",
      test: /^[-+]?[0-9][0-9_]*$/,
      resolve: (str, _onError, opt) => intResolve(str, 0, 10, opt),
      stringify: stringifyNumber.stringifyNumber
    };
    var intHex = {
      identify: intIdentify,
      default: true,
      tag: "tag:yaml.org,2002:int",
      format: "HEX",
      test: /^[-+]?0x[0-9a-fA-F_]+$/,
      resolve: (str, _onError, opt) => intResolve(str, 2, 16, opt),
      stringify: (node) => intStringify(node, 16, "0x")
    };
    exports.int = int;
    exports.intBin = intBin;
    exports.intHex = intHex;
    exports.intOct = intOct;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/set.js
var require_set = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/set.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Pair = require_Pair();
    var YAMLMap = require_YAMLMap();
    var YAMLSet = class _YAMLSet extends YAMLMap.YAMLMap {
      constructor(schema) {
        super(schema);
        this.tag = _YAMLSet.tag;
      }
      add(key) {
        let pair;
        if (identity.isPair(key))
          pair = key;
        else if (key && typeof key === "object" && "key" in key && "value" in key && key.value === null)
          pair = new Pair.Pair(key.key, null);
        else
          pair = new Pair.Pair(key, null);
        const prev = YAMLMap.findPair(this.items, pair.key);
        if (!prev)
          this.items.push(pair);
      }
      /**
       * If `keepPair` is `true`, returns the Pair matching `key`.
       * Otherwise, returns the value of that Pair's key.
       */
      get(key, keepPair) {
        const pair = YAMLMap.findPair(this.items, key);
        return !keepPair && identity.isPair(pair) ? identity.isScalar(pair.key) ? pair.key.value : pair.key : pair;
      }
      set(key, value2) {
        if (typeof value2 !== "boolean")
          throw new Error(`Expected boolean value for set(key, value) in a YAML set, not ${typeof value2}`);
        const prev = YAMLMap.findPair(this.items, key);
        if (prev && !value2) {
          this.items.splice(this.items.indexOf(prev), 1);
        } else if (!prev && value2) {
          this.items.push(new Pair.Pair(key));
        }
      }
      toJSON(_, ctx) {
        return super.toJSON(_, ctx, Set);
      }
      toString(ctx, onComment, onChompKeep) {
        if (!ctx)
          return JSON.stringify(this);
        if (this.hasAllNullValues(true))
          return super.toString(Object.assign({}, ctx, { allNullValues: true }), onComment, onChompKeep);
        else
          throw new Error("Set items must all have null values");
      }
      static from(schema, iterable, ctx) {
        const { replacer } = ctx;
        const set2 = new this(schema);
        if (iterable && Symbol.iterator in Object(iterable))
          for (let value2 of iterable) {
            if (typeof replacer === "function")
              value2 = replacer.call(iterable, value2, value2);
            set2.items.push(Pair.createPair(value2, null, ctx));
          }
        return set2;
      }
    };
    YAMLSet.tag = "tag:yaml.org,2002:set";
    var set = {
      collection: "map",
      identify: (value2) => value2 instanceof Set,
      nodeClass: YAMLSet,
      default: false,
      tag: "tag:yaml.org,2002:set",
      createNode: (schema, iterable, ctx) => YAMLSet.from(schema, iterable, ctx),
      resolve(map, onError2) {
        if (identity.isMap(map)) {
          if (map.hasAllNullValues(true))
            return Object.assign(new YAMLSet(), map);
          else
            onError2("Set items must all have null values");
        } else
          onError2("Expected a mapping for this tag");
        return map;
      }
    };
    exports.YAMLSet = YAMLSet;
    exports.set = set;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/timestamp.js
var require_timestamp = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/timestamp.js"(exports) {
    "use strict";
    var stringifyNumber = require_stringifyNumber();
    function parseSexagesimal(str, asBigInt) {
      const sign = str[0];
      const parts = sign === "-" || sign === "+" ? str.substring(1) : str;
      const num = (n) => asBigInt ? BigInt(n) : Number(n);
      const res = parts.replace(/_/g, "").split(":").reduce((res2, p) => res2 * num(60) + num(p), num(0));
      return sign === "-" ? num(-1) * res : res;
    }
    function stringifySexagesimal(node) {
      let { value: value2 } = node;
      let num = (n) => n;
      if (typeof value2 === "bigint")
        num = (n) => BigInt(n);
      else if (isNaN(value2) || !isFinite(value2))
        return stringifyNumber.stringifyNumber(node);
      let sign = "";
      if (value2 < 0) {
        sign = "-";
        value2 *= num(-1);
      }
      const _60 = num(60);
      const parts = [value2 % _60];
      if (value2 < 60) {
        parts.unshift(0);
      } else {
        value2 = (value2 - parts[0]) / _60;
        parts.unshift(value2 % _60);
        if (value2 >= 60) {
          value2 = (value2 - parts[0]) / _60;
          parts.unshift(value2);
        }
      }
      return sign + parts.map((n) => String(n).padStart(2, "0")).join(":").replace(/000000\d*$/, "");
    }
    var intTime = {
      identify: (value2) => typeof value2 === "bigint" || Number.isInteger(value2),
      default: true,
      tag: "tag:yaml.org,2002:int",
      format: "TIME",
      test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+$/,
      resolve: (str, _onError, { intAsBigInt }) => parseSexagesimal(str, intAsBigInt),
      stringify: stringifySexagesimal
    };
    var floatTime = {
      identify: (value2) => typeof value2 === "number",
      default: true,
      tag: "tag:yaml.org,2002:float",
      format: "TIME",
      test: /^[-+]?[0-9][0-9_]*(?::[0-5]?[0-9])+\.[0-9_]*$/,
      resolve: (str) => parseSexagesimal(str, false),
      stringify: stringifySexagesimal
    };
    var timestamp = {
      identify: (value2) => value2 instanceof Date,
      default: true,
      tag: "tag:yaml.org,2002:timestamp",
      // If the time zone is omitted, the timestamp is assumed to be specified in UTC. The time part
      // may be omitted altogether, resulting in a date format. In such a case, the time part is
      // assumed to be 00:00:00Z (start of day, UTC).
      test: RegExp("^([0-9]{4})-([0-9]{1,2})-([0-9]{1,2})(?:(?:t|T|[ \\t]+)([0-9]{1,2}):([0-9]{1,2}):([0-9]{1,2}(\\.[0-9]+)?)(?:[ \\t]*(Z|[-+][012]?[0-9](?::[0-9]{2})?))?)?$"),
      resolve(str) {
        const match = str.match(timestamp.test);
        if (!match)
          throw new Error("!!timestamp expects a date, starting with yyyy-mm-dd");
        const [, year, month, day, hour, minute, second] = match.map(Number);
        const millisec = match[7] ? Number((match[7] + "00").substr(1, 3)) : 0;
        let date = Date.UTC(year, month - 1, day, hour || 0, minute || 0, second || 0, millisec);
        const tz = match[8];
        if (tz && tz !== "Z") {
          let d = parseSexagesimal(tz, false);
          if (Math.abs(d) < 30)
            d *= 60;
          date -= 6e4 * d;
        }
        return new Date(date);
      },
      stringify: ({ value: value2 }) => value2?.toISOString().replace(/(T00:00:00)?\.000Z$/, "") ?? ""
    };
    exports.floatTime = floatTime;
    exports.intTime = intTime;
    exports.timestamp = timestamp;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/schema.js
var require_schema3 = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/yaml-1.1/schema.js"(exports) {
    "use strict";
    var map = require_map();
    var _null = require_null();
    var seq = require_seq();
    var string = require_string();
    var binary = require_binary();
    var bool = require_bool2();
    var float = require_float2();
    var int = require_int2();
    var merge = require_merge();
    var omap = require_omap();
    var pairs = require_pairs();
    var set = require_set();
    var timestamp = require_timestamp();
    var schema = [
      map.map,
      seq.seq,
      string.string,
      _null.nullTag,
      bool.trueTag,
      bool.falseTag,
      int.intBin,
      int.intOct,
      int.int,
      int.intHex,
      float.floatNaN,
      float.floatExp,
      float.float,
      binary.binary,
      merge.merge,
      omap.omap,
      pairs.pairs,
      set.set,
      timestamp.intTime,
      timestamp.floatTime,
      timestamp.timestamp
    ];
    exports.schema = schema;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/tags.js
var require_tags = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/tags.js"(exports) {
    "use strict";
    var map = require_map();
    var _null = require_null();
    var seq = require_seq();
    var string = require_string();
    var bool = require_bool();
    var float = require_float();
    var int = require_int();
    var schema = require_schema();
    var schema$1 = require_schema2();
    var binary = require_binary();
    var merge = require_merge();
    var omap = require_omap();
    var pairs = require_pairs();
    var schema$2 = require_schema3();
    var set = require_set();
    var timestamp = require_timestamp();
    var schemas = /* @__PURE__ */ new Map([
      ["core", schema.schema],
      ["failsafe", [map.map, seq.seq, string.string]],
      ["json", schema$1.schema],
      ["yaml11", schema$2.schema],
      ["yaml-1.1", schema$2.schema]
    ]);
    var tagsByName = {
      binary: binary.binary,
      bool: bool.boolTag,
      float: float.float,
      floatExp: float.floatExp,
      floatNaN: float.floatNaN,
      floatTime: timestamp.floatTime,
      int: int.int,
      intHex: int.intHex,
      intOct: int.intOct,
      intTime: timestamp.intTime,
      map: map.map,
      merge: merge.merge,
      null: _null.nullTag,
      omap: omap.omap,
      pairs: pairs.pairs,
      seq: seq.seq,
      set: set.set,
      timestamp: timestamp.timestamp
    };
    var coreKnownTags = {
      "tag:yaml.org,2002:binary": binary.binary,
      "tag:yaml.org,2002:merge": merge.merge,
      "tag:yaml.org,2002:omap": omap.omap,
      "tag:yaml.org,2002:pairs": pairs.pairs,
      "tag:yaml.org,2002:set": set.set,
      "tag:yaml.org,2002:timestamp": timestamp.timestamp
    };
    function getTags(customTags, schemaName, addMergeTag) {
      const schemaTags = schemas.get(schemaName);
      if (schemaTags && !customTags) {
        return addMergeTag && !schemaTags.includes(merge.merge) ? schemaTags.concat(merge.merge) : schemaTags.slice();
      }
      let tags = schemaTags;
      if (!tags) {
        if (Array.isArray(customTags))
          tags = [];
        else {
          const keys = Array.from(schemas.keys()).filter((key) => key !== "yaml11").map((key) => JSON.stringify(key)).join(", ");
          throw new Error(`Unknown schema "${schemaName}"; use one of ${keys} or define customTags array`);
        }
      }
      if (Array.isArray(customTags)) {
        for (const tag of customTags)
          tags = tags.concat(tag);
      } else if (typeof customTags === "function") {
        tags = customTags(tags.slice());
      }
      if (addMergeTag)
        tags = tags.concat(merge.merge);
      return tags.reduce((tags2, tag) => {
        const tagObj = typeof tag === "string" ? tagsByName[tag] : tag;
        if (!tagObj) {
          const tagName = JSON.stringify(tag);
          const keys = Object.keys(tagsByName).map((key) => JSON.stringify(key)).join(", ");
          throw new Error(`Unknown custom tag ${tagName}; use one of ${keys}`);
        }
        if (!tags2.includes(tagObj))
          tags2.push(tagObj);
        return tags2;
      }, []);
    }
    exports.coreKnownTags = coreKnownTags;
    exports.getTags = getTags;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/Schema.js
var require_Schema = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/schema/Schema.js"(exports) {
    "use strict";
    var identity = require_identity();
    var map = require_map();
    var seq = require_seq();
    var string = require_string();
    var tags = require_tags();
    var sortMapEntriesByKey = (a, b) => a.key < b.key ? -1 : a.key > b.key ? 1 : 0;
    var Schema = class _Schema {
      constructor({ compat, customTags, merge, resolveKnownTags, schema, sortMapEntries, toStringDefaults }) {
        this.compat = Array.isArray(compat) ? tags.getTags(compat, "compat") : compat ? tags.getTags(null, compat) : null;
        this.name = typeof schema === "string" && schema || "core";
        this.knownTags = resolveKnownTags ? tags.coreKnownTags : {};
        this.tags = tags.getTags(customTags, this.name, merge);
        this.toStringOptions = toStringDefaults ?? null;
        Object.defineProperty(this, identity.MAP, { value: map.map });
        Object.defineProperty(this, identity.SCALAR, { value: string.string });
        Object.defineProperty(this, identity.SEQ, { value: seq.seq });
        this.sortMapEntries = typeof sortMapEntries === "function" ? sortMapEntries : sortMapEntries === true ? sortMapEntriesByKey : null;
      }
      clone() {
        const copy = Object.create(_Schema.prototype, Object.getOwnPropertyDescriptors(this));
        copy.tags = this.tags.slice();
        return copy;
      }
    };
    exports.Schema = Schema;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyDocument.js
var require_stringifyDocument = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/stringify/stringifyDocument.js"(exports) {
    "use strict";
    var identity = require_identity();
    var stringify = require_stringify();
    var stringifyComment = require_stringifyComment();
    function stringifyDocument(doc, options) {
      const lines = [];
      let hasDirectives = options.directives === true;
      if (options.directives !== false && doc.directives) {
        const dir = doc.directives.toString(doc);
        if (dir) {
          lines.push(dir);
          hasDirectives = true;
        } else if (doc.directives.docStart)
          hasDirectives = true;
      }
      if (hasDirectives)
        lines.push("---");
      const ctx = stringify.createStringifyContext(doc, options);
      const { commentString } = ctx.options;
      if (doc.commentBefore) {
        if (lines.length !== 1)
          lines.unshift("");
        const cs = commentString(doc.commentBefore);
        lines.unshift(stringifyComment.indentComment(cs, ""));
      }
      let chompKeep = false;
      let contentComment = null;
      if (doc.contents) {
        if (identity.isNode(doc.contents)) {
          if (doc.contents.spaceBefore && hasDirectives)
            lines.push("");
          if (doc.contents.commentBefore) {
            const cs = commentString(doc.contents.commentBefore);
            lines.push(stringifyComment.indentComment(cs, ""));
          }
          ctx.forceBlockIndent = !!doc.comment;
          contentComment = doc.contents.comment;
        }
        const onChompKeep = contentComment ? void 0 : () => chompKeep = true;
        let body = stringify.stringify(doc.contents, ctx, () => contentComment = null, onChompKeep);
        if (contentComment)
          body += stringifyComment.lineComment(body, "", commentString(contentComment));
        if ((body[0] === "|" || body[0] === ">") && lines[lines.length - 1] === "---") {
          lines[lines.length - 1] = `--- ${body}`;
        } else
          lines.push(body);
      } else {
        lines.push(stringify.stringify(doc.contents, ctx));
      }
      if (doc.directives?.docEnd) {
        if (doc.comment) {
          const cs = commentString(doc.comment);
          if (cs.includes("\n")) {
            lines.push("...");
            lines.push(stringifyComment.indentComment(cs, ""));
          } else {
            lines.push(`... ${cs}`);
          }
        } else {
          lines.push("...");
        }
      } else {
        let dc = doc.comment;
        if (dc && chompKeep)
          dc = dc.replace(/^\n+/, "");
        if (dc) {
          if ((!chompKeep || contentComment) && lines[lines.length - 1] !== "")
            lines.push("");
          lines.push(stringifyComment.indentComment(commentString(dc), ""));
        }
      }
      return lines.join("\n") + "\n";
    }
    exports.stringifyDocument = stringifyDocument;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/Document.js
var require_Document = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/doc/Document.js"(exports) {
    "use strict";
    var Alias = require_Alias();
    var Collection = require_Collection();
    var identity = require_identity();
    var Pair = require_Pair();
    var toJS = require_toJS();
    var Schema = require_Schema();
    var stringifyDocument = require_stringifyDocument();
    var anchors = require_anchors();
    var applyReviver = require_applyReviver();
    var createNode = require_createNode();
    var directives = require_directives();
    var Document = class _Document {
      constructor(value2, replacer, options) {
        this.commentBefore = null;
        this.comment = null;
        this.errors = [];
        this.warnings = [];
        Object.defineProperty(this, identity.NODE_TYPE, { value: identity.DOC });
        let _replacer = null;
        if (typeof replacer === "function" || Array.isArray(replacer)) {
          _replacer = replacer;
        } else if (options === void 0 && replacer) {
          options = replacer;
          replacer = void 0;
        }
        const opt = Object.assign({
          intAsBigInt: false,
          keepSourceTokens: false,
          logLevel: "warn",
          prettyErrors: true,
          strict: true,
          stringKeys: false,
          uniqueKeys: true,
          version: "1.2"
        }, options);
        this.options = opt;
        let { version } = opt;
        if (options?._directives) {
          this.directives = options._directives.atDocument();
          if (this.directives.yaml.explicit)
            version = this.directives.yaml.version;
        } else
          this.directives = new directives.Directives({ version });
        this.setSchema(version, options);
        this.contents = value2 === void 0 ? null : this.createNode(value2, _replacer, options);
      }
      /**
       * Create a deep copy of this Document and its contents.
       *
       * Custom Node values that inherit from `Object` still refer to their original instances.
       */
      clone() {
        const copy = Object.create(_Document.prototype, {
          [identity.NODE_TYPE]: { value: identity.DOC }
        });
        copy.commentBefore = this.commentBefore;
        copy.comment = this.comment;
        copy.errors = this.errors.slice();
        copy.warnings = this.warnings.slice();
        copy.options = Object.assign({}, this.options);
        if (this.directives)
          copy.directives = this.directives.clone();
        copy.schema = this.schema.clone();
        copy.contents = identity.isNode(this.contents) ? this.contents.clone(copy.schema) : this.contents;
        if (this.range)
          copy.range = this.range.slice();
        return copy;
      }
      /** Adds a value to the document. */
      add(value2) {
        if (assertCollection(this.contents))
          this.contents.add(value2);
      }
      /** Adds a value to the document. */
      addIn(path21, value2) {
        if (assertCollection(this.contents))
          this.contents.addIn(path21, value2);
      }
      /**
       * Create a new `Alias` node, ensuring that the target `node` has the required anchor.
       *
       * If `node` already has an anchor, `name` is ignored.
       * Otherwise, the `node.anchor` value will be set to `name`,
       * or if an anchor with that name is already present in the document,
       * `name` will be used as a prefix for a new unique anchor.
       * If `name` is undefined, the generated anchor will use 'a' as a prefix.
       */
      createAlias(node, name16) {
        if (!node.anchor) {
          const prev = anchors.anchorNames(this);
          node.anchor = // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
          !name16 || prev.has(name16) ? anchors.findNewAnchor(name16 || "a", prev) : name16;
        }
        return new Alias.Alias(node.anchor);
      }
      createNode(value2, replacer, options) {
        let _replacer = void 0;
        if (typeof replacer === "function") {
          value2 = replacer.call({ "": value2 }, "", value2);
          _replacer = replacer;
        } else if (Array.isArray(replacer)) {
          const keyToStr = (v) => typeof v === "number" || v instanceof String || v instanceof Number;
          const asStr = replacer.filter(keyToStr).map(String);
          if (asStr.length > 0)
            replacer = replacer.concat(asStr);
          _replacer = replacer;
        } else if (options === void 0 && replacer) {
          options = replacer;
          replacer = void 0;
        }
        const { aliasDuplicateObjects, anchorPrefix, flow, keepUndefined, onTagObj, tag } = options ?? {};
        const { onAnchor, setAnchors, sourceObjects } = anchors.createNodeAnchors(
          this,
          // eslint-disable-next-line @typescript-eslint/prefer-nullish-coalescing
          anchorPrefix || "a"
        );
        const ctx = {
          aliasDuplicateObjects: aliasDuplicateObjects ?? true,
          keepUndefined: keepUndefined ?? false,
          onAnchor,
          onTagObj,
          replacer: _replacer,
          schema: this.schema,
          sourceObjects
        };
        const node = createNode.createNode(value2, tag, ctx);
        if (flow && identity.isCollection(node))
          node.flow = true;
        setAnchors();
        return node;
      }
      /**
       * Convert a key and a value into a `Pair` using the current schema,
       * recursively wrapping all values as `Scalar` or `Collection` nodes.
       */
      createPair(key, value2, options = {}) {
        const k = this.createNode(key, null, options);
        const v = this.createNode(value2, null, options);
        return new Pair.Pair(k, v);
      }
      /**
       * Removes a value from the document.
       * @returns `true` if the item was found and removed.
       */
      delete(key) {
        return assertCollection(this.contents) ? this.contents.delete(key) : false;
      }
      /**
       * Removes a value from the document.
       * @returns `true` if the item was found and removed.
       */
      deleteIn(path21) {
        if (Collection.isEmptyPath(path21)) {
          if (this.contents == null)
            return false;
          this.contents = null;
          return true;
        }
        return assertCollection(this.contents) ? this.contents.deleteIn(path21) : false;
      }
      /**
       * Returns item at `key`, or `undefined` if not found. By default unwraps
       * scalar values from their surrounding node; to disable set `keepScalar` to
       * `true` (collections are always returned intact).
       */
      get(key, keepScalar) {
        return identity.isCollection(this.contents) ? this.contents.get(key, keepScalar) : void 0;
      }
      /**
       * Returns item at `path`, or `undefined` if not found. By default unwraps
       * scalar values from their surrounding node; to disable set `keepScalar` to
       * `true` (collections are always returned intact).
       */
      getIn(path21, keepScalar) {
        if (Collection.isEmptyPath(path21))
          return !keepScalar && identity.isScalar(this.contents) ? this.contents.value : this.contents;
        return identity.isCollection(this.contents) ? this.contents.getIn(path21, keepScalar) : void 0;
      }
      /**
       * Checks if the document includes a value with the key `key`.
       */
      has(key) {
        return identity.isCollection(this.contents) ? this.contents.has(key) : false;
      }
      /**
       * Checks if the document includes a value at `path`.
       */
      hasIn(path21) {
        if (Collection.isEmptyPath(path21))
          return this.contents !== void 0;
        return identity.isCollection(this.contents) ? this.contents.hasIn(path21) : false;
      }
      /**
       * Sets a value in this document. For `!!set`, `value` needs to be a
       * boolean to add/remove the item from the set.
       */
      set(key, value2) {
        if (this.contents == null) {
          this.contents = Collection.collectionFromPath(this.schema, [key], value2);
        } else if (assertCollection(this.contents)) {
          this.contents.set(key, value2);
        }
      }
      /**
       * Sets a value in this document. For `!!set`, `value` needs to be a
       * boolean to add/remove the item from the set.
       */
      setIn(path21, value2) {
        if (Collection.isEmptyPath(path21)) {
          this.contents = value2;
        } else if (this.contents == null) {
          this.contents = Collection.collectionFromPath(this.schema, Array.from(path21), value2);
        } else if (assertCollection(this.contents)) {
          this.contents.setIn(path21, value2);
        }
      }
      /**
       * Change the YAML version and schema used by the document.
       * A `null` version disables support for directives, explicit tags, anchors, and aliases.
       * It also requires the `schema` option to be given as a `Schema` instance value.
       *
       * Overrides all previously set schema options.
       */
      setSchema(version, options = {}) {
        if (typeof version === "number")
          version = String(version);
        let opt;
        switch (version) {
          case "1.1":
            if (this.directives)
              this.directives.yaml.version = "1.1";
            else
              this.directives = new directives.Directives({ version: "1.1" });
            opt = { resolveKnownTags: false, schema: "yaml-1.1" };
            break;
          case "1.2":
          case "next":
            if (this.directives)
              this.directives.yaml.version = version;
            else
              this.directives = new directives.Directives({ version });
            opt = { resolveKnownTags: true, schema: "core" };
            break;
          case null:
            if (this.directives)
              delete this.directives;
            opt = null;
            break;
          default: {
            const sv = JSON.stringify(version);
            throw new Error(`Expected '1.1', '1.2' or null as first argument, but found: ${sv}`);
          }
        }
        if (options.schema instanceof Object)
          this.schema = options.schema;
        else if (opt)
          this.schema = new Schema.Schema(Object.assign(opt, options));
        else
          throw new Error(`With a null YAML version, the { schema: Schema } option is required`);
      }
      // json & jsonArg are only used from toJSON()
      toJS({ json, jsonArg, mapAsMap, maxAliasCount, onAnchor, reviver } = {}) {
        const ctx = {
          anchors: /* @__PURE__ */ new Map(),
          doc: this,
          keep: !json,
          mapAsMap: mapAsMap === true,
          mapKeyWarned: false,
          maxAliasCount: typeof maxAliasCount === "number" ? maxAliasCount : 100
        };
        const res = toJS.toJS(this.contents, jsonArg ?? "", ctx);
        if (typeof onAnchor === "function")
          for (const { count, res: res2 } of ctx.anchors.values())
            onAnchor(res2, count);
        return typeof reviver === "function" ? applyReviver.applyReviver(reviver, { "": res }, "", res) : res;
      }
      /**
       * A JSON representation of the document `contents`.
       *
       * @param jsonArg Used by `JSON.stringify` to indicate the array index or
       *   property name.
       */
      toJSON(jsonArg, onAnchor) {
        return this.toJS({ json: true, jsonArg, mapAsMap: false, onAnchor });
      }
      /** A YAML representation of the document. */
      toString(options = {}) {
        if (this.errors.length > 0)
          throw new Error("Document with errors cannot be stringified");
        if ("indent" in options && (!Number.isInteger(options.indent) || Number(options.indent) <= 0)) {
          const s = JSON.stringify(options.indent);
          throw new Error(`"indent" option must be a positive integer, not ${s}`);
        }
        return stringifyDocument.stringifyDocument(this, options);
      }
    };
    function assertCollection(contents) {
      if (identity.isCollection(contents))
        return true;
      throw new Error("Expected a YAML collection as document contents");
    }
    exports.Document = Document;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/errors.js
var require_errors = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/errors.js"(exports) {
    "use strict";
    var YAMLError = class extends Error {
      constructor(name16, pos, code, message) {
        super();
        this.name = name16;
        this.code = code;
        this.message = message;
        this.pos = pos;
      }
    };
    var YAMLParseError = class extends YAMLError {
      constructor(pos, code, message) {
        super("YAMLParseError", pos, code, message);
      }
    };
    var YAMLWarning = class extends YAMLError {
      constructor(pos, code, message) {
        super("YAMLWarning", pos, code, message);
      }
    };
    var prettifyError = (src, lc) => (error) => {
      if (error.pos[0] === -1)
        return;
      error.linePos = error.pos.map((pos) => lc.linePos(pos));
      const { line, col } = error.linePos[0];
      error.message += ` at line ${line}, column ${col}`;
      let ci = col - 1;
      let lineStr = src.substring(lc.lineStarts[line - 1], lc.lineStarts[line]).replace(/[\n\r]+$/, "");
      if (ci >= 60 && lineStr.length > 80) {
        const trimStart = Math.min(ci - 39, lineStr.length - 79);
        lineStr = "\u2026" + lineStr.substring(trimStart);
        ci -= trimStart - 1;
      }
      if (lineStr.length > 80)
        lineStr = lineStr.substring(0, 79) + "\u2026";
      if (line > 1 && /^ *$/.test(lineStr.substring(0, ci))) {
        let prev = src.substring(lc.lineStarts[line - 2], lc.lineStarts[line - 1]);
        if (prev.length > 80)
          prev = prev.substring(0, 79) + "\u2026\n";
        lineStr = prev + lineStr;
      }
      if (/[^ ]/.test(lineStr)) {
        let count = 1;
        const end = error.linePos[1];
        if (end?.line === line && end.col > col) {
          count = Math.max(1, Math.min(end.col - col, 80 - ci));
        }
        const pointer = " ".repeat(ci) + "^".repeat(count);
        error.message += `:

${lineStr}
${pointer}
`;
      }
    };
    exports.YAMLError = YAMLError;
    exports.YAMLParseError = YAMLParseError;
    exports.YAMLWarning = YAMLWarning;
    exports.prettifyError = prettifyError;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-props.js
var require_resolve_props = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-props.js"(exports) {
    "use strict";
    function resolveProps(tokens, { flow, indicator, next, offset, onError: onError2, parentIndent, startOnNewline }) {
      let spaceBefore = false;
      let atNewline = startOnNewline;
      let hasSpace = startOnNewline;
      let comment = "";
      let commentSep = "";
      let hasNewline = false;
      let reqSpace = false;
      let tab = null;
      let anchor = null;
      let tag = null;
      let newlineAfterProp = null;
      let comma = null;
      let found = null;
      let start = null;
      for (const token of tokens) {
        if (reqSpace) {
          if (token.type !== "space" && token.type !== "newline" && token.type !== "comma")
            onError2(token.offset, "MISSING_CHAR", "Tags and anchors must be separated from the next token by white space");
          reqSpace = false;
        }
        if (tab) {
          if (atNewline && token.type !== "comment" && token.type !== "newline") {
            onError2(tab, "TAB_AS_INDENT", "Tabs are not allowed as indentation");
          }
          tab = null;
        }
        switch (token.type) {
          case "space":
            if (!flow && (indicator !== "doc-start" || next?.type !== "flow-collection") && token.source.includes("	")) {
              tab = token;
            }
            hasSpace = true;
            break;
          case "comment": {
            if (!hasSpace)
              onError2(token, "MISSING_CHAR", "Comments must be separated from other tokens by white space characters");
            const cb = token.source.substring(1) || " ";
            if (!comment)
              comment = cb;
            else
              comment += commentSep + cb;
            commentSep = "";
            atNewline = false;
            break;
          }
          case "newline":
            if (atNewline) {
              if (comment)
                comment += token.source;
              else if (!found || indicator !== "seq-item-ind")
                spaceBefore = true;
            } else
              commentSep += token.source;
            atNewline = true;
            hasNewline = true;
            if (anchor || tag)
              newlineAfterProp = token;
            hasSpace = true;
            break;
          case "anchor":
            if (anchor)
              onError2(token, "MULTIPLE_ANCHORS", "A node can have at most one anchor");
            if (token.source.endsWith(":"))
              onError2(token.offset + token.source.length - 1, "BAD_ALIAS", "Anchor ending in : is ambiguous", true);
            anchor = token;
            start ?? (start = token.offset);
            atNewline = false;
            hasSpace = false;
            reqSpace = true;
            break;
          case "tag": {
            if (tag)
              onError2(token, "MULTIPLE_TAGS", "A node can have at most one tag");
            tag = token;
            start ?? (start = token.offset);
            atNewline = false;
            hasSpace = false;
            reqSpace = true;
            break;
          }
          case indicator:
            if (anchor || tag)
              onError2(token, "BAD_PROP_ORDER", `Anchors and tags must be after the ${token.source} indicator`);
            if (found)
              onError2(token, "UNEXPECTED_TOKEN", `Unexpected ${token.source} in ${flow ?? "collection"}`);
            found = token;
            atNewline = indicator === "seq-item-ind" || indicator === "explicit-key-ind";
            hasSpace = false;
            break;
          case "comma":
            if (flow) {
              if (comma)
                onError2(token, "UNEXPECTED_TOKEN", `Unexpected , in ${flow}`);
              comma = token;
              atNewline = false;
              hasSpace = false;
              break;
            }
          // else fallthrough
          default:
            onError2(token, "UNEXPECTED_TOKEN", `Unexpected ${token.type} token`);
            atNewline = false;
            hasSpace = false;
        }
      }
      const last = tokens[tokens.length - 1];
      const end = last ? last.offset + last.source.length : offset;
      if (reqSpace && next && next.type !== "space" && next.type !== "newline" && next.type !== "comma" && (next.type !== "scalar" || next.source !== "")) {
        onError2(next.offset, "MISSING_CHAR", "Tags and anchors must be separated from the next token by white space");
      }
      if (tab && (atNewline && tab.indent <= parentIndent || next?.type === "block-map" || next?.type === "block-seq"))
        onError2(tab, "TAB_AS_INDENT", "Tabs are not allowed as indentation");
      return {
        comma,
        found,
        spaceBefore,
        comment,
        hasNewline,
        anchor,
        tag,
        newlineAfterProp,
        end,
        start: start ?? end
      };
    }
    exports.resolveProps = resolveProps;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-contains-newline.js
var require_util_contains_newline = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-contains-newline.js"(exports) {
    "use strict";
    function containsNewline(key) {
      if (!key)
        return null;
      switch (key.type) {
        case "alias":
        case "scalar":
        case "double-quoted-scalar":
        case "single-quoted-scalar":
          if (key.source.includes("\n"))
            return true;
          if (key.end) {
            for (const st of key.end)
              if (st.type === "newline")
                return true;
          }
          return false;
        case "flow-collection":
          for (const it of key.items) {
            for (const st of it.start)
              if (st.type === "newline")
                return true;
            if (it.sep) {
              for (const st of it.sep)
                if (st.type === "newline")
                  return true;
            }
            if (containsNewline(it.key) || containsNewline(it.value))
              return true;
          }
          return false;
        default:
          return true;
      }
    }
    exports.containsNewline = containsNewline;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-flow-indent-check.js
var require_util_flow_indent_check = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-flow-indent-check.js"(exports) {
    "use strict";
    var utilContainsNewline = require_util_contains_newline();
    function flowIndentCheck(indent, fc, onError2) {
      if (fc?.type === "flow-collection") {
        const end = fc.end[0];
        if (end.indent === indent && (end.source === "]" || end.source === "}") && utilContainsNewline.containsNewline(fc)) {
          const msg = "Flow end indicator should be more indented than parent";
          onError2(end, "BAD_INDENT", msg, true);
        }
      }
    }
    exports.flowIndentCheck = flowIndentCheck;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-map-includes.js
var require_util_map_includes = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-map-includes.js"(exports) {
    "use strict";
    var identity = require_identity();
    function mapIncludes(ctx, items, search) {
      const { uniqueKeys } = ctx.options;
      if (uniqueKeys === false)
        return false;
      const isEqual = typeof uniqueKeys === "function" ? uniqueKeys : (a, b) => a === b || identity.isScalar(a) && identity.isScalar(b) && a.value === b.value;
      return items.some((pair) => isEqual(pair.key, search));
    }
    exports.mapIncludes = mapIncludes;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-map.js
var require_resolve_block_map = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-map.js"(exports) {
    "use strict";
    var Pair = require_Pair();
    var YAMLMap = require_YAMLMap();
    var resolveProps = require_resolve_props();
    var utilContainsNewline = require_util_contains_newline();
    var utilFlowIndentCheck = require_util_flow_indent_check();
    var utilMapIncludes = require_util_map_includes();
    var startColMsg = "All mapping items must start at the same column";
    function resolveBlockMap({ composeNode, composeEmptyNode }, ctx, bm, onError2, tag) {
      const NodeClass = tag?.nodeClass ?? YAMLMap.YAMLMap;
      const map = new NodeClass(ctx.schema);
      if (ctx.atRoot)
        ctx.atRoot = false;
      let offset = bm.offset;
      let commentEnd = null;
      for (const collItem of bm.items) {
        const { start, key, sep, value: value2 } = collItem;
        const keyProps = resolveProps.resolveProps(start, {
          indicator: "explicit-key-ind",
          next: key ?? sep?.[0],
          offset,
          onError: onError2,
          parentIndent: bm.indent,
          startOnNewline: true
        });
        const implicitKey = !keyProps.found;
        if (implicitKey) {
          if (key) {
            if (key.type === "block-seq")
              onError2(offset, "BLOCK_AS_IMPLICIT_KEY", "A block sequence may not be used as an implicit map key");
            else if ("indent" in key && key.indent !== bm.indent)
              onError2(offset, "BAD_INDENT", startColMsg);
          }
          if (!keyProps.anchor && !keyProps.tag && !sep) {
            commentEnd = keyProps.end;
            if (keyProps.comment) {
              if (map.comment)
                map.comment += "\n" + keyProps.comment;
              else
                map.comment = keyProps.comment;
            }
            continue;
          }
          if (keyProps.newlineAfterProp || utilContainsNewline.containsNewline(key)) {
            onError2(key ?? start[start.length - 1], "MULTILINE_IMPLICIT_KEY", "Implicit keys need to be on a single line");
          }
        } else if (keyProps.found?.indent !== bm.indent) {
          onError2(offset, "BAD_INDENT", startColMsg);
        }
        ctx.atKey = true;
        const keyStart = keyProps.end;
        const keyNode = key ? composeNode(ctx, key, keyProps, onError2) : composeEmptyNode(ctx, keyStart, start, null, keyProps, onError2);
        if (ctx.schema.compat)
          utilFlowIndentCheck.flowIndentCheck(bm.indent, key, onError2);
        ctx.atKey = false;
        if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode))
          onError2(keyStart, "DUPLICATE_KEY", "Map keys must be unique");
        const valueProps = resolveProps.resolveProps(sep ?? [], {
          indicator: "map-value-ind",
          next: value2,
          offset: keyNode.range[2],
          onError: onError2,
          parentIndent: bm.indent,
          startOnNewline: !key || key.type === "block-scalar"
        });
        offset = valueProps.end;
        if (valueProps.found) {
          if (implicitKey) {
            if (value2?.type === "block-map" && !valueProps.hasNewline)
              onError2(offset, "BLOCK_AS_IMPLICIT_KEY", "Nested mappings are not allowed in compact mappings");
            if (ctx.options.strict && keyProps.start < valueProps.found.offset - 1024)
              onError2(keyNode.range, "KEY_OVER_1024_CHARS", "The : indicator must be at most 1024 chars after the start of an implicit block mapping key");
          }
          const valueNode = value2 ? composeNode(ctx, value2, valueProps, onError2) : composeEmptyNode(ctx, offset, sep, null, valueProps, onError2);
          if (ctx.schema.compat)
            utilFlowIndentCheck.flowIndentCheck(bm.indent, value2, onError2);
          offset = valueNode.range[2];
          const pair = new Pair.Pair(keyNode, valueNode);
          if (ctx.options.keepSourceTokens)
            pair.srcToken = collItem;
          map.items.push(pair);
        } else {
          if (implicitKey)
            onError2(keyNode.range, "MISSING_CHAR", "Implicit map keys need to be followed by map values");
          if (valueProps.comment) {
            if (keyNode.comment)
              keyNode.comment += "\n" + valueProps.comment;
            else
              keyNode.comment = valueProps.comment;
          }
          const pair = new Pair.Pair(keyNode);
          if (ctx.options.keepSourceTokens)
            pair.srcToken = collItem;
          map.items.push(pair);
        }
      }
      if (commentEnd && commentEnd < offset)
        onError2(commentEnd, "IMPOSSIBLE", "Map comment with trailing content");
      map.range = [bm.offset, offset, commentEnd ?? offset];
      return map;
    }
    exports.resolveBlockMap = resolveBlockMap;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-seq.js
var require_resolve_block_seq = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-seq.js"(exports) {
    "use strict";
    var YAMLSeq = require_YAMLSeq();
    var resolveProps = require_resolve_props();
    var utilFlowIndentCheck = require_util_flow_indent_check();
    function resolveBlockSeq({ composeNode, composeEmptyNode }, ctx, bs, onError2, tag) {
      const NodeClass = tag?.nodeClass ?? YAMLSeq.YAMLSeq;
      const seq = new NodeClass(ctx.schema);
      if (ctx.atRoot)
        ctx.atRoot = false;
      if (ctx.atKey)
        ctx.atKey = false;
      let offset = bs.offset;
      let commentEnd = null;
      for (const { start, value: value2 } of bs.items) {
        const props = resolveProps.resolveProps(start, {
          indicator: "seq-item-ind",
          next: value2,
          offset,
          onError: onError2,
          parentIndent: bs.indent,
          startOnNewline: true
        });
        if (!props.found) {
          if (props.anchor || props.tag || value2) {
            if (value2?.type === "block-seq")
              onError2(props.end, "BAD_INDENT", "All sequence items must start at the same column");
            else
              onError2(offset, "MISSING_CHAR", "Sequence item without - indicator");
          } else {
            commentEnd = props.end;
            if (props.comment)
              seq.comment = props.comment;
            continue;
          }
        }
        const node = value2 ? composeNode(ctx, value2, props, onError2) : composeEmptyNode(ctx, props.end, start, null, props, onError2);
        if (ctx.schema.compat)
          utilFlowIndentCheck.flowIndentCheck(bs.indent, value2, onError2);
        offset = node.range[2];
        seq.items.push(node);
      }
      seq.range = [bs.offset, offset, commentEnd ?? offset];
      return seq;
    }
    exports.resolveBlockSeq = resolveBlockSeq;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-end.js
var require_resolve_end = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-end.js"(exports) {
    "use strict";
    function resolveEnd(end, offset, reqSpace, onError2) {
      let comment = "";
      if (end) {
        let hasSpace = false;
        let sep = "";
        for (const token of end) {
          const { source, type: type2 } = token;
          switch (type2) {
            case "space":
              hasSpace = true;
              break;
            case "comment": {
              if (reqSpace && !hasSpace)
                onError2(token, "MISSING_CHAR", "Comments must be separated from other tokens by white space characters");
              const cb = source.substring(1) || " ";
              if (!comment)
                comment = cb;
              else
                comment += sep + cb;
              sep = "";
              break;
            }
            case "newline":
              if (comment)
                sep += source;
              hasSpace = true;
              break;
            default:
              onError2(token, "UNEXPECTED_TOKEN", `Unexpected ${type2} at node end`);
          }
          offset += source.length;
        }
      }
      return { comment, offset };
    }
    exports.resolveEnd = resolveEnd;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-flow-collection.js
var require_resolve_flow_collection = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-flow-collection.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Pair = require_Pair();
    var YAMLMap = require_YAMLMap();
    var YAMLSeq = require_YAMLSeq();
    var resolveEnd = require_resolve_end();
    var resolveProps = require_resolve_props();
    var utilContainsNewline = require_util_contains_newline();
    var utilMapIncludes = require_util_map_includes();
    var blockMsg = "Block collections are not allowed within flow collections";
    var isBlock = (token) => token && (token.type === "block-map" || token.type === "block-seq");
    function resolveFlowCollection({ composeNode, composeEmptyNode }, ctx, fc, onError2, tag) {
      const isMap = fc.start.source === "{";
      const fcName = isMap ? "flow map" : "flow sequence";
      const NodeClass = tag?.nodeClass ?? (isMap ? YAMLMap.YAMLMap : YAMLSeq.YAMLSeq);
      const coll = new NodeClass(ctx.schema);
      coll.flow = true;
      const atRoot = ctx.atRoot;
      if (atRoot)
        ctx.atRoot = false;
      if (ctx.atKey)
        ctx.atKey = false;
      let offset = fc.offset + fc.start.source.length;
      for (let i = 0; i < fc.items.length; ++i) {
        const collItem = fc.items[i];
        const { start, key, sep, value: value2 } = collItem;
        const props = resolveProps.resolveProps(start, {
          flow: fcName,
          indicator: "explicit-key-ind",
          next: key ?? sep?.[0],
          offset,
          onError: onError2,
          parentIndent: fc.indent,
          startOnNewline: false
        });
        if (!props.found) {
          if (!props.anchor && !props.tag && !sep && !value2) {
            if (i === 0 && props.comma)
              onError2(props.comma, "UNEXPECTED_TOKEN", `Unexpected , in ${fcName}`);
            else if (i < fc.items.length - 1)
              onError2(props.start, "UNEXPECTED_TOKEN", `Unexpected empty item in ${fcName}`);
            if (props.comment) {
              if (coll.comment)
                coll.comment += "\n" + props.comment;
              else
                coll.comment = props.comment;
            }
            offset = props.end;
            continue;
          }
          if (!isMap && ctx.options.strict && utilContainsNewline.containsNewline(key))
            onError2(
              key,
              // checked by containsNewline()
              "MULTILINE_IMPLICIT_KEY",
              "Implicit keys of flow sequence pairs need to be on a single line"
            );
        }
        if (i === 0) {
          if (props.comma)
            onError2(props.comma, "UNEXPECTED_TOKEN", `Unexpected , in ${fcName}`);
        } else {
          if (!props.comma)
            onError2(props.start, "MISSING_CHAR", `Missing , between ${fcName} items`);
          if (props.comment) {
            let prevItemComment = "";
            loop: for (const st of start) {
              switch (st.type) {
                case "comma":
                case "space":
                  break;
                case "comment":
                  prevItemComment = st.source.substring(1);
                  break loop;
                default:
                  break loop;
              }
            }
            if (prevItemComment) {
              let prev = coll.items[coll.items.length - 1];
              if (identity.isPair(prev))
                prev = prev.value ?? prev.key;
              if (prev.comment)
                prev.comment += "\n" + prevItemComment;
              else
                prev.comment = prevItemComment;
              props.comment = props.comment.substring(prevItemComment.length + 1);
            }
          }
        }
        if (!isMap && !sep && !props.found) {
          const valueNode = value2 ? composeNode(ctx, value2, props, onError2) : composeEmptyNode(ctx, props.end, sep, null, props, onError2);
          coll.items.push(valueNode);
          offset = valueNode.range[2];
          if (isBlock(value2))
            onError2(valueNode.range, "BLOCK_IN_FLOW", blockMsg);
        } else {
          ctx.atKey = true;
          const keyStart = props.end;
          const keyNode = key ? composeNode(ctx, key, props, onError2) : composeEmptyNode(ctx, keyStart, start, null, props, onError2);
          if (isBlock(key))
            onError2(keyNode.range, "BLOCK_IN_FLOW", blockMsg);
          ctx.atKey = false;
          const valueProps = resolveProps.resolveProps(sep ?? [], {
            flow: fcName,
            indicator: "map-value-ind",
            next: value2,
            offset: keyNode.range[2],
            onError: onError2,
            parentIndent: fc.indent,
            startOnNewline: false
          });
          if (valueProps.found) {
            if (!isMap && !props.found && ctx.options.strict) {
              if (sep)
                for (const st of sep) {
                  if (st === valueProps.found)
                    break;
                  if (st.type === "newline") {
                    onError2(st, "MULTILINE_IMPLICIT_KEY", "Implicit keys of flow sequence pairs need to be on a single line");
                    break;
                  }
                }
              if (props.start < valueProps.found.offset - 1024)
                onError2(valueProps.found, "KEY_OVER_1024_CHARS", "The : indicator must be at most 1024 chars after the start of an implicit flow sequence key");
            }
          } else if (value2) {
            if ("source" in value2 && value2.source?.[0] === ":")
              onError2(value2, "MISSING_CHAR", `Missing space after : in ${fcName}`);
            else
              onError2(valueProps.start, "MISSING_CHAR", `Missing , or : between ${fcName} items`);
          }
          const valueNode = value2 ? composeNode(ctx, value2, valueProps, onError2) : valueProps.found ? composeEmptyNode(ctx, valueProps.end, sep, null, valueProps, onError2) : null;
          if (valueNode) {
            if (isBlock(value2))
              onError2(valueNode.range, "BLOCK_IN_FLOW", blockMsg);
          } else if (valueProps.comment) {
            if (keyNode.comment)
              keyNode.comment += "\n" + valueProps.comment;
            else
              keyNode.comment = valueProps.comment;
          }
          const pair = new Pair.Pair(keyNode, valueNode);
          if (ctx.options.keepSourceTokens)
            pair.srcToken = collItem;
          if (isMap) {
            const map = coll;
            if (utilMapIncludes.mapIncludes(ctx, map.items, keyNode))
              onError2(keyStart, "DUPLICATE_KEY", "Map keys must be unique");
            map.items.push(pair);
          } else {
            const map = new YAMLMap.YAMLMap(ctx.schema);
            map.flow = true;
            map.items.push(pair);
            const endRange = (valueNode ?? keyNode).range;
            map.range = [keyNode.range[0], endRange[1], endRange[2]];
            coll.items.push(map);
          }
          offset = valueNode ? valueNode.range[2] : valueProps.end;
        }
      }
      const expectedEnd = isMap ? "}" : "]";
      const [ce, ...ee] = fc.end;
      let cePos = offset;
      if (ce?.source === expectedEnd)
        cePos = ce.offset + ce.source.length;
      else {
        const name16 = fcName[0].toUpperCase() + fcName.substring(1);
        const msg = atRoot ? `${name16} must end with a ${expectedEnd}` : `${name16} in block collection must be sufficiently indented and end with a ${expectedEnd}`;
        onError2(offset, atRoot ? "MISSING_CHAR" : "BAD_INDENT", msg);
        if (ce && ce.source.length !== 1)
          ee.unshift(ce);
      }
      if (ee.length > 0) {
        const end = resolveEnd.resolveEnd(ee, cePos, ctx.options.strict, onError2);
        if (end.comment) {
          if (coll.comment)
            coll.comment += "\n" + end.comment;
          else
            coll.comment = end.comment;
        }
        coll.range = [fc.offset, cePos, end.offset];
      } else {
        coll.range = [fc.offset, cePos, cePos];
      }
      return coll;
    }
    exports.resolveFlowCollection = resolveFlowCollection;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-collection.js
var require_compose_collection = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-collection.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Scalar = require_Scalar();
    var YAMLMap = require_YAMLMap();
    var YAMLSeq = require_YAMLSeq();
    var resolveBlockMap = require_resolve_block_map();
    var resolveBlockSeq = require_resolve_block_seq();
    var resolveFlowCollection = require_resolve_flow_collection();
    function resolveCollection(CN, ctx, token, onError2, tagName, tag) {
      const coll = token.type === "block-map" ? resolveBlockMap.resolveBlockMap(CN, ctx, token, onError2, tag) : token.type === "block-seq" ? resolveBlockSeq.resolveBlockSeq(CN, ctx, token, onError2, tag) : resolveFlowCollection.resolveFlowCollection(CN, ctx, token, onError2, tag);
      const Coll = coll.constructor;
      if (tagName === "!" || tagName === Coll.tagName) {
        coll.tag = Coll.tagName;
        return coll;
      }
      if (tagName)
        coll.tag = tagName;
      return coll;
    }
    function composeCollection(CN, ctx, token, props, onError2) {
      const tagToken = props.tag;
      const tagName = !tagToken ? null : ctx.directives.tagName(tagToken.source, (msg) => onError2(tagToken, "TAG_RESOLVE_FAILED", msg));
      if (token.type === "block-seq") {
        const { anchor, newlineAfterProp: nl } = props;
        const lastProp = anchor && tagToken ? anchor.offset > tagToken.offset ? anchor : tagToken : anchor ?? tagToken;
        if (lastProp && (!nl || nl.offset < lastProp.offset)) {
          const message = "Missing newline after block sequence props";
          onError2(lastProp, "MISSING_CHAR", message);
        }
      }
      const expType = token.type === "block-map" ? "map" : token.type === "block-seq" ? "seq" : token.start.source === "{" ? "map" : "seq";
      if (!tagToken || !tagName || tagName === "!" || tagName === YAMLMap.YAMLMap.tagName && expType === "map" || tagName === YAMLSeq.YAMLSeq.tagName && expType === "seq") {
        return resolveCollection(CN, ctx, token, onError2, tagName);
      }
      let tag = ctx.schema.tags.find((t) => t.tag === tagName && t.collection === expType);
      if (!tag) {
        const kt = ctx.schema.knownTags[tagName];
        if (kt?.collection === expType) {
          ctx.schema.tags.push(Object.assign({}, kt, { default: false }));
          tag = kt;
        } else {
          if (kt) {
            onError2(tagToken, "BAD_COLLECTION_TYPE", `${kt.tag} used for ${expType} collection, but expects ${kt.collection ?? "scalar"}`, true);
          } else {
            onError2(tagToken, "TAG_RESOLVE_FAILED", `Unresolved tag: ${tagName}`, true);
          }
          return resolveCollection(CN, ctx, token, onError2, tagName);
        }
      }
      const coll = resolveCollection(CN, ctx, token, onError2, tagName, tag);
      const res = tag.resolve?.(coll, (msg) => onError2(tagToken, "TAG_RESOLVE_FAILED", msg), ctx.options) ?? coll;
      const node = identity.isNode(res) ? res : new Scalar.Scalar(res);
      node.range = coll.range;
      node.tag = tagName;
      if (tag?.format)
        node.format = tag.format;
      return node;
    }
    exports.composeCollection = composeCollection;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-scalar.js
var require_resolve_block_scalar = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-block-scalar.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    function resolveBlockScalar(ctx, scalar, onError2) {
      const start = scalar.offset;
      const header = parseBlockScalarHeader(scalar, ctx.options.strict, onError2);
      if (!header)
        return { value: "", type: null, comment: "", range: [start, start, start] };
      const type2 = header.mode === ">" ? Scalar.Scalar.BLOCK_FOLDED : Scalar.Scalar.BLOCK_LITERAL;
      const lines = scalar.source ? splitLines2(scalar.source) : [];
      let chompStart = lines.length;
      for (let i = lines.length - 1; i >= 0; --i) {
        const content = lines[i][1];
        if (content === "" || content === "\r")
          chompStart = i;
        else
          break;
      }
      if (chompStart === 0) {
        const value3 = header.chomp === "+" && lines.length > 0 ? "\n".repeat(Math.max(1, lines.length - 1)) : "";
        let end2 = start + header.length;
        if (scalar.source)
          end2 += scalar.source.length;
        return { value: value3, type: type2, comment: header.comment, range: [start, end2, end2] };
      }
      let trimIndent = scalar.indent + header.indent;
      let offset = scalar.offset + header.length;
      let contentStart = 0;
      for (let i = 0; i < chompStart; ++i) {
        const [indent, content] = lines[i];
        if (content === "" || content === "\r") {
          if (header.indent === 0 && indent.length > trimIndent)
            trimIndent = indent.length;
        } else {
          if (indent.length < trimIndent) {
            const message = "Block scalars with more-indented leading empty lines must use an explicit indentation indicator";
            onError2(offset + indent.length, "MISSING_CHAR", message);
          }
          if (header.indent === 0)
            trimIndent = indent.length;
          contentStart = i;
          if (trimIndent === 0 && !ctx.atRoot) {
            const message = "Block scalar values in collections must be indented";
            onError2(offset, "BAD_INDENT", message);
          }
          break;
        }
        offset += indent.length + content.length + 1;
      }
      for (let i = lines.length - 1; i >= chompStart; --i) {
        if (lines[i][0].length > trimIndent)
          chompStart = i + 1;
      }
      let value2 = "";
      let sep = "";
      let prevMoreIndented = false;
      for (let i = 0; i < contentStart; ++i)
        value2 += lines[i][0].slice(trimIndent) + "\n";
      for (let i = contentStart; i < chompStart; ++i) {
        let [indent, content] = lines[i];
        offset += indent.length + content.length + 1;
        const crlf = content[content.length - 1] === "\r";
        if (crlf)
          content = content.slice(0, -1);
        if (content && indent.length < trimIndent) {
          const src = header.indent ? "explicit indentation indicator" : "first line";
          const message = `Block scalar lines must not be less indented than their ${src}`;
          onError2(offset - content.length - (crlf ? 2 : 1), "BAD_INDENT", message);
          indent = "";
        }
        if (type2 === Scalar.Scalar.BLOCK_LITERAL) {
          value2 += sep + indent.slice(trimIndent) + content;
          sep = "\n";
        } else if (indent.length > trimIndent || content[0] === "	") {
          if (sep === " ")
            sep = "\n";
          else if (!prevMoreIndented && sep === "\n")
            sep = "\n\n";
          value2 += sep + indent.slice(trimIndent) + content;
          sep = "\n";
          prevMoreIndented = true;
        } else if (content === "") {
          if (sep === "\n")
            value2 += "\n";
          else
            sep = "\n";
        } else {
          value2 += sep + content;
          sep = " ";
          prevMoreIndented = false;
        }
      }
      switch (header.chomp) {
        case "-":
          break;
        case "+":
          for (let i = chompStart; i < lines.length; ++i)
            value2 += "\n" + lines[i][0].slice(trimIndent);
          if (value2[value2.length - 1] !== "\n")
            value2 += "\n";
          break;
        default:
          value2 += "\n";
      }
      const end = start + header.length + scalar.source.length;
      return { value: value2, type: type2, comment: header.comment, range: [start, end, end] };
    }
    function parseBlockScalarHeader({ offset, props }, strict, onError2) {
      if (props[0].type !== "block-scalar-header") {
        onError2(props[0], "IMPOSSIBLE", "Block scalar header not found");
        return null;
      }
      const { source } = props[0];
      const mode = source[0];
      let indent = 0;
      let chomp = "";
      let error = -1;
      for (let i = 1; i < source.length; ++i) {
        const ch = source[i];
        if (!chomp && (ch === "-" || ch === "+"))
          chomp = ch;
        else {
          const n = Number(ch);
          if (!indent && n)
            indent = n;
          else if (error === -1)
            error = offset + i;
        }
      }
      if (error !== -1)
        onError2(error, "UNEXPECTED_TOKEN", `Block scalar header includes extra characters: ${source}`);
      let hasSpace = false;
      let comment = "";
      let length = source.length;
      for (let i = 1; i < props.length; ++i) {
        const token = props[i];
        switch (token.type) {
          case "space":
            hasSpace = true;
          // fallthrough
          case "newline":
            length += token.source.length;
            break;
          case "comment":
            if (strict && !hasSpace) {
              const message = "Comments must be separated from other tokens by white space characters";
              onError2(token, "MISSING_CHAR", message);
            }
            length += token.source.length;
            comment = token.source.substring(1);
            break;
          case "error":
            onError2(token, "UNEXPECTED_TOKEN", token.message);
            length += token.source.length;
            break;
          /* istanbul ignore next should not happen */
          default: {
            const message = `Unexpected token in block scalar header: ${token.type}`;
            onError2(token, "UNEXPECTED_TOKEN", message);
            const ts = token.source;
            if (ts && typeof ts === "string")
              length += ts.length;
          }
        }
      }
      return { mode, indent, chomp, comment, length };
    }
    function splitLines2(source) {
      const split = source.split(/\n( *)/);
      const first = split[0];
      const m = first.match(/^( *)/);
      const line0 = m?.[1] ? [m[1], first.slice(m[1].length)] : ["", first];
      const lines = [line0];
      for (let i = 1; i < split.length; i += 2)
        lines.push([split[i], split[i + 1]]);
      return lines;
    }
    exports.resolveBlockScalar = resolveBlockScalar;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-flow-scalar.js
var require_resolve_flow_scalar = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/resolve-flow-scalar.js"(exports) {
    "use strict";
    var Scalar = require_Scalar();
    var resolveEnd = require_resolve_end();
    function resolveFlowScalar(scalar, strict, onError2) {
      const { offset, type: type2, source, end } = scalar;
      let _type;
      let value2;
      const _onError = (rel, code, msg) => onError2(offset + rel, code, msg);
      switch (type2) {
        case "scalar":
          _type = Scalar.Scalar.PLAIN;
          value2 = plainValue(source, _onError);
          break;
        case "single-quoted-scalar":
          _type = Scalar.Scalar.QUOTE_SINGLE;
          value2 = singleQuotedValue(source, _onError);
          break;
        case "double-quoted-scalar":
          _type = Scalar.Scalar.QUOTE_DOUBLE;
          value2 = doubleQuotedValue(source, _onError);
          break;
        /* istanbul ignore next should not happen */
        default:
          onError2(scalar, "UNEXPECTED_TOKEN", `Expected a flow scalar value, but found: ${type2}`);
          return {
            value: "",
            type: null,
            comment: "",
            range: [offset, offset + source.length, offset + source.length]
          };
      }
      const valueEnd = offset + source.length;
      const re2 = resolveEnd.resolveEnd(end, valueEnd, strict, onError2);
      return {
        value: value2,
        type: _type,
        comment: re2.comment,
        range: [offset, valueEnd, re2.offset]
      };
    }
    function plainValue(source, onError2) {
      let badChar = "";
      switch (source[0]) {
        /* istanbul ignore next should not happen */
        case "	":
          badChar = "a tab character";
          break;
        case ",":
          badChar = "flow indicator character ,";
          break;
        case "%":
          badChar = "directive indicator character %";
          break;
        case "|":
        case ">": {
          badChar = `block scalar indicator ${source[0]}`;
          break;
        }
        case "@":
        case "`": {
          badChar = `reserved character ${source[0]}`;
          break;
        }
      }
      if (badChar)
        onError2(0, "BAD_SCALAR_START", `Plain value cannot start with ${badChar}`);
      return foldLines(source);
    }
    function singleQuotedValue(source, onError2) {
      if (source[source.length - 1] !== "'" || source.length === 1)
        onError2(source.length, "MISSING_CHAR", "Missing closing 'quote");
      return foldLines(source.slice(1, -1)).replace(/''/g, "'");
    }
    function foldLines(source) {
      let first, line;
      try {
        first = new RegExp("(.*?)(?<![ 	])[ 	]*\r?\n", "sy");
        line = new RegExp("[ 	]*(.*?)(?:(?<![ 	])[ 	]*)?\r?\n", "sy");
      } catch {
        first = /(.*?)[ \t]*\r?\n/sy;
        line = /[ \t]*(.*?)[ \t]*\r?\n/sy;
      }
      let match = first.exec(source);
      if (!match)
        return source;
      let res = match[1];
      let sep = " ";
      let pos = first.lastIndex;
      line.lastIndex = pos;
      while (match = line.exec(source)) {
        if (match[1] === "") {
          if (sep === "\n")
            res += sep;
          else
            sep = "\n";
        } else {
          res += sep + match[1];
          sep = " ";
        }
        pos = line.lastIndex;
      }
      const last = /[ \t]*(.*)/sy;
      last.lastIndex = pos;
      match = last.exec(source);
      return res + sep + (match?.[1] ?? "");
    }
    function doubleQuotedValue(source, onError2) {
      let res = "";
      for (let i = 1; i < source.length - 1; ++i) {
        const ch = source[i];
        if (ch === "\r" && source[i + 1] === "\n")
          continue;
        if (ch === "\n") {
          const { fold, offset } = foldNewline(source, i);
          res += fold;
          i = offset;
        } else if (ch === "\\") {
          let next = source[++i];
          const cc = escapeCodes[next];
          if (cc)
            res += cc;
          else if (next === "\n") {
            next = source[i + 1];
            while (next === " " || next === "	")
              next = source[++i + 1];
          } else if (next === "\r" && source[i + 1] === "\n") {
            next = source[++i + 1];
            while (next === " " || next === "	")
              next = source[++i + 1];
          } else if (next === "x" || next === "u" || next === "U") {
            const length = { x: 2, u: 4, U: 8 }[next];
            res += parseCharCode(source, i + 1, length, onError2);
            i += length;
          } else {
            const raw = source.substr(i - 1, 2);
            onError2(i - 1, "BAD_DQ_ESCAPE", `Invalid escape sequence ${raw}`);
            res += raw;
          }
        } else if (ch === " " || ch === "	") {
          const wsStart = i;
          let next = source[i + 1];
          while (next === " " || next === "	")
            next = source[++i + 1];
          if (next !== "\n" && !(next === "\r" && source[i + 2] === "\n"))
            res += i > wsStart ? source.slice(wsStart, i + 1) : ch;
        } else {
          res += ch;
        }
      }
      if (source[source.length - 1] !== '"' || source.length === 1)
        onError2(source.length, "MISSING_CHAR", 'Missing closing "quote');
      return res;
    }
    function foldNewline(source, offset) {
      let fold = "";
      let ch = source[offset + 1];
      while (ch === " " || ch === "	" || ch === "\n" || ch === "\r") {
        if (ch === "\r" && source[offset + 2] !== "\n")
          break;
        if (ch === "\n")
          fold += "\n";
        offset += 1;
        ch = source[offset + 1];
      }
      if (!fold)
        fold = " ";
      return { fold, offset };
    }
    var escapeCodes = {
      "0": "\0",
      // null character
      a: "\x07",
      // bell character
      b: "\b",
      // backspace
      e: "\x1B",
      // escape character
      f: "\f",
      // form feed
      n: "\n",
      // line feed
      r: "\r",
      // carriage return
      t: "	",
      // horizontal tab
      v: "\v",
      // vertical tab
      N: "\x85",
      // Unicode next line
      _: "\xA0",
      // Unicode non-breaking space
      L: "\u2028",
      // Unicode line separator
      P: "\u2029",
      // Unicode paragraph separator
      " ": " ",
      '"': '"',
      "/": "/",
      "\\": "\\",
      "	": "	"
    };
    function parseCharCode(source, offset, length, onError2) {
      const cc = source.substr(offset, length);
      const ok = cc.length === length && /^[0-9a-fA-F]+$/.test(cc);
      const code = ok ? parseInt(cc, 16) : NaN;
      if (isNaN(code)) {
        const raw = source.substr(offset - 2, length + 2);
        onError2(offset - 2, "BAD_DQ_ESCAPE", `Invalid escape sequence ${raw}`);
        return raw;
      }
      return String.fromCodePoint(code);
    }
    exports.resolveFlowScalar = resolveFlowScalar;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-scalar.js
var require_compose_scalar = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-scalar.js"(exports) {
    "use strict";
    var identity = require_identity();
    var Scalar = require_Scalar();
    var resolveBlockScalar = require_resolve_block_scalar();
    var resolveFlowScalar = require_resolve_flow_scalar();
    function composeScalar(ctx, token, tagToken, onError2) {
      const { value: value2, type: type2, comment, range } = token.type === "block-scalar" ? resolveBlockScalar.resolveBlockScalar(ctx, token, onError2) : resolveFlowScalar.resolveFlowScalar(token, ctx.options.strict, onError2);
      const tagName = tagToken ? ctx.directives.tagName(tagToken.source, (msg) => onError2(tagToken, "TAG_RESOLVE_FAILED", msg)) : null;
      let tag;
      if (ctx.options.stringKeys && ctx.atKey) {
        tag = ctx.schema[identity.SCALAR];
      } else if (tagName)
        tag = findScalarTagByName(ctx.schema, value2, tagName, tagToken, onError2);
      else if (token.type === "scalar")
        tag = findScalarTagByTest(ctx, value2, token, onError2);
      else
        tag = ctx.schema[identity.SCALAR];
      let scalar;
      try {
        const res = tag.resolve(value2, (msg) => onError2(tagToken ?? token, "TAG_RESOLVE_FAILED", msg), ctx.options);
        scalar = identity.isScalar(res) ? res : new Scalar.Scalar(res);
      } catch (error) {
        const msg = error instanceof Error ? error.message : String(error);
        onError2(tagToken ?? token, "TAG_RESOLVE_FAILED", msg);
        scalar = new Scalar.Scalar(value2);
      }
      scalar.range = range;
      scalar.source = value2;
      if (type2)
        scalar.type = type2;
      if (tagName)
        scalar.tag = tagName;
      if (tag.format)
        scalar.format = tag.format;
      if (comment)
        scalar.comment = comment;
      return scalar;
    }
    function findScalarTagByName(schema, value2, tagName, tagToken, onError2) {
      if (tagName === "!")
        return schema[identity.SCALAR];
      const matchWithTest = [];
      for (const tag of schema.tags) {
        if (!tag.collection && tag.tag === tagName) {
          if (tag.default && tag.test)
            matchWithTest.push(tag);
          else
            return tag;
        }
      }
      for (const tag of matchWithTest)
        if (tag.test?.test(value2))
          return tag;
      const kt = schema.knownTags[tagName];
      if (kt && !kt.collection) {
        schema.tags.push(Object.assign({}, kt, { default: false, test: void 0 }));
        return kt;
      }
      onError2(tagToken, "TAG_RESOLVE_FAILED", `Unresolved tag: ${tagName}`, tagName !== "tag:yaml.org,2002:str");
      return schema[identity.SCALAR];
    }
    function findScalarTagByTest({ atKey, directives, schema }, value2, token, onError2) {
      const tag = schema.tags.find((tag2) => (tag2.default === true || atKey && tag2.default === "key") && tag2.test?.test(value2)) || schema[identity.SCALAR];
      if (schema.compat) {
        const compat = schema.compat.find((tag2) => tag2.default && tag2.test?.test(value2)) ?? schema[identity.SCALAR];
        if (tag.tag !== compat.tag) {
          const ts = directives.tagString(tag.tag);
          const cs = directives.tagString(compat.tag);
          const msg = `Value may be parsed as either ${ts} or ${cs}`;
          onError2(token, "TAG_RESOLVE_FAILED", msg, true);
        }
      }
      return tag;
    }
    exports.composeScalar = composeScalar;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-empty-scalar-position.js
var require_util_empty_scalar_position = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/util-empty-scalar-position.js"(exports) {
    "use strict";
    function emptyScalarPosition(offset, before, pos) {
      if (before) {
        pos ?? (pos = before.length);
        for (let i = pos - 1; i >= 0; --i) {
          let st = before[i];
          switch (st.type) {
            case "space":
            case "comment":
            case "newline":
              offset -= st.source.length;
              continue;
          }
          st = before[++i];
          while (st?.type === "space") {
            offset += st.source.length;
            st = before[++i];
          }
          break;
        }
      }
      return offset;
    }
    exports.emptyScalarPosition = emptyScalarPosition;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-node.js
var require_compose_node = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-node.js"(exports) {
    "use strict";
    var Alias = require_Alias();
    var identity = require_identity();
    var composeCollection = require_compose_collection();
    var composeScalar = require_compose_scalar();
    var resolveEnd = require_resolve_end();
    var utilEmptyScalarPosition = require_util_empty_scalar_position();
    var CN = { composeNode, composeEmptyNode };
    function composeNode(ctx, token, props, onError2) {
      const atKey = ctx.atKey;
      const { spaceBefore, comment, anchor, tag } = props;
      let node;
      let isSrcToken = true;
      switch (token.type) {
        case "alias":
          node = composeAlias(ctx, token, onError2);
          if (anchor || tag)
            onError2(token, "ALIAS_PROPS", "An alias node must not specify any properties");
          break;
        case "scalar":
        case "single-quoted-scalar":
        case "double-quoted-scalar":
        case "block-scalar":
          node = composeScalar.composeScalar(ctx, token, tag, onError2);
          if (anchor)
            node.anchor = anchor.source.substring(1);
          break;
        case "block-map":
        case "block-seq":
        case "flow-collection":
          node = composeCollection.composeCollection(CN, ctx, token, props, onError2);
          if (anchor)
            node.anchor = anchor.source.substring(1);
          break;
        default: {
          const message = token.type === "error" ? token.message : `Unsupported token (type: ${token.type})`;
          onError2(token, "UNEXPECTED_TOKEN", message);
          node = composeEmptyNode(ctx, token.offset, void 0, null, props, onError2);
          isSrcToken = false;
        }
      }
      if (anchor && node.anchor === "")
        onError2(anchor, "BAD_ALIAS", "Anchor cannot be an empty string");
      if (atKey && ctx.options.stringKeys && (!identity.isScalar(node) || typeof node.value !== "string" || node.tag && node.tag !== "tag:yaml.org,2002:str")) {
        const msg = "With stringKeys, all keys must be strings";
        onError2(tag ?? token, "NON_STRING_KEY", msg);
      }
      if (spaceBefore)
        node.spaceBefore = true;
      if (comment) {
        if (token.type === "scalar" && token.source === "")
          node.comment = comment;
        else
          node.commentBefore = comment;
      }
      if (ctx.options.keepSourceTokens && isSrcToken)
        node.srcToken = token;
      return node;
    }
    function composeEmptyNode(ctx, offset, before, pos, { spaceBefore, comment, anchor, tag, end }, onError2) {
      const token = {
        type: "scalar",
        offset: utilEmptyScalarPosition.emptyScalarPosition(offset, before, pos),
        indent: -1,
        source: ""
      };
      const node = composeScalar.composeScalar(ctx, token, tag, onError2);
      if (anchor) {
        node.anchor = anchor.source.substring(1);
        if (node.anchor === "")
          onError2(anchor, "BAD_ALIAS", "Anchor cannot be an empty string");
      }
      if (spaceBefore)
        node.spaceBefore = true;
      if (comment) {
        node.comment = comment;
        node.range[2] = end;
      }
      return node;
    }
    function composeAlias({ options }, { offset, source, end }, onError2) {
      const alias = new Alias.Alias(source.substring(1));
      if (alias.source === "")
        onError2(offset, "BAD_ALIAS", "Alias cannot be an empty string");
      if (alias.source.endsWith(":"))
        onError2(offset + source.length - 1, "BAD_ALIAS", "Alias ending in : is ambiguous", true);
      const valueEnd = offset + source.length;
      const re2 = resolveEnd.resolveEnd(end, valueEnd, options.strict, onError2);
      alias.range = [offset, valueEnd, re2.offset];
      if (re2.comment)
        alias.comment = re2.comment;
      return alias;
    }
    exports.composeEmptyNode = composeEmptyNode;
    exports.composeNode = composeNode;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-doc.js
var require_compose_doc = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/compose-doc.js"(exports) {
    "use strict";
    var Document = require_Document();
    var composeNode = require_compose_node();
    var resolveEnd = require_resolve_end();
    var resolveProps = require_resolve_props();
    function composeDoc(options, directives, { offset, start, value: value2, end }, onError2) {
      const opts = Object.assign({ _directives: directives }, options);
      const doc = new Document.Document(void 0, opts);
      const ctx = {
        atKey: false,
        atRoot: true,
        directives: doc.directives,
        options: doc.options,
        schema: doc.schema
      };
      const props = resolveProps.resolveProps(start, {
        indicator: "doc-start",
        next: value2 ?? end?.[0],
        offset,
        onError: onError2,
        parentIndent: 0,
        startOnNewline: true
      });
      if (props.found) {
        doc.directives.docStart = true;
        if (value2 && (value2.type === "block-map" || value2.type === "block-seq") && !props.hasNewline)
          onError2(props.end, "MISSING_CHAR", "Block collection cannot start on same line with directives-end marker");
      }
      doc.contents = value2 ? composeNode.composeNode(ctx, value2, props, onError2) : composeNode.composeEmptyNode(ctx, props.end, start, null, props, onError2);
      const contentEnd = doc.contents.range[2];
      const re2 = resolveEnd.resolveEnd(end, contentEnd, false, onError2);
      if (re2.comment)
        doc.comment = re2.comment;
      doc.range = [offset, contentEnd, re2.offset];
      return doc;
    }
    exports.composeDoc = composeDoc;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/composer.js
var require_composer = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/compose/composer.js"(exports) {
    "use strict";
    var node_process = __require("process");
    var directives = require_directives();
    var Document = require_Document();
    var errors = require_errors();
    var identity = require_identity();
    var composeDoc = require_compose_doc();
    var resolveEnd = require_resolve_end();
    function getErrorPos(src) {
      if (typeof src === "number")
        return [src, src + 1];
      if (Array.isArray(src))
        return src.length === 2 ? src : [src[0], src[1]];
      const { offset, source } = src;
      return [offset, offset + (typeof source === "string" ? source.length : 1)];
    }
    function parsePrelude(prelude) {
      let comment = "";
      let atComment = false;
      let afterEmptyLine = false;
      for (let i = 0; i < prelude.length; ++i) {
        const source = prelude[i];
        switch (source[0]) {
          case "#":
            comment += (comment === "" ? "" : afterEmptyLine ? "\n\n" : "\n") + (source.substring(1) || " ");
            atComment = true;
            afterEmptyLine = false;
            break;
          case "%":
            if (prelude[i + 1]?.[0] !== "#")
              i += 1;
            atComment = false;
            break;
          default:
            if (!atComment)
              afterEmptyLine = true;
            atComment = false;
        }
      }
      return { comment, afterEmptyLine };
    }
    var Composer = class {
      constructor(options = {}) {
        this.doc = null;
        this.atDirectives = false;
        this.prelude = [];
        this.errors = [];
        this.warnings = [];
        this.onError = (source, code, message, warning) => {
          const pos = getErrorPos(source);
          if (warning)
            this.warnings.push(new errors.YAMLWarning(pos, code, message));
          else
            this.errors.push(new errors.YAMLParseError(pos, code, message));
        };
        this.directives = new directives.Directives({ version: options.version || "1.2" });
        this.options = options;
      }
      decorate(doc, afterDoc) {
        const { comment, afterEmptyLine } = parsePrelude(this.prelude);
        if (comment) {
          const dc = doc.contents;
          if (afterDoc) {
            doc.comment = doc.comment ? `${doc.comment}
${comment}` : comment;
          } else if (afterEmptyLine || doc.directives.docStart || !dc) {
            doc.commentBefore = comment;
          } else if (identity.isCollection(dc) && !dc.flow && dc.items.length > 0) {
            let it = dc.items[0];
            if (identity.isPair(it))
              it = it.key;
            const cb = it.commentBefore;
            it.commentBefore = cb ? `${comment}
${cb}` : comment;
          } else {
            const cb = dc.commentBefore;
            dc.commentBefore = cb ? `${comment}
${cb}` : comment;
          }
        }
        if (afterDoc) {
          Array.prototype.push.apply(doc.errors, this.errors);
          Array.prototype.push.apply(doc.warnings, this.warnings);
        } else {
          doc.errors = this.errors;
          doc.warnings = this.warnings;
        }
        this.prelude = [];
        this.errors = [];
        this.warnings = [];
      }
      /**
       * Current stream status information.
       *
       * Mostly useful at the end of input for an empty stream.
       */
      streamInfo() {
        return {
          comment: parsePrelude(this.prelude).comment,
          directives: this.directives,
          errors: this.errors,
          warnings: this.warnings
        };
      }
      /**
       * Compose tokens into documents.
       *
       * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
       * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
       */
      *compose(tokens, forceDoc = false, endOffset = -1) {
        for (const token of tokens)
          yield* this.next(token);
        yield* this.end(forceDoc, endOffset);
      }
      /** Advance the composer by one CST token. */
      *next(token) {
        if (node_process.env.LOG_STREAM)
          console.dir(token, { depth: null });
        switch (token.type) {
          case "directive":
            this.directives.add(token.source, (offset, message, warning) => {
              const pos = getErrorPos(token);
              pos[0] += offset;
              this.onError(pos, "BAD_DIRECTIVE", message, warning);
            });
            this.prelude.push(token.source);
            this.atDirectives = true;
            break;
          case "document": {
            const doc = composeDoc.composeDoc(this.options, this.directives, token, this.onError);
            if (this.atDirectives && !doc.directives.docStart)
              this.onError(token, "MISSING_CHAR", "Missing directives-end/doc-start indicator line");
            this.decorate(doc, false);
            if (this.doc)
              yield this.doc;
            this.doc = doc;
            this.atDirectives = false;
            break;
          }
          case "byte-order-mark":
          case "space":
            break;
          case "comment":
          case "newline":
            this.prelude.push(token.source);
            break;
          case "error": {
            const msg = token.source ? `${token.message}: ${JSON.stringify(token.source)}` : token.message;
            const error = new errors.YAMLParseError(getErrorPos(token), "UNEXPECTED_TOKEN", msg);
            if (this.atDirectives || !this.doc)
              this.errors.push(error);
            else
              this.doc.errors.push(error);
            break;
          }
          case "doc-end": {
            if (!this.doc) {
              const msg = "Unexpected doc-end without preceding document";
              this.errors.push(new errors.YAMLParseError(getErrorPos(token), "UNEXPECTED_TOKEN", msg));
              break;
            }
            this.doc.directives.docEnd = true;
            const end = resolveEnd.resolveEnd(token.end, token.offset + token.source.length, this.doc.options.strict, this.onError);
            this.decorate(this.doc, true);
            if (end.comment) {
              const dc = this.doc.comment;
              this.doc.comment = dc ? `${dc}
${end.comment}` : end.comment;
            }
            this.doc.range[2] = end.offset;
            break;
          }
          default:
            this.errors.push(new errors.YAMLParseError(getErrorPos(token), "UNEXPECTED_TOKEN", `Unsupported token ${token.type}`));
        }
      }
      /**
       * Call at end of input to yield any remaining document.
       *
       * @param forceDoc - If the stream contains no document, still emit a final document including any comments and directives that would be applied to a subsequent document.
       * @param endOffset - Should be set if `forceDoc` is also set, to set the document range end and to indicate errors correctly.
       */
      *end(forceDoc = false, endOffset = -1) {
        if (this.doc) {
          this.decorate(this.doc, true);
          yield this.doc;
          this.doc = null;
        } else if (forceDoc) {
          const opts = Object.assign({ _directives: this.directives }, this.options);
          const doc = new Document.Document(void 0, opts);
          if (this.atDirectives)
            this.onError(endOffset, "MISSING_CHAR", "Missing directives-end indicator line");
          doc.range = [0, endOffset, endOffset];
          this.decorate(doc, false);
          yield doc;
        }
      }
    };
    exports.Composer = Composer;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-scalar.js
var require_cst_scalar = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-scalar.js"(exports) {
    "use strict";
    var resolveBlockScalar = require_resolve_block_scalar();
    var resolveFlowScalar = require_resolve_flow_scalar();
    var errors = require_errors();
    var stringifyString = require_stringifyString();
    function resolveAsScalar(token, strict = true, onError2) {
      if (token) {
        const _onError = (pos, code, message) => {
          const offset = typeof pos === "number" ? pos : Array.isArray(pos) ? pos[0] : pos.offset;
          if (onError2)
            onError2(offset, code, message);
          else
            throw new errors.YAMLParseError([offset, offset + 1], code, message);
        };
        switch (token.type) {
          case "scalar":
          case "single-quoted-scalar":
          case "double-quoted-scalar":
            return resolveFlowScalar.resolveFlowScalar(token, strict, _onError);
          case "block-scalar":
            return resolveBlockScalar.resolveBlockScalar({ options: { strict } }, token, _onError);
        }
      }
      return null;
    }
    function createScalarToken(value2, context) {
      const { implicitKey = false, indent, inFlow = false, offset = -1, type: type2 = "PLAIN" } = context;
      const source = stringifyString.stringifyString({ type: type2, value: value2 }, {
        implicitKey,
        indent: indent > 0 ? " ".repeat(indent) : "",
        inFlow,
        options: { blockQuote: true, lineWidth: -1 }
      });
      const end = context.end ?? [
        { type: "newline", offset: -1, indent, source: "\n" }
      ];
      switch (source[0]) {
        case "|":
        case ">": {
          const he = source.indexOf("\n");
          const head = source.substring(0, he);
          const body = source.substring(he + 1) + "\n";
          const props = [
            { type: "block-scalar-header", offset, indent, source: head }
          ];
          if (!addEndtoBlockProps(props, end))
            props.push({ type: "newline", offset: -1, indent, source: "\n" });
          return { type: "block-scalar", offset, indent, props, source: body };
        }
        case '"':
          return { type: "double-quoted-scalar", offset, indent, source, end };
        case "'":
          return { type: "single-quoted-scalar", offset, indent, source, end };
        default:
          return { type: "scalar", offset, indent, source, end };
      }
    }
    function setScalarValue(token, value2, context = {}) {
      let { afterKey = false, implicitKey = false, inFlow = false, type: type2 } = context;
      let indent = "indent" in token ? token.indent : null;
      if (afterKey && typeof indent === "number")
        indent += 2;
      if (!type2)
        switch (token.type) {
          case "single-quoted-scalar":
            type2 = "QUOTE_SINGLE";
            break;
          case "double-quoted-scalar":
            type2 = "QUOTE_DOUBLE";
            break;
          case "block-scalar": {
            const header = token.props[0];
            if (header.type !== "block-scalar-header")
              throw new Error("Invalid block scalar header");
            type2 = header.source[0] === ">" ? "BLOCK_FOLDED" : "BLOCK_LITERAL";
            break;
          }
          default:
            type2 = "PLAIN";
        }
      const source = stringifyString.stringifyString({ type: type2, value: value2 }, {
        implicitKey: implicitKey || indent === null,
        indent: indent !== null && indent > 0 ? " ".repeat(indent) : "",
        inFlow,
        options: { blockQuote: true, lineWidth: -1 }
      });
      switch (source[0]) {
        case "|":
        case ">":
          setBlockScalarValue(token, source);
          break;
        case '"':
          setFlowScalarValue(token, source, "double-quoted-scalar");
          break;
        case "'":
          setFlowScalarValue(token, source, "single-quoted-scalar");
          break;
        default:
          setFlowScalarValue(token, source, "scalar");
      }
    }
    function setBlockScalarValue(token, source) {
      const he = source.indexOf("\n");
      const head = source.substring(0, he);
      const body = source.substring(he + 1) + "\n";
      if (token.type === "block-scalar") {
        const header = token.props[0];
        if (header.type !== "block-scalar-header")
          throw new Error("Invalid block scalar header");
        header.source = head;
        token.source = body;
      } else {
        const { offset } = token;
        const indent = "indent" in token ? token.indent : -1;
        const props = [
          { type: "block-scalar-header", offset, indent, source: head }
        ];
        if (!addEndtoBlockProps(props, "end" in token ? token.end : void 0))
          props.push({ type: "newline", offset: -1, indent, source: "\n" });
        for (const key of Object.keys(token))
          if (key !== "type" && key !== "offset")
            delete token[key];
        Object.assign(token, { type: "block-scalar", indent, props, source: body });
      }
    }
    function addEndtoBlockProps(props, end) {
      if (end)
        for (const st of end)
          switch (st.type) {
            case "space":
            case "comment":
              props.push(st);
              break;
            case "newline":
              props.push(st);
              return true;
          }
      return false;
    }
    function setFlowScalarValue(token, source, type2) {
      switch (token.type) {
        case "scalar":
        case "double-quoted-scalar":
        case "single-quoted-scalar":
          token.type = type2;
          token.source = source;
          break;
        case "block-scalar": {
          const end = token.props.slice(1);
          let oa = source.length;
          if (token.props[0].type === "block-scalar-header")
            oa -= token.props[0].source.length;
          for (const tok of end)
            tok.offset += oa;
          delete token.props;
          Object.assign(token, { type: type2, source, end });
          break;
        }
        case "block-map":
        case "block-seq": {
          const offset = token.offset + source.length;
          const nl = { type: "newline", offset, indent: token.indent, source: "\n" };
          delete token.items;
          Object.assign(token, { type: type2, source, end: [nl] });
          break;
        }
        default: {
          const indent = "indent" in token ? token.indent : -1;
          const end = "end" in token && Array.isArray(token.end) ? token.end.filter((st) => st.type === "space" || st.type === "comment" || st.type === "newline") : [];
          for (const key of Object.keys(token))
            if (key !== "type" && key !== "offset")
              delete token[key];
          Object.assign(token, { type: type2, indent, source, end });
        }
      }
    }
    exports.createScalarToken = createScalarToken;
    exports.resolveAsScalar = resolveAsScalar;
    exports.setScalarValue = setScalarValue;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-stringify.js
var require_cst_stringify = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-stringify.js"(exports) {
    "use strict";
    var stringify = (cst) => "type" in cst ? stringifyToken(cst) : stringifyItem(cst);
    function stringifyToken(token) {
      switch (token.type) {
        case "block-scalar": {
          let res = "";
          for (const tok of token.props)
            res += stringifyToken(tok);
          return res + token.source;
        }
        case "block-map":
        case "block-seq": {
          let res = "";
          for (const item of token.items)
            res += stringifyItem(item);
          return res;
        }
        case "flow-collection": {
          let res = token.start.source;
          for (const item of token.items)
            res += stringifyItem(item);
          for (const st of token.end)
            res += st.source;
          return res;
        }
        case "document": {
          let res = stringifyItem(token);
          if (token.end)
            for (const st of token.end)
              res += st.source;
          return res;
        }
        default: {
          let res = token.source;
          if ("end" in token && token.end)
            for (const st of token.end)
              res += st.source;
          return res;
        }
      }
    }
    function stringifyItem({ start, key, sep, value: value2 }) {
      let res = "";
      for (const st of start)
        res += st.source;
      if (key)
        res += stringifyToken(key);
      if (sep)
        for (const st of sep)
          res += st.source;
      if (value2)
        res += stringifyToken(value2);
      return res;
    }
    exports.stringify = stringify;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-visit.js
var require_cst_visit = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst-visit.js"(exports) {
    "use strict";
    var BREAK = Symbol("break visit");
    var SKIP = Symbol("skip children");
    var REMOVE = Symbol("remove item");
    function visit(cst, visitor) {
      if ("type" in cst && cst.type === "document")
        cst = { start: cst.start, value: cst.value };
      _visit(Object.freeze([]), cst, visitor);
    }
    visit.BREAK = BREAK;
    visit.SKIP = SKIP;
    visit.REMOVE = REMOVE;
    visit.itemAtPath = (cst, path21) => {
      let item = cst;
      for (const [field, index] of path21) {
        const tok = item?.[field];
        if (tok && "items" in tok) {
          item = tok.items[index];
        } else
          return void 0;
      }
      return item;
    };
    visit.parentCollection = (cst, path21) => {
      const parent = visit.itemAtPath(cst, path21.slice(0, -1));
      const field = path21[path21.length - 1][0];
      const coll = parent?.[field];
      if (coll && "items" in coll)
        return coll;
      throw new Error("Parent collection not found");
    };
    function _visit(path21, item, visitor) {
      let ctrl = visitor(item, path21);
      if (typeof ctrl === "symbol")
        return ctrl;
      for (const field of ["key", "value"]) {
        const token = item[field];
        if (token && "items" in token) {
          for (let i = 0; i < token.items.length; ++i) {
            const ci = _visit(Object.freeze(path21.concat([[field, i]])), token.items[i], visitor);
            if (typeof ci === "number")
              i = ci - 1;
            else if (ci === BREAK)
              return BREAK;
            else if (ci === REMOVE) {
              token.items.splice(i, 1);
              i -= 1;
            }
          }
          if (typeof ctrl === "function" && field === "key")
            ctrl = ctrl(item, path21);
        }
      }
      return typeof ctrl === "function" ? ctrl(item, path21) : ctrl;
    }
    exports.visit = visit;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst.js
var require_cst = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/cst.js"(exports) {
    "use strict";
    var cstScalar = require_cst_scalar();
    var cstStringify = require_cst_stringify();
    var cstVisit = require_cst_visit();
    var BOM = "\uFEFF";
    var DOCUMENT = "";
    var FLOW_END = "";
    var SCALAR = "";
    var isCollection = (token) => !!token && "items" in token;
    var isScalar = (token) => !!token && (token.type === "scalar" || token.type === "single-quoted-scalar" || token.type === "double-quoted-scalar" || token.type === "block-scalar");
    function prettyToken(token) {
      switch (token) {
        case BOM:
          return "<BOM>";
        case DOCUMENT:
          return "<DOC>";
        case FLOW_END:
          return "<FLOW_END>";
        case SCALAR:
          return "<SCALAR>";
        default:
          return JSON.stringify(token);
      }
    }
    function tokenType(source) {
      switch (source) {
        case BOM:
          return "byte-order-mark";
        case DOCUMENT:
          return "doc-mode";
        case FLOW_END:
          return "flow-error-end";
        case SCALAR:
          return "scalar";
        case "---":
          return "doc-start";
        case "...":
          return "doc-end";
        case "":
        case "\n":
        case "\r\n":
          return "newline";
        case "-":
          return "seq-item-ind";
        case "?":
          return "explicit-key-ind";
        case ":":
          return "map-value-ind";
        case "{":
          return "flow-map-start";
        case "}":
          return "flow-map-end";
        case "[":
          return "flow-seq-start";
        case "]":
          return "flow-seq-end";
        case ",":
          return "comma";
      }
      switch (source[0]) {
        case " ":
        case "	":
          return "space";
        case "#":
          return "comment";
        case "%":
          return "directive-line";
        case "*":
          return "alias";
        case "&":
          return "anchor";
        case "!":
          return "tag";
        case "'":
          return "single-quoted-scalar";
        case '"':
          return "double-quoted-scalar";
        case "|":
        case ">":
          return "block-scalar-header";
      }
      return null;
    }
    exports.createScalarToken = cstScalar.createScalarToken;
    exports.resolveAsScalar = cstScalar.resolveAsScalar;
    exports.setScalarValue = cstScalar.setScalarValue;
    exports.stringify = cstStringify.stringify;
    exports.visit = cstVisit.visit;
    exports.BOM = BOM;
    exports.DOCUMENT = DOCUMENT;
    exports.FLOW_END = FLOW_END;
    exports.SCALAR = SCALAR;
    exports.isCollection = isCollection;
    exports.isScalar = isScalar;
    exports.prettyToken = prettyToken;
    exports.tokenType = tokenType;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/lexer.js
var require_lexer = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/lexer.js"(exports) {
    "use strict";
    var cst = require_cst();
    function isEmpty(ch) {
      switch (ch) {
        case void 0:
        case " ":
        case "\n":
        case "\r":
        case "	":
          return true;
        default:
          return false;
      }
    }
    var hexDigits = new Set("0123456789ABCDEFabcdef");
    var tagChars = new Set("0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz-#;/?:@&=+$_.!~*'()");
    var flowIndicatorChars = new Set(",[]{}");
    var invalidAnchorChars = new Set(" ,[]{}\n\r	");
    var isNotAnchorChar = (ch) => !ch || invalidAnchorChars.has(ch);
    var Lexer = class {
      constructor() {
        this.atEnd = false;
        this.blockScalarIndent = -1;
        this.blockScalarKeep = false;
        this.buffer = "";
        this.flowKey = false;
        this.flowLevel = 0;
        this.indentNext = 0;
        this.indentValue = 0;
        this.lineEndPos = null;
        this.next = null;
        this.pos = 0;
      }
      /**
       * Generate YAML tokens from the `source` string. If `incomplete`,
       * a part of the last line may be left as a buffer for the next call.
       *
       * @returns A generator of lexical tokens
       */
      *lex(source, incomplete = false) {
        if (source) {
          if (typeof source !== "string")
            throw TypeError("source is not a string");
          this.buffer = this.buffer ? this.buffer + source : source;
          this.lineEndPos = null;
        }
        this.atEnd = !incomplete;
        let next = this.next ?? "stream";
        while (next && (incomplete || this.hasChars(1)))
          next = yield* this.parseNext(next);
      }
      atLineEnd() {
        let i = this.pos;
        let ch = this.buffer[i];
        while (ch === " " || ch === "	")
          ch = this.buffer[++i];
        if (!ch || ch === "#" || ch === "\n")
          return true;
        if (ch === "\r")
          return this.buffer[i + 1] === "\n";
        return false;
      }
      charAt(n) {
        return this.buffer[this.pos + n];
      }
      continueScalar(offset) {
        let ch = this.buffer[offset];
        if (this.indentNext > 0) {
          let indent = 0;
          while (ch === " ")
            ch = this.buffer[++indent + offset];
          if (ch === "\r") {
            const next = this.buffer[indent + offset + 1];
            if (next === "\n" || !next && !this.atEnd)
              return offset + indent + 1;
          }
          return ch === "\n" || indent >= this.indentNext || !ch && !this.atEnd ? offset + indent : -1;
        }
        if (ch === "-" || ch === ".") {
          const dt = this.buffer.substr(offset, 3);
          if ((dt === "---" || dt === "...") && isEmpty(this.buffer[offset + 3]))
            return -1;
        }
        return offset;
      }
      getLine() {
        let end = this.lineEndPos;
        if (typeof end !== "number" || end !== -1 && end < this.pos) {
          end = this.buffer.indexOf("\n", this.pos);
          this.lineEndPos = end;
        }
        if (end === -1)
          return this.atEnd ? this.buffer.substring(this.pos) : null;
        if (this.buffer[end - 1] === "\r")
          end -= 1;
        return this.buffer.substring(this.pos, end);
      }
      hasChars(n) {
        return this.pos + n <= this.buffer.length;
      }
      setNext(state) {
        this.buffer = this.buffer.substring(this.pos);
        this.pos = 0;
        this.lineEndPos = null;
        this.next = state;
        return null;
      }
      peek(n) {
        return this.buffer.substr(this.pos, n);
      }
      *parseNext(next) {
        switch (next) {
          case "stream":
            return yield* this.parseStream();
          case "line-start":
            return yield* this.parseLineStart();
          case "block-start":
            return yield* this.parseBlockStart();
          case "doc":
            return yield* this.parseDocument();
          case "flow":
            return yield* this.parseFlowCollection();
          case "quoted-scalar":
            return yield* this.parseQuotedScalar();
          case "block-scalar":
            return yield* this.parseBlockScalar();
          case "plain-scalar":
            return yield* this.parsePlainScalar();
        }
      }
      *parseStream() {
        let line = this.getLine();
        if (line === null)
          return this.setNext("stream");
        if (line[0] === cst.BOM) {
          yield* this.pushCount(1);
          line = line.substring(1);
        }
        if (line[0] === "%") {
          let dirEnd = line.length;
          let cs = line.indexOf("#");
          while (cs !== -1) {
            const ch = line[cs - 1];
            if (ch === " " || ch === "	") {
              dirEnd = cs - 1;
              break;
            } else {
              cs = line.indexOf("#", cs + 1);
            }
          }
          while (true) {
            const ch = line[dirEnd - 1];
            if (ch === " " || ch === "	")
              dirEnd -= 1;
            else
              break;
          }
          const n = (yield* this.pushCount(dirEnd)) + (yield* this.pushSpaces(true));
          yield* this.pushCount(line.length - n);
          this.pushNewline();
          return "stream";
        }
        if (this.atLineEnd()) {
          const sp = yield* this.pushSpaces(true);
          yield* this.pushCount(line.length - sp);
          yield* this.pushNewline();
          return "stream";
        }
        yield cst.DOCUMENT;
        return yield* this.parseLineStart();
      }
      *parseLineStart() {
        const ch = this.charAt(0);
        if (!ch && !this.atEnd)
          return this.setNext("line-start");
        if (ch === "-" || ch === ".") {
          if (!this.atEnd && !this.hasChars(4))
            return this.setNext("line-start");
          const s = this.peek(3);
          if ((s === "---" || s === "...") && isEmpty(this.charAt(3))) {
            yield* this.pushCount(3);
            this.indentValue = 0;
            this.indentNext = 0;
            return s === "---" ? "doc" : "stream";
          }
        }
        this.indentValue = yield* this.pushSpaces(false);
        if (this.indentNext > this.indentValue && !isEmpty(this.charAt(1)))
          this.indentNext = this.indentValue;
        return yield* this.parseBlockStart();
      }
      *parseBlockStart() {
        const [ch0, ch1] = this.peek(2);
        if (!ch1 && !this.atEnd)
          return this.setNext("block-start");
        if ((ch0 === "-" || ch0 === "?" || ch0 === ":") && isEmpty(ch1)) {
          const n = (yield* this.pushCount(1)) + (yield* this.pushSpaces(true));
          this.indentNext = this.indentValue + 1;
          this.indentValue += n;
          return yield* this.parseBlockStart();
        }
        return "doc";
      }
      *parseDocument() {
        yield* this.pushSpaces(true);
        const line = this.getLine();
        if (line === null)
          return this.setNext("doc");
        let n = yield* this.pushIndicators();
        switch (line[n]) {
          case "#":
            yield* this.pushCount(line.length - n);
          // fallthrough
          case void 0:
            yield* this.pushNewline();
            return yield* this.parseLineStart();
          case "{":
          case "[":
            yield* this.pushCount(1);
            this.flowKey = false;
            this.flowLevel = 1;
            return "flow";
          case "}":
          case "]":
            yield* this.pushCount(1);
            return "doc";
          case "*":
            yield* this.pushUntil(isNotAnchorChar);
            return "doc";
          case '"':
          case "'":
            return yield* this.parseQuotedScalar();
          case "|":
          case ">":
            n += yield* this.parseBlockScalarHeader();
            n += yield* this.pushSpaces(true);
            yield* this.pushCount(line.length - n);
            yield* this.pushNewline();
            return yield* this.parseBlockScalar();
          default:
            return yield* this.parsePlainScalar();
        }
      }
      *parseFlowCollection() {
        let nl, sp;
        let indent = -1;
        do {
          nl = yield* this.pushNewline();
          if (nl > 0) {
            sp = yield* this.pushSpaces(false);
            this.indentValue = indent = sp;
          } else {
            sp = 0;
          }
          sp += yield* this.pushSpaces(true);
        } while (nl + sp > 0);
        const line = this.getLine();
        if (line === null)
          return this.setNext("flow");
        if (indent !== -1 && indent < this.indentNext && line[0] !== "#" || indent === 0 && (line.startsWith("---") || line.startsWith("...")) && isEmpty(line[3])) {
          const atFlowEndMarker = indent === this.indentNext - 1 && this.flowLevel === 1 && (line[0] === "]" || line[0] === "}");
          if (!atFlowEndMarker) {
            this.flowLevel = 0;
            yield cst.FLOW_END;
            return yield* this.parseLineStart();
          }
        }
        let n = 0;
        while (line[n] === ",") {
          n += yield* this.pushCount(1);
          n += yield* this.pushSpaces(true);
          this.flowKey = false;
        }
        n += yield* this.pushIndicators();
        switch (line[n]) {
          case void 0:
            return "flow";
          case "#":
            yield* this.pushCount(line.length - n);
            return "flow";
          case "{":
          case "[":
            yield* this.pushCount(1);
            this.flowKey = false;
            this.flowLevel += 1;
            return "flow";
          case "}":
          case "]":
            yield* this.pushCount(1);
            this.flowKey = true;
            this.flowLevel -= 1;
            return this.flowLevel ? "flow" : "doc";
          case "*":
            yield* this.pushUntil(isNotAnchorChar);
            return "flow";
          case '"':
          case "'":
            this.flowKey = true;
            return yield* this.parseQuotedScalar();
          case ":": {
            const next = this.charAt(1);
            if (this.flowKey || isEmpty(next) || next === ",") {
              this.flowKey = false;
              yield* this.pushCount(1);
              yield* this.pushSpaces(true);
              return "flow";
            }
          }
          // fallthrough
          default:
            this.flowKey = false;
            return yield* this.parsePlainScalar();
        }
      }
      *parseQuotedScalar() {
        const quote = this.charAt(0);
        let end = this.buffer.indexOf(quote, this.pos + 1);
        if (quote === "'") {
          while (end !== -1 && this.buffer[end + 1] === "'")
            end = this.buffer.indexOf("'", end + 2);
        } else {
          while (end !== -1) {
            let n = 0;
            while (this.buffer[end - 1 - n] === "\\")
              n += 1;
            if (n % 2 === 0)
              break;
            end = this.buffer.indexOf('"', end + 1);
          }
        }
        const qb = this.buffer.substring(0, end);
        let nl = qb.indexOf("\n", this.pos);
        if (nl !== -1) {
          while (nl !== -1) {
            const cs = this.continueScalar(nl + 1);
            if (cs === -1)
              break;
            nl = qb.indexOf("\n", cs);
          }
          if (nl !== -1) {
            end = nl - (qb[nl - 1] === "\r" ? 2 : 1);
          }
        }
        if (end === -1) {
          if (!this.atEnd)
            return this.setNext("quoted-scalar");
          end = this.buffer.length;
        }
        yield* this.pushToIndex(end + 1, false);
        return this.flowLevel ? "flow" : "doc";
      }
      *parseBlockScalarHeader() {
        this.blockScalarIndent = -1;
        this.blockScalarKeep = false;
        let i = this.pos;
        while (true) {
          const ch = this.buffer[++i];
          if (ch === "+")
            this.blockScalarKeep = true;
          else if (ch > "0" && ch <= "9")
            this.blockScalarIndent = Number(ch) - 1;
          else if (ch !== "-")
            break;
        }
        return yield* this.pushUntil((ch) => isEmpty(ch) || ch === "#");
      }
      *parseBlockScalar() {
        let nl = this.pos - 1;
        let indent = 0;
        let ch;
        loop: for (let i2 = this.pos; ch = this.buffer[i2]; ++i2) {
          switch (ch) {
            case " ":
              indent += 1;
              break;
            case "\n":
              nl = i2;
              indent = 0;
              break;
            case "\r": {
              const next = this.buffer[i2 + 1];
              if (!next && !this.atEnd)
                return this.setNext("block-scalar");
              if (next === "\n")
                break;
            }
            // fallthrough
            default:
              break loop;
          }
        }
        if (!ch && !this.atEnd)
          return this.setNext("block-scalar");
        if (indent >= this.indentNext) {
          if (this.blockScalarIndent === -1)
            this.indentNext = indent;
          else {
            this.indentNext = this.blockScalarIndent + (this.indentNext === 0 ? 1 : this.indentNext);
          }
          do {
            const cs = this.continueScalar(nl + 1);
            if (cs === -1)
              break;
            nl = this.buffer.indexOf("\n", cs);
          } while (nl !== -1);
          if (nl === -1) {
            if (!this.atEnd)
              return this.setNext("block-scalar");
            nl = this.buffer.length;
          }
        }
        let i = nl + 1;
        ch = this.buffer[i];
        while (ch === " ")
          ch = this.buffer[++i];
        if (ch === "	") {
          while (ch === "	" || ch === " " || ch === "\r" || ch === "\n")
            ch = this.buffer[++i];
          nl = i - 1;
        } else if (!this.blockScalarKeep) {
          do {
            let i2 = nl - 1;
            let ch2 = this.buffer[i2];
            if (ch2 === "\r")
              ch2 = this.buffer[--i2];
            const lastChar = i2;
            while (ch2 === " ")
              ch2 = this.buffer[--i2];
            if (ch2 === "\n" && i2 >= this.pos && i2 + 1 + indent > lastChar)
              nl = i2;
            else
              break;
          } while (true);
        }
        yield cst.SCALAR;
        yield* this.pushToIndex(nl + 1, true);
        return yield* this.parseLineStart();
      }
      *parsePlainScalar() {
        const inFlow = this.flowLevel > 0;
        let end = this.pos - 1;
        let i = this.pos - 1;
        let ch;
        while (ch = this.buffer[++i]) {
          if (ch === ":") {
            const next = this.buffer[i + 1];
            if (isEmpty(next) || inFlow && flowIndicatorChars.has(next))
              break;
            end = i;
          } else if (isEmpty(ch)) {
            let next = this.buffer[i + 1];
            if (ch === "\r") {
              if (next === "\n") {
                i += 1;
                ch = "\n";
                next = this.buffer[i + 1];
              } else
                end = i;
            }
            if (next === "#" || inFlow && flowIndicatorChars.has(next))
              break;
            if (ch === "\n") {
              const cs = this.continueScalar(i + 1);
              if (cs === -1)
                break;
              i = Math.max(i, cs - 2);
            }
          } else {
            if (inFlow && flowIndicatorChars.has(ch))
              break;
            end = i;
          }
        }
        if (!ch && !this.atEnd)
          return this.setNext("plain-scalar");
        yield cst.SCALAR;
        yield* this.pushToIndex(end + 1, true);
        return inFlow ? "flow" : "doc";
      }
      *pushCount(n) {
        if (n > 0) {
          yield this.buffer.substr(this.pos, n);
          this.pos += n;
          return n;
        }
        return 0;
      }
      *pushToIndex(i, allowEmpty) {
        const s = this.buffer.slice(this.pos, i);
        if (s) {
          yield s;
          this.pos += s.length;
          return s.length;
        } else if (allowEmpty)
          yield "";
        return 0;
      }
      *pushIndicators() {
        switch (this.charAt(0)) {
          case "!":
            return (yield* this.pushTag()) + (yield* this.pushSpaces(true)) + (yield* this.pushIndicators());
          case "&":
            return (yield* this.pushUntil(isNotAnchorChar)) + (yield* this.pushSpaces(true)) + (yield* this.pushIndicators());
          case "-":
          // this is an error
          case "?":
          // this is an error outside flow collections
          case ":": {
            const inFlow = this.flowLevel > 0;
            const ch1 = this.charAt(1);
            if (isEmpty(ch1) || inFlow && flowIndicatorChars.has(ch1)) {
              if (!inFlow)
                this.indentNext = this.indentValue + 1;
              else if (this.flowKey)
                this.flowKey = false;
              return (yield* this.pushCount(1)) + (yield* this.pushSpaces(true)) + (yield* this.pushIndicators());
            }
          }
        }
        return 0;
      }
      *pushTag() {
        if (this.charAt(1) === "<") {
          let i = this.pos + 2;
          let ch = this.buffer[i];
          while (!isEmpty(ch) && ch !== ">")
            ch = this.buffer[++i];
          return yield* this.pushToIndex(ch === ">" ? i + 1 : i, false);
        } else {
          let i = this.pos + 1;
          let ch = this.buffer[i];
          while (ch) {
            if (tagChars.has(ch))
              ch = this.buffer[++i];
            else if (ch === "%" && hexDigits.has(this.buffer[i + 1]) && hexDigits.has(this.buffer[i + 2])) {
              ch = this.buffer[i += 3];
            } else
              break;
          }
          return yield* this.pushToIndex(i, false);
        }
      }
      *pushNewline() {
        const ch = this.buffer[this.pos];
        if (ch === "\n")
          return yield* this.pushCount(1);
        else if (ch === "\r" && this.charAt(1) === "\n")
          return yield* this.pushCount(2);
        else
          return 0;
      }
      *pushSpaces(allowTabs) {
        let i = this.pos - 1;
        let ch;
        do {
          ch = this.buffer[++i];
        } while (ch === " " || allowTabs && ch === "	");
        const n = i - this.pos;
        if (n > 0) {
          yield this.buffer.substr(this.pos, n);
          this.pos = i;
        }
        return n;
      }
      *pushUntil(test) {
        let i = this.pos;
        let ch = this.buffer[i];
        while (!test(ch))
          ch = this.buffer[++i];
        return yield* this.pushToIndex(i, false);
      }
    };
    exports.Lexer = Lexer;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/line-counter.js
var require_line_counter = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/line-counter.js"(exports) {
    "use strict";
    var LineCounter = class {
      constructor() {
        this.lineStarts = [];
        this.addNewLine = (offset) => this.lineStarts.push(offset);
        this.linePos = (offset) => {
          let low = 0;
          let high = this.lineStarts.length;
          while (low < high) {
            const mid = low + high >> 1;
            if (this.lineStarts[mid] < offset)
              low = mid + 1;
            else
              high = mid;
          }
          if (this.lineStarts[low] === offset)
            return { line: low + 1, col: 1 };
          if (low === 0)
            return { line: 0, col: offset };
          const start = this.lineStarts[low - 1];
          return { line: low, col: offset - start + 1 };
        };
      }
    };
    exports.LineCounter = LineCounter;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/parser.js
var require_parser = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/parse/parser.js"(exports) {
    "use strict";
    var node_process = __require("process");
    var cst = require_cst();
    var lexer = require_lexer();
    function includesToken(list, type2) {
      for (let i = 0; i < list.length; ++i)
        if (list[i].type === type2)
          return true;
      return false;
    }
    function findNonEmptyIndex(list) {
      for (let i = 0; i < list.length; ++i) {
        switch (list[i].type) {
          case "space":
          case "comment":
          case "newline":
            break;
          default:
            return i;
        }
      }
      return -1;
    }
    function isFlowToken(token) {
      switch (token?.type) {
        case "alias":
        case "scalar":
        case "single-quoted-scalar":
        case "double-quoted-scalar":
        case "flow-collection":
          return true;
        default:
          return false;
      }
    }
    function getPrevProps(parent) {
      switch (parent.type) {
        case "document":
          return parent.start;
        case "block-map": {
          const it = parent.items[parent.items.length - 1];
          return it.sep ?? it.start;
        }
        case "block-seq":
          return parent.items[parent.items.length - 1].start;
        /* istanbul ignore next should not happen */
        default:
          return [];
      }
    }
    function getFirstKeyStartProps(prev) {
      if (prev.length === 0)
        return [];
      let i = prev.length;
      loop: while (--i >= 0) {
        switch (prev[i].type) {
          case "doc-start":
          case "explicit-key-ind":
          case "map-value-ind":
          case "seq-item-ind":
          case "newline":
            break loop;
        }
      }
      while (prev[++i]?.type === "space") {
      }
      return prev.splice(i, prev.length);
    }
    function fixFlowSeqItems(fc) {
      if (fc.start.type === "flow-seq-start") {
        for (const it of fc.items) {
          if (it.sep && !it.value && !includesToken(it.start, "explicit-key-ind") && !includesToken(it.sep, "map-value-ind")) {
            if (it.key)
              it.value = it.key;
            delete it.key;
            if (isFlowToken(it.value)) {
              if (it.value.end)
                Array.prototype.push.apply(it.value.end, it.sep);
              else
                it.value.end = it.sep;
            } else
              Array.prototype.push.apply(it.start, it.sep);
            delete it.sep;
          }
        }
      }
    }
    var Parser = class {
      /**
       * @param onNewLine - If defined, called separately with the start position of
       *   each new line (in `parse()`, including the start of input).
       */
      constructor(onNewLine) {
        this.atNewLine = true;
        this.atScalar = false;
        this.indent = 0;
        this.offset = 0;
        this.onKeyLine = false;
        this.stack = [];
        this.source = "";
        this.type = "";
        this.lexer = new lexer.Lexer();
        this.onNewLine = onNewLine;
      }
      /**
       * Parse `source` as a YAML stream.
       * If `incomplete`, a part of the last line may be left as a buffer for the next call.
       *
       * Errors are not thrown, but yielded as `{ type: 'error', message }` tokens.
       *
       * @returns A generator of tokens representing each directive, document, and other structure.
       */
      *parse(source, incomplete = false) {
        if (this.onNewLine && this.offset === 0)
          this.onNewLine(0);
        for (const lexeme of this.lexer.lex(source, incomplete))
          yield* this.next(lexeme);
        if (!incomplete)
          yield* this.end();
      }
      /**
       * Advance the parser by the `source` of one lexical token.
       */
      *next(source) {
        this.source = source;
        if (node_process.env.LOG_TOKENS)
          console.log("|", cst.prettyToken(source));
        if (this.atScalar) {
          this.atScalar = false;
          yield* this.step();
          this.offset += source.length;
          return;
        }
        const type2 = cst.tokenType(source);
        if (!type2) {
          const message = `Not a YAML token: ${source}`;
          yield* this.pop({ type: "error", offset: this.offset, message, source });
          this.offset += source.length;
        } else if (type2 === "scalar") {
          this.atNewLine = false;
          this.atScalar = true;
          this.type = "scalar";
        } else {
          this.type = type2;
          yield* this.step();
          switch (type2) {
            case "newline":
              this.atNewLine = true;
              this.indent = 0;
              if (this.onNewLine)
                this.onNewLine(this.offset + source.length);
              break;
            case "space":
              if (this.atNewLine && source[0] === " ")
                this.indent += source.length;
              break;
            case "explicit-key-ind":
            case "map-value-ind":
            case "seq-item-ind":
              if (this.atNewLine)
                this.indent += source.length;
              break;
            case "doc-mode":
            case "flow-error-end":
              return;
            default:
              this.atNewLine = false;
          }
          this.offset += source.length;
        }
      }
      /** Call at end of input to push out any remaining constructions */
      *end() {
        while (this.stack.length > 0)
          yield* this.pop();
      }
      get sourceToken() {
        const st = {
          type: this.type,
          offset: this.offset,
          indent: this.indent,
          source: this.source
        };
        return st;
      }
      *step() {
        const top = this.peek(1);
        if (this.type === "doc-end" && top?.type !== "doc-end") {
          while (this.stack.length > 0)
            yield* this.pop();
          this.stack.push({
            type: "doc-end",
            offset: this.offset,
            source: this.source
          });
          return;
        }
        if (!top)
          return yield* this.stream();
        switch (top.type) {
          case "document":
            return yield* this.document(top);
          case "alias":
          case "scalar":
          case "single-quoted-scalar":
          case "double-quoted-scalar":
            return yield* this.scalar(top);
          case "block-scalar":
            return yield* this.blockScalar(top);
          case "block-map":
            return yield* this.blockMap(top);
          case "block-seq":
            return yield* this.blockSequence(top);
          case "flow-collection":
            return yield* this.flowCollection(top);
          case "doc-end":
            return yield* this.documentEnd(top);
        }
        yield* this.pop();
      }
      peek(n) {
        return this.stack[this.stack.length - n];
      }
      *pop(error) {
        const token = error ?? this.stack.pop();
        if (!token) {
          const message = "Tried to pop an empty stack";
          yield { type: "error", offset: this.offset, source: "", message };
        } else if (this.stack.length === 0) {
          yield token;
        } else {
          const top = this.peek(1);
          if (token.type === "block-scalar") {
            token.indent = "indent" in top ? top.indent : 0;
          } else if (token.type === "flow-collection" && top.type === "document") {
            token.indent = 0;
          }
          if (token.type === "flow-collection")
            fixFlowSeqItems(token);
          switch (top.type) {
            case "document":
              top.value = token;
              break;
            case "block-scalar":
              top.props.push(token);
              break;
            case "block-map": {
              const it = top.items[top.items.length - 1];
              if (it.value) {
                top.items.push({ start: [], key: token, sep: [] });
                this.onKeyLine = true;
                return;
              } else if (it.sep) {
                it.value = token;
              } else {
                Object.assign(it, { key: token, sep: [] });
                this.onKeyLine = !it.explicitKey;
                return;
              }
              break;
            }
            case "block-seq": {
              const it = top.items[top.items.length - 1];
              if (it.value)
                top.items.push({ start: [], value: token });
              else
                it.value = token;
              break;
            }
            case "flow-collection": {
              const it = top.items[top.items.length - 1];
              if (!it || it.value)
                top.items.push({ start: [], key: token, sep: [] });
              else if (it.sep)
                it.value = token;
              else
                Object.assign(it, { key: token, sep: [] });
              return;
            }
            /* istanbul ignore next should not happen */
            default:
              yield* this.pop();
              yield* this.pop(token);
          }
          if ((top.type === "document" || top.type === "block-map" || top.type === "block-seq") && (token.type === "block-map" || token.type === "block-seq")) {
            const last = token.items[token.items.length - 1];
            if (last && !last.sep && !last.value && last.start.length > 0 && findNonEmptyIndex(last.start) === -1 && (token.indent === 0 || last.start.every((st) => st.type !== "comment" || st.indent < token.indent))) {
              if (top.type === "document")
                top.end = last.start;
              else
                top.items.push({ start: last.start });
              token.items.splice(-1, 1);
            }
          }
        }
      }
      *stream() {
        switch (this.type) {
          case "directive-line":
            yield { type: "directive", offset: this.offset, source: this.source };
            return;
          case "byte-order-mark":
          case "space":
          case "comment":
          case "newline":
            yield this.sourceToken;
            return;
          case "doc-mode":
          case "doc-start": {
            const doc = {
              type: "document",
              offset: this.offset,
              start: []
            };
            if (this.type === "doc-start")
              doc.start.push(this.sourceToken);
            this.stack.push(doc);
            return;
          }
        }
        yield {
          type: "error",
          offset: this.offset,
          message: `Unexpected ${this.type} token in YAML stream`,
          source: this.source
        };
      }
      *document(doc) {
        if (doc.value)
          return yield* this.lineEnd(doc);
        switch (this.type) {
          case "doc-start": {
            if (findNonEmptyIndex(doc.start) !== -1) {
              yield* this.pop();
              yield* this.step();
            } else
              doc.start.push(this.sourceToken);
            return;
          }
          case "anchor":
          case "tag":
          case "space":
          case "comment":
          case "newline":
            doc.start.push(this.sourceToken);
            return;
        }
        const bv = this.startBlockValue(doc);
        if (bv)
          this.stack.push(bv);
        else {
          yield {
            type: "error",
            offset: this.offset,
            message: `Unexpected ${this.type} token in YAML document`,
            source: this.source
          };
        }
      }
      *scalar(scalar) {
        if (this.type === "map-value-ind") {
          const prev = getPrevProps(this.peek(2));
          const start = getFirstKeyStartProps(prev);
          let sep;
          if (scalar.end) {
            sep = scalar.end;
            sep.push(this.sourceToken);
            delete scalar.end;
          } else
            sep = [this.sourceToken];
          const map = {
            type: "block-map",
            offset: scalar.offset,
            indent: scalar.indent,
            items: [{ start, key: scalar, sep }]
          };
          this.onKeyLine = true;
          this.stack[this.stack.length - 1] = map;
        } else
          yield* this.lineEnd(scalar);
      }
      *blockScalar(scalar) {
        switch (this.type) {
          case "space":
          case "comment":
          case "newline":
            scalar.props.push(this.sourceToken);
            return;
          case "scalar":
            scalar.source = this.source;
            this.atNewLine = true;
            this.indent = 0;
            if (this.onNewLine) {
              let nl = this.source.indexOf("\n") + 1;
              while (nl !== 0) {
                this.onNewLine(this.offset + nl);
                nl = this.source.indexOf("\n", nl) + 1;
              }
            }
            yield* this.pop();
            break;
          /* istanbul ignore next should not happen */
          default:
            yield* this.pop();
            yield* this.step();
        }
      }
      *blockMap(map) {
        const it = map.items[map.items.length - 1];
        switch (this.type) {
          case "newline":
            this.onKeyLine = false;
            if (it.value) {
              const end = "end" in it.value ? it.value.end : void 0;
              const last = Array.isArray(end) ? end[end.length - 1] : void 0;
              if (last?.type === "comment")
                end?.push(this.sourceToken);
              else
                map.items.push({ start: [this.sourceToken] });
            } else if (it.sep) {
              it.sep.push(this.sourceToken);
            } else {
              it.start.push(this.sourceToken);
            }
            return;
          case "space":
          case "comment":
            if (it.value) {
              map.items.push({ start: [this.sourceToken] });
            } else if (it.sep) {
              it.sep.push(this.sourceToken);
            } else {
              if (this.atIndentedComment(it.start, map.indent)) {
                const prev = map.items[map.items.length - 2];
                const end = prev?.value?.end;
                if (Array.isArray(end)) {
                  Array.prototype.push.apply(end, it.start);
                  end.push(this.sourceToken);
                  map.items.pop();
                  return;
                }
              }
              it.start.push(this.sourceToken);
            }
            return;
        }
        if (this.indent >= map.indent) {
          const atMapIndent = !this.onKeyLine && this.indent === map.indent;
          const atNextItem = atMapIndent && (it.sep || it.explicitKey) && this.type !== "seq-item-ind";
          let start = [];
          if (atNextItem && it.sep && !it.value) {
            const nl = [];
            for (let i = 0; i < it.sep.length; ++i) {
              const st = it.sep[i];
              switch (st.type) {
                case "newline":
                  nl.push(i);
                  break;
                case "space":
                  break;
                case "comment":
                  if (st.indent > map.indent)
                    nl.length = 0;
                  break;
                default:
                  nl.length = 0;
              }
            }
            if (nl.length >= 2)
              start = it.sep.splice(nl[1]);
          }
          switch (this.type) {
            case "anchor":
            case "tag":
              if (atNextItem || it.value) {
                start.push(this.sourceToken);
                map.items.push({ start });
                this.onKeyLine = true;
              } else if (it.sep) {
                it.sep.push(this.sourceToken);
              } else {
                it.start.push(this.sourceToken);
              }
              return;
            case "explicit-key-ind":
              if (!it.sep && !it.explicitKey) {
                it.start.push(this.sourceToken);
                it.explicitKey = true;
              } else if (atNextItem || it.value) {
                start.push(this.sourceToken);
                map.items.push({ start, explicitKey: true });
              } else {
                this.stack.push({
                  type: "block-map",
                  offset: this.offset,
                  indent: this.indent,
                  items: [{ start: [this.sourceToken], explicitKey: true }]
                });
              }
              this.onKeyLine = true;
              return;
            case "map-value-ind":
              if (it.explicitKey) {
                if (!it.sep) {
                  if (includesToken(it.start, "newline")) {
                    Object.assign(it, { key: null, sep: [this.sourceToken] });
                  } else {
                    const start2 = getFirstKeyStartProps(it.start);
                    this.stack.push({
                      type: "block-map",
                      offset: this.offset,
                      indent: this.indent,
                      items: [{ start: start2, key: null, sep: [this.sourceToken] }]
                    });
                  }
                } else if (it.value) {
                  map.items.push({ start: [], key: null, sep: [this.sourceToken] });
                } else if (includesToken(it.sep, "map-value-ind")) {
                  this.stack.push({
                    type: "block-map",
                    offset: this.offset,
                    indent: this.indent,
                    items: [{ start, key: null, sep: [this.sourceToken] }]
                  });
                } else if (isFlowToken(it.key) && !includesToken(it.sep, "newline")) {
                  const start2 = getFirstKeyStartProps(it.start);
                  const key = it.key;
                  const sep = it.sep;
                  sep.push(this.sourceToken);
                  delete it.key;
                  delete it.sep;
                  this.stack.push({
                    type: "block-map",
                    offset: this.offset,
                    indent: this.indent,
                    items: [{ start: start2, key, sep }]
                  });
                } else if (start.length > 0) {
                  it.sep = it.sep.concat(start, this.sourceToken);
                } else {
                  it.sep.push(this.sourceToken);
                }
              } else {
                if (!it.sep) {
                  Object.assign(it, { key: null, sep: [this.sourceToken] });
                } else if (it.value || atNextItem) {
                  map.items.push({ start, key: null, sep: [this.sourceToken] });
                } else if (includesToken(it.sep, "map-value-ind")) {
                  this.stack.push({
                    type: "block-map",
                    offset: this.offset,
                    indent: this.indent,
                    items: [{ start: [], key: null, sep: [this.sourceToken] }]
                  });
                } else {
                  it.sep.push(this.sourceToken);
                }
              }
              this.onKeyLine = true;
              return;
            case "alias":
            case "scalar":
            case "single-quoted-scalar":
            case "double-quoted-scalar": {
              const fs14 = this.flowScalar(this.type);
              if (atNextItem || it.value) {
                map.items.push({ start, key: fs14, sep: [] });
                this.onKeyLine = true;
              } else if (it.sep) {
                this.stack.push(fs14);
              } else {
                Object.assign(it, { key: fs14, sep: [] });
                this.onKeyLine = true;
              }
              return;
            }
            default: {
              const bv = this.startBlockValue(map);
              if (bv) {
                if (bv.type === "block-seq") {
                  if (!it.explicitKey && it.sep && !includesToken(it.sep, "newline")) {
                    yield* this.pop({
                      type: "error",
                      offset: this.offset,
                      message: "Unexpected block-seq-ind on same line with key",
                      source: this.source
                    });
                    return;
                  }
                } else if (atMapIndent) {
                  map.items.push({ start });
                }
                this.stack.push(bv);
                return;
              }
            }
          }
        }
        yield* this.pop();
        yield* this.step();
      }
      *blockSequence(seq) {
        const it = seq.items[seq.items.length - 1];
        switch (this.type) {
          case "newline":
            if (it.value) {
              const end = "end" in it.value ? it.value.end : void 0;
              const last = Array.isArray(end) ? end[end.length - 1] : void 0;
              if (last?.type === "comment")
                end?.push(this.sourceToken);
              else
                seq.items.push({ start: [this.sourceToken] });
            } else
              it.start.push(this.sourceToken);
            return;
          case "space":
          case "comment":
            if (it.value)
              seq.items.push({ start: [this.sourceToken] });
            else {
              if (this.atIndentedComment(it.start, seq.indent)) {
                const prev = seq.items[seq.items.length - 2];
                const end = prev?.value?.end;
                if (Array.isArray(end)) {
                  Array.prototype.push.apply(end, it.start);
                  end.push(this.sourceToken);
                  seq.items.pop();
                  return;
                }
              }
              it.start.push(this.sourceToken);
            }
            return;
          case "anchor":
          case "tag":
            if (it.value || this.indent <= seq.indent)
              break;
            it.start.push(this.sourceToken);
            return;
          case "seq-item-ind":
            if (this.indent !== seq.indent)
              break;
            if (it.value || includesToken(it.start, "seq-item-ind"))
              seq.items.push({ start: [this.sourceToken] });
            else
              it.start.push(this.sourceToken);
            return;
        }
        if (this.indent > seq.indent) {
          const bv = this.startBlockValue(seq);
          if (bv) {
            this.stack.push(bv);
            return;
          }
        }
        yield* this.pop();
        yield* this.step();
      }
      *flowCollection(fc) {
        const it = fc.items[fc.items.length - 1];
        if (this.type === "flow-error-end") {
          let top;
          do {
            yield* this.pop();
            top = this.peek(1);
          } while (top?.type === "flow-collection");
        } else if (fc.end.length === 0) {
          switch (this.type) {
            case "comma":
            case "explicit-key-ind":
              if (!it || it.sep)
                fc.items.push({ start: [this.sourceToken] });
              else
                it.start.push(this.sourceToken);
              return;
            case "map-value-ind":
              if (!it || it.value)
                fc.items.push({ start: [], key: null, sep: [this.sourceToken] });
              else if (it.sep)
                it.sep.push(this.sourceToken);
              else
                Object.assign(it, { key: null, sep: [this.sourceToken] });
              return;
            case "space":
            case "comment":
            case "newline":
            case "anchor":
            case "tag":
              if (!it || it.value)
                fc.items.push({ start: [this.sourceToken] });
              else if (it.sep)
                it.sep.push(this.sourceToken);
              else
                it.start.push(this.sourceToken);
              return;
            case "alias":
            case "scalar":
            case "single-quoted-scalar":
            case "double-quoted-scalar": {
              const fs14 = this.flowScalar(this.type);
              if (!it || it.value)
                fc.items.push({ start: [], key: fs14, sep: [] });
              else if (it.sep)
                this.stack.push(fs14);
              else
                Object.assign(it, { key: fs14, sep: [] });
              return;
            }
            case "flow-map-end":
            case "flow-seq-end":
              fc.end.push(this.sourceToken);
              return;
          }
          const bv = this.startBlockValue(fc);
          if (bv)
            this.stack.push(bv);
          else {
            yield* this.pop();
            yield* this.step();
          }
        } else {
          const parent = this.peek(2);
          if (parent.type === "block-map" && (this.type === "map-value-ind" && parent.indent === fc.indent || this.type === "newline" && !parent.items[parent.items.length - 1].sep)) {
            yield* this.pop();
            yield* this.step();
          } else if (this.type === "map-value-ind" && parent.type !== "flow-collection") {
            const prev = getPrevProps(parent);
            const start = getFirstKeyStartProps(prev);
            fixFlowSeqItems(fc);
            const sep = fc.end.splice(1, fc.end.length);
            sep.push(this.sourceToken);
            const map = {
              type: "block-map",
              offset: fc.offset,
              indent: fc.indent,
              items: [{ start, key: fc, sep }]
            };
            this.onKeyLine = true;
            this.stack[this.stack.length - 1] = map;
          } else {
            yield* this.lineEnd(fc);
          }
        }
      }
      flowScalar(type2) {
        if (this.onNewLine) {
          let nl = this.source.indexOf("\n") + 1;
          while (nl !== 0) {
            this.onNewLine(this.offset + nl);
            nl = this.source.indexOf("\n", nl) + 1;
          }
        }
        return {
          type: type2,
          offset: this.offset,
          indent: this.indent,
          source: this.source
        };
      }
      startBlockValue(parent) {
        switch (this.type) {
          case "alias":
          case "scalar":
          case "single-quoted-scalar":
          case "double-quoted-scalar":
            return this.flowScalar(this.type);
          case "block-scalar-header":
            return {
              type: "block-scalar",
              offset: this.offset,
              indent: this.indent,
              props: [this.sourceToken],
              source: ""
            };
          case "flow-map-start":
          case "flow-seq-start":
            return {
              type: "flow-collection",
              offset: this.offset,
              indent: this.indent,
              start: this.sourceToken,
              items: [],
              end: []
            };
          case "seq-item-ind":
            return {
              type: "block-seq",
              offset: this.offset,
              indent: this.indent,
              items: [{ start: [this.sourceToken] }]
            };
          case "explicit-key-ind": {
            this.onKeyLine = true;
            const prev = getPrevProps(parent);
            const start = getFirstKeyStartProps(prev);
            start.push(this.sourceToken);
            return {
              type: "block-map",
              offset: this.offset,
              indent: this.indent,
              items: [{ start, explicitKey: true }]
            };
          }
          case "map-value-ind": {
            this.onKeyLine = true;
            const prev = getPrevProps(parent);
            const start = getFirstKeyStartProps(prev);
            return {
              type: "block-map",
              offset: this.offset,
              indent: this.indent,
              items: [{ start, key: null, sep: [this.sourceToken] }]
            };
          }
        }
        return null;
      }
      atIndentedComment(start, indent) {
        if (this.type !== "comment")
          return false;
        if (this.indent <= indent)
          return false;
        return start.every((st) => st.type === "newline" || st.type === "space");
      }
      *documentEnd(docEnd) {
        if (this.type !== "doc-mode") {
          if (docEnd.end)
            docEnd.end.push(this.sourceToken);
          else
            docEnd.end = [this.sourceToken];
          if (this.type === "newline")
            yield* this.pop();
        }
      }
      *lineEnd(token) {
        switch (this.type) {
          case "comma":
          case "doc-start":
          case "doc-end":
          case "flow-seq-end":
          case "flow-map-end":
          case "map-value-ind":
            yield* this.pop();
            yield* this.step();
            break;
          case "newline":
            this.onKeyLine = false;
          // fallthrough
          case "space":
          case "comment":
          default:
            if (token.end)
              token.end.push(this.sourceToken);
            else
              token.end = [this.sourceToken];
            if (this.type === "newline")
              yield* this.pop();
        }
      }
    };
    exports.Parser = Parser;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/public-api.js
var require_public_api = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/public-api.js"(exports) {
    "use strict";
    var composer = require_composer();
    var Document = require_Document();
    var errors = require_errors();
    var log2 = require_log();
    var identity = require_identity();
    var lineCounter = require_line_counter();
    var parser = require_parser();
    function parseOptions(options) {
      const prettyErrors = options.prettyErrors !== false;
      const lineCounter$1 = options.lineCounter || prettyErrors && new lineCounter.LineCounter() || null;
      return { lineCounter: lineCounter$1, prettyErrors };
    }
    function parseAllDocuments(source, options = {}) {
      const { lineCounter: lineCounter2, prettyErrors } = parseOptions(options);
      const parser$1 = new parser.Parser(lineCounter2?.addNewLine);
      const composer$1 = new composer.Composer(options);
      const docs = Array.from(composer$1.compose(parser$1.parse(source)));
      if (prettyErrors && lineCounter2)
        for (const doc of docs) {
          doc.errors.forEach(errors.prettifyError(source, lineCounter2));
          doc.warnings.forEach(errors.prettifyError(source, lineCounter2));
        }
      if (docs.length > 0)
        return docs;
      return Object.assign([], { empty: true }, composer$1.streamInfo());
    }
    function parseDocument(source, options = {}) {
      const { lineCounter: lineCounter2, prettyErrors } = parseOptions(options);
      const parser$1 = new parser.Parser(lineCounter2?.addNewLine);
      const composer$1 = new composer.Composer(options);
      let doc = null;
      for (const _doc of composer$1.compose(parser$1.parse(source), true, source.length)) {
        if (!doc)
          doc = _doc;
        else if (doc.options.logLevel !== "silent") {
          doc.errors.push(new errors.YAMLParseError(_doc.range.slice(0, 2), "MULTIPLE_DOCS", "Source contains multiple documents; please use YAML.parseAllDocuments()"));
          break;
        }
      }
      if (prettyErrors && lineCounter2) {
        doc.errors.forEach(errors.prettifyError(source, lineCounter2));
        doc.warnings.forEach(errors.prettifyError(source, lineCounter2));
      }
      return doc;
    }
    function parse3(src, reviver, options) {
      let _reviver = void 0;
      if (typeof reviver === "function") {
        _reviver = reviver;
      } else if (options === void 0 && reviver && typeof reviver === "object") {
        options = reviver;
      }
      const doc = parseDocument(src, options);
      if (!doc)
        return null;
      doc.warnings.forEach((warning) => log2.warn(doc.options.logLevel, warning));
      if (doc.errors.length > 0) {
        if (doc.options.logLevel !== "silent")
          throw doc.errors[0];
        else
          doc.errors = [];
      }
      return doc.toJS(Object.assign({ reviver: _reviver }, options));
    }
    function stringify(value2, replacer, options) {
      let _replacer = null;
      if (typeof replacer === "function" || Array.isArray(replacer)) {
        _replacer = replacer;
      } else if (options === void 0 && replacer) {
        options = replacer;
      }
      if (typeof options === "string")
        options = options.length;
      if (typeof options === "number") {
        const indent = Math.round(options);
        options = indent < 1 ? void 0 : indent > 8 ? { indent: 8 } : { indent };
      }
      if (value2 === void 0) {
        const { keepUndefined } = options ?? replacer ?? {};
        if (!keepUndefined)
          return void 0;
      }
      if (identity.isDocument(value2) && !_replacer)
        return value2.toString(options);
      return new Document.Document(value2, _replacer, options).toString(options);
    }
    exports.parse = parse3;
    exports.parseAllDocuments = parseAllDocuments;
    exports.parseDocument = parseDocument;
    exports.stringify = stringify;
  }
});

// node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/index.js
var require_dist3 = __commonJS({
  "node_modules/.pnpm/yaml@2.8.2/node_modules/yaml/dist/index.js"(exports) {
    "use strict";
    var composer = require_composer();
    var Document = require_Document();
    var Schema = require_Schema();
    var errors = require_errors();
    var Alias = require_Alias();
    var identity = require_identity();
    var Pair = require_Pair();
    var Scalar = require_Scalar();
    var YAMLMap = require_YAMLMap();
    var YAMLSeq = require_YAMLSeq();
    var cst = require_cst();
    var lexer = require_lexer();
    var lineCounter = require_line_counter();
    var parser = require_parser();
    var publicApi = require_public_api();
    var visit = require_visit();
    exports.Composer = composer.Composer;
    exports.Document = Document.Document;
    exports.Schema = Schema.Schema;
    exports.YAMLError = errors.YAMLError;
    exports.YAMLParseError = errors.YAMLParseError;
    exports.YAMLWarning = errors.YAMLWarning;
    exports.Alias = Alias.Alias;
    exports.isAlias = identity.isAlias;
    exports.isCollection = identity.isCollection;
    exports.isDocument = identity.isDocument;
    exports.isMap = identity.isMap;
    exports.isNode = identity.isNode;
    exports.isPair = identity.isPair;
    exports.isScalar = identity.isScalar;
    exports.isSeq = identity.isSeq;
    exports.Pair = Pair.Pair;
    exports.Scalar = Scalar.Scalar;
    exports.YAMLMap = YAMLMap.YAMLMap;
    exports.YAMLSeq = YAMLSeq.YAMLSeq;
    exports.CST = cst;
    exports.Lexer = lexer.Lexer;
    exports.LineCounter = lineCounter.LineCounter;
    exports.Parser = parser.Parser;
    exports.parse = publicApi.parse;
    exports.parseAllDocuments = publicApi.parseAllDocuments;
    exports.parseDocument = publicApi.parseDocument;
    exports.stringify = publicApi.stringify;
    exports.visit = visit.visit;
    exports.visitAsync = visit.visitAsync;
  }
});

// node_modules/trpc-cli/dist/index.js
import { Argument as Argument2, Command as BaseCommand, InvalidArgumentError, InvalidOptionArgumentError } from "commander";
import { Option as BaseOption } from "commander";
import { inspect as inspect2 } from "util";

// node_modules/trpc-cli/dist/completions.js
function addCompletions(program, completion) {
  const commandSymbol = Symbol("command");
  const cTree = {};
  function addCommandCompletions(command, cTreeNode) {
    command.commands.forEach((c) => {
      const node = cTreeNode[c.name()] ||= {};
      Object.defineProperty(node, commandSymbol, { value: c, enumerable: false });
      addCommandCompletions(c, node);
    });
  }
  addCommandCompletions(program, cTree);
  completion.on("complete", (fragment, params) => {
    const segments = params.line.split(/ +/).slice(1, params.fragment);
    const last = segments.at(-1);
    let node = cTree;
    const existingFlags = /* @__PURE__ */ new Set();
    for (const segment of segments) {
      if (segment.startsWith("-")) {
        existingFlags.add(segment);
        continue;
      }
      if (existingFlags.size > 0)
        continue;
      node = node[segment];
      if (!node)
        return;
    }
    const correspondingCommand = node[commandSymbol];
    if (correspondingCommand?.options?.length) {
      const suggestions = [];
      for (const o of correspondingCommand.options) {
        if (last === o.long || last === o.short) {
          if (o.argChoices)
            suggestions.push(...o.argChoices);
          if (!o.isBoolean())
            break;
        }
        if (existingFlags.has(o.long))
          continue;
        if (existingFlags.has(o.short))
          continue;
        suggestions.push(o.long);
      }
      return void params.reply(suggestions);
    }
  });
  completion.tree(cTree).init();
}

// node_modules/trpc-cli/dist/errors.js
var CliValidationError = class extends Error {
};
var FailedToExitError = class extends Error {
  exitCode;
  constructor(message, { exitCode, cause }) {
    const fullMessage = `${message}. The process was expected to exit with exit code ${exitCode} but did not. This may be because a custom \`process\` parameter was used. The exit reason is in the \`cause\` property.`;
    super(fullMessage, { cause });
    this.exitCode = exitCode;
  }
};

// node_modules/trpc-cli/dist/json-schema.js
var capitaliseFromCamelCase = (camel) => {
  const parts = camel.split(/(?=[A-Z])/);
  return capitalise(parts.map((p) => p.toLowerCase()).join(" "));
};
var capitalise = (s) => s.slice(0, 1).toUpperCase() + s.slice(1);
var flattenedProperties = (sch) => {
  if ("properties" in sch) {
    return sch.properties;
  }
  if ("allOf" in sch) {
    return Object.fromEntries(sch.allOf.flatMap((subSchema) => Object.entries(flattenedProperties(subSchema))));
  }
  if ("anyOf" in sch) {
    const isExcluded = (v) => Object.keys(v).join(",") === "not";
    const entries = sch.anyOf.flatMap((subSchema) => {
      const flattened = flattenedProperties(subSchema);
      const excluded = Object.entries(flattened).flatMap(([name16, propSchema]) => {
        return isExcluded(propSchema) ? [`--${name16}`] : [];
      });
      return Object.entries(flattened).map(([k, v]) => {
        if (!isExcluded(v) && excluded.length > 0) {
          return [k, Object.assign({}, v, { "Do not use with": excluded })];
        }
        return [k, v];
      });
    });
    return Object.fromEntries(entries.sort((a, b) => {
      const scores = [a, b].map(([_k, v]) => isExcluded(v) ? 0 : 1);
      return scores[0] - scores[1];
    }));
  }
  return {};
};
var incompatiblePropertyPairs = (sch) => {
  const isUnion = "anyOf" in sch;
  if (!isUnion)
    return [];
  const sets = sch.anyOf.map((subSchema) => {
    const keys = Object.keys(flattenedProperties(subSchema));
    return { keys, set: new Set(keys) };
  });
  const compatiblityEntries = sets.flatMap(({ keys }) => {
    return keys.map((key) => {
      return [key, new Set(sets.filter((other) => other.set.has(key)).flatMap((other) => other.keys))];
    });
  });
  const allKeys = sets.flatMap(({ keys }) => keys);
  return compatiblityEntries.flatMap(([key, compatibleWith]) => {
    const incompatibleEntries = allKeys.filter((other) => key < other && !compatibleWith.has(other)).map((other) => [key, other]);
    return incompatibleEntries;
  });
};
var getDescription = (v, depth = 0) => {
  if ("items" in v && v.items) {
    const { items, ...rest } = v;
    return [getDescription(items, 1), getDescription(rest), "array"].filter(Boolean).join(" ");
  }
  return Object.entries(v).filter(([k, vv]) => {
    if (k === "default" || k === "additionalProperties" || k === "optional")
      return false;
    if (k === "type" && typeof vv === "string")
      return depth > 0;
    if (k.startsWith("$"))
      return false;
    if (k === "maximum" && vv === Number.MAX_SAFE_INTEGER)
      return false;
    if (depth <= 1 && k === "enum" && getEnumChoices(v)?.type === "string_enum")
      return false;
    return true;
  }).sort(([a], [b]) => {
    const scores = [a, b].map((k) => k === "description" ? 0 : 1);
    return scores[0] - scores[1];
  }).map(([k, vv], i) => {
    if (k === "type" && Array.isArray(vv))
      return `type: ${vv.join(" or ")}`;
    if (k === "description" && i === 0)
      return String(vv);
    if (k === "properties")
      return `Object (json formatted)`;
    if (typeof vv === "object")
      return `${capitaliseFromCamelCase(k)}: ${JSON.stringify(vv)}`;
    return `${capitaliseFromCamelCase(k)}: ${vv}`;
  }).join("; ") || "";
};
var getSchemaTypes = (propertyValue) => {
  const array = [];
  if ("type" in propertyValue) {
    array.push(...[propertyValue.type].flat());
  }
  if ("enum" in propertyValue && Array.isArray(propertyValue.enum)) {
    array.push(...propertyValue.enum.flatMap((s) => typeof s));
  }
  if ("const" in propertyValue && propertyValue.const === null) {
    array.push("null");
  } else if ("const" in propertyValue) {
    array.push(typeof propertyValue.const);
  }
  if ("oneOf" in propertyValue) {
    array.push(...propertyValue.oneOf.flatMap(getSchemaTypes));
  }
  if ("anyOf" in propertyValue) {
    array.push(...propertyValue.anyOf.flatMap(getSchemaTypes));
  }
  return [...new Set(array)];
};
var getAllowedSchemas = (schema) => {
  if (!schema)
    return [];
  if ("anyOf" in schema && Array.isArray(schema.anyOf))
    return schema.anyOf.flatMap(getAllowedSchemas);
  if ("oneOf" in schema && Array.isArray(schema.oneOf))
    return schema.oneOf.flatMap(getAllowedSchemas);
  const types = getSchemaTypes(schema);
  if (types.length === 1)
    return [schema];
  return types.map((type2) => ({ ...schema, type: type2 }));
};
var getEnumChoices = (propertyValue) => {
  if (!propertyValue)
    return null;
  if (!("enum" in propertyValue && Array.isArray(propertyValue.enum))) {
    if ("anyOf" in propertyValue && propertyValue.anyOf?.every((subSchema) => {
      if (subSchema && typeof subSchema === "object" && "const" in subSchema && Object.keys(subSchema).length === 1 && typeof subSchema.const === "string") {
        return true;
      }
      return false;
    })) {
      return {
        type: "string_enum",
        choices: propertyValue.anyOf.map((subSchema) => subSchema.const)
      };
    }
    if ("anyOf" in propertyValue && propertyValue.anyOf?.every((subSchema) => {
      if (subSchema && typeof subSchema === "object" && "const" in subSchema && Object.keys(subSchema).length === 1 && typeof subSchema.const === "number") {
        return true;
      }
      return false;
    })) {
      return {
        type: "number_enum",
        choices: propertyValue.anyOf.map((subSchema) => subSchema.const)
      };
    }
    return null;
  }
  if (propertyValue.enum.every((s) => typeof s === "string")) {
    return {
      type: "string_enum",
      choices: propertyValue.enum
    };
  }
  if (propertyValue.enum.every((s) => typeof s === "number")) {
    return {
      type: "number_enum",
      choices: propertyValue.enum
    };
  }
  return null;
};

// node_modules/trpc-cli/dist/json.js
var commandToJSON = (command) => {
  const json = {};
  const name16 = command.name();
  if (name16)
    json.name = name16;
  const version = command.version();
  if (version)
    json.version = version;
  const description = command.description();
  if (description)
    json.description = description;
  const usage = command.usage();
  if (usage)
    json.usage = usage;
  json.arguments = command.registeredArguments.map((arg) => {
    const result = { name: arg.name() };
    result.variadic = arg.variadic;
    result.required = arg.required;
    if (arg.description)
      result.description = arg.description;
    if (arg.defaultValue)
      result.defaultValue = arg.defaultValue;
    if (arg.defaultValueDescription)
      result.defaultValueDescription = arg.defaultValueDescription;
    if (arg.argChoices)
      result.choices = arg.argChoices;
    return result;
  });
  json.options = command.options.map((o) => {
    const result = { name: o.name() };
    result.required = o.required;
    result.optional = o.optional;
    result.negate = o.negate;
    result.variadic = o.variadic;
    if (o.flags)
      result.flags = o.flags;
    if (o.short)
      result.short = o.short;
    if (o.description)
      result.description = o.description;
    if (o.argChoices)
      result.choices = o.argChoices;
    const attributeName = o.attributeName();
    if (attributeName)
      result.attributeName = attributeName;
    if (o.defaultValue)
      result.defaultValue = o.defaultValue;
    if (o.defaultValueDescription)
      result.defaultValueDescription = o.defaultValueDescription;
    return result;
  });
  json.commands = command.commands.map((c) => commandToJSON(c));
  return json;
};

// node_modules/trpc-cli/dist/logging.js
var lineByLineLogger = getLoggerTransformer((log2) => {
  const wrapper = (args2, depth) => {
    if (args2.length === 1 && Array.isArray(args2[0]) && depth === 0) {
      args2[0].forEach((item) => wrapper([item], 1));
    } else if (args2.every(isPrimitive)) {
      log2(...args2);
    } else if (args2.length === 1) {
      log2(JSON.stringify(args2[0], null, 2));
    } else {
      log2(JSON.stringify(args2, null, 2));
    }
  };
  return (...args2) => wrapper(args2, 0);
});
var isPrimitive = (value2) => {
  const type2 = typeof value2;
  return type2 === "string" || type2 === "number" || type2 === "boolean";
};
function getLoggerTransformer(transform) {
  return (logger) => {
    const info = logger.info && transform(logger.info);
    const error = logger.error && transform(logger.error);
    return { info, error };
  };
}
var lineByLineConsoleLogger = lineByLineLogger(console);

// node_modules/trpc-cli/dist/parse-procedure.js
import { inspect } from "util";

// node_modules/trpc-cli/dist/zod-to-json-schema/Options.js
var ignoreOverride = Symbol("Let zodToJsonSchema decide on which parser to use");
var defaultOptions = {
  name: void 0,
  $refStrategy: "root",
  basePath: ["#"],
  effectStrategy: "input",
  pipeStrategy: "all",
  dateStrategy: "format:date-time",
  mapStrategy: "entries",
  removeAdditionalStrategy: "passthrough",
  allowedAdditionalProperties: true,
  rejectedAdditionalProperties: false,
  definitionPath: "definitions",
  target: "jsonSchema7",
  strictUnions: false,
  definitions: {},
  errorMessages: false,
  markdownDescription: false,
  patternStrategy: "escape",
  applyRegexFlags: false,
  emailStrategy: "format:email",
  base64Strategy: "contentEncoding:base64",
  nameStrategy: "ref",
  openAiAnyTypeName: "OpenAiAnyType"
};
var getDefaultOptions = (options) => typeof options === "string" ? {
  ...defaultOptions,
  name: options
} : {
  ...defaultOptions,
  ...options
};

// node_modules/trpc-cli/dist/zod-to-json-schema/Refs.js
var getRefs = (options) => {
  const _options = getDefaultOptions(options);
  const currentPath = _options.name !== void 0 ? [..._options.basePath, _options.definitionPath, _options.name] : _options.basePath;
  return {
    ..._options,
    flags: { hasReferencedOpenAiAnyType: false },
    currentPath,
    propertyPath: void 0,
    seen: new Map(Object.entries(_options.definitions).map(([name16, def]) => [
      def._def,
      {
        def: def._def,
        path: [..._options.basePath, _options.definitionPath, name16],
        // Resolution of references will be forced even though seen, so it's ok that the schema is undefined here for now.
        jsonSchema: void 0
      }
    ]))
  };
};

// node_modules/trpc-cli/dist/zod-to-json-schema/errorMessages.js
function addErrorMessage(res, key, errorMessage, refs) {
  if (!refs?.errorMessages)
    return;
  if (errorMessage) {
    res.errorMessage = {
      ...res.errorMessage,
      [key]: errorMessage
    };
  }
}
function setResponseValueAndErrors(res, key, value2, errorMessage, refs) {
  res[key] = value2;
  addErrorMessage(res, key, errorMessage, refs);
}

// node_modules/trpc-cli/dist/zod-to-json-schema/getRelativePath.js
var getRelativePath = (pathA, pathB) => {
  let i = 0;
  for (; i < pathA.length && i < pathB.length; i++) {
    if (pathA[i] !== pathB[i])
      break;
  }
  return [(pathA.length - i).toString(), ...pathB.slice(i)].join("/");
};

// node_modules/trpc-cli/dist/zod-to-json-schema/ZodFirstPartyTypeKind.js
var ZodFirstPartyTypeKind;
(function(ZodFirstPartyTypeKind4) {
  ZodFirstPartyTypeKind4["ZodString"] = "ZodString";
  ZodFirstPartyTypeKind4["ZodNumber"] = "ZodNumber";
  ZodFirstPartyTypeKind4["ZodNaN"] = "ZodNaN";
  ZodFirstPartyTypeKind4["ZodBigInt"] = "ZodBigInt";
  ZodFirstPartyTypeKind4["ZodBoolean"] = "ZodBoolean";
  ZodFirstPartyTypeKind4["ZodDate"] = "ZodDate";
  ZodFirstPartyTypeKind4["ZodSymbol"] = "ZodSymbol";
  ZodFirstPartyTypeKind4["ZodUndefined"] = "ZodUndefined";
  ZodFirstPartyTypeKind4["ZodNull"] = "ZodNull";
  ZodFirstPartyTypeKind4["ZodAny"] = "ZodAny";
  ZodFirstPartyTypeKind4["ZodUnknown"] = "ZodUnknown";
  ZodFirstPartyTypeKind4["ZodNever"] = "ZodNever";
  ZodFirstPartyTypeKind4["ZodVoid"] = "ZodVoid";
  ZodFirstPartyTypeKind4["ZodArray"] = "ZodArray";
  ZodFirstPartyTypeKind4["ZodObject"] = "ZodObject";
  ZodFirstPartyTypeKind4["ZodUnion"] = "ZodUnion";
  ZodFirstPartyTypeKind4["ZodDiscriminatedUnion"] = "ZodDiscriminatedUnion";
  ZodFirstPartyTypeKind4["ZodIntersection"] = "ZodIntersection";
  ZodFirstPartyTypeKind4["ZodTuple"] = "ZodTuple";
  ZodFirstPartyTypeKind4["ZodRecord"] = "ZodRecord";
  ZodFirstPartyTypeKind4["ZodMap"] = "ZodMap";
  ZodFirstPartyTypeKind4["ZodSet"] = "ZodSet";
  ZodFirstPartyTypeKind4["ZodFunction"] = "ZodFunction";
  ZodFirstPartyTypeKind4["ZodLazy"] = "ZodLazy";
  ZodFirstPartyTypeKind4["ZodLiteral"] = "ZodLiteral";
  ZodFirstPartyTypeKind4["ZodEnum"] = "ZodEnum";
  ZodFirstPartyTypeKind4["ZodEffects"] = "ZodEffects";
  ZodFirstPartyTypeKind4["ZodNativeEnum"] = "ZodNativeEnum";
  ZodFirstPartyTypeKind4["ZodOptional"] = "ZodOptional";
  ZodFirstPartyTypeKind4["ZodNullable"] = "ZodNullable";
  ZodFirstPartyTypeKind4["ZodDefault"] = "ZodDefault";
  ZodFirstPartyTypeKind4["ZodCatch"] = "ZodCatch";
  ZodFirstPartyTypeKind4["ZodPromise"] = "ZodPromise";
  ZodFirstPartyTypeKind4["ZodBranded"] = "ZodBranded";
  ZodFirstPartyTypeKind4["ZodPipeline"] = "ZodPipeline";
  ZodFirstPartyTypeKind4["ZodReadonly"] = "ZodReadonly";
})(ZodFirstPartyTypeKind || (ZodFirstPartyTypeKind = {}));

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/any.js
function parseAnyDef(refs) {
  if (refs.target !== "openAi") {
    return {};
  }
  const anyDefinitionPath = [
    ...refs.basePath,
    refs.definitionPath,
    refs.openAiAnyTypeName
  ];
  refs.flags.hasReferencedOpenAiAnyType = true;
  return {
    $ref: refs.$refStrategy === "relative" ? getRelativePath(anyDefinitionPath, refs.currentPath) : anyDefinitionPath.join("/")
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/array.js
function parseArrayDef(def, refs) {
  const res = {
    type: "array"
  };
  if (def.type?._def && def.type?._def?.typeName !== ZodFirstPartyTypeKind.ZodAny) {
    res.items = parseDef(def.type._def, {
      ...refs,
      currentPath: [...refs.currentPath, "items"]
    });
  }
  if (def.minLength) {
    setResponseValueAndErrors(res, "minItems", def.minLength.value, def.minLength.message, refs);
  }
  if (def.maxLength) {
    setResponseValueAndErrors(res, "maxItems", def.maxLength.value, def.maxLength.message, refs);
  }
  if (def.exactLength) {
    setResponseValueAndErrors(res, "minItems", def.exactLength.value, def.exactLength.message, refs);
    setResponseValueAndErrors(res, "maxItems", def.exactLength.value, def.exactLength.message, refs);
  }
  return res;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/bigint.js
function parseBigintDef(def, refs) {
  const res = {
    type: "integer",
    format: "int64"
  };
  if (!def.checks)
    return res;
  for (const check of def.checks) {
    switch (check.kind) {
      case "min":
        if (refs.target === "jsonSchema7") {
          if (check.inclusive) {
            setResponseValueAndErrors(res, "minimum", check.value, check.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMinimum", check.value, check.message, refs);
          }
        } else {
          if (!check.inclusive) {
            res.exclusiveMinimum = true;
          }
          setResponseValueAndErrors(res, "minimum", check.value, check.message, refs);
        }
        break;
      case "max":
        if (refs.target === "jsonSchema7") {
          if (check.inclusive) {
            setResponseValueAndErrors(res, "maximum", check.value, check.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMaximum", check.value, check.message, refs);
          }
        } else {
          if (!check.inclusive) {
            res.exclusiveMaximum = true;
          }
          setResponseValueAndErrors(res, "maximum", check.value, check.message, refs);
        }
        break;
      case "multipleOf":
        setResponseValueAndErrors(res, "multipleOf", check.value, check.message, refs);
        break;
    }
  }
  return res;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/boolean.js
function parseBooleanDef() {
  return {
    type: "boolean"
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/branded.js
function parseBrandedDef(_def, refs) {
  return parseDef(_def.type._def, refs);
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/catch.js
var parseCatchDef = (def, refs) => {
  return parseDef(def.innerType._def, refs);
};

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/date.js
function parseDateDef(def, refs, overrideDateStrategy) {
  const strategy = overrideDateStrategy ?? refs.dateStrategy;
  if (Array.isArray(strategy)) {
    return {
      anyOf: strategy.map((item, i) => parseDateDef(def, refs, item))
    };
  }
  switch (strategy) {
    case "string":
    case "format:date-time":
      return {
        type: "string",
        format: "date-time"
      };
    case "format:date":
      return {
        type: "string",
        format: "date"
      };
    case "integer":
      return integerDateParser(def, refs);
  }
}
var integerDateParser = (def, refs) => {
  const res = {
    type: "integer",
    format: "unix-time"
  };
  if (refs.target === "openApi3") {
    return res;
  }
  for (const check of def.checks) {
    switch (check.kind) {
      case "min":
        setResponseValueAndErrors(
          res,
          "minimum",
          check.value,
          // This is in milliseconds
          check.message,
          refs
        );
        break;
      case "max":
        setResponseValueAndErrors(
          res,
          "maximum",
          check.value,
          // This is in milliseconds
          check.message,
          refs
        );
        break;
    }
  }
  return res;
};

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/default.js
function parseDefaultDef(_def, refs) {
  return {
    ...parseDef(_def.innerType._def, refs),
    default: _def.defaultValue()
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/effects.js
function parseEffectsDef(_def, refs) {
  return refs.effectStrategy === "input" ? parseDef(_def.schema._def, refs) : parseAnyDef(refs);
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/enum.js
function parseEnumDef(def) {
  return {
    type: "string",
    enum: Array.from(def.values)
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/intersection.js
var isJsonSchema7AllOfType = (type2) => {
  if ("type" in type2 && type2.type === "string")
    return false;
  return "allOf" in type2;
};
function parseIntersectionDef(def, refs) {
  const allOf = [
    parseDef(def.left._def, {
      ...refs,
      currentPath: [...refs.currentPath, "allOf", "0"]
    }),
    parseDef(def.right._def, {
      ...refs,
      currentPath: [...refs.currentPath, "allOf", "1"]
    })
  ].filter((x) => !!x);
  let unevaluatedProperties = refs.target === "jsonSchema2019-09" ? { unevaluatedProperties: false } : void 0;
  const mergedAllOf = [];
  allOf.forEach((schema) => {
    if (isJsonSchema7AllOfType(schema)) {
      mergedAllOf.push(...schema.allOf);
      if (schema.unevaluatedProperties === void 0) {
        unevaluatedProperties = void 0;
      }
    } else {
      let nestedSchema = schema;
      if ("additionalProperties" in schema && schema.additionalProperties === false) {
        const { additionalProperties, ...rest } = schema;
        nestedSchema = rest;
      } else {
        unevaluatedProperties = void 0;
      }
      mergedAllOf.push(nestedSchema);
    }
  });
  return mergedAllOf.length ? {
    allOf: mergedAllOf,
    ...unevaluatedProperties
  } : void 0;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/literal.js
function parseLiteralDef(def, refs) {
  const parsedType = typeof def.value;
  if (parsedType !== "bigint" && parsedType !== "number" && parsedType !== "boolean" && parsedType !== "string") {
    return {
      type: Array.isArray(def.value) ? "array" : "object"
    };
  }
  if (refs.target === "openApi3") {
    return {
      type: parsedType === "bigint" ? "integer" : parsedType,
      enum: [def.value]
    };
  }
  return {
    type: parsedType === "bigint" ? "integer" : parsedType,
    const: def.value
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/string.js
var emojiRegex = void 0;
var zodPatterns = {
  /**
   * `c` was changed to `[cC]` to replicate /i flag
   */
  cuid: /^[cC][^\s-]{8,}$/,
  cuid2: /^[0-9a-z]+$/,
  ulid: /^[0-9A-HJKMNP-TV-Z]{26}$/,
  /**
   * `a-z` was added to replicate /i flag
   */
  email: /^(?!\.)(?!.*\.\.)([a-zA-Z0-9_'+\-\.]*)[a-zA-Z0-9_+-]@([a-zA-Z0-9][a-zA-Z0-9\-]*\.)+[a-zA-Z]{2,}$/,
  /**
   * Constructed a valid Unicode RegExp
   *
   * Lazily instantiate since this type of regex isn't supported
   * in all envs (e.g. React Native).
   *
   * See:
   * https://github.com/colinhacks/zod/issues/2433
   * Fix in Zod:
   * https://github.com/colinhacks/zod/commit/9340fd51e48576a75adc919bff65dbc4a5d4c99b
   */
  emoji: () => {
    if (emojiRegex === void 0) {
      emojiRegex = RegExp("^(\\p{Extended_Pictographic}|\\p{Emoji_Component})+$", "u");
    }
    return emojiRegex;
  },
  /**
   * Unused
   */
  uuid: /^[0-9a-fA-F]{8}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{12}$/,
  /**
   * Unused
   */
  ipv4: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/,
  ipv4Cidr: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\/(3[0-2]|[12]?[0-9])$/,
  /**
   * Unused
   */
  ipv6: /^(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))$/,
  ipv6Cidr: /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\/(12[0-8]|1[01][0-9]|[1-9]?[0-9])$/,
  base64: /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/,
  base64url: /^([0-9a-zA-Z-_]{4})*(([0-9a-zA-Z-_]{2}(==)?)|([0-9a-zA-Z-_]{3}(=)?))?$/,
  nanoid: /^[a-zA-Z0-9_-]{21}$/,
  jwt: /^[A-Za-z0-9-_]+\.[A-Za-z0-9-_]+\.[A-Za-z0-9-_]*$/
};
function parseStringDef(def, refs) {
  const res = {
    type: "string"
  };
  if (def.checks) {
    for (const check of def.checks) {
      switch (check.kind) {
        case "min":
          setResponseValueAndErrors(res, "minLength", typeof res.minLength === "number" ? Math.max(res.minLength, check.value) : check.value, check.message, refs);
          break;
        case "max":
          setResponseValueAndErrors(res, "maxLength", typeof res.maxLength === "number" ? Math.min(res.maxLength, check.value) : check.value, check.message, refs);
          break;
        case "email":
          switch (refs.emailStrategy) {
            case "format:email":
              addFormat(res, "email", check.message, refs);
              break;
            case "format:idn-email":
              addFormat(res, "idn-email", check.message, refs);
              break;
            case "pattern:zod":
              addPattern(res, zodPatterns.email, check.message, refs);
              break;
          }
          break;
        case "url":
          addFormat(res, "uri", check.message, refs);
          break;
        case "uuid":
          addFormat(res, "uuid", check.message, refs);
          break;
        case "regex":
          addPattern(res, check.regex, check.message, refs);
          break;
        case "cuid":
          addPattern(res, zodPatterns.cuid, check.message, refs);
          break;
        case "cuid2":
          addPattern(res, zodPatterns.cuid2, check.message, refs);
          break;
        case "startsWith":
          addPattern(res, RegExp(`^${escapeLiteralCheckValue(check.value, refs)}`), check.message, refs);
          break;
        case "endsWith":
          addPattern(res, RegExp(`${escapeLiteralCheckValue(check.value, refs)}$`), check.message, refs);
          break;
        case "datetime":
          addFormat(res, "date-time", check.message, refs);
          break;
        case "date":
          addFormat(res, "date", check.message, refs);
          break;
        case "time":
          addFormat(res, "time", check.message, refs);
          break;
        case "duration":
          addFormat(res, "duration", check.message, refs);
          break;
        case "length":
          setResponseValueAndErrors(res, "minLength", typeof res.minLength === "number" ? Math.max(res.minLength, check.value) : check.value, check.message, refs);
          setResponseValueAndErrors(res, "maxLength", typeof res.maxLength === "number" ? Math.min(res.maxLength, check.value) : check.value, check.message, refs);
          break;
        case "includes": {
          addPattern(res, RegExp(escapeLiteralCheckValue(check.value, refs)), check.message, refs);
          break;
        }
        case "ip": {
          if (check.version !== "v6") {
            addFormat(res, "ipv4", check.message, refs);
          }
          if (check.version !== "v4") {
            addFormat(res, "ipv6", check.message, refs);
          }
          break;
        }
        case "base64url":
          addPattern(res, zodPatterns.base64url, check.message, refs);
          break;
        case "jwt":
          addPattern(res, zodPatterns.jwt, check.message, refs);
          break;
        case "cidr": {
          if (check.version !== "v6") {
            addPattern(res, zodPatterns.ipv4Cidr, check.message, refs);
          }
          if (check.version !== "v4") {
            addPattern(res, zodPatterns.ipv6Cidr, check.message, refs);
          }
          break;
        }
        case "emoji":
          addPattern(res, zodPatterns.emoji(), check.message, refs);
          break;
        case "ulid": {
          addPattern(res, zodPatterns.ulid, check.message, refs);
          break;
        }
        case "base64": {
          switch (refs.base64Strategy) {
            case "format:binary": {
              addFormat(res, "binary", check.message, refs);
              break;
            }
            case "contentEncoding:base64": {
              setResponseValueAndErrors(res, "contentEncoding", "base64", check.message, refs);
              break;
            }
            case "pattern:zod": {
              addPattern(res, zodPatterns.base64, check.message, refs);
              break;
            }
          }
          break;
        }
        case "nanoid": {
          addPattern(res, zodPatterns.nanoid, check.message, refs);
        }
        case "toLowerCase":
        case "toUpperCase":
        case "trim":
          break;
        default:
          /* @__PURE__ */ ((_) => {
          })(check);
      }
    }
  }
  return res;
}
function escapeLiteralCheckValue(literal, refs) {
  return refs.patternStrategy === "escape" ? escapeNonAlphaNumeric(literal) : literal;
}
var ALPHA_NUMERIC = new Set("ABCDEFGHIJKLMNOPQRSTUVXYZabcdefghijklmnopqrstuvxyz0123456789");
function escapeNonAlphaNumeric(source) {
  let result = "";
  for (let i = 0; i < source.length; i++) {
    if (!ALPHA_NUMERIC.has(source[i])) {
      result += "\\";
    }
    result += source[i];
  }
  return result;
}
function addFormat(schema, value2, message, refs) {
  if (schema.format || schema.anyOf?.some((x) => x.format)) {
    if (!schema.anyOf) {
      schema.anyOf = [];
    }
    if (schema.format) {
      schema.anyOf.push({
        format: schema.format,
        ...schema.errorMessage && refs.errorMessages && {
          errorMessage: { format: schema.errorMessage.format }
        }
      });
      delete schema.format;
      if (schema.errorMessage) {
        delete schema.errorMessage.format;
        if (Object.keys(schema.errorMessage).length === 0) {
          delete schema.errorMessage;
        }
      }
    }
    schema.anyOf.push({
      format: value2,
      ...message && refs.errorMessages && { errorMessage: { format: message } }
    });
  } else {
    setResponseValueAndErrors(schema, "format", value2, message, refs);
  }
}
function addPattern(schema, regex, message, refs) {
  if (schema.pattern || schema.allOf?.some((x) => x.pattern)) {
    if (!schema.allOf) {
      schema.allOf = [];
    }
    if (schema.pattern) {
      schema.allOf.push({
        pattern: schema.pattern,
        ...schema.errorMessage && refs.errorMessages && {
          errorMessage: { pattern: schema.errorMessage.pattern }
        }
      });
      delete schema.pattern;
      if (schema.errorMessage) {
        delete schema.errorMessage.pattern;
        if (Object.keys(schema.errorMessage).length === 0) {
          delete schema.errorMessage;
        }
      }
    }
    schema.allOf.push({
      pattern: stringifyRegExpWithFlags(regex, refs),
      ...message && refs.errorMessages && { errorMessage: { pattern: message } }
    });
  } else {
    setResponseValueAndErrors(schema, "pattern", stringifyRegExpWithFlags(regex, refs), message, refs);
  }
}
function stringifyRegExpWithFlags(regex, refs) {
  if (!refs.applyRegexFlags || !regex.flags) {
    return regex.source;
  }
  const flags = {
    i: regex.flags.includes("i"),
    // Case-insensitive
    m: regex.flags.includes("m"),
    // `^` and `$` matches adjacent to newline characters
    s: regex.flags.includes("s")
    // `.` matches newlines
  };
  const source = flags.i ? regex.source.toLowerCase() : regex.source;
  let pattern = "";
  let isEscaped = false;
  let inCharGroup = false;
  let inCharRange = false;
  for (let i = 0; i < source.length; i++) {
    if (isEscaped) {
      pattern += source[i];
      isEscaped = false;
      continue;
    }
    if (flags.i) {
      if (inCharGroup) {
        if (source[i].match(/[a-z]/)) {
          if (inCharRange) {
            pattern += source[i];
            pattern += `${source[i - 2]}-${source[i]}`.toUpperCase();
            inCharRange = false;
          } else if (source[i + 1] === "-" && source[i + 2]?.match(/[a-z]/)) {
            pattern += source[i];
            inCharRange = true;
          } else {
            pattern += `${source[i]}${source[i].toUpperCase()}`;
          }
          continue;
        }
      } else if (source[i].match(/[a-z]/)) {
        pattern += `[${source[i]}${source[i].toUpperCase()}]`;
        continue;
      }
    }
    if (flags.m) {
      if (source[i] === "^") {
        pattern += `(^|(?<=[\r
]))`;
        continue;
      } else if (source[i] === "$") {
        pattern += `($|(?=[\r
]))`;
        continue;
      }
    }
    if (flags.s && source[i] === ".") {
      pattern += inCharGroup ? `${source[i]}\r
` : `[${source[i]}\r
]`;
      continue;
    }
    pattern += source[i];
    if (source[i] === "\\") {
      isEscaped = true;
    } else if (inCharGroup && source[i] === "]") {
      inCharGroup = false;
    } else if (!inCharGroup && source[i] === "[") {
      inCharGroup = true;
    }
  }
  try {
    new RegExp(pattern);
  } catch {
    console.warn(`Could not convert regex pattern at ${refs.currentPath.join("/")} to a flag-independent form! Falling back to the flag-ignorant source`);
    return regex.source;
  }
  return pattern;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/record.js
function parseRecordDef(def, refs) {
  if (refs.target === "openAi") {
    console.warn("Warning: OpenAI may not support records in schemas! Try an array of key-value pairs instead.");
  }
  if (refs.target === "openApi3" && def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) {
    return {
      type: "object",
      required: def.keyType._def.values,
      properties: def.keyType._def.values.reduce((acc, key) => ({
        ...acc,
        [key]: parseDef(def.valueType._def, {
          ...refs,
          currentPath: [...refs.currentPath, "properties", key]
        }) ?? parseAnyDef(refs)
      }), {}),
      additionalProperties: refs.rejectedAdditionalProperties
    };
  }
  const schema = {
    type: "object",
    additionalProperties: parseDef(def.valueType._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    }) ?? refs.allowedAdditionalProperties
  };
  if (refs.target === "openApi3") {
    return schema;
  }
  if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodString && def.keyType._def.checks?.length) {
    const { type: type2, ...keyType } = parseStringDef(def.keyType._def, refs);
    return {
      ...schema,
      propertyNames: keyType
    };
  } else if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodEnum) {
    return {
      ...schema,
      propertyNames: {
        enum: def.keyType._def.values
      }
    };
  } else if (def.keyType?._def.typeName === ZodFirstPartyTypeKind.ZodBranded && def.keyType._def.type._def.typeName === ZodFirstPartyTypeKind.ZodString && def.keyType._def.type._def.checks?.length) {
    const { type: type2, ...keyType } = parseBrandedDef(def.keyType._def, refs);
    return {
      ...schema,
      propertyNames: keyType
    };
  }
  return schema;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/map.js
function parseMapDef(def, refs) {
  if (refs.mapStrategy === "record") {
    return parseRecordDef(def, refs);
  }
  const keys = parseDef(def.keyType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items", "items", "0"]
  }) || parseAnyDef(refs);
  const values = parseDef(def.valueType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items", "items", "1"]
  }) || parseAnyDef(refs);
  return {
    type: "array",
    maxItems: 125,
    items: {
      type: "array",
      items: [keys, values],
      minItems: 2,
      maxItems: 2
    }
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/nativeEnum.js
function parseNativeEnumDef(def) {
  const object2 = def.values;
  const actualKeys = Object.keys(def.values).filter((key) => {
    return typeof object2[object2[key]] !== "number";
  });
  const actualValues = actualKeys.map((key) => object2[key]);
  const parsedTypes = Array.from(new Set(actualValues.map((values) => typeof values)));
  return {
    type: parsedTypes.length === 1 ? parsedTypes[0] === "string" ? "string" : "number" : ["string", "number"],
    enum: actualValues
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/never.js
function parseNeverDef(refs) {
  return refs.target === "openAi" ? void 0 : {
    not: parseAnyDef({
      ...refs,
      currentPath: [...refs.currentPath, "not"]
    })
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/null.js
function parseNullDef(refs) {
  return refs.target === "openApi3" ? {
    enum: ["null"],
    nullable: true
  } : {
    type: "null"
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/union.js
var primitiveMappings = {
  ZodString: "string",
  ZodNumber: "number",
  ZodBigInt: "integer",
  ZodBoolean: "boolean",
  ZodNull: "null"
};
function parseUnionDef(def, refs) {
  if (refs.target === "openApi3")
    return asAnyOf(def, refs);
  const options = def.options instanceof Map ? Array.from(def.options.values()) : def.options;
  if (options.every((x) => x._def.typeName in primitiveMappings && (!x._def.checks || !x._def.checks.length))) {
    const types = options.reduce((types2, x) => {
      const type2 = primitiveMappings[x._def.typeName];
      return type2 && !types2.includes(type2) ? [...types2, type2] : types2;
    }, []);
    return {
      type: types.length > 1 ? types : types[0]
    };
  } else if (options.every((x) => x._def.typeName === "ZodLiteral" && !x.description)) {
    const types = options.reduce((acc, x) => {
      const type2 = typeof x._def.value;
      switch (type2) {
        case "string":
        case "number":
        case "boolean":
          return [...acc, type2];
        case "bigint":
          return [...acc, "integer"];
        case "object":
          if (x._def.value === null)
            return [...acc, "null"];
        case "symbol":
        case "undefined":
        case "function":
        default:
          return acc;
      }
    }, []);
    if (types.length === options.length) {
      const uniqueTypes = types.filter((x, i, a) => a.indexOf(x) === i);
      return {
        type: uniqueTypes.length > 1 ? uniqueTypes : uniqueTypes[0],
        enum: options.reduce((acc, x) => {
          return acc.includes(x._def.value) ? acc : [...acc, x._def.value];
        }, [])
      };
    }
  } else if (options.every((x) => x._def.typeName === "ZodEnum")) {
    return {
      type: "string",
      enum: options.reduce((acc, x) => [
        ...acc,
        ...x._def.values.filter((x2) => !acc.includes(x2))
      ], [])
    };
  }
  return asAnyOf(def, refs);
}
var asAnyOf = (def, refs) => {
  const anyOf = (def.options instanceof Map ? Array.from(def.options.values()) : def.options).map((x, i) => parseDef(x._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", `${i}`]
  })).filter((x) => !!x && (!refs.strictUnions || typeof x === "object" && Object.keys(x).length > 0));
  return anyOf.length ? { anyOf } : void 0;
};

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/nullable.js
function parseNullableDef(def, refs) {
  if (["ZodString", "ZodNumber", "ZodBigInt", "ZodBoolean", "ZodNull"].includes(def.innerType._def.typeName) && (!def.innerType._def.checks || !def.innerType._def.checks.length)) {
    if (refs.target === "openApi3") {
      return {
        type: primitiveMappings[def.innerType._def.typeName],
        nullable: true
      };
    }
    return {
      type: [
        primitiveMappings[def.innerType._def.typeName],
        "null"
      ]
    };
  }
  if (refs.target === "openApi3") {
    const base2 = parseDef(def.innerType._def, {
      ...refs,
      currentPath: [...refs.currentPath]
    });
    if (base2 && "$ref" in base2)
      return { allOf: [base2], nullable: true };
    return base2 && { ...base2, nullable: true };
  }
  const base = parseDef(def.innerType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", "0"]
  });
  return base && { anyOf: [base, { type: "null" }] };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/number.js
function parseNumberDef(def, refs) {
  const res = {
    type: "number"
  };
  if (!def.checks)
    return res;
  for (const check of def.checks) {
    switch (check.kind) {
      case "int":
        res.type = "integer";
        addErrorMessage(res, "type", check.message, refs);
        break;
      case "min":
        if (refs.target === "jsonSchema7") {
          if (check.inclusive) {
            setResponseValueAndErrors(res, "minimum", check.value, check.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMinimum", check.value, check.message, refs);
          }
        } else {
          if (!check.inclusive) {
            res.exclusiveMinimum = true;
          }
          setResponseValueAndErrors(res, "minimum", check.value, check.message, refs);
        }
        break;
      case "max":
        if (refs.target === "jsonSchema7") {
          if (check.inclusive) {
            setResponseValueAndErrors(res, "maximum", check.value, check.message, refs);
          } else {
            setResponseValueAndErrors(res, "exclusiveMaximum", check.value, check.message, refs);
          }
        } else {
          if (!check.inclusive) {
            res.exclusiveMaximum = true;
          }
          setResponseValueAndErrors(res, "maximum", check.value, check.message, refs);
        }
        break;
      case "multipleOf":
        setResponseValueAndErrors(res, "multipleOf", check.value, check.message, refs);
        break;
    }
  }
  return res;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/object.js
function parseObjectDef(def, refs) {
  const forceOptionalIntoNullable = refs.target === "openAi";
  const result = {
    type: "object",
    properties: {}
  };
  const required = [];
  const shape = def.shape();
  for (const propName in shape) {
    let propDef = shape[propName];
    if (propDef === void 0 || propDef._def === void 0) {
      continue;
    }
    let propOptional = safeIsOptional(propDef);
    if (propOptional && forceOptionalIntoNullable) {
      if (propDef._def.typeName === "ZodOptional") {
        propDef = propDef._def.innerType;
      }
      if (!propDef.isNullable()) {
        propDef = propDef.nullable();
      }
      propOptional = false;
    }
    const parsedDef = parseDef(propDef._def, {
      ...refs,
      currentPath: [...refs.currentPath, "properties", propName],
      propertyPath: [...refs.currentPath, "properties", propName]
    });
    if (parsedDef === void 0) {
      continue;
    }
    result.properties[propName] = parsedDef;
    if (!propOptional) {
      required.push(propName);
    }
  }
  if (required.length) {
    result.required = required;
  }
  const additionalProperties = decideAdditionalProperties(def, refs);
  if (additionalProperties !== void 0) {
    result.additionalProperties = additionalProperties;
  }
  return result;
}
function decideAdditionalProperties(def, refs) {
  if (def.catchall._def.typeName !== "ZodNever") {
    return parseDef(def.catchall._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    });
  }
  switch (def.unknownKeys) {
    case "passthrough":
      return refs.allowedAdditionalProperties;
    case "strict":
      return refs.rejectedAdditionalProperties;
    case "strip":
      return refs.removeAdditionalStrategy === "strict" ? refs.allowedAdditionalProperties : refs.rejectedAdditionalProperties;
  }
}
function safeIsOptional(schema) {
  try {
    return schema.isOptional();
  } catch {
    return true;
  }
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/optional.js
var parseOptionalDef = (def, refs) => {
  if (refs.currentPath.toString() === refs.propertyPath?.toString()) {
    return parseDef(def.innerType._def, refs);
  }
  const innerSchema = parseDef(def.innerType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", "1"]
  });
  return innerSchema ? {
    anyOf: [
      {
        not: parseAnyDef(refs)
      },
      innerSchema
    ]
  } : parseAnyDef(refs);
};

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/pipeline.js
var parsePipelineDef = (def, refs) => {
  if (refs.pipeStrategy === "input") {
    return parseDef(def.in._def, refs);
  } else if (refs.pipeStrategy === "output") {
    return parseDef(def.out._def, refs);
  }
  const a = parseDef(def.in._def, {
    ...refs,
    currentPath: [...refs.currentPath, "allOf", "0"]
  });
  const b = parseDef(def.out._def, {
    ...refs,
    currentPath: [...refs.currentPath, "allOf", a ? "1" : "0"]
  });
  return {
    allOf: [a, b].filter((x) => x !== void 0)
  };
};

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/promise.js
function parsePromiseDef(def, refs) {
  return parseDef(def.type._def, refs);
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/set.js
function parseSetDef(def, refs) {
  const items = parseDef(def.valueType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items"]
  });
  const schema = {
    type: "array",
    uniqueItems: true,
    items
  };
  if (def.minSize) {
    setResponseValueAndErrors(schema, "minItems", def.minSize.value, def.minSize.message, refs);
  }
  if (def.maxSize) {
    setResponseValueAndErrors(schema, "maxItems", def.maxSize.value, def.maxSize.message, refs);
  }
  return schema;
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/tuple.js
function parseTupleDef(def, refs) {
  if (def.rest) {
    return {
      type: "array",
      minItems: def.items.length,
      items: def.items.map((x, i) => parseDef(x._def, {
        ...refs,
        currentPath: [...refs.currentPath, "items", `${i}`]
      })).reduce((acc, x) => x === void 0 ? acc : [...acc, x], []),
      additionalItems: parseDef(def.rest._def, {
        ...refs,
        currentPath: [...refs.currentPath, "additionalItems"]
      })
    };
  } else {
    return {
      type: "array",
      minItems: def.items.length,
      maxItems: def.items.length,
      items: def.items.map((x, i) => parseDef(x._def, {
        ...refs,
        currentPath: [...refs.currentPath, "items", `${i}`]
      })).reduce((acc, x) => x === void 0 ? acc : [...acc, x], [])
    };
  }
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/undefined.js
function parseUndefinedDef(refs) {
  return {
    not: parseAnyDef(refs)
  };
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/unknown.js
function parseUnknownDef(refs) {
  return parseAnyDef(refs);
}

// node_modules/trpc-cli/dist/zod-to-json-schema/parsers/readonly.js
var parseReadonlyDef = (def, refs) => {
  return parseDef(def.innerType._def, refs);
};

// node_modules/trpc-cli/dist/zod-to-json-schema/selectParser.js
var selectParser = (def, typeName, refs) => {
  switch (typeName) {
    case ZodFirstPartyTypeKind.ZodString:
      return parseStringDef(def, refs);
    case ZodFirstPartyTypeKind.ZodNumber:
      return parseNumberDef(def, refs);
    case ZodFirstPartyTypeKind.ZodObject:
      return parseObjectDef(def, refs);
    case ZodFirstPartyTypeKind.ZodBigInt:
      return parseBigintDef(def, refs);
    case ZodFirstPartyTypeKind.ZodBoolean:
      return parseBooleanDef();
    case ZodFirstPartyTypeKind.ZodDate:
      return parseDateDef(def, refs);
    case ZodFirstPartyTypeKind.ZodUndefined:
      return parseUndefinedDef(refs);
    case ZodFirstPartyTypeKind.ZodNull:
      return parseNullDef(refs);
    case ZodFirstPartyTypeKind.ZodArray:
      return parseArrayDef(def, refs);
    case ZodFirstPartyTypeKind.ZodUnion:
    case ZodFirstPartyTypeKind.ZodDiscriminatedUnion:
      return parseUnionDef(def, refs);
    case ZodFirstPartyTypeKind.ZodIntersection:
      return parseIntersectionDef(def, refs);
    case ZodFirstPartyTypeKind.ZodTuple:
      return parseTupleDef(def, refs);
    case ZodFirstPartyTypeKind.ZodRecord:
      return parseRecordDef(def, refs);
    case ZodFirstPartyTypeKind.ZodLiteral:
      return parseLiteralDef(def, refs);
    case ZodFirstPartyTypeKind.ZodEnum:
      return parseEnumDef(def);
    case ZodFirstPartyTypeKind.ZodNativeEnum:
      return parseNativeEnumDef(def);
    case ZodFirstPartyTypeKind.ZodNullable:
      return parseNullableDef(def, refs);
    case ZodFirstPartyTypeKind.ZodOptional:
      return parseOptionalDef(def, refs);
    case ZodFirstPartyTypeKind.ZodMap:
      return parseMapDef(def, refs);
    case ZodFirstPartyTypeKind.ZodSet:
      return parseSetDef(def, refs);
    case ZodFirstPartyTypeKind.ZodLazy:
      return () => def.getter()._def;
    case ZodFirstPartyTypeKind.ZodPromise:
      return parsePromiseDef(def, refs);
    case ZodFirstPartyTypeKind.ZodNaN:
    case ZodFirstPartyTypeKind.ZodNever:
      return parseNeverDef(refs);
    case ZodFirstPartyTypeKind.ZodEffects:
      return parseEffectsDef(def, refs);
    case ZodFirstPartyTypeKind.ZodAny:
      return parseAnyDef(refs);
    case ZodFirstPartyTypeKind.ZodUnknown:
      return parseUnknownDef(refs);
    case ZodFirstPartyTypeKind.ZodDefault:
      return parseDefaultDef(def, refs);
    case ZodFirstPartyTypeKind.ZodBranded:
      return parseBrandedDef(def, refs);
    case ZodFirstPartyTypeKind.ZodReadonly:
      return parseReadonlyDef(def, refs);
    case ZodFirstPartyTypeKind.ZodCatch:
      return parseCatchDef(def, refs);
    case ZodFirstPartyTypeKind.ZodPipeline:
      return parsePipelineDef(def, refs);
    case ZodFirstPartyTypeKind.ZodFunction:
    case ZodFirstPartyTypeKind.ZodVoid:
    case ZodFirstPartyTypeKind.ZodSymbol:
      return void 0;
    default:
      return /* @__PURE__ */ ((_) => void 0)(typeName);
  }
};

// node_modules/trpc-cli/dist/zod-to-json-schema/parseDef.js
function parseDef(def, refs, forceResolution = false) {
  const seenItem = refs.seen.get(def);
  if (refs.override) {
    const overrideResult = refs.override?.(def, refs, seenItem, forceResolution);
    if (overrideResult !== ignoreOverride) {
      return overrideResult;
    }
  }
  if (seenItem && !forceResolution) {
    const seenSchema = get$ref(seenItem, refs);
    if (seenSchema !== void 0) {
      return seenSchema;
    }
  }
  const newItem = { def, path: refs.currentPath, jsonSchema: void 0 };
  refs.seen.set(def, newItem);
  const jsonSchemaOrGetter = selectParser(def, def.typeName, refs);
  const jsonSchema2 = typeof jsonSchemaOrGetter === "function" ? parseDef(jsonSchemaOrGetter(), refs) : jsonSchemaOrGetter;
  if (jsonSchema2) {
    addMeta(def, refs, jsonSchema2);
  }
  if (refs.postProcess) {
    const postProcessResult = refs.postProcess(jsonSchema2, def, refs);
    newItem.jsonSchema = jsonSchema2;
    return postProcessResult;
  }
  newItem.jsonSchema = jsonSchema2;
  return jsonSchema2;
}
var get$ref = (item, refs) => {
  switch (refs.$refStrategy) {
    case "root":
      return { $ref: item.path.join("/") };
    case "relative":
      return { $ref: getRelativePath(refs.currentPath, item.path) };
    case "none":
    case "seen": {
      if (item.path.length < refs.currentPath.length && item.path.every((value2, index) => refs.currentPath[index] === value2)) {
        console.warn(`Recursive reference detected at ${refs.currentPath.join("/")}! Defaulting to any`);
        return parseAnyDef(refs);
      }
      return refs.$refStrategy === "seen" ? parseAnyDef(refs) : void 0;
    }
  }
};
var addMeta = (def, refs, jsonSchema2) => {
  if (def.description) {
    jsonSchema2.description = def.description;
    if (refs.markdownDescription) {
      jsonSchema2.markdownDescription = def.description;
    }
  }
  return jsonSchema2;
};

// node_modules/trpc-cli/dist/zod-to-json-schema/zodToJsonSchema.js
var zodToJsonSchema = (schema, options) => {
  const refs = getRefs(options);
  let definitions = typeof options === "object" && options.definitions ? Object.entries(options.definitions).reduce((acc, [name17, schema2]) => ({
    ...acc,
    [name17]: parseDef(schema2._def, {
      ...refs,
      currentPath: [...refs.basePath, refs.definitionPath, name17]
    }, true) ?? parseAnyDef(refs)
  }), {}) : void 0;
  const name16 = typeof options === "string" ? options : options?.nameStrategy === "title" ? void 0 : options?.name;
  const main = parseDef(schema._def, name16 === void 0 ? refs : {
    ...refs,
    currentPath: [...refs.basePath, refs.definitionPath, name16]
  }, false) ?? parseAnyDef(refs);
  const title = typeof options === "object" && options.name !== void 0 && options.nameStrategy === "title" ? options.name : void 0;
  if (title !== void 0) {
    main.title = title;
  }
  if (refs.flags.hasReferencedOpenAiAnyType) {
    if (!definitions) {
      definitions = {};
    }
    if (!definitions[refs.openAiAnyTypeName]) {
      definitions[refs.openAiAnyTypeName] = {
        // Skipping "object" as no properties can be defined and additionalProperties must be "false"
        type: ["string", "number", "integer", "boolean", "array", "null"],
        items: {
          $ref: refs.$refStrategy === "relative" ? "1" : [
            ...refs.basePath,
            refs.definitionPath,
            refs.openAiAnyTypeName
          ].join("/")
        }
      };
    }
  }
  const combined = name16 === void 0 ? definitions ? {
    ...main,
    [refs.definitionPath]: definitions
  } : main : {
    $ref: [
      ...refs.$refStrategy === "relative" ? [] : refs.basePath,
      refs.definitionPath,
      name16
    ].join("/"),
    [refs.definitionPath]: {
      ...definitions,
      [name16]: main
    }
  };
  if (refs.target === "jsonSchema7") {
    combined.$schema = "http://json-schema.org/draft-07/schema#";
  } else if (refs.target === "jsonSchema2019-09" || refs.target === "openAi") {
    combined.$schema = "https://json-schema.org/draft/2019-09/schema#";
  }
  if (refs.target === "openAi" && ("anyOf" in combined || "oneOf" in combined || "allOf" in combined || "type" in combined && Array.isArray(combined.type))) {
    console.warn("Warning: OpenAI may not support schemas with unions as roots! Try wrapping it in an object property.");
  }
  return combined;
};

// node_modules/trpc-cli/dist/parse-procedure.js
var [valibotOrError, valibotToJsonSchemaOrError, effectOrError, zod4CoreOrError] = await Promise.all([
  import("valibot").catch(String),
  import("@valibot/to-json-schema").catch(String),
  import("effect").catch(String),
  import("zod/v4/core").catch(String)
]);
var getModule = (moduleOrError) => {
  if (typeof moduleOrError === "string") {
    throw new Error(`${moduleOrError} - try installing it and re-running`);
  }
  return moduleOrError;
};
function toJsonSchema(input, dependencies) {
  try {
    const jsonSchemaConverters = getJsonSchemaConverters(dependencies);
    const vendor = getVendor(input);
    if (vendor && vendor in jsonSchemaConverters) {
      const converter = jsonSchemaConverters[vendor];
      const converted = converter(input);
      return { success: true, value: converted };
    }
    return { success: false, error: `Schema not convertible to JSON schema` };
  } catch (e) {
    const message = e instanceof Error ? e.message : String(e);
    return { success: false, error: `Failed to convert input to JSON Schema: ${message}` };
  }
}
function looksLikeJsonSchema(value2) {
  return typeof value2 === "object" && value2 !== null && ("type" in value2 && (typeof value2.type === "string" || Array.isArray(value2.type)) || "const" in value2 || "oneOf" in value2 || "anyOf" in value2);
}
function parseProcedureInputs(inputs, dependencies) {
  const inner = parseProcedureInputsInner(inputs, dependencies);
  if (inner.success && inner.value.positionalParameters.some((param, i, { length }) => param.array && i < length - 1)) {
    return { success: false, error: `Array positional parameters must be at the end of the input.` };
  }
  if (inner.success) {
    const optionsProps = schemaDefPropValue(inner.value.optionsJsonSchema, "properties");
    if (optionsProps) {
      const optionishPositionals = Object.entries(optionsProps).flatMap(([key, schema]) => {
        if (typeof schema === "object" && "positional" in schema && schema.positional === true) {
          return [{ key, schema }];
        }
        return [];
      });
      if (optionishPositionals.length > 0) {
        return {
          success: true,
          value: {
            positionalParameters: [
              ...inner.value.positionalParameters,
              ...optionishPositionals.map(({ key, schema }) => ({
                name: key,
                array: looksLikeArray(schema),
                description: schema.description ?? "",
                required: !isOptional(schema),
                type: getSchemaTypes(schema).join(" | ")
              }))
            ],
            optionsJsonSchema: {
              ...inner.value.optionsJsonSchema,
              properties: Object.fromEntries(Object.entries(optionsProps).filter(([key]) => !optionishPositionals.some((x) => x.key === key)))
            },
            getPojoInput: (params) => {
              const positionalValues = [...params.positionalValues];
              const options = { ...params.options };
              for (const { key, schema } of optionishPositionals) {
                options[key] = convertPositional(schema, positionalValues.shift());
              }
              return inner.value.getPojoInput({ positionalValues, options });
            }
          }
        };
      }
    }
  }
  return inner;
}
function parseProcedureInputsInner(inputs, dependencies) {
  if (inputs.length === 0) {
    return {
      success: true,
      value: {
        positionalParameters: [],
        optionsJsonSchema: {},
        getPojoInput: () => ({})
      }
    };
  }
  const allJsonSchemaable = inputs.every((input) => looksJsonSchemaable(input));
  if (!allJsonSchemaable) {
    return {
      success: false,
      error: `Invalid input type ${inputs.map((s) => s?.constructor.name).join(", ")}, only inputs that can be converted to JSON Schema are supported`
    };
  }
  if (inputs.length > 1) {
    return parseMultiInputs(inputs, dependencies);
  }
  const mergedSchemaResult = toJsonSchema(inputs[0], dependencies);
  if (!mergedSchemaResult.success) {
    return {
      success: false,
      error: mergedSchemaResult.error
    };
  }
  const mergedSchema = mergedSchemaResult.value;
  return handleMergedSchema(mergedSchema);
}
function handleMergedSchema(mergedSchema) {
  if (mergedSchema.additionalProperties) {
    return { success: false, error: `Inputs with additional properties are not currently supported` };
  }
  if (acceptedPrimitiveTypes(mergedSchema).length > 0) {
    return parsePrimitiveInput(mergedSchema);
  }
  if (isTuple(mergedSchema)) {
    return parseTupleInput(mergedSchema);
  }
  if (mergedSchema.type === "array") {
    return parseArrayInput(mergedSchema);
  }
  if (mergedSchema.anyOf) {
    const allObjects = mergedSchema.anyOf.every((sub) => acceptsObject(toRoughJsonSchema7(sub)));
    if (allObjects) {
      return {
        success: true,
        value: {
          positionalParameters: [],
          optionsJsonSchema: mergedSchema,
          getPojoInput: (argv) => argv.options
        }
      };
    }
    if (mergedSchema.anyOf.length === 2 && JSON.stringify(mergedSchema.anyOf[0]) === '{"not":{}}') {
      return handleMergedSchema(mergedSchema.anyOf[1]);
    }
  }
  if (mergedSchema.type !== "object") {
    return {
      success: false,
      error: `Invalid input type ${inspect(mergedSchema, { depth: 2, breakLength: Infinity })}, expected object or tuple.`
    };
  }
  return {
    success: true,
    value: {
      positionalParameters: [],
      optionsJsonSchema: mergedSchema,
      getPojoInput: (argv) => argv.options
    }
  };
}
function isOptional(schema) {
  if (schema && typeof schema === "object" && "optional" in schema)
    return schema.optional === true;
  if (schemaDefPropValue(schema, "not") && JSON.stringify(schema) === '{"not":{}}')
    return true;
  const anyOf = schemaDefPropValue(schema, "anyOf");
  if (anyOf?.some((sub) => isOptional(sub)))
    return true;
  if (schemaDefPropValue(schema, "default") !== void 0)
    return true;
  return false;
}
function parsePrimitiveInput(schema) {
  const typeName = acceptedPrimitiveTypes(schema).join(" | ");
  const name16 = (schema.title || schema.description || /\W/.test(typeName) ? "value" : typeName).replaceAll(/\s+/g, "_");
  return {
    success: true,
    value: {
      positionalParameters: [
        {
          name: name16,
          array: false,
          description: schema.description || "",
          required: !isOptional(schema),
          type: typeName
        }
      ],
      optionsJsonSchema: {},
      getPojoInput: (argv) => convertPositional(schema, argv.positionalValues[0])
    }
  };
}
var schemaDefPropValue = (schema, prop) => {
  if (schema && typeof schema === "object" && prop in schema)
    return schema[prop];
  return void 0;
};
var primitiveCandidateTypes = ["string", "number", "boolean", "integer"];
function acceptedPrimitiveTypes(schema) {
  let constVals = [toRoughJsonSchema7(schema).const, toRoughJsonSchema7(schema).enum].flat().filter(Boolean).map((s) => typeof s);
  if (constVals.length === 0)
    constVals = void 0;
  const typeList = constVals || schemaDefPropValue(schema, "type") || schemaDefPropValue(schema, "oneOf")?.flatMap((s) => acceptedPrimitiveTypes(s)) || schemaDefPropValue(schema, "anyOf")?.flatMap((s) => acceptedPrimitiveTypes(s));
  const acceptedJsonSchemaTypes = new Set([typeList].flat().filter(Boolean));
  return primitiveCandidateTypes.filter((c) => acceptedJsonSchemaTypes.has(c));
}
function maybeMergeObjectSchemas(schemas) {
  const required = [];
  const properties = {};
  for (const schema of schemas) {
    if (!schema)
      return null;
    const { required: schemaRequired, properties: schemaProperties, type: type2, $schema, ...rest } = schema;
    if (type2 && type2 !== "object")
      return null;
    if (Object.keys(rest).length)
      return null;
    if (schemaRequired)
      required.push(...schemaRequired);
    if (schemaProperties)
      Object.assign(properties, schemaProperties);
  }
  return { type: "object", required, properties };
}
function parseMultiInputs(inputs, dependencies) {
  const parsedIndividually = inputs.map((input) => parseProcedureInputsInner([input], dependencies));
  const failures = parsedIndividually.flatMap((p) => p.success ? [] : [p.error]);
  if (failures.length > 0) {
    return { success: false, error: failures.join("\n") };
  }
  const allObjects = parsedIndividually.every((p) => p.success && p.value.positionalParameters.length === 0);
  if (!allObjects) {
    return {
      success: false,
      error: `Can't use positional parameters with multi-input type.`
    };
  }
  const merged = maybeMergeObjectSchemas(parsedIndividually.map((p) => p.success ? p.value.optionsJsonSchema : {}));
  if (merged) {
    return {
      success: true,
      value: {
        positionalParameters: [],
        optionsJsonSchema: merged,
        getPojoInput: (argv) => argv.options
      }
    };
  }
  return {
    success: true,
    value: {
      positionalParameters: [],
      optionsJsonSchema: {
        allOf: parsedIndividually.map((p) => {
          const successful = p;
          const optionsSchema = successful.value.optionsJsonSchema;
          if ("additionalProperties" in optionsSchema && optionsSchema.additionalProperties === false) {
            const { additionalProperties, ...rest } = optionsSchema;
            return rest;
          }
          return optionsSchema;
        })
      },
      getPojoInput: (argv) => argv.options
    }
  };
}
function isNullable(schema) {
  if (Array.isArray(schema.type) && schema.type.includes("null"))
    return true;
  if (schema.type === "null")
    return true;
  if ((schema.anyOf || schema.oneOf)?.some((sub) => isNullable(toRoughJsonSchema7(sub))))
    return true;
  if (schema.const === null)
    return true;
  return false;
}
var tupleItemsSchemas = (schema) => {
  if (!schema || typeof schema !== "object")
    return void 0;
  if (Array.isArray(schema.items))
    return schema.items;
  if ("prefixItems" in schema && Array.isArray(schema.prefixItems))
    return schema.prefixItems;
  return void 0;
};
function isTuple(schema) {
  return Array.isArray(tupleItemsSchemas(schema));
}
function parseArrayInput(array) {
  if (looksLikeJsonSchema(array.items) && isNullable(array.items)) {
    return {
      success: false,
      error: `Invalid input type Array<${getSchemaTypes(array.items).join(" | ")}>. Nullable arrays are not supported.`
    };
  }
  return {
    success: true,
    value: {
      positionalParameters: [
        {
          name: parameterName(array, 1),
          array: true,
          description: array.description || "",
          required: !isOptional(array),
          type: "string"
        }
      ],
      optionsJsonSchema: {},
      getPojoInput: (argv) => argv.positionalValues.at(-1).map((s) => convertPositional(array.items, s))
    }
  };
}
function parseTupleInput(tuple) {
  const items = tupleItemsSchemas(tuple);
  if (!Array.isArray(items))
    throw new Error(".items is not an array, is this really a tuple?");
  const flagsSchemaIndex = items.findIndex((item) => {
    if (acceptedPrimitiveTypes(item).length > 0) {
      return false;
    }
    if (looksLikeArray(item) && acceptedPrimitiveTypes(item.items).length > 0) {
      return false;
    }
    return true;
  });
  const types = `[${items.map((s) => schemaDefPropValue(s, "type")).join(", ")}]`;
  if (flagsSchemaIndex > -1 && flagsSchemaIndex !== items.length - 1) {
    return {
      success: false,
      error: `Invalid input type ${types}. Positional parameters must be strings, numbers or booleans.`
    };
  }
  const flagsSchema = flagsSchemaIndex === -1 ? null : items[flagsSchemaIndex];
  if (flagsSchema && !acceptsObject(flagsSchema)) {
    return {
      success: false,
      error: `Invalid input type ${types}. The last type must accept object inputs.`
    };
  }
  const positionalSchemas = flagsSchemaIndex === -1 ? items : items.slice(0, flagsSchemaIndex);
  return {
    success: true,
    value: {
      positionalParameters: positionalSchemas.map((schema, i) => ({
        name: parameterName(schema, i + 1),
        array: looksLikeArray(schema),
        description: schemaDefPropValue(schema, "description") || "",
        required: !isOptional(schema),
        type: getSchemaTypes(toRoughJsonSchema7(schema)).join(" | ")
      })),
      optionsJsonSchema: flagsSchema && typeof flagsSchema === "object" ? flagsSchema : {},
      getPojoInput: (commandArgs) => {
        const inputs = commandArgs.positionalValues.map((v, i) => {
          const correspondingSchema = positionalSchemas[i];
          if (looksLikeArray(correspondingSchema)) {
            if (!Array.isArray(v)) {
              throw new CliValidationError(`Expected array at position ${i}, got ${typeof v}`);
            }
            return v.map((s) => {
              if (!correspondingSchema.items || Array.isArray(correspondingSchema.items))
                return s;
              return convertPositional(correspondingSchema.items, s);
            });
          }
          if (typeof v !== "string" && v !== void 0) {
            throw new CliValidationError(`Expected string at position ${i}, got ${typeof v}`);
          }
          return convertPositional(correspondingSchema, v);
        });
        if (flagsSchema) {
          inputs.push(commandArgs.options);
        }
        return inputs;
      }
    }
  };
}
var convertPositional = (schema, value2) => {
  let preprocessed = void 0;
  const acceptedTypes = new Set(acceptedPrimitiveTypes(schema));
  if (acceptedTypes.has("string")) {
    preprocessed = value2;
  }
  if (acceptedTypes.has("boolean")) {
    if (value2 === "true")
      preprocessed = true;
    else if (value2 === "false")
      preprocessed = false;
  }
  if (acceptedTypes.has("number")) {
    const number = Number(value2);
    if (!Number.isNaN(number)) {
      preprocessed = number;
    }
  }
  if (acceptedTypes.has("integer")) {
    const num = Number(value2);
    if (Number.isInteger(num)) {
      preprocessed = num;
    } else if (!Number.isNaN(num) && acceptedTypes === void 0) {
      preprocessed = value2;
    }
  }
  if (preprocessed === void 0) {
    return value2;
  }
  return preprocessed;
};
var looksLikeArray = (schema) => {
  return schemaDefPropValue(schema, "type") === "array";
};
var toRoughJsonSchema7 = (schema) => {
  if (!schema || typeof schema !== "object") {
    return {};
  }
  return schema;
};
var maybeParameterName = (s) => {
  const value2 = schemaDefPropValue(s, "title") || schemaDefPropValue(s, "description");
  if (!value2 && looksLikeArray(s)) {
    const items = toRoughJsonSchema7(s).items;
    return items && !Array.isArray(items) ? maybeParameterName(items) : void 0;
  }
  return value2;
};
var parameterName = (s, position) => {
  let name16 = maybeParameterName(s) || `parameter_${position}`;
  if (looksLikeArray(s))
    return `[${name16}...]`;
  name16 = name16.replaceAll(/\W+/g, " ").trim();
  return isOptional(s) ? `[${name16}]` : `<${name16}>`;
};
var acceptsObject = (schema) => {
  return (schema.type === "object" || schema.anyOf?.some((sub) => acceptsObject(toRoughJsonSchema7(sub)))) ?? false;
};
var getJsonSchemaConverters = (dependencies) => {
  return {
    zod: (input) => {
      if (input._zod?.version?.major == 4) {
        const zod4 = getModule(zod4CoreOrError);
        return zod4.toJSONSchema(input, {
          io: "input",
          // todo[zod@>=4.1.0] remove the override if https://github.com/colinhacks/zod/issues/4164 is resolved, or this comment if it's closed
          unrepresentable: "any",
          // todo[zod@>=4.1.0] remove the override if https://github.com/colinhacks/zod/issues/4164 is resolved, or this comment if it's closed
          override: (ctx) => {
            if (ctx.zodSchema?.constructor?.name === "ZodOptional") {
              ctx.jsonSchema.optional = true;
            }
            const meta = ctx.zodSchema.meta?.();
            if (meta)
              Object.assign(ctx.jsonSchema, meta);
          }
        });
      }
      return zodToJsonSchema(input);
    },
    arktype: (input) => {
      const type2 = prepareArktypeType(input);
      return type2.toJsonSchema({
        fallback: (ctx) => {
          if (ctx.code === "unit" && ctx.unit === void 0)
            return { ...ctx.base, optional: true };
          return ctx.base;
        }
      });
    },
    valibot: (input) => {
      const valibotToJsonSchemaLib = dependencies["@valibot/to-json-schema"] || getModule(valibotToJsonSchemaOrError);
      const valibotToJsonSchema = valibotToJsonSchemaLib?.toJsonSchema;
      if (!valibotToJsonSchema) {
        throw new Error(`no 'toJsonSchema' function found in @valibot/to-json-schema - check you are using a supported version`);
      }
      if (typeof valibotOrError === "string") {
        return valibotToJsonSchema(input);
      }
      const v = getModule(valibotOrError);
      const parent = valibotToJsonSchema(v.object({ child: input }), {
        errorMode: "ignore"
      });
      const child = parent.properties.child;
      return parent.required?.length === 0 ? Object.assign(child, { optional: true }) : child;
    },
    effect: (input) => {
      const effect = dependencies.effect || getModule(effectOrError);
      if (!effect) {
        throw new Error(`effect dependency could not be found - try installing it and re-running`);
      }
      if (!effect.Schema.isSchema(input)) {
        const message = `input was not an effect schema - please use effect version 3.14.2 or higher. See https://github.com/mmkal/trpc-cli/pull/63`;
        throw new Error(message);
      }
      return effect.JSONSchema.make(input);
    }
  };
};
function getVendor(schema) {
  return schema?.["~standard"]?.vendor ?? null;
}
var jsonSchemaVendorNames = new Set(Object.keys(getJsonSchemaConverters({})));
function looksJsonSchemaable(value2) {
  const vendor = getVendor(value2);
  return !!vendor && jsonSchemaVendorNames.has(vendor);
}
function prepareArktypeType(type2) {
  let innerType = type2;
  while (innerType) {
    if (innerType?.in && innerType.in !== innerType) {
      innerType = innerType.in;
    } else {
      break;
    }
  }
  return innerType;
}

// node_modules/trpc-cli/dist/prompts.js
import { Argument, Command, Option } from "commander";
var parseUpstreamOptionInfo = (value2) => {
  if (typeof value2 !== "string" || !value2.startsWith("{"))
    return null;
  try {
    const info = JSON.parse(value2);
    if (info.typeName !== "UpstreamOptionInfo")
      return null;
    return info;
  } catch {
    return null;
  }
};
var parseUpstreamArgumentInfo = (value2) => {
  if (typeof value2 !== "string" || !value2.startsWith("{"))
    return null;
  try {
    const info = JSON.parse(value2);
    if (info.typeName !== "UpstreamArgumentInfo")
      return null;
    return info;
  } catch {
    return null;
  }
};
var getDefaultSubcommand = (command) => {
  const defaultChild = command.description().match(/Available subcommands:.* (\S+) \(default\)/)?.[1];
  return defaultChild ? command.commands.find((c) => c.name() === defaultChild) : void 0;
};
var createShadowCommand = (command, onAnalyze) => {
  const shadow = new Command(command.name());
  shadow.exitOverride();
  shadow.configureOutput({
    writeOut: () => {
    },
    writeErr: () => {
    }
  });
  const argumentsMap = /* @__PURE__ */ new Map();
  const optionsMap = /* @__PURE__ */ new Map();
  command.options.forEach((original) => {
    const id = Date.now().toString() + Math.random().toString().slice(1);
    const shadowOption = new Option(original.flags.replace("<", "[").replace(">", "]"), JSON.stringify([`id=${id}`, original.description]));
    const upstreamOptionInfo = { typeName: "UpstreamOptionInfo", id, specified: false };
    shadowOption.default(JSON.stringify(upstreamOptionInfo));
    shadowOption.argParser((value2) => JSON.stringify({ ...upstreamOptionInfo, specified: true, value: value2 }));
    shadow.addOption(shadowOption);
    optionsMap.set(id, { shadow: shadowOption, original });
  });
  command.registeredArguments.forEach((original) => {
    const shadowArgument = new Argument(original.name(), original.description);
    const id = Date.now().toString() + Math.random().toString().slice(1);
    shadowArgument.argOptional();
    const upstreamArgumentInfo = { typeName: "UpstreamArgumentInfo", id, specified: false };
    shadowArgument.default(JSON.stringify(upstreamArgumentInfo));
    shadowArgument.argParser((value2) => JSON.stringify({ ...upstreamArgumentInfo, specified: true, value: value2 }));
    shadow.addArgument(shadowArgument);
    argumentsMap.set(id, { shadow: shadowArgument, original });
  });
  const analysis = {
    command: { shadow, original: command },
    arguments: [],
    options: []
  };
  shadow.action(async (...args2) => {
    const positionalValues = args2.slice(0, -2);
    const options = shadow.opts();
    if (args2.at(-2) !== options) {
      throw new Error(`Unexpected args format, second last arg is not the options object`, { cause: args2 });
    }
    if (args2.at(-1) !== shadow) {
      throw new Error(`Unexpected args format, last arg is not the Command instance`, { cause: args2 });
    }
    positionalValues.forEach((value2) => {
      const argumentInfo = parseUpstreamArgumentInfo(value2);
      if (argumentInfo) {
        analysis.arguments.push({
          ...argumentsMap.get(argumentInfo.id),
          value: argumentInfo.value,
          specified: argumentInfo.specified
        });
      }
    });
    Object.values(options).forEach((value2) => {
      const upstreamOptionInfo = parseUpstreamOptionInfo(value2);
      if (upstreamOptionInfo) {
        analysis.options.push({
          ...optionsMap.get(upstreamOptionInfo.id),
          value: upstreamOptionInfo.value,
          specified: upstreamOptionInfo.specified
        });
      }
    });
    await onAnalyze(analysis);
  });
  command.commands.forEach((subcommand) => {
    const shadowSubcommand = createShadowCommand(subcommand, onAnalyze);
    shadow.addCommand(shadowSubcommand);
  });
  return shadow;
};
var inquirerPrompter = (prompts) => {
  return prompts;
};
var clackPrompter = (prompts) => {
  const clack = prompts;
  class ExitPromptError extends Error {
  }
  const throwOnCancel = (value2) => {
    if (clack.isCancel(value2))
      throw new ExitPromptError();
    return value2;
  };
  return {
    input: async (params) => {
      return clack.text({
        message: params.message,
        initialValue: params.default,
        defaultValue: params.default,
        placeholder: params.default,
        validate: params.validate ? (input) => {
          const result = params.validate(input);
          if (result === true)
            return void 0;
          if (result === false)
            return `Invalid input`;
          return result;
        } : void 0
      }).then(throwOnCancel);
    },
    checkbox: async (params) => {
      return clack.multiselect({
        message: params.message,
        options: params.choices.map((c) => ({
          label: c.name,
          value: c.value
        })),
        initialValues: params.choices.flatMap((c) => c.checked ? [c.value] : [])
      }).then(throwOnCancel);
    },
    confirm: async (params) => {
      return clack.confirm({
        message: params.message,
        initialValue: params.default
      }).then(throwOnCancel);
    },
    select: async (params) => {
      return clack.select({
        message: params.message,
        options: params.choices.map((sorc) => {
          const c = typeof sorc === "string" ? { name: sorc, value: sorc } : sorc;
          return {
            label: c.name,
            value: c.value,
            hint: c.description
          };
        }),
        initialValue: params.default
      }).then(throwOnCancel);
    }
  };
};
var promptsPrompter = (prompts) => {
  const p = prompts;
  function x() {
    return (value2) => value2.x;
  }
  return {
    input: async (params) => {
      return p({
        name: "x",
        type: "text",
        message: params.message,
        validate: params.validate,
        initial: params.default
      }).then(x());
    },
    confirm: async (params) => {
      return p({
        name: "x",
        type: "confirm",
        message: params.message,
        active: params.default ? "yes" : "no"
      }).then(x());
    },
    select: async (params) => {
      const choicesObjects = params.choices.map((c) => typeof c === "string" ? { name: c, value: c } : c);
      return p({
        name: "x",
        type: "select",
        message: params.message,
        active: params.default,
        choices: choicesObjects.map((c) => ({
          title: c.name || c.value,
          value: c.value
        })),
        initial: params.default ? choicesObjects.findIndex((c) => c.value === params.default) : void 0
      }).then(x());
    },
    checkbox: async (params) => {
      const choicesObjects = params.choices.map((c) => typeof c === "string" ? { name: c, value: c } : c);
      return p({
        name: "x",
        type: "multiselect",
        message: params.message,
        choices: choicesObjects.map((c) => ({
          title: c.name || c.value,
          value: c.value,
          selected: c.checked
        }))
      }).then(x());
    }
  };
};
var enquirerPrompter = (prompts) => {
  const enquirer = prompts;
  function x() {
    return (value2) => value2.x;
  }
  return {
    input: async (params) => {
      return enquirer.prompt({
        type: "input",
        name: "x",
        message: params.message,
        validate: params.validate,
        initial: params.default
      }).then(x());
    },
    confirm: async (params) => {
      return enquirer.prompt({
        type: "confirm",
        name: "x",
        message: params.message,
        validate: params.validate,
        initial: params.default
      }).then(x());
    },
    select: async (params) => {
      return enquirer.prompt({
        type: "select",
        name: "x",
        message: params.message,
        // @ts-expect-error not sure why this is an error, in the IDE it infers the type correctly
        choices: params.choices.slice(),
        validate: params.validate,
        initial: params.default
      }).then(x());
    },
    checkbox: async (params) => {
      return enquirer.prompt({
        type: "multiselect",
        name: "x",
        message: params.message,
        // @ts-expect-error not sure why this is an error, in the IDE it infers the type correctly
        choices: params.choices.slice().map((c) => ({
          name: c.name,
          value: c.value
        })),
        // validate: params.validate ? v => params.validate!([{value: v}]) : undefined,
        initial: params.choices.flatMap((c, i) => c.checked ? [i] : [])
      }).then(x());
    }
  };
};
var promptify = (program, prompts) => {
  let promptsInput = prompts;
  if (promptsInput?.default)
    promptsInput = promptsInput.default;
  let prompter;
  if (typeof promptsInput === "function" && typeof promptsInput.inject === "function") {
    prompter = promptsPrompter(promptsInput);
  } else if (promptsInput?.name === "Enquirer") {
    prompter = enquirerPrompter(promptsInput);
  } else if (typeof promptsInput?.rawlist === "function") {
    prompter = inquirerPrompter(promptsInput);
  } else if (typeof promptsInput?.intro === "function") {
    prompter = clackPrompter(promptsInput);
  } else if (typeof promptsInput === "function") {
    prompter = promptsInput(program);
  } else {
    prompter = promptsInput;
  }
  const command = program;
  const analyseThenParse = async (argv, parseOptions) => {
    if (parseOptions?.from === "electron") {
      console.warn(`Warning: using prompts in electron mode is untested. The first two args of $0 are not available in electron mode. Assuming that the first two args of ${JSON.stringify(argv)} are electron-related and not intended for the CLI.`);
    }
    if (parseOptions?.from !== "user") {
      argv = argv.slice(2);
      parseOptions = { from: "user" };
    }
    const f = { command, args: [...argv] };
    const nextArgv = [...f.args];
    let analysis = void 0;
    const maxAttempts = 100;
    for (let i = maxAttempts; i >= 0 && !analysis; i--) {
      analysis = await new Promise((resolve3, reject) => {
        const shadow = createShadowCommand(f.command, async (an) => {
          if (an.command.original.commands.length === 0) {
            resolve3(an);
            return;
          }
          const defaultSubcommand = getDefaultSubcommand(an.command.original);
          if (defaultSubcommand) {
            resolve3(an);
            return;
          }
          const name16 = await prompter.select({
            message: `Select a ${an.command.original.name() || ""} subcommand`.replace("  ", " "),
            choices: an.command.original.commands.map((c) => ({
              name: c.name(),
              value: c.name(),
              description: c.description()
            }))
          }, {});
          nextArgv.push(name16);
          resolve3(void 0);
        });
        shadow.parseAsync(nextArgv, parseOptions).catch((e) => {
          if (e?.constructor?.name === "CommanderError") {
            resolve3({
              command: { shadow: f.command, original: f.command },
              arguments: [],
              options: []
            });
          } else {
            reject(e);
          }
        });
      });
    }
    if (!analysis) {
      const message = `Failed to find a subcommand after ${maxAttempts} attempts - failing to avoid an infinite loop. This is probably a bug in trpc-cli.`;
      throw new Error(message);
    }
    const getMessage = (argOrOpt) => {
      const name16 = "long" in argOrOpt ? argOrOpt.flags : `[${argOrOpt.name()}]`;
      const parts = [
        name16,
        argOrOpt.description,
        argOrOpt.defaultValue && `(default: ${argOrOpt.defaultValue})`,
        !argOrOpt.defaultValue && !argOrOpt.required && "(optional)"
      ];
      return parts.filter(Boolean).join(" ").trim() + ":";
    };
    const baseContext = {
      command: analysis.command.original,
      inputs: {
        argv,
        arguments: analysis.arguments.map((a) => ({ name: a.original.name(), specified: a.specified, value: a.value })),
        options: analysis.options.map((o) => ({ name: o.original.name(), specified: o.specified, value: o.value }))
      }
    };
    await prompter.setup?.(baseContext);
    const procedureMeta = analysis.command.original.__trpcCli?.meta;
    let shouldPrompt;
    if (typeof procedureMeta?.prompt === "boolean") {
      shouldPrompt = procedureMeta.prompt;
    } else {
      const someRequiredArgsUnspecified = analysis.arguments.some((a) => a.original.required && !a.specified);
      const someRequiredOptionsUnspecified = analysis.options.some((o) => o.original.required && !o.specified);
      shouldPrompt = someRequiredArgsUnspecified || someRequiredOptionsUnspecified;
    }
    if (shouldPrompt) {
      for (const arg of analysis.arguments) {
        const ctx = { ...baseContext, argument: arg.original };
        if (!arg.specified) {
          const parseArg = "parseArg" in arg.original && typeof arg.original.parseArg === "function" ? arg.original.parseArg : void 0;
          const promptedValue = await prompter.input({
            message: getMessage(arg.original),
            required: arg.original.required,
            default: arg.value,
            validate: (input) => {
              try {
                parseArg?.(input);
                return true;
              } catch (e) {
                return `${e?.message || e}`;
              }
            }
          }, ctx);
          nextArgv.push(promptedValue);
        }
      }
      for (const option of analysis.options) {
        const ctx = { ...baseContext, option: option.original };
        if (!option.specified) {
          const fullFlag = option.original.long || `--${option.original.name()}`;
          const isBoolean = option.original.isBoolean() || option.original.flags.includes("[boolean]");
          if (isBoolean) {
            const promptedValue = await prompter.confirm({
              message: getMessage(option.original),
              default: option.original.defaultValue ?? false
            }, ctx);
            if (promptedValue)
              nextArgv.push(fullFlag);
          } else if (option.original.variadic && option.original.argChoices) {
            const choices = option.original.argChoices.slice();
            const results = await prompter.checkbox({
              message: getMessage(option.original),
              choices: choices.map((choice) => ({
                value: choice,
                name: choice,
                checked: true
              }))
            }, ctx);
            results.forEach((result) => {
              if (typeof result === "string")
                nextArgv.push(fullFlag, result);
            });
          } else if (option.original.argChoices) {
            const choices = option.original.argChoices.slice();
            const set = new Set(choices);
            const promptedValue = await prompter.select({
              message: getMessage(option.original),
              choices,
              default: option.original.defaultValue
              // required: option.original.required,
            }, ctx);
            if (set.has(promptedValue)) {
              nextArgv.push(fullFlag, promptedValue);
            }
          } else if (option.original.variadic) {
            const values = [];
            do {
              const promptedValue = await prompter.input({
                message: getMessage(option.original),
                default: option.original.defaultValue?.[values.length]
              }, ctx);
              if (!promptedValue)
                break;
              values.push(fullFlag, promptedValue);
            } while (values);
            nextArgv.push(...values);
          } else {
            const getParsedValue = (input) => {
              return option.original.parseArg ? option.original.parseArg(input, void 0) : input;
            };
            const promptedValue = await prompter.input({
              message: getMessage(option.original),
              default: option.value,
              required: option.original.required,
              validate: (input) => {
                const parsed = getParsedValue(input);
                if (parsed == null && input != null)
                  return "Invalid value";
                return true;
              }
            }, ctx);
            if (promptedValue)
              nextArgv.push(fullFlag, getParsedValue(promptedValue) ?? promptedValue);
          }
        }
      }
    }
    await prompter.teardown?.(baseContext);
    return f.command.parseAsync(nextArgv, parseOptions);
  };
  const parseAsync = (args2, parseOptions) => analyseThenParse(args2, parseOptions).catch((e) => {
    if (e?.constructor?.name === "ExitPromptError")
      return;
    throw e;
  });
  return new Proxy(program, {
    get(target, prop, receiver) {
      if (prop === "parseAsync")
        return parseAsync;
      return Reflect.get(target, prop, receiver);
    }
  });
};

// node_modules/trpc-cli/dist/standard-schema/utils.js
var looksLikeStandardSchemaFailure = (error) => {
  return !!error && typeof error === "object" && "issues" in error && Array.isArray(error.issues);
};

// node_modules/trpc-cli/dist/standard-schema/errors.js
var prettifyStandardSchemaError = (error) => {
  if (!looksLikeStandardSchemaFailure(error))
    return null;
  const issues = [...error.issues].map((issue) => {
    const path21 = issue.path || [];
    const primitivePathSegments = path21.map((segment) => {
      if (typeof segment === "string" || typeof segment === "number" || typeof segment === "symbol")
        return segment;
      return segment.key;
    });
    const dotPath = toDotPath(primitivePathSegments);
    return {
      issue,
      path: path21,
      primitivePathSegments,
      dotPath
    };
  }).sort((a, b) => a.path.length - b.path.length);
  const lines = [];
  for (const { issue, dotPath } of issues) {
    let message = `\u2716 ${issue.message}`;
    if (dotPath)
      message += ` \u2192 at ${dotPath}`;
    lines.push(message);
  }
  return lines.join("\n");
};
function toDotPath(path21) {
  const segs = [];
  for (const seg of path21) {
    if (typeof seg === "number")
      segs.push(`[${seg}]`);
    else if (typeof seg === "symbol")
      segs.push(`[${JSON.stringify(String(seg))}]`);
    else if (/[^\w$]/.test(seg))
      segs.push(`[${JSON.stringify(seg)}]`);
    else {
      if (segs.length)
        segs.push(".");
      segs.push(seg);
    }
  }
  return segs.join("");
}

// node_modules/trpc-cli/dist/trpc-compat.js
var isOrpcRouter = (router2) => {
  const values = [];
  for (const v of Object.values(router2)) {
    if (typeof v === "function")
      return false;
    values.push(v);
  }
  return values.every((v) => isOrpcProcedure(v) || isOrpcRouter(v));
};
var isOrpcProcedure = (procedure) => {
  return typeof procedure === "object" && "~orpc" in procedure && typeof procedure["~orpc"] === "object";
};

// node_modules/trpc-cli/dist/util.js
var looksLikeInstanceof = (value2, target) => {
  let current = value2?.constructor;
  while (current?.name) {
    if (current?.name === (typeof target === "string" ? target : target.name))
      return true;
    current = Object.getPrototypeOf(current);
  }
  return false;
};

// node_modules/trpc-cli/dist/index.js
var orpcServerOrError = await Promise.resolve().then(() => (init_dist5(), dist_exports)).catch(String);
var getOrpcServerModule = () => {
  if (typeof orpcServerOrError === "string") {
    throw new Error(`@orpc/server must be installed. Error loading: ${orpcServerOrError}`);
  }
  return orpcServerOrError;
};
var Command2 = class extends BaseCommand {
  /** @internal track the commands that have been run, so that we can find the `__result` of the last command */
  __ran = [];
  __input;
  /** @internal stash the return value of the underlying procedure on the command so to pass to `FailedToExitError` for use in a pinch */
  __result;
};
var parseRouter = ({ router: router2, ...params }) => {
  if (isOrpcRouter(router2))
    return parseOrpcRouter({ router: router2, ...params });
  return parseTrpcRouter({ router: router2, ...params });
};
var parseTrpcRouter = ({ router: router2, ...params }) => {
  const defEntries = Object.entries(router2._def.procedures);
  return defEntries.map(([procedurePath, procedure]) => {
    const meta = getMeta(procedure);
    if (meta.jsonInput) {
      return [procedurePath, { meta, parsedProcedure: jsonProcedureInputs(), incompatiblePairs: [], procedure }];
    }
    const procedureInputsResult = parseProcedureInputs(procedure._def.inputs, params);
    if (!procedureInputsResult.success) {
      const procedureInputs2 = jsonProcedureInputs(`procedure's schema couldn't be converted to CLI arguments: ${procedureInputsResult.error}`);
      return [procedurePath, { meta, parsedProcedure: procedureInputs2, incompatiblePairs: [], procedure }];
    }
    const procedureInputs = procedureInputsResult.value;
    const incompatiblePairs = incompatiblePropertyPairs(procedureInputs.optionsJsonSchema);
    return [procedurePath, { meta: getMeta(procedure), parsedProcedure: procedureInputs, incompatiblePairs, procedure }];
  });
};
var parseOrpcRouter = (params) => {
  const entries = [];
  const { traverseContractProcedures: traverseContractProcedures2, isProcedure: isProcedure2 } = getOrpcServerModule();
  const router2 = params.router;
  const lazyRoutes = traverseContractProcedures2({ path: [], router: router2 }, ({ contract, path: path21 }) => {
    let procedure = params.router;
    for (const p of path21)
      procedure = procedure[p];
    if (!isProcedure2(procedure))
      return;
    const procedureInputsResult = parseProcedureInputs([contract["~orpc"].inputSchema], {
      "@valibot/to-json-schema": params["@valibot/to-json-schema"],
      effect: params.effect
    });
    const procedurePath = path21.join(".");
    const procedureish = { _def: { meta: contract["~orpc"].meta } };
    const meta = getMeta(procedureish);
    if (meta.jsonInput) {
      entries.push([procedurePath, { meta, parsedProcedure: jsonProcedureInputs(), incompatiblePairs: [], procedure }]);
      return;
    }
    if (!procedureInputsResult.success) {
      const parsedProcedure2 = jsonProcedureInputs(`procedure's schema couldn't be converted to CLI arguments: ${procedureInputsResult.error}`);
      entries.push([procedurePath, { meta, parsedProcedure: parsedProcedure2, incompatiblePairs: [], procedure }]);
      return;
    }
    const parsedProcedure = procedureInputsResult.value;
    const incompatiblePairs = incompatiblePropertyPairs(parsedProcedure.optionsJsonSchema);
    entries.push([procedurePath, { procedure, meta, incompatiblePairs, parsedProcedure }]);
  });
  if (lazyRoutes.length) {
    const suggestion = `Please use \`import {unlazyRouter} from '@orpc/server'\` to unlazy the router before passing it to trpc-cli`;
    const routes = lazyRoutes.map(({ path: path21 }) => path21.join(".")).join(", ");
    throw new Error(`Lazy routers are not supported. ${suggestion}. Lazy routes detected: ${routes}`);
  }
  return entries;
};
var jsonProcedureInputs = (reason) => {
  let description = `Input formatted as JSON`;
  if (reason)
    description += ` (${reason})`;
  return {
    positionalParameters: [],
    optionsJsonSchema: {
      type: "object",
      properties: {
        input: { description }
        // omit `type` - this is json input, it could be anything
      }
    },
    getPojoInput: (parsedCliParams) => parsedCliParams.options.input
  };
};
function createCli({ router: router2, ...params }) {
  const procedureEntries = parseRouter({ router: router2, ...params });
  function buildProgram(runParams) {
    const logger = { ...lineByLineConsoleLogger, ...runParams?.logger };
    const program = new Command2(params.name);
    if (params.version)
      program.version(params.version);
    if (params.description)
      program.description(params.description);
    if (params.usage)
      [params.usage].flat().forEach((usage) => program.usage(usage));
    program.showHelpAfterError();
    program.showSuggestionAfterError();
    const commandTree = {
      "": program
      // Root level
    };
    const defaultCommands = {};
    const _process = runParams?.process || process;
    const configureCommand = (command, procedurePath, { meta, parsedProcedure, incompatiblePairs, procedure }) => {
      Object.assign(command, { __trpcCli: { path: procedurePath, meta } });
      const optionJsonSchemaProperties = flattenedProperties(parsedProcedure.optionsJsonSchema);
      command.exitOverride((ec) => {
        _process.exit(ec.exitCode);
        throw new FailedToExitError(`Command ${command.name()} exitOverride`, { exitCode: ec.exitCode, cause: ec });
      });
      command.configureOutput({
        writeOut: (str) => {
          logger.info?.(str);
        },
        writeErr: (str) => {
          logger.error?.(str);
        }
      });
      command.showHelpAfterError();
      if (meta.usage)
        command.usage([meta.usage].flat().join("\n"));
      if (meta.examples)
        command.addHelpText("after", `
Examples:
${[meta.examples].flat().join("\n")}`);
      meta?.aliases?.command?.forEach((alias) => {
        command.alias(alias);
      });
      command.description(meta?.description || "");
      parsedProcedure.positionalParameters.forEach((param) => {
        const descriptionParts = [
          param.type === "string" ? "" : param.type,
          // "string" is the default assumption, don't bother showing it
          param.description,
          param.required ? "(required)" : ""
        ];
        const argument = new Argument2(param.name, descriptionParts.filter(Boolean).join(" "));
        if (param.type === "number") {
          argument.argParser((value2) => {
            const number = numberParser(value2, { fallback: null });
            if (number == null)
              throw new InvalidArgumentError(`Invalid number: ${value2}`);
            return value2;
          });
        }
        argument.required = param.required;
        argument.variadic = param.array;
        command.addArgument(argument);
      });
      const unusedOptionAliases = { ...meta.aliases?.options };
      const addOptionForProperty = ([propertyKey, propertyValue]) => {
        class Option2 extends BaseOption {
          attributeName() {
            return propertyKey;
          }
        }
        const description = getDescription(propertyValue);
        const longOption = `--${kebabCase(propertyKey)}`;
        let flags = longOption;
        const alias = propertyValue && "alias" in propertyValue && typeof propertyValue.alias === "string" ? propertyValue.alias : meta.aliases?.options?.[propertyKey];
        if (alias) {
          let prefix = "-";
          if (alias.startsWith("-"))
            prefix = "";
          else if (alias.length > 1)
            prefix = "--";
          flags = `${prefix}${alias}, ${flags}`;
          delete unusedOptionAliases[propertyKey];
        }
        const allowedSchemas = getAllowedSchemas(propertyValue);
        const firstSchemaWithDefault = allowedSchemas.find((subSchema) => "default" in subSchema);
        const defaultValue = firstSchemaWithDefault ? { exists: true, value: firstSchemaWithDefault.default } : { exists: false };
        const rootTypes = getSchemaTypes(propertyValue).sort();
        const propertyType = rootTypes[0];
        const isValueRequired = "required" in parsedProcedure.optionsJsonSchema && parsedProcedure.optionsJsonSchema.required?.includes(propertyKey);
        const isCliOptionRequired = isValueRequired && propertyType !== "boolean" && !defaultValue.exists;
        function negate() {
          const shouldNegate = "negatable" in propertyValue ? propertyValue.negatable : meta.negateBooleans;
          if (shouldNegate) {
            const negation = new Option2(longOption.replace("--", "--no-"), `Negate \`${longOption}\` option.`.trim());
            command.addOption(negation);
          }
        }
        const bracketise = (name16) => isCliOptionRequired ? `<${name16}>` : `[${name16}]`;
        if (allowedSchemas.length > 1) {
          const option2 = new Option2(`${flags} [value]`, description);
          if (defaultValue.exists)
            option2.default(defaultValue.value);
          else if (rootTypes.includes("boolean"))
            option2.default(false);
          option2.argParser(getOptionValueParser(propertyValue));
          command.addOption(option2);
          if (rootTypes.includes("boolean"))
            negate();
          return;
        }
        if (rootTypes.length !== 1) {
          const option2 = new Option2(`${flags} ${bracketise("json")}`, description);
          option2.argParser(getOptionValueParser(propertyValue));
          command.addOption(option2);
          return;
        }
        if (propertyType === "boolean") {
          const option2 = new Option2(`${flags} [boolean]`, description);
          option2.argParser((value2) => booleanParser(value2));
          if (isValueRequired)
            option2.default(false);
          else if (defaultValue.exists)
            option2.default(defaultValue.value);
          command.addOption(option2);
          negate();
          return;
        }
        let option = null;
        if (propertyType === "string") {
          option = new Option2(`${flags} ${bracketise("string")}`, description);
        } else if (propertyType === "boolean") {
          option = new Option2(flags, description);
        } else if (propertyType === "number" || propertyType === "integer") {
          option = new Option2(`${flags} ${bracketise("number")}`, description);
          option.argParser((value2) => numberParser(value2, { fallback: null }));
        } else if (propertyType === "array") {
          option = new Option2(`${flags} [values...]`, description);
          if (defaultValue.exists)
            option.default(defaultValue.value);
          else if (isValueRequired)
            option.default([]);
          const itemsSchema = "items" in propertyValue ? propertyValue.items : {};
          const itemEnumTypes = getEnumChoices(itemsSchema);
          if (itemEnumTypes?.type === "string_enum") {
            option.choices(itemEnumTypes.choices);
          }
          const itemParser = getOptionValueParser(itemsSchema);
          if (itemParser) {
            option.argParser((value2, previous) => {
              const parsed = itemParser(value2);
              return Array.isArray(previous) ? [...previous, parsed] : [parsed];
            });
          }
        }
        if (!option) {
          option = new Option2(`${flags} [json]`, description);
          option.argParser((value2) => parseJson(value2, InvalidOptionArgumentError));
        }
        if (defaultValue.exists && option.defaultValue !== defaultValue.value) {
          option.default(defaultValue.value);
        }
        if (option.flags.includes("<")) {
          option.makeOptionMandatory();
        }
        const enumChoices = getEnumChoices(propertyValue);
        if (enumChoices?.type === "string_enum") {
          option.choices(enumChoices.choices);
        }
        option.conflicts(incompatiblePairs.flatMap((pair) => {
          const filtered = pair.filter((p) => p !== propertyKey);
          if (filtered.length === pair.length)
            return [];
          return filtered;
        }));
        command.addOption(option);
        if (propertyType === "boolean")
          negate();
      };
      Object.entries(optionJsonSchemaProperties).forEach(addOptionForProperty);
      const invalidOptionAliases = Object.entries(unusedOptionAliases).map(([option, alias]) => `${option}: ${alias}`);
      if (invalidOptionAliases.length) {
        throw new Error(`Invalid option aliases: ${invalidOptionAliases.join(", ")}`);
      }
      command.action(async (...args2) => {
        program.__ran ||= [];
        program.__ran.push(command);
        const options = command.opts();
        if (args2.at(-2) !== options) {
          throw new Error(`Unexpected args format, second last arg is not the options object`, { cause: args2 });
        }
        if (args2.at(-1) !== command) {
          throw new Error(`Unexpected args format, last arg is not the Command instance`, { cause: args2 });
        }
        const positionalValues = args2.slice(0, -2);
        const input = parsedProcedure.getPojoInput({ positionalValues, options });
        let caller;
        const deprecatedCreateCaller = Reflect.get(params, "createCallerFactory");
        if (deprecatedCreateCaller) {
          const message = `Using deprecated \`createCallerFactory\` option. Use \`trpcServer\` instead. e.g. \`createCli({router: myRouter, trpcServer: import('@trpc/server')})\``;
          logger.error?.(message);
          caller = deprecatedCreateCaller(router2)(params.context);
        } else if (isOrpcRouter(router2)) {
          const { call: call2 } = getOrpcServerModule();
          caller = { [procedurePath]: (_input) => call2(procedure, _input, { context: params.context }) };
        } else {
          const resolvedTrpcServer = await (params.trpcServer || await import("@trpc/server"));
          const createCallerFactor = resolvedTrpcServer.initTRPC.create().createCallerFactory;
          caller = createCallerFactor(router2)(params.context);
        }
        const result = await caller[procedurePath](input).catch((err) => {
          throw transformError(err, command);
        });
        command.__result = result;
        if (result != null)
          logger.info?.(result);
      });
    };
    procedureEntries.forEach(([procedurePath, commandConfig]) => {
      const segments = procedurePath.split(".");
      let currentPath = "";
      for (let i = 0; i < segments.length - 1; i++) {
        const segment = segments[i];
        const parentPath2 = currentPath;
        currentPath = currentPath ? `${currentPath}.${segment}` : segment;
        if (!commandTree[currentPath]) {
          const parentCommand2 = commandTree[parentPath2];
          const newCommand = new Command2(kebabCase(segment));
          newCommand.showHelpAfterError();
          parentCommand2.addCommand(newCommand);
          commandTree[currentPath] = newCommand;
        }
      }
      const leafName = segments.at(-1);
      const parentPath = segments.length > 1 ? segments.slice(0, -1).join(".") : "";
      const parentCommand = commandTree[parentPath];
      const leafCommand = new Command2(leafName && kebabCase(leafName));
      configureCommand(leafCommand, procedurePath, commandConfig);
      parentCommand.addCommand(leafCommand);
      const meta = commandConfig.meta;
      if (meta.default === true) {
        parentCommand.allowExcessArguments();
        parentCommand.allowUnknownOption();
        parentCommand.addHelpText("after", leafCommand.helpInformation());
        parentCommand.action(async () => {
          await leafCommand.parseAsync([...parentCommand.args], { from: "user" });
        });
        defaultCommands[parentPath] = {
          procedurePath,
          config: commandConfig,
          command: leafCommand
        };
      }
    });
    Object.entries(commandTree).forEach(([path21, command]) => {
      if (command.commands.length === 0)
        return;
      const subcommandNames = command.commands.map((cmd) => cmd.name());
      const defaultCommand = defaultCommands[path21]?.command.name();
      const formattedSubcommands = subcommandNames.map((name16) => name16 === defaultCommand ? `${name16} (default)` : name16).join(", ");
      const existingDescription = command.description() || "";
      const descriptionParts = [existingDescription, `Available subcommands: ${formattedSubcommands}`];
      command.description(descriptionParts.filter(Boolean).join("\n"));
    });
    return program;
  }
  const run = async (runParams, program = buildProgram(runParams)) => {
    if (!looksLikeInstanceof(program, "Command"))
      throw new Error(`program is not a Command instance`);
    const opts = runParams?.argv ? { from: "user" } : void 0;
    const argv = [...runParams?.argv || process.argv];
    const _process = runParams?.process || process;
    const logger = { ...lineByLineConsoleLogger, ...runParams?.logger };
    program.exitOverride((exit) => {
      _process.exit(exit.exitCode);
      throw new FailedToExitError("Root command exitOverride", { exitCode: exit.exitCode, cause: exit });
    });
    program.configureOutput({
      writeOut: (str) => logger.info?.(str),
      writeErr: (str) => logger.error?.(str)
    });
    if (runParams?.completion) {
      const completion = typeof runParams.completion === "function" ? await runParams.completion() : runParams.completion;
      addCompletions(program, completion);
    }
    const formatError3 = runParams?.formatError || ((err) => {
      if (err instanceof CliValidationError) {
        return err.message;
      }
      return inspect2(err);
    });
    if (runParams?.prompts) {
      program = promptify(program, runParams.prompts);
    }
    await program.parseAsync(argv, opts).catch((err) => {
      if (err instanceof FailedToExitError)
        throw err;
      const logMessage = looksLikeInstanceof(err, Error) ? formatError3(err) || err.message : `Non-error of type ${typeof err} thrown: ${err}`;
      logger.error?.(logMessage);
      _process.exit(1);
      throw new FailedToExitError(`Program exit after failure`, { exitCode: 1, cause: err });
    });
    _process.exit(0);
    throw new FailedToExitError("Program exit after success", {
      exitCode: 0,
      cause: program.__ran.at(-1)?.__result
    });
  };
  return { run, buildProgram, toJSON: (program = buildProgram()) => commandToJSON(program) };
}
function getMeta(procedure) {
  const meta = procedure._def.meta;
  return meta?.cliMeta || meta || {};
}
var kebabCase = (str) => str.replaceAll(/([\da-z])([A-Z])/g, "$1-$2").replaceAll(/([A-Z]+)([A-Z][a-z])/g, "$1-$2").toLowerCase();
function transformError(err, command) {
  if (looksLikeInstanceof(err, Error) && err.message.includes("This is a client-only function")) {
    return new Error("Failed to create trpc caller. If using trpc v10, either upgrade to v11 or pass in the `@trpc/server` module to `createCli` explicitly");
  }
  if (looksLikeInstanceof(err, "TRPCError")) {
    const cause = err.cause;
    if (looksLikeStandardSchemaFailure(cause)) {
      const prettyMessage = prettifyStandardSchemaError(cause);
      return new CliValidationError(prettyMessage + "\n\n" + command.helpInformation());
    }
    if (err.code === "BAD_REQUEST" && (err.cause?.constructor?.name === "TraversalError" || // arktype error
    err.cause?.constructor?.name === "StandardSchemaV1Error")) {
      return new CliValidationError(err.cause.message + "\n\n" + command.helpInformation());
    }
    if (err.code === "INTERNAL_SERVER_ERROR") {
      return cause;
    }
  }
  return err;
}
var numberParser = (val, { fallback = val } = {}) => {
  const number = Number(val);
  return Number.isNaN(number) ? fallback : number;
};
var booleanParser = (val, { fallback = val } = {}) => {
  if (val === "true")
    return true;
  if (val === "false")
    return false;
  return fallback;
};
var getOptionValueParser = (schema) => {
  const allowedSchemas = getAllowedSchemas(schema).slice().sort((a, b) => String(getSchemaTypes(a)[0]).localeCompare(String(getSchemaTypes(b)[0])));
  const typesArray = allowedSchemas.flatMap(getSchemaTypes);
  const types = new Set(typesArray);
  return (value2) => {
    const definitelyPrimitive = typesArray.every((t) => t === "boolean" || t === "number" || t === "integer" || t === "string");
    if (types.size === 0 || !definitelyPrimitive) {
      const hint = `Malformed JSON. If passing a string, pass it as a valid JSON string with quotes (${JSON.stringify(value2)})`;
      const parsed = parseJson(value2, InvalidOptionArgumentError, hint);
      if (!types.size)
        return parsed;
      const jsonSchemaType = Array.isArray(parsed) ? "array" : parsed === null ? "null" : typeof parsed;
      if (!types.has(jsonSchemaType)) {
        throw new InvalidOptionArgumentError(`Got ${jsonSchemaType} but expected ${[...types].join(" or ")}`);
      }
      return parsed;
    }
    if (types.has("boolean")) {
      const parsed = booleanParser(value2, { fallback: null });
      if (typeof parsed === "boolean")
        return parsed;
    }
    if (types.has("number")) {
      const parsed = numberParser(value2, { fallback: null });
      if (typeof parsed === "number")
        return parsed;
    }
    if (types.has("integer")) {
      const parsed = numberParser(value2, { fallback: null });
      if (typeof parsed === "number" && Number.isInteger(parsed))
        return parsed;
    }
    if (types.has("string")) {
      return value2;
    }
    throw new InvalidOptionArgumentError(`Got ${JSON.stringify(value2)} but expected ${[...types].join(" or ")}`);
  };
};
var parseJson = (value2, ErrorClass = InvalidArgumentError, hint = `Malformed JSON.`) => {
  try {
    return JSON.parse(value2);
  } catch {
    throw new ErrorClass(hint);
  }
};

// src/node/orpc/router.ts
init_dist5();

// src/common/orpc/schemas/result.ts
import { z } from "zod";
var ResultSchema = (dataSchema, errorSchema = z.string()) => z.discriminatedUnion("success", [
  z.object({ success: z.literal(true), data: dataSchema }),
  z.object({ success: z.literal(false), error: errorSchema })
]);

// src/common/orpc/schemas/runtime.ts
import { z as z3 } from "zod";

// src/common/orpc/schemas/lattice.ts
import { z as z2 } from "zod";
var LatticeWorkspaceConfigSchema = z2.object({
  /**
   * Lattice workspace name.
   * - For new workspaces: omit or undefined (backend derives from unix branch name)
   * - For existing workspaces: required (the selected Lattice workspace name)
   * - After creation: populated with the actual Lattice workspace name for reference
   */
  workspaceName: z2.string().optional().meta({ description: "Lattice workspace name" }),
  template: z2.string().optional().meta({ description: "Template used to create workspace" }),
  templateOrg: z2.string().optional().meta({
    description: "Template organization (for disambiguation when templates have same name)"
  }),
  preset: z2.string().optional().meta({ description: "Preset used during creation" }),
  /** True if connected to pre-existing Lattice workspace (vs unix creating one). */
  existingWorkspace: z2.boolean().optional().meta({
    description: "True if connected to pre-existing Lattice workspace"
  })
});
var LatticeUnavailableReasonSchema = z2.union([
  z2.literal("missing"),
  z2.object({ kind: z2.literal("error"), message: z2.string() })
]);
var LatticeInfoSchema = z2.discriminatedUnion("state", [
  z2.object({ state: z2.literal("available"), version: z2.string() }),
  z2.object({ state: z2.literal("outdated"), version: z2.string(), minVersion: z2.string() }),
  z2.object({ state: z2.literal("unavailable"), reason: LatticeUnavailableReasonSchema })
]);
var LatticeTemplateSchema = z2.object({
  name: z2.string(),
  displayName: z2.string(),
  organizationName: z2.string()
});
var LatticePresetSchema = z2.object({
  id: z2.string(),
  name: z2.string(),
  description: z2.string().optional(),
  isDefault: z2.boolean()
});
var LatticeWorkspaceStatusSchema = z2.enum([
  "running",
  "stopped",
  "starting",
  "stopping",
  "failed",
  "pending",
  "canceling",
  "canceled",
  "deleting",
  "deleted"
]);
var LatticeWorkspaceSchema = z2.object({
  name: z2.string(),
  templateName: z2.string(),
  templateDisplayName: z2.string(),
  status: LatticeWorkspaceStatusSchema
});
var lattice = {
  getInfo: {
    input: z2.void(),
    output: LatticeInfoSchema
  },
  listTemplates: {
    input: z2.void(),
    output: z2.array(LatticeTemplateSchema)
  },
  listPresets: {
    input: z2.object({
      template: z2.string(),
      org: z2.string().optional().meta({ description: "Organization name for disambiguation" })
    }),
    output: z2.array(LatticePresetSchema)
  },
  listWorkspaces: {
    input: z2.void(),
    output: z2.array(LatticeWorkspaceSchema)
  }
};

// src/common/orpc/schemas/runtime.ts
var RuntimeModeSchema = z3.enum(["local", "worktree", "ssh", "docker", "devcontainer"]);
var bgOutputDirField = z3.string().optional().meta({ description: "Directory for background process output (e.g., /tmp/unix-bashes)" });
var DevcontainerConfigInfoSchema = z3.object({
  path: z3.string(),
  label: z3.string()
});
var RuntimeAvailabilityStatusSchema = z3.union([
  // Devcontainer-specific: available with configs (must be first to preserve configs)
  z3.object({
    available: z3.literal(true),
    configs: z3.array(DevcontainerConfigInfoSchema),
    cliVersion: z3.string().optional()
  }),
  // Generic: available without extra data
  z3.object({ available: z3.literal(true) }),
  // Unavailable with reason
  z3.object({ available: z3.literal(false), reason: z3.string() })
]);
var RuntimeAvailabilitySchema = z3.object({
  local: RuntimeAvailabilityStatusSchema,
  worktree: RuntimeAvailabilityStatusSchema,
  ssh: RuntimeAvailabilityStatusSchema,
  docker: RuntimeAvailabilityStatusSchema,
  devcontainer: RuntimeAvailabilityStatusSchema
});
var RuntimeConfigSchema = z3.union([
  // Legacy local with srcBaseDir (treated as worktree)
  z3.object({
    type: z3.literal("local"),
    srcBaseDir: z3.string().meta({
      description: "Base directory where all workspaces are stored (legacy worktree config)"
    }),
    bgOutputDir: bgOutputDirField
  }),
  // New project-dir local (no srcBaseDir)
  z3.object({
    type: z3.literal("local"),
    bgOutputDir: bgOutputDirField
  }),
  // Explicit worktree runtime
  z3.object({
    type: z3.literal("worktree"),
    srcBaseDir: z3.string().meta({ description: "Base directory where all workspaces are stored (e.g., ~/.unix/src)" }),
    bgOutputDir: bgOutputDirField
  }),
  // SSH runtime
  z3.object({
    type: z3.literal("ssh"),
    host: z3.string().meta({ description: "SSH host (can be hostname, user@host, or SSH config alias)" }),
    srcBaseDir: z3.string().meta({ description: "Base directory on remote host where all workspaces are stored" }),
    bgOutputDir: bgOutputDirField,
    identityFile: z3.string().optional().meta({ description: "Path to SSH private key (if not using ~/.ssh/config or ssh-agent)" }),
    port: z3.number().optional().meta({ description: "SSH port (default: 22)" }),
    lattice: LatticeWorkspaceConfigSchema.optional().meta({
      description: "Lattice workspace configuration (when using Lattice as SSH backend)"
    })
  }),
  // Docker runtime - each workspace runs in its own container
  z3.object({
    type: z3.literal("docker"),
    image: z3.string().meta({ description: "Docker image to use (e.g., node:20)" }),
    containerName: z3.string().optional().meta({ description: "Container name (populated after workspace creation)" }),
    shareCredentials: z3.boolean().optional().meta({
      description: "Forward SSH agent and mount ~/.gitconfig read-only"
    })
  }),
  // Devcontainer runtime - uses devcontainer CLI to build/run containers from devcontainer.json
  z3.object({
    type: z3.literal("devcontainer"),
    configPath: z3.string().meta({ description: "Path to devcontainer.json (relative to project root)" }),
    shareCredentials: z3.boolean().optional().meta({
      description: "Forward SSH agent and mount ~/.gitconfig read-only"
    })
  })
]);

// src/common/orpc/schemas/project.ts
import { z as z6 } from "zod";

// src/common/orpc/schemas/mcp.ts
import { z as z4 } from "zod";
var WorkspaceMCPOverridesSchema = z4.object({
  /** Server names to explicitly disable for this workspace. */
  disabledServers: z4.array(z4.string()).optional(),
  /** Server names to explicitly enable for this workspace (overrides project-level disabled). */
  enabledServers: z4.array(z4.string()).optional(),
  /**
   * Per-server tool allowlist.
   * Key: server name (from .unix/mcp.jsonc)
   * Value: raw MCP tool names (NOT namespaced)
   *
   * If omitted for a server => expose all tools from that server.
   * If present but empty => expose no tools from that server.
   */
  toolAllowlist: z4.record(z4.string(), z4.array(z4.string())).optional()
});
var MCPTransportSchema = z4.enum(["stdio", "http", "sse", "auto"]);
var MCPHeaderValueSchema = z4.union([z4.string(), z4.object({ secret: z4.string() })]);
var MCPHeadersSchema = z4.record(z4.string(), MCPHeaderValueSchema);
var MCPServerInfoSchema = z4.discriminatedUnion("transport", [
  z4.object({
    transport: z4.literal("stdio"),
    command: z4.string(),
    disabled: z4.boolean(),
    toolAllowlist: z4.array(z4.string()).optional()
  }),
  z4.object({
    transport: z4.literal("http"),
    url: z4.string(),
    headers: MCPHeadersSchema.optional(),
    disabled: z4.boolean(),
    toolAllowlist: z4.array(z4.string()).optional()
  }),
  z4.object({
    transport: z4.literal("sse"),
    url: z4.string(),
    headers: MCPHeadersSchema.optional(),
    disabled: z4.boolean(),
    toolAllowlist: z4.array(z4.string()).optional()
  }),
  z4.object({
    transport: z4.literal("auto"),
    url: z4.string(),
    headers: MCPHeadersSchema.optional(),
    disabled: z4.boolean(),
    toolAllowlist: z4.array(z4.string()).optional()
  })
]);
var MCPServerMapSchema = z4.record(z4.string(), MCPServerInfoSchema);
var MCPAddParamsSchema = z4.object({
  projectPath: z4.string(),
  name: z4.string(),
  // Backward-compatible: if transport omitted, interpret as stdio.
  transport: MCPTransportSchema.optional(),
  command: z4.string().optional(),
  url: z4.string().optional(),
  headers: MCPHeadersSchema.optional()
}).superRefine((input, ctx) => {
  const transport = input.transport ?? "stdio";
  if (transport === "stdio") {
    if (!input.command?.trim()) {
      ctx.addIssue({ code: z4.ZodIssueCode.custom, message: "command is required for stdio" });
    }
    return;
  }
  if (!input.url?.trim()) {
    ctx.addIssue({ code: z4.ZodIssueCode.custom, message: "url is required for http/sse/auto" });
  }
});
var MCPRemoveParamsSchema = z4.object({
  projectPath: z4.string(),
  name: z4.string()
});
var MCPSetEnabledParamsSchema = z4.object({
  projectPath: z4.string(),
  name: z4.string(),
  enabled: z4.boolean()
});
var MCPSetToolAllowlistParamsSchema = z4.object({
  projectPath: z4.string(),
  name: z4.string(),
  /** Tool names to allow. Empty array = no tools allowed. */
  toolAllowlist: z4.array(z4.string())
});
var MCPTestParamsSchema = z4.object({
  projectPath: z4.string(),
  name: z4.string().optional(),
  transport: MCPTransportSchema.optional(),
  command: z4.string().optional(),
  url: z4.string().optional(),
  headers: MCPHeadersSchema.optional()
}).superRefine((input, ctx) => {
  if (input.name?.trim()) {
    return;
  }
  if (input.command?.trim()) {
    return;
  }
  if (input.url?.trim()) {
    const transport = input.transport;
    if (transport !== "http" && transport !== "sse" && transport !== "auto") {
      ctx.addIssue({
        code: z4.ZodIssueCode.custom,
        message: "transport must be http|sse|auto when testing by url"
      });
    }
    return;
  }
  ctx.addIssue({
    code: z4.ZodIssueCode.custom,
    message: "Either name, command, or url is required"
  });
});
var MCPTestResultSchema = z4.discriminatedUnion("success", [
  z4.object({ success: z4.literal(true), tools: z4.array(z4.string()) }),
  z4.object({ success: z4.literal(false), error: z4.string() })
]);

// src/common/orpc/schemas/workspaceAiSettings.ts
import { z as z5 } from "zod";
var WorkspaceAISettingsSchema = z5.object({
  model: z5.string().meta({ description: 'Canonical model id in the form "provider:model"' }),
  thinkingLevel: z5.enum(["off", "low", "medium", "high", "xhigh"]).meta({
    description: "Thinking/reasoning effort level"
  })
});
var WorkspaceAISettingsByAgentSchema = z5.record(
  z5.string().min(1),
  WorkspaceAISettingsSchema
);

// src/common/orpc/schemas/project.ts
var ThinkingLevelSchema = z6.enum(["off", "low", "medium", "high", "xhigh"]);
var SectionConfigSchema = z6.object({
  id: z6.string().meta({
    description: "Unique section ID (8 hex chars)"
  }),
  name: z6.string().meta({
    description: "Display name for the section"
  }),
  color: z6.string().optional().meta({
    description: "Accent color (hex value like #ff6b6b or preset name)"
  }),
  nextId: z6.string().nullable().optional().meta({
    description: "ID of the next section in display order (null = last, undefined treated as null)"
  })
});
var WorkspaceConfigSchema = z6.object({
  path: z6.string().meta({
    description: "Absolute path to workspace directory - REQUIRED for backward compatibility"
  }),
  id: z6.string().optional().meta({
    description: "Stable workspace ID (10 hex chars for new workspaces) - optional for legacy"
  }),
  name: z6.string().optional().meta({
    description: 'Git branch / directory name (e.g., "plan-a1b2") - optional for legacy'
  }),
  title: z6.string().optional().meta({
    description: 'Human-readable workspace title (e.g., "Fix plan mode over SSH") - optional for legacy'
  }),
  createdAt: z6.string().optional().meta({ description: "ISO 8601 creation timestamp - optional for legacy" }),
  aiSettingsByAgent: WorkspaceAISettingsByAgentSchema.optional().meta({
    description: "Per-agent workspace-scoped AI settings"
  }),
  runtimeConfig: RuntimeConfigSchema.optional().meta({
    description: "Runtime configuration (local vs SSH) - optional, defaults to local"
  }),
  aiSettings: WorkspaceAISettingsSchema.optional().meta({
    description: "Workspace-scoped AI settings (model + thinking level)"
  }),
  parentWorkspaceId: z6.string().optional().meta({
    description: "If set, this workspace is a child workspace spawned from the parent workspaceId (enables nesting in UI and backend orchestration)."
  }),
  agentType: z6.string().optional().meta({
    description: 'If set, selects an agent preset for this workspace (e.g., "explore" or "exec").'
  }),
  agentId: z6.string().optional().meta({
    description: 'If set, selects an agent definition for this workspace (e.g., "explore" or "exec").'
  }),
  taskStatus: z6.enum(["queued", "running", "awaiting_report", "reported"]).optional().meta({
    description: "Agent task lifecycle status for child workspaces (queued|running|awaiting_report|reported)."
  }),
  reportedAt: z6.string().optional().meta({
    description: "ISO 8601 timestamp for when an agent task reported completion (optional)."
  }),
  taskModelString: z6.string().optional().meta({
    description: "Model string used to run this agent task (used for restart-safe resumptions)."
  }),
  taskThinkingLevel: ThinkingLevelSchema.optional().meta({
    description: "Thinking level used for this agent task (used for restart-safe resumptions)."
  }),
  taskPrompt: z6.string().optional().meta({
    description: "Initial prompt for a queued agent task (persisted only until the task actually starts)."
  }),
  taskExperiments: z6.object({
    programmaticToolCalling: z6.boolean().optional(),
    programmaticToolCallingExclusive: z6.boolean().optional()
  }).optional().meta({
    description: "PTC experiments inherited from parent for restart-safe resumptions."
  }),
  taskTrunkBranch: z6.string().optional().meta({
    description: "Trunk branch used to create/init this agent task workspace (used for restart-safe init on queued tasks)."
  }),
  mcp: WorkspaceMCPOverridesSchema.optional().meta({
    description: "LEGACY: Per-workspace MCP overrides (migrated to <workspace>/.unix/mcp.local.jsonc)"
  }),
  archivedAt: z6.string().optional().meta({
    description: "ISO 8601 timestamp when workspace was last archived. Workspace is considered archived if archivedAt > unarchivedAt (or unarchivedAt is absent)."
  }),
  unarchivedAt: z6.string().optional().meta({
    description: "ISO 8601 timestamp when workspace was last unarchived. Used for recency calculation to bump restored workspaces to top."
  }),
  sectionId: z6.string().optional().meta({
    description: "ID of the section this workspace belongs to (optional, unsectioned if absent)"
  })
});
var ProjectConfigSchema = z6.object({
  workspaces: z6.array(WorkspaceConfigSchema),
  sections: z6.array(SectionConfigSchema).optional().meta({
    description: "Sections for organizing workspaces within this project"
  }),
  idleCompactionHours: z6.number().min(1).nullable().optional().meta({
    description: "Hours of inactivity before auto-compacting workspaces. null/undefined = disabled."
  })
});

// src/common/orpc/schemas/workspace.ts
import { z as z7 } from "zod";
var ThinkingLevelSchema2 = z7.enum(["off", "low", "medium", "high", "xhigh"]);
var WorkspaceMetadataSchema = z7.object({
  id: z7.string().meta({
    description: "Stable unique identifier (10 hex chars for new workspaces, legacy format for old)"
  }),
  name: z7.string().meta({
    description: 'Git branch / directory name (e.g., "plan-a1b2") - used for path computation'
  }),
  title: z7.string().optional().meta({
    description: 'Human-readable workspace title (e.g., "Fix plan mode over SSH") - optional for legacy workspaces'
  }),
  projectName: z7.string().meta({ description: "Project name extracted from project path (for display)" }),
  projectPath: z7.string().meta({ description: "Absolute path to the project (needed to compute workspace path)" }),
  createdAt: z7.string().optional().meta({
    description: "ISO 8601 timestamp of when workspace was created (optional for backward compatibility)"
  }),
  aiSettingsByAgent: WorkspaceAISettingsByAgentSchema.optional().meta({
    description: "Per-agent AI settings persisted in config"
  }),
  runtimeConfig: RuntimeConfigSchema.meta({
    description: "Runtime configuration for this workspace (always set, defaults to local on load)"
  }),
  aiSettings: WorkspaceAISettingsSchema.optional().meta({
    description: "Workspace-scoped AI settings (model + thinking level) persisted in config"
  }),
  parentWorkspaceId: z7.string().optional().meta({
    description: "If set, this workspace is a child workspace spawned from the parent workspaceId (enables nesting in UI and backend orchestration)."
  }),
  agentType: z7.string().optional().meta({
    description: 'If set, selects an agent preset for this workspace (e.g., "explore" or "exec").'
  }),
  agentId: z7.string().optional().meta({
    description: 'If set, selects an agent definition for this workspace (e.g., "explore" or "exec").'
  }),
  taskStatus: z7.enum(["queued", "running", "awaiting_report", "reported"]).optional().meta({
    description: "Agent task lifecycle status for child workspaces (queued|running|awaiting_report|reported)."
  }),
  reportedAt: z7.string().optional().meta({
    description: "ISO 8601 timestamp for when an agent task reported completion (optional)."
  }),
  taskModelString: z7.string().optional().meta({
    description: "Model string used to run this agent task (used for restart-safe resumptions)."
  }),
  taskThinkingLevel: ThinkingLevelSchema2.optional().meta({
    description: "Thinking level used for this agent task (used for restart-safe resumptions)."
  }),
  taskPrompt: z7.string().optional().meta({
    description: "Initial prompt for a queued agent task (persisted only until the task actually starts)."
  }),
  taskTrunkBranch: z7.string().optional().meta({
    description: "Trunk branch used to create/init this agent task workspace (used for restart-safe init on queued tasks)."
  }),
  status: z7.enum(["creating"]).optional().meta({
    description: "Workspace creation status. 'creating' = pending setup (ephemeral, not persisted). Absent = ready."
  }),
  archivedAt: z7.string().optional().meta({
    description: "ISO 8601 timestamp when workspace was last archived. Workspace is considered archived if archivedAt > unarchivedAt (or unarchivedAt is absent)."
  }),
  unarchivedAt: z7.string().optional().meta({
    description: "ISO 8601 timestamp when workspace was last unarchived. Used for recency calculation to bump restored workspaces to top."
  }),
  sectionId: z7.string().optional().meta({
    description: "ID of the section this workspace belongs to (optional, unsectioned if absent)"
  })
});
var FrontendWorkspaceMetadataSchema = WorkspaceMetadataSchema.extend({
  namedWorkspacePath: z7.string().meta({ description: "Worktree path (uses workspace name as directory)" }),
  incompatibleRuntime: z7.string().optional().meta({
    description: "If set, this workspace has an incompatible runtime configuration (e.g., from a newer version of unix). The workspace should be displayed but interactions should show this error message."
  }),
  isRemoving: z7.boolean().optional().meta({
    description: "True if this workspace is currently being deleted (deletion in progress)."
  })
});
var WorkspaceActivitySnapshotSchema = z7.object({
  recency: z7.number().meta({ description: "Unix ms timestamp of last user interaction" }),
  streaming: z7.boolean().meta({ description: "Whether workspace currently has an active stream" }),
  lastModel: z7.string().nullable().meta({ description: "Last model sent from this workspace" }),
  lastThinkingLevel: ThinkingLevelSchema2.nullable().meta({
    description: "Last thinking/reasoning level used in this workspace"
  })
});
var PostCompactionStateSchema = z7.object({
  planPath: z7.string().nullable(),
  trackedFilePaths: z7.array(z7.string()),
  excludedItems: z7.array(z7.string())
});
var GitStatusSchema = z7.object({
  /** Commit divergence relative to origin's primary branch */
  ahead: z7.number(),
  behind: z7.number(),
  dirty: z7.boolean().meta({ description: "Whether there are uncommitted changes (staged or unstaged)" }),
  /**
   * Line deltas for changes unique to this workspace.
   * Computed vs the merge-base with origin's primary branch.
   *
   * Note: outgoing includes committed changes + uncommitted changes (working tree).
   */
  outgoingAdditions: z7.number(),
  outgoingDeletions: z7.number(),
  /** Line deltas for changes that exist on origin's primary branch but not locally */
  incomingAdditions: z7.number(),
  incomingDeletions: z7.number()
});

// src/common/orpc/schemas/workspaceStats.ts
import { z as z9 } from "zod";

// src/common/types/mode.ts
import { z as z8 } from "zod";
var UI_MODE_VALUES = ["plan", "exec"];
var UIModeSchema = z8.enum(UI_MODE_VALUES);
var AGENT_MODE_VALUES = [...UI_MODE_VALUES, "compact"];
var AgentModeSchema = z8.enum(AGENT_MODE_VALUES);

// src/common/orpc/schemas/workspaceStats.ts
var ModeSchema = AgentModeSchema.optional().catch(void 0);
var TimingAnomalySchema = z9.enum([
  "negative_duration",
  "tool_gt_total",
  "ttft_gt_total",
  "percent_out_of_range",
  "nan"
]);
var ActiveStreamStatsSchema = z9.object({
  messageId: z9.string(),
  model: z9.string(),
  mode: ModeSchema,
  elapsedMs: z9.number(),
  ttftMs: z9.number().nullable(),
  toolExecutionMs: z9.number(),
  modelTimeMs: z9.number(),
  streamingMs: z9.number(),
  outputTokens: z9.number(),
  reasoningTokens: z9.number(),
  /** Total tokens streamed so far (text + reasoning + tool args). */
  liveTokenCount: z9.number(),
  /** Tokens/sec, trailing window. */
  liveTPS: z9.number(),
  invalid: z9.boolean(),
  anomalies: z9.array(TimingAnomalySchema)
});
var CompletedStreamStatsSchema = z9.object({
  messageId: z9.string(),
  model: z9.string(),
  mode: ModeSchema,
  totalDurationMs: z9.number(),
  ttftMs: z9.number().nullable(),
  toolExecutionMs: z9.number(),
  modelTimeMs: z9.number(),
  streamingMs: z9.number(),
  outputTokens: z9.number(),
  reasoningTokens: z9.number(),
  invalid: z9.boolean(),
  anomalies: z9.array(TimingAnomalySchema)
});
var ModelTimingStatsSchema = z9.object({
  model: z9.string(),
  mode: ModeSchema,
  totalDurationMs: z9.number(),
  totalToolExecutionMs: z9.number(),
  totalStreamingMs: z9.number(),
  totalTtftMs: z9.number(),
  ttftCount: z9.number(),
  responseCount: z9.number(),
  totalOutputTokens: z9.number(),
  totalReasoningTokens: z9.number()
});
var SessionTimingStatsSchema = z9.object({
  totalDurationMs: z9.number(),
  totalToolExecutionMs: z9.number(),
  totalStreamingMs: z9.number(),
  totalTtftMs: z9.number(),
  ttftCount: z9.number(),
  responseCount: z9.number(),
  totalOutputTokens: z9.number(),
  totalReasoningTokens: z9.number(),
  /** Per-model breakdown (key is stable identifier like normalizeGatewayModel(model) or model:mode). */
  byModel: z9.record(z9.string(), ModelTimingStatsSchema)
});
var WorkspaceStatsSnapshotSchema = z9.object({
  workspaceId: z9.string(),
  generatedAt: z9.number(),
  active: ActiveStreamStatsSchema.optional(),
  lastRequest: CompletedStreamStatsSchema.optional(),
  session: SessionTimingStatsSchema.optional()
});
var SessionTimingFileSchema = z9.object({
  version: z9.literal(2),
  lastRequest: CompletedStreamStatsSchema.optional(),
  session: SessionTimingStatsSchema,
  /**
   * Idempotency ledger for rolled-up sub-agent timing.
   *
   * When a child workspace is deleted, we merge its session timing into the parent.
   * This tracks which children have already been merged to prevent double-counting
   * if removal is retried.
   */
  rolledUpFrom: z9.record(z9.string(), z9.literal(true)).optional()
});

// src/common/orpc/schemas/chatStats.ts
import { z as z10 } from "zod";
var TopFilePathSchema = z10.object({
  path: z10.string().meta({ description: "File path (relative or absolute)" }),
  tokens: z10.number().meta({ description: "Token count for this file" })
});
var TokenConsumerSchema = z10.object({
  name: z10.string().meta({ description: '"User", "Assistant", "bash", "readFile", etc.' }),
  tokens: z10.number().meta({ description: "Total token count for this consumer" }),
  percentage: z10.number().meta({ description: "% of total tokens" }),
  fixedTokens: z10.number().optional().meta({ description: "Fixed overhead (e.g., tool definitions)" }),
  variableTokens: z10.number().optional().meta({ description: "Variable usage (e.g., actual tool calls, text)" })
});
var ChatUsageComponentSchema = z10.object({
  tokens: z10.number(),
  cost_usd: z10.number().optional()
});
var ChatUsageDisplaySchema = z10.object({
  input: ChatUsageComponentSchema,
  cached: ChatUsageComponentSchema,
  cacheCreate: ChatUsageComponentSchema,
  output: ChatUsageComponentSchema,
  reasoning: ChatUsageComponentSchema,
  model: z10.string().optional()
});
var ChatStatsSchema = z10.object({
  consumers: z10.array(TokenConsumerSchema).meta({ description: "Sorted descending by token count" }),
  totalTokens: z10.number(),
  model: z10.string(),
  tokenizerName: z10.string().meta({ description: 'e.g., "o200k_base", "claude"' }),
  usageHistory: z10.array(ChatUsageDisplaySchema).meta({ description: "Ordered array of actual usage statistics from API responses" }),
  topFilePaths: z10.array(TopFilePathSchema).optional().meta({ description: "Top 10 files by token count aggregated across all file tools" })
});
var SessionUsageTokenStatsCacheSchema = z10.object({
  version: z10.literal(1),
  computedAt: z10.number().meta({ description: "Unix timestamp (ms) when this cache was computed" }),
  model: z10.string().meta({ description: "Model used for tokenization (affects tokenizer + tool definitions)" }),
  tokenizerName: z10.string().meta({ description: 'e.g., "o200k_base", "claude"' }),
  history: z10.object({
    messageCount: z10.number().meta({ description: "Number of messages used to compute this cache" }),
    maxHistorySequence: z10.number().optional().meta({ description: "Max UnixMessage.metadata.historySequence seen in the message list" })
  }),
  consumers: z10.array(TokenConsumerSchema).meta({ description: "Sorted descending by token count" }),
  totalTokens: z10.number(),
  topFilePaths: z10.array(TopFilePathSchema).optional().meta({ description: "Top 10 files by token count aggregated across all file tools" })
});
var SessionUsageFileSchema = z10.object({
  byModel: z10.record(z10.string(), ChatUsageDisplaySchema),
  lastRequest: z10.object({
    model: z10.string(),
    usage: ChatUsageDisplaySchema,
    timestamp: z10.number()
  }).optional(),
  /**
   * Idempotency ledger for rolled-up sub-agent usage.
   * Key: child workspaceId, value: true.
   */
  rolledUpFrom: z10.record(z10.string(), z10.literal(true)).optional(),
  tokenStatsCache: SessionUsageTokenStatsCacheSchema.optional(),
  version: z10.literal(1)
});

// src/common/orpc/schemas/agentSkill.ts
import { z as z11 } from "zod";
var AgentSkillScopeSchema = z11.enum(["project", "global", "built-in"]);
var SkillNameSchema = z11.string().min(1).max(64).regex(/^[a-z0-9]+(?:-[a-z0-9]+)*$/);
var AgentSkillFrontmatterSchema = z11.object({
  name: SkillNameSchema,
  description: z11.string().min(1).max(1024),
  license: z11.string().optional(),
  compatibility: z11.string().min(1).max(500).optional(),
  metadata: z11.record(z11.string(), z11.string()).optional()
});
var AgentSkillDescriptorSchema = z11.object({
  name: SkillNameSchema,
  description: z11.string().min(1).max(1024),
  scope: AgentSkillScopeSchema
});
var AgentSkillPackageSchema = z11.object({
  scope: AgentSkillScopeSchema,
  directoryName: SkillNameSchema,
  frontmatter: AgentSkillFrontmatterSchema,
  body: z11.string()
}).refine((value2) => value2.directoryName === value2.frontmatter.name, {
  message: "SKILL.md frontmatter.name must match the parent directory name",
  path: ["frontmatter", "name"]
});

// src/common/orpc/schemas/agentDefinition.ts
import { z as z12 } from "zod";
var AgentDefinitionScopeSchema = z12.enum(["built-in", "project", "global"]);
var AgentIdSchema = z12.string().min(1).max(64).regex(/^[a-z0-9]+(?:[a-z0-9_-]*[a-z0-9])?$/);
var ThinkingLevelSchema3 = z12.enum(["off", "low", "medium", "high", "xhigh"]);
var AgentDefinitionUiSchema = z12.object({
  // New: hidden is opt-out. Default: visible.
  hidden: z12.boolean().optional(),
  // Legacy: selectable was opt-in. Keep for backwards compatibility.
  selectable: z12.boolean().optional(),
  // When true, completely hides this agent (useful for disabling built-ins)
  disabled: z12.boolean().optional(),
  // UI color (CSS color value). Inherited from base agent if not specified.
  color: z12.string().min(1).optional()
}).strip();
var AgentDefinitionSubagentSchema = z12.object({
  runnable: z12.boolean().optional(),
  // Instructions appended when this agent runs as a subagent (child workspace)
  append_prompt: z12.string().min(1).optional(),
  // When true, do not run the project's .unix/init hook for this sub-agent.
  // NOTE: This skips only the hook execution, not runtime provisioning (e.g. SSH sync, Docker setup).
  skip_init_hook: z12.boolean().optional()
}).strip();
var AgentDefinitionAiDefaultsSchema = z12.object({
  // Model identifier: full string (e.g. "anthropic:claude-sonnet-4-5") or abbreviation (e.g. "sonnet")
  model: z12.string().min(1).optional(),
  thinkingLevel: ThinkingLevelSchema3.optional()
}).strip();
var AgentDefinitionPromptSchema = z12.object({
  // When true, append this agent's body to the base agent's body (default: false = replace)
  append: z12.boolean().optional()
}).strip();
var AgentDefinitionToolsSchema = z12.object({
  // Patterns to add (enable). Processed before remove.
  add: z12.array(z12.string().min(1)).optional(),
  // Patterns to remove (disable). Processed after add.
  remove: z12.array(z12.string().min(1)).optional()
}).strip();
var AgentDefinitionFrontmatterSchema = z12.object({
  name: z12.string().min(1).max(128),
  description: z12.string().min(1).max(1024).optional(),
  // Inheritance: reference a built-in or custom agent ID
  base: AgentIdSchema.optional(),
  // UI metadata (color, visibility, etc.)
  ui: AgentDefinitionUiSchema.optional(),
  // Prompt behavior configuration
  prompt: AgentDefinitionPromptSchema.optional(),
  subagent: AgentDefinitionSubagentSchema.optional(),
  ai: AgentDefinitionAiDefaultsSchema.optional(),
  // Tool configuration: add/remove patterns (regex).
  // If omitted and no base, no tools are available.
  tools: AgentDefinitionToolsSchema.optional()
}).strip();
var AgentDefinitionDescriptorSchema = z12.object({
  id: AgentIdSchema,
  scope: AgentDefinitionScopeSchema,
  name: z12.string().min(1).max(128),
  description: z12.string().min(1).max(1024).optional(),
  uiSelectable: z12.boolean(),
  uiColor: z12.string().min(1).optional(),
  subagentRunnable: z12.boolean(),
  // Base agent ID for inheritance (e.g., "exec", "plan", or custom agent)
  base: AgentIdSchema.optional(),
  aiDefaults: AgentDefinitionAiDefaultsSchema.optional(),
  // Tool configuration (for UI display / inheritance computation)
  tools: AgentDefinitionToolsSchema.optional()
}).strict();
var AgentDefinitionPackageSchema = z12.object({
  id: AgentIdSchema,
  scope: AgentDefinitionScopeSchema,
  frontmatter: AgentDefinitionFrontmatterSchema,
  body: z12.string()
}).strict();

// src/common/orpc/schemas/errors.ts
import { z as z13 } from "zod";
var SendMessageErrorSchema = z13.discriminatedUnion("type", [
  z13.object({ type: z13.literal("api_key_not_found"), provider: z13.string() }),
  z13.object({ type: z13.literal("provider_not_supported"), provider: z13.string() }),
  z13.object({ type: z13.literal("invalid_model_string"), message: z13.string() }),
  z13.object({ type: z13.literal("incompatible_workspace"), message: z13.string() }),
  z13.object({ type: z13.literal("runtime_not_ready"), message: z13.string() }),
  z13.object({ type: z13.literal("runtime_start_failed"), message: z13.string() }),
  // Transient - retryable
  z13.object({ type: z13.literal("unknown"), raw: z13.string() })
]);
var StreamErrorTypeSchema = z13.enum([
  "authentication",
  // API key issues, 401 errors
  "rate_limit",
  // 429 rate limiting
  "server_error",
  // 5xx server errors
  "api",
  // Generic API errors
  "retry_failed",
  // Retry exhausted
  "aborted",
  // User aborted
  "network",
  // Network/fetch errors
  "context_exceeded",
  // Context length/token limit exceeded
  "quota",
  // Usage quota/billing limits
  "model_not_found",
  // Model does not exist
  "runtime_not_ready",
  // Container/runtime doesn't exist or failed to start (permanent)
  "runtime_start_failed",
  // Runtime is starting or temporarily unavailable (retryable)
  "unknown"
  // Catch-all
]);

// src/common/orpc/schemas/tools.ts
import { z as z14 } from "zod";
var ToolOutputUiOnlySchema = z14.object({
  ask_user_question: z14.object({
    questions: z14.array(z14.unknown()),
    answers: z14.record(z14.string(), z14.string())
  }).optional(),
  file_edit: z14.object({
    diff: z14.string()
  }).optional(),
  notify: z14.object({
    notifiedVia: z14.enum(["electron", "browser"]),
    workspaceId: z14.string().optional()
  }).optional()
});
var ToolOutputUiOnlyFieldSchema = {
  ui_only: ToolOutputUiOnlySchema.optional()
};
var BashToolResultSchema = z14.discriminatedUnion("success", [
  z14.object({
    success: z14.literal(true),
    wall_duration_ms: z14.number(),
    output: z14.string(),
    exitCode: z14.literal(0),
    note: z14.string().optional(),
    truncated: z14.object({
      reason: z14.string(),
      totalLines: z14.number()
    }).optional()
  }).extend(ToolOutputUiOnlyFieldSchema),
  z14.object({
    success: z14.literal(false),
    wall_duration_ms: z14.number(),
    output: z14.string().optional(),
    exitCode: z14.number(),
    error: z14.string(),
    note: z14.string().optional(),
    truncated: z14.object({
      reason: z14.string(),
      totalLines: z14.number()
    }).optional()
  }).extend(ToolOutputUiOnlyFieldSchema)
]);
var FileTreeNodeSchema = z14.object({
  name: z14.string(),
  path: z14.string(),
  isDirectory: z14.boolean(),
  get children() {
    return z14.array(FileTreeNodeSchema);
  },
  /** Whether this file/directory is gitignored */
  ignored: z14.boolean().optional(),
  stats: z14.object({
    filePath: z14.string(),
    additions: z14.number(),
    deletions: z14.number()
  }).optional(),
  totalStats: z14.object({
    filePath: z14.string(),
    additions: z14.number(),
    deletions: z14.number()
  }).optional()
});

// src/common/orpc/schemas/secrets.ts
import { z as z15 } from "zod";
var SecretSchema = z15.object({
  key: z15.string(),
  value: z15.string()
}).meta({
  description: "A key-value pair for storing sensitive configuration"
});

// src/common/orpc/schemas/providerOptions.ts
import { z as z16 } from "zod";
var UnixProviderOptionsSchema = z16.object({
  anthropic: z16.object({
    use1MContext: z16.boolean().optional().meta({
      description: "Enable 1M context window (requires beta header)"
    })
  }).optional(),
  openai: z16.object({
    serviceTier: z16.enum(["auto", "default", "flex", "priority"]).optional().meta({
      description: "OpenAI service tier: priority (low-latency), flex (50% cheaper, higher latency), auto/default (standard)"
    }),
    forceContextLimitError: z16.boolean().optional().meta({
      description: "Force context limit error (used in integration tests to simulate overflow)"
    }),
    simulateToolPolicyNoop: z16.boolean().optional().meta({
      description: "Simulate successful response without executing tools (used in tool policy tests)"
    })
  }).optional(),
  google: z16.record(z16.string(), z16.unknown()).optional(),
  ollama: z16.record(z16.string(), z16.unknown()).optional(),
  openrouter: z16.record(z16.string(), z16.unknown()).optional(),
  xai: z16.object({
    searchParameters: z16.object({
      mode: z16.enum(["auto", "off", "on"]),
      returnCitations: z16.boolean().optional(),
      fromDate: z16.string().optional(),
      toDate: z16.string().optional(),
      maxSearchResults: z16.number().optional(),
      sources: z16.array(
        z16.discriminatedUnion("type", [
          z16.object({
            type: z16.literal("web"),
            country: z16.string().optional(),
            excludedWebsites: z16.array(z16.string()).optional(),
            allowedWebsites: z16.array(z16.string()).optional(),
            safeSearch: z16.boolean().optional()
          }),
          z16.object({
            type: z16.literal("x"),
            excludedXHandles: z16.array(z16.string()).optional(),
            includedXHandles: z16.array(z16.string()).optional(),
            postFavoriteCount: z16.number().optional(),
            postViewCount: z16.number().optional(),
            xHandles: z16.array(z16.string()).optional()
          }),
          z16.object({
            type: z16.literal("news"),
            country: z16.string().optional(),
            excludedWebsites: z16.array(z16.string()).optional(),
            safeSearch: z16.boolean().optional()
          }),
          z16.object({
            type: z16.literal("rss"),
            links: z16.array(z16.string())
          })
        ])
      ).optional()
    }).optional()
  }).optional()
});

// src/common/orpc/schemas/uiLayouts.ts
import { z as z17 } from "zod";
var KeybindSchema = z17.object({
  key: z17.string().min(1),
  allowShift: z17.boolean().optional(),
  ctrl: z17.boolean().optional(),
  shift: z17.boolean().optional(),
  alt: z17.boolean().optional(),
  meta: z17.boolean().optional(),
  macCtrlBehavior: z17.enum(["either", "command", "control"]).optional()
}).strict();
var RightSidebarPresetBaseTabSchema = z17.enum(["costs", "review", "explorer", "stats"]);
var RightSidebarPresetTabSchema = z17.union([
  RightSidebarPresetBaseTabSchema,
  z17.string().min("terminal_new:".length + 1).regex(/^terminal_new:.+$/)
]);
var RightSidebarLayoutPresetNodeSchema = z17.lazy(
  () => {
    const tabset = z17.object({
      type: z17.literal("tabset"),
      id: z17.string().min(1),
      tabs: z17.array(RightSidebarPresetTabSchema),
      activeTab: RightSidebarPresetTabSchema
    }).strict();
    const split = z17.object({
      type: z17.literal("split"),
      id: z17.string().min(1),
      direction: z17.enum(["horizontal", "vertical"]),
      sizes: z17.tuple([z17.number(), z17.number()]),
      children: z17.tuple([RightSidebarLayoutPresetNodeSchema, RightSidebarLayoutPresetNodeSchema])
    }).strict();
    return z17.union([split, tabset]);
  }
);
var RightSidebarLayoutPresetStateSchema = z17.object({
  version: z17.literal(1),
  nextId: z17.number().int(),
  focusedTabsetId: z17.string().min(1),
  root: RightSidebarLayoutPresetNodeSchema
}).strict();
var RightSidebarWidthPresetSchema = z17.discriminatedUnion("mode", [
  z17.object({
    mode: z17.literal("px"),
    value: z17.number().int()
  }).strict(),
  z17.object({
    mode: z17.literal("fraction"),
    value: z17.number()
  }).strict()
]);
var LayoutPresetSchema = z17.object({
  id: z17.string().min(1),
  name: z17.string().min(1),
  leftSidebarCollapsed: z17.boolean(),
  rightSidebar: z17.object({
    collapsed: z17.boolean(),
    width: RightSidebarWidthPresetSchema,
    layout: RightSidebarLayoutPresetStateSchema
  }).strict()
}).strict();
var LayoutSlotSchema = z17.object({
  slot: z17.number().int().min(1),
  preset: LayoutPresetSchema.optional(),
  keybindOverride: KeybindSchema.optional()
}).strict();
var LayoutPresetsConfigSchema = z17.object({
  version: z17.literal(2),
  slots: z17.array(LayoutSlotSchema)
}).strict();

// src/common/orpc/schemas/terminal.ts
import { z as z18 } from "zod";
var TerminalSessionSchema = z18.object({
  sessionId: z18.string(),
  workspaceId: z18.string(),
  cols: z18.number(),
  rows: z18.number()
});
var TerminalCreateParamsSchema = z18.object({
  workspaceId: z18.string(),
  cols: z18.number(),
  rows: z18.number(),
  /** Optional command to run immediately after terminal creation */
  initialCommand: z18.string().optional()
});
var TerminalResizeParamsSchema = z18.object({
  sessionId: z18.string(),
  cols: z18.number(),
  rows: z18.number()
});

// src/common/orpc/schemas/message.ts
import { z as z19 } from "zod";
var FilePartSchema = z19.object({
  url: z19.string(),
  mediaType: z19.string(),
  filename: z19.string().optional()
});
var UnixTextPartSchema = z19.object({
  type: z19.literal("text"),
  text: z19.string(),
  timestamp: z19.number().optional()
});
var UnixReasoningPartSchema = z19.object({
  type: z19.literal("reasoning"),
  text: z19.string(),
  timestamp: z19.number().optional()
});
var UnixToolPartBase = z19.object({
  type: z19.literal("dynamic-tool"),
  toolCallId: z19.string(),
  toolName: z19.string(),
  input: z19.unknown(),
  timestamp: z19.number().optional()
});
var NestedToolCallSchema = z19.object({
  toolCallId: z19.string(),
  toolName: z19.string(),
  input: z19.unknown(),
  output: z19.unknown().optional(),
  state: z19.enum(["input-available", "output-available"]),
  timestamp: z19.number().optional()
});
var DynamicToolPartPendingSchema = UnixToolPartBase.extend({
  state: z19.literal("input-available"),
  nestedCalls: z19.array(NestedToolCallSchema).optional()
});
var DynamicToolPartAvailableSchema = UnixToolPartBase.extend({
  state: z19.literal("output-available"),
  output: z19.unknown(),
  nestedCalls: z19.array(NestedToolCallSchema).optional()
});
var DynamicToolPartSchema = z19.discriminatedUnion("state", [
  DynamicToolPartAvailableSchema,
  DynamicToolPartPendingSchema
]);
var UnixToolPartSchema = DynamicToolPartSchema;
var UnixFilePartSchema = FilePartSchema.extend({
  type: z19.literal("file")
});
var UnixMessageSchema = z19.object({
  id: z19.string(),
  role: z19.enum(["system", "user", "assistant"]),
  parts: z19.array(
    z19.discriminatedUnion("type", [
      UnixTextPartSchema,
      UnixReasoningPartSchema,
      UnixToolPartSchema,
      UnixFilePartSchema
    ])
  ),
  createdAt: z19.date().optional(),
  metadata: z19.object({
    historySequence: z19.number().optional(),
    timestamp: z19.number().optional(),
    model: z19.string().optional(),
    usage: z19.any().optional(),
    contextUsage: z19.any().optional(),
    providerMetadata: z19.record(z19.string(), z19.unknown()).optional(),
    contextProviderMetadata: z19.record(z19.string(), z19.unknown()).optional(),
    duration: z19.number().optional(),
    systemMessageTokens: z19.number().optional(),
    unixMetadata: z19.any().optional(),
    cunixMetadata: z19.any().optional(),
    // Legacy field for backward compatibility
    // Compaction source: "user" (manual), "idle" (auto), or legacy boolean (true)
    compacted: z19.union([z19.literal("user"), z19.literal("idle"), z19.boolean()]).optional(),
    toolPolicy: z19.any().optional(),
    agentId: AgentIdSchema.optional().catch(void 0),
    partial: z19.boolean().optional(),
    synthetic: z19.boolean().optional(),
    agentSkillSnapshot: z19.object({
      skillName: SkillNameSchema,
      scope: AgentSkillScopeSchema,
      sha256: z19.string()
    }).optional(),
    error: z19.string().optional(),
    errorType: StreamErrorTypeSchema.optional()
  }).optional()
});
var BranchListResultSchema = z19.object({
  branches: z19.array(z19.string()),
  /** Recommended trunk branch, or null for non-git directories */
  recommendedTrunk: z19.string().nullable()
});

// src/common/orpc/schemas/stream.ts
import { z as z20 } from "zod";
var HeartbeatEventSchema = z20.object({
  type: z20.literal("heartbeat")
});
var CaughtUpMessageSchema = z20.object({
  type: z20.literal("caught-up")
});
var RuntimeStatusEventSchema = z20.object({
  type: z20.literal("runtime-status"),
  workspaceId: z20.string(),
  phase: z20.enum(["checking", "starting", "waiting", "ready", "error"]),
  runtimeType: RuntimeModeSchema,
  detail: z20.string().optional()
  // Human-readable status like "Starting Lattice workspace..."
});
var IdleCompactionNeededEventSchema = z20.object({
  type: z20.literal("idle-compaction-needed")
});
var StreamErrorMessageSchema = z20.object({
  type: z20.literal("stream-error"),
  messageId: z20.string(),
  error: z20.string(),
  errorType: StreamErrorTypeSchema
});
var DeleteMessageSchema = z20.object({
  type: z20.literal("delete"),
  historySequences: z20.array(z20.number())
});
var StreamStartEventSchema = z20.object({
  type: z20.literal("stream-start"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" }),
  model: z20.string(),
  historySequence: z20.number().meta({
    description: "Backend assigns global message ordering"
  }),
  startTime: z20.number().meta({
    description: "Backend timestamp when stream started (Date.now())"
  }),
  mode: AgentModeSchema.optional().catch(void 0).meta({
    description: "Legacy base mode (plan/exec/compact) derived from agent"
  }),
  agentId: AgentIdSchema.optional().catch(void 0).meta({
    description: "Agent id for this stream"
  })
});
var StreamDeltaEventSchema = z20.object({
  type: z20.literal("stream-delta"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" }),
  delta: z20.string(),
  tokens: z20.number().meta({
    description: "Token count for this delta"
  }),
  timestamp: z20.number().meta({
    description: "When delta was received (Date.now())"
  })
});
var CompletedMessagePartSchema = z20.discriminatedUnion("type", [
  UnixReasoningPartSchema,
  UnixTextPartSchema,
  UnixToolPartSchema
]);
var LanguageModelV2UsageSchema = z20.object({
  inputTokens: z20.union([z20.number(), z20.undefined()]).meta({ description: "The number of input tokens used" }),
  outputTokens: z20.union([z20.number(), z20.undefined()]).meta({ description: "The number of output tokens used" }),
  totalTokens: z20.union([z20.number(), z20.undefined()]).meta({
    description: "Total tokens used - may differ from sum of inputTokens and outputTokens (e.g. reasoning tokens or overhead)"
  }),
  reasoningTokens: z20.number().optional().meta({ description: "The number of reasoning tokens used" }),
  cachedInputTokens: z20.number().optional().meta({ description: "The number of cached input tokens" })
});
var StreamEndEventSchema = z20.object({
  type: z20.literal("stream-end"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  metadata: z20.object({
    model: z20.string(),
    // Total usage across all steps (for cost calculation)
    usage: LanguageModelV2UsageSchema.optional(),
    // Last step's usage only (for context window display - inputTokens = current context size)
    contextUsage: LanguageModelV2UsageSchema.optional(),
    // Aggregated provider metadata across all steps (for cost calculation)
    providerMetadata: z20.record(z20.string(), z20.unknown()).optional(),
    // Last step's provider metadata (for context window cache display)
    contextProviderMetadata: z20.record(z20.string(), z20.unknown()).optional(),
    duration: z20.number().optional(),
    systemMessageTokens: z20.number().optional(),
    historySequence: z20.number().optional().meta({
      description: "Present when loading from history"
    }),
    timestamp: z20.number().optional().meta({
      description: "Present when loading from history"
    })
  }).meta({
    description: "Structured metadata from backend - directly mergeable with UnixMetadata"
  }),
  parts: z20.array(CompletedMessagePartSchema).meta({
    description: "Parts array preserves temporal ordering of reasoning, text, and tool calls"
  })
});
var StreamAbortReasonSchema = z20.enum(["user", "startup", "system"]);
var StreamAbortEventSchema = z20.object({
  type: z20.literal("stream-abort"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  abortReason: StreamAbortReasonSchema.optional(),
  metadata: z20.object({
    // Total usage across all steps (for cost calculation)
    usage: LanguageModelV2UsageSchema.optional(),
    // Last step's usage (for context window display - inputTokens = current context size)
    contextUsage: LanguageModelV2UsageSchema.optional(),
    // Provider metadata for cost calculation (cache tokens, etc.)
    providerMetadata: z20.record(z20.string(), z20.unknown()).optional(),
    // Last step's provider metadata (for context window cache display)
    contextProviderMetadata: z20.record(z20.string(), z20.unknown()).optional(),
    duration: z20.number().optional()
  }).optional().meta({
    description: "Metadata may contain usage if abort occurred after stream completed processing"
  }),
  abandonPartial: z20.boolean().optional()
});
var ToolCallStartEventSchema = z20.object({
  type: z20.literal("tool-call-start"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" }),
  toolCallId: z20.string(),
  toolName: z20.string(),
  args: z20.unknown(),
  tokens: z20.number().meta({ description: "Token count for tool input" }),
  timestamp: z20.number().meta({ description: "When tool call started (Date.now())" }),
  parentToolCallId: z20.string().optional().meta({ description: "Set for nested PTC calls" })
});
var ToolCallDeltaEventSchema = z20.object({
  type: z20.literal("tool-call-delta"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" }),
  toolCallId: z20.string(),
  toolName: z20.string(),
  delta: z20.unknown(),
  tokens: z20.number().meta({ description: "Token count for this delta" }),
  timestamp: z20.number().meta({ description: "When delta was received (Date.now())" })
});
var BashOutputEventSchema = z20.object({
  type: z20.literal("bash-output"),
  workspaceId: z20.string(),
  toolCallId: z20.string(),
  phase: z20.enum(["output", "filtering"]).optional().meta({ description: "UI hint for bash output state" }),
  text: z20.string(),
  isError: z20.boolean().meta({ description: "True if this chunk is from stderr" }),
  timestamp: z20.number().meta({ description: "When output was flushed (Date.now())" })
});
var ToolCallEndEventSchema = z20.object({
  type: z20.literal("tool-call-end"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" }),
  toolCallId: z20.string(),
  toolName: z20.string(),
  result: z20.unknown(),
  timestamp: z20.number().meta({ description: "When tool call completed (Date.now())" }),
  parentToolCallId: z20.string().optional().meta({ description: "Set for nested PTC calls" })
});
var ReasoningDeltaEventSchema = z20.object({
  type: z20.literal("reasoning-delta"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" }),
  delta: z20.string(),
  tokens: z20.number().meta({ description: "Token count for this delta" }),
  timestamp: z20.number().meta({ description: "When delta was received (Date.now())" }),
  signature: z20.string().optional().meta({ description: "Anthropic thinking block signature for replay" })
});
var ReasoningEndEventSchema = z20.object({
  type: z20.literal("reasoning-end"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  replay: z20.boolean().optional().meta({ description: "True when this event is emitted during stream replay" })
});
var ErrorEventSchema = z20.object({
  type: z20.literal("error"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  error: z20.string(),
  errorType: StreamErrorTypeSchema.optional()
});
var SessionUsageDeltaEventSchema = z20.object({
  type: z20.literal("session-usage-delta"),
  workspaceId: z20.string().meta({ description: "Parent workspace ID" }),
  sourceWorkspaceId: z20.string().meta({ description: "Deleted child workspace ID" }),
  byModelDelta: z20.record(z20.string(), ChatUsageDisplaySchema),
  timestamp: z20.number()
});
var UsageDeltaEventSchema = z20.object({
  type: z20.literal("usage-delta"),
  workspaceId: z20.string(),
  messageId: z20.string(),
  // Step-level: this step only (for context window display)
  usage: LanguageModelV2UsageSchema,
  providerMetadata: z20.record(z20.string(), z20.unknown()).optional(),
  // Cumulative: sum across all steps (for live cost display)
  cumulativeUsage: LanguageModelV2UsageSchema,
  cumulativeProviderMetadata: z20.record(z20.string(), z20.unknown()).optional()
});
var InitStartEventSchema = z20.object({
  type: z20.literal("init-start"),
  hookPath: z20.string(),
  timestamp: z20.number()
});
var InitOutputEventSchema = z20.object({
  type: z20.literal("init-output"),
  line: z20.string(),
  timestamp: z20.number(),
  isError: z20.boolean().optional()
});
var InitEndEventSchema = z20.object({
  type: z20.literal("init-end"),
  exitCode: z20.number(),
  timestamp: z20.number(),
  /** Number of lines dropped from middle when output exceeded limit (omitted if 0) */
  truncatedLines: z20.number().optional()
});
var WorkspaceInitEventSchema = z20.discriminatedUnion("type", [
  InitStartEventSchema,
  InitOutputEventSchema,
  InitEndEventSchema
]);
var ChatUnixMessageSchema = UnixMessageSchema.extend({
  type: z20.literal("message")
});
var ReviewNoteDataSchema = z20.object({
  filePath: z20.string(),
  lineRange: z20.string(),
  selectedCode: z20.string(),
  selectedDiff: z20.string().optional(),
  oldStart: z20.number().optional(),
  newStart: z20.number().optional(),
  userNote: z20.string()
});
var QueuedMessageChangedEventSchema = z20.object({
  type: z20.literal("queued-message-changed"),
  workspaceId: z20.string(),
  queuedMessages: z20.array(z20.string()),
  displayText: z20.string(),
  fileParts: z20.array(FilePartSchema).optional(),
  reviews: z20.array(ReviewNoteDataSchema).optional(),
  /** True when the queued message is a compaction request (/compact) */
  hasCompactionRequest: z20.boolean().optional()
});
var RestoreToInputEventSchema = z20.object({
  type: z20.literal("restore-to-input"),
  workspaceId: z20.string(),
  text: z20.string(),
  fileParts: z20.array(FilePartSchema).optional()
});
var WorkspaceChatMessageSchema = z20.discriminatedUnion("type", [
  // Stream lifecycle events
  HeartbeatEventSchema,
  CaughtUpMessageSchema,
  StreamErrorMessageSchema,
  DeleteMessageSchema,
  StreamStartEventSchema,
  StreamDeltaEventSchema,
  StreamEndEventSchema,
  StreamAbortEventSchema,
  // Tool events
  ToolCallStartEventSchema,
  ToolCallDeltaEventSchema,
  ToolCallEndEventSchema,
  BashOutputEventSchema,
  // Reasoning events
  ReasoningDeltaEventSchema,
  ReasoningEndEventSchema,
  // Error events
  ErrorEventSchema,
  // Usage and queue events
  UsageDeltaEventSchema,
  SessionUsageDeltaEventSchema,
  QueuedMessageChangedEventSchema,
  RestoreToInputEventSchema,
  // Idle compaction notification
  IdleCompactionNeededEventSchema,
  // Runtime status events
  RuntimeStatusEventSchema,
  // Init events
  ...WorkspaceInitEventSchema.def.options,
  // Chat messages with type discriminator
  ChatUnixMessageSchema
]);
var UpdateStatusSchema = z20.discriminatedUnion("type", [
  z20.object({ type: z20.literal("idle") }),
  z20.object({ type: z20.literal("checking") }),
  z20.object({ type: z20.literal("available"), info: z20.object({ version: z20.string() }) }),
  z20.object({ type: z20.literal("up-to-date") }),
  z20.object({ type: z20.literal("downloading"), percent: z20.number() }),
  z20.object({ type: z20.literal("downloaded"), info: z20.object({ version: z20.string() }) }),
  z20.object({ type: z20.literal("error"), message: z20.string() })
]);
var ToolPolicyFilterSchema = z20.object({
  regex_match: z20.string().meta({
    description: 'Regex pattern to match tool names (e.g., "bash", "file_edit_.*", ".*")'
  }),
  action: z20.enum(["enable", "disable", "require"]).meta({
    description: "Action to take when pattern matches"
  })
});
var ToolPolicySchema = z20.array(ToolPolicyFilterSchema).meta({
  description: "Tool policy - array of filters applied in order. Default behavior is allow all tools."
});
var ExperimentsSchema = z20.object({
  programmaticToolCalling: z20.boolean().optional(),
  programmaticToolCallingExclusive: z20.boolean().optional(),
  system1: z20.boolean().optional()
});
var SendMessageOptionsSchema = z20.object({
  editMessageId: z20.string().optional(),
  thinkingLevel: z20.enum(["off", "low", "medium", "high", "xhigh"]).optional(),
  model: z20.string("No model specified"),
  system1ThinkingLevel: z20.enum(["off", "low", "medium", "high", "xhigh"]).optional(),
  system1Model: z20.string().optional(),
  toolPolicy: ToolPolicySchema.optional(),
  additionalSystemInstructions: z20.string().optional(),
  maxOutputTokens: z20.number().optional(),
  agentId: AgentIdSchema.meta({
    description: "Agent id for this request"
  }),
  mode: AgentModeSchema.optional().catch(void 0).meta({
    description: "Legacy base mode (plan/exec/compact) for backend fallback"
  }),
  providerOptions: UnixProviderOptionsSchema.optional(),
  unixMetadata: z20.any().optional(),
  // Black box
  experiments: ExperimentsSchema.optional(),
  /**
   * When true, workspace-specific agent definitions are disabled.
   * Only built-in and global agents are loaded. Useful for "unbricking" when
   * iterating on agent files - a broken agent in the worktree won't affect message sending.
   */
  disableWorkspaceAgents: z20.boolean().optional()
});

// src/common/orpc/schemas/api.ts
init_dist5();
import { z as z23 } from "zod";

// src/common/orpc/schemas/telemetry.ts
import { z as z21 } from "zod";
var ErrorContextSchema = z21.enum([
  "workspace-creation",
  "workspace-deletion",
  "workspace-switch",
  "message-send",
  "message-stream",
  "project-add",
  "project-remove",
  "git-operation"
]);
var TelemetryRuntimeTypeSchema = RuntimeModeSchema;
var FrontendPlatformInfoSchema = z21.object({
  userAgent: z21.string(),
  platform: z21.string()
});
var TelemetryThinkingLevelSchema = z21.enum(["off", "low", "medium", "high", "xhigh"]);
var TelemetryCommandTypeSchema = z21.enum([
  "clear",
  "compact",
  "new",
  "fork",
  "vim",
  "model",
  "mode",
  "plan",
  "providers"
]);
var AppStartedPropertiesSchema = z21.object({
  isFirstLaunch: z21.boolean(),
  vimModeEnabled: z21.boolean()
});
var WorkspaceCreatedPropertiesSchema = z21.object({
  workspaceId: z21.string(),
  runtimeType: TelemetryRuntimeTypeSchema,
  frontendPlatform: FrontendPlatformInfoSchema
});
var WorkspaceSwitchedPropertiesSchema = z21.object({
  fromWorkspaceId: z21.string(),
  toWorkspaceId: z21.string()
});
var MessageSentPropertiesSchema = z21.object({
  workspaceId: z21.string(),
  model: z21.string(),
  agentId: z21.string().min(1).optional().catch(void 0),
  message_length_b2: z21.number(),
  runtimeType: TelemetryRuntimeTypeSchema,
  frontendPlatform: FrontendPlatformInfoSchema,
  thinkingLevel: TelemetryThinkingLevelSchema
});
var TelemetryMCPTransportModeSchema = z21.enum([
  "none",
  "stdio_only",
  "http_only",
  "sse_only",
  "mixed"
]);
var MCPContextInjectedPropertiesSchema = z21.object({
  workspaceId: z21.string(),
  model: z21.string(),
  agentId: z21.string().min(1).optional().catch(void 0),
  runtimeType: TelemetryRuntimeTypeSchema,
  mcp_server_enabled_count: z21.number(),
  mcp_server_started_count: z21.number(),
  mcp_server_failed_count: z21.number(),
  mcp_tool_count: z21.number(),
  total_tool_count: z21.number(),
  builtin_tool_count: z21.number(),
  mcp_transport_mode: TelemetryMCPTransportModeSchema,
  mcp_has_http: z21.boolean(),
  mcp_has_sse: z21.boolean(),
  mcp_has_stdio: z21.boolean(),
  mcp_auto_fallback_count: z21.number(),
  mcp_setup_duration_ms_b2: z21.number()
});
var TelemetryMCPServerTransportSchema = z21.enum(["stdio", "http", "sse", "auto"]);
var TelemetryMCPTestErrorCategorySchema = z21.enum([
  "timeout",
  "connect",
  "http_status",
  "unknown"
]);
var MCPServerTestedPropertiesSchema = z21.object({
  transport: TelemetryMCPServerTransportSchema,
  success: z21.boolean(),
  duration_ms_b2: z21.number(),
  error_category: TelemetryMCPTestErrorCategorySchema.optional()
});
var TelemetryMCPServerConfigActionSchema = z21.enum([
  "add",
  "edit",
  "remove",
  "enable",
  "disable",
  "set_tool_allowlist",
  "set_headers"
]);
var StatsTabOpenedPropertiesSchema = z21.object({
  viewMode: z21.enum(["session", "last-request"]),
  showModeBreakdown: z21.boolean()
});
var StreamTimingComputedPropertiesSchema = z21.object({
  model: z21.string(),
  agentId: z21.string().min(1).optional().catch(void 0),
  duration_b2: z21.number(),
  ttft_ms_b2: z21.number(),
  tool_ms_b2: z21.number(),
  streaming_ms_b2: z21.number(),
  tool_percent_bucket: z21.number(),
  invalid: z21.boolean()
});
var StreamTimingInvalidPropertiesSchema = z21.object({
  reason: z21.string()
});
var MCPServerConfigChangedPropertiesSchema = z21.object({
  action: TelemetryMCPServerConfigActionSchema,
  transport: TelemetryMCPServerTransportSchema,
  has_headers: z21.boolean(),
  uses_secret_headers: z21.boolean(),
  tool_allowlist_size_b2: z21.number().optional()
});
var StreamCompletedPropertiesSchema = z21.object({
  model: z21.string(),
  wasInterrupted: z21.boolean(),
  duration_b2: z21.number(),
  output_tokens_b2: z21.number()
});
var CompactionCompletedPropertiesSchema = z21.object({
  model: z21.string(),
  duration_b2: z21.number(),
  input_tokens_b2: z21.number(),
  output_tokens_b2: z21.number(),
  compaction_source: z21.enum(["manual", "idle"])
});
var ProviderConfiguredPropertiesSchema = z21.object({
  provider: z21.string(),
  keyType: z21.string()
});
var CommandUsedPropertiesSchema = z21.object({
  command: TelemetryCommandTypeSchema
});
var VoiceTranscriptionPropertiesSchema = z21.object({
  audio_duration_b2: z21.number(),
  success: z21.boolean()
});
var ErrorOccurredPropertiesSchema = z21.object({
  errorType: z21.string(),
  context: ErrorContextSchema
});
var ExperimentOverriddenPropertiesSchema = z21.object({
  experimentId: z21.string(),
  assignedVariant: z21.union([z21.string(), z21.boolean(), z21.null()]),
  userChoice: z21.boolean()
});
var TelemetryEventSchema = z21.discriminatedUnion("event", [
  z21.object({
    event: z21.literal("app_started"),
    properties: AppStartedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("workspace_created"),
    properties: WorkspaceCreatedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("workspace_switched"),
    properties: WorkspaceSwitchedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("mcp_context_injected"),
    properties: MCPContextInjectedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("mcp_server_tested"),
    properties: MCPServerTestedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("stats_tab_opened"),
    properties: StatsTabOpenedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("stream_timing_computed"),
    properties: StreamTimingComputedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("stream_timing_invalid"),
    properties: StreamTimingInvalidPropertiesSchema
  }),
  z21.object({
    event: z21.literal("mcp_server_config_changed"),
    properties: MCPServerConfigChangedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("message_sent"),
    properties: MessageSentPropertiesSchema
  }),
  z21.object({
    event: z21.literal("stream_completed"),
    properties: StreamCompletedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("compaction_completed"),
    properties: CompactionCompletedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("provider_configured"),
    properties: ProviderConfiguredPropertiesSchema
  }),
  z21.object({
    event: z21.literal("command_used"),
    properties: CommandUsedPropertiesSchema
  }),
  z21.object({
    event: z21.literal("voice_transcription"),
    properties: VoiceTranscriptionPropertiesSchema
  }),
  z21.object({
    event: z21.literal("error_occurred"),
    properties: ErrorOccurredPropertiesSchema
  }),
  z21.object({
    event: z21.literal("experiment_overridden"),
    properties: ExperimentOverriddenPropertiesSchema
  })
]);
var telemetry = {
  track: {
    input: TelemetryEventSchema,
    output: z21.void()
  },
  status: {
    input: z21.void(),
    output: z21.object({
      /** True if telemetry is actively running (false in dev mode) */
      enabled: z21.boolean(),
      /** True only if user explicitly set UNIX_DISABLE_TELEMETRY=1 */
      explicit: z21.boolean()
    })
  }
};

// src/common/orpc/schemas/signing.ts
import { z as z22 } from "zod";
var signingCapabilitiesInput = z22.object({});
var signingErrorOutput = z22.object({
  /** Error message */
  message: z22.string(),
  /** True if a compatible key was found but requires a passphrase */
  hasEncryptedKey: z22.boolean()
});
var signingCapabilitiesOutput = z22.object({
  /** Public key in OpenSSH format (ssh-ed25519 AAAA...), null if no key is available */
  publicKey: z22.string().nullable(),
  /** Detected GitHub username, if any */
  githubUser: z22.string().nullable(),
  /** Error info if key loading or identity detection failed */
  error: signingErrorOutput.nullable()
});
var signatureEnvelopeOutput = z22.object({
  sig: z22.string(),
  publicKey: z22.string(),
  githubUser: z22.string().optional()
});
var signMessageInput = z22.object({
  content: z22.string()
}).strict();
var signMessageOutput = signatureEnvelopeOutput;
var clearIdentityCacheInput = z22.object({});
var clearIdentityCacheOutput = z22.object({
  success: z22.boolean()
});
var signing = {
  capabilities: {
    input: signingCapabilitiesInput,
    output: signingCapabilitiesOutput
  },
  signMessage: {
    input: signMessageInput,
    output: signMessageOutput
  },
  clearIdentityCache: {
    input: clearIdentityCacheInput,
    output: clearIdentityCacheOutput
  }
};

// src/common/orpc/schemas/api.ts
var ExperimentValueSchema = z23.object({
  value: z23.union([z23.string(), z23.boolean(), z23.null()]),
  source: z23.enum(["posthog", "cache", "disabled"])
});
var experiments = {
  getAll: {
    input: z23.void(),
    output: z23.record(z23.string(), ExperimentValueSchema)
  },
  reload: {
    input: z23.void(),
    output: z23.void()
  }
};
var BackgroundProcessInfoSchema = z23.object({
  id: z23.string(),
  pid: z23.number(),
  script: z23.string(),
  displayName: z23.string().optional(),
  startTime: z23.number(),
  status: z23.enum(["running", "exited", "killed", "failed"]),
  exitCode: z23.number().optional()
});
var tokenizer = {
  countTokens: {
    input: z23.object({ model: z23.string(), text: z23.string() }),
    output: z23.number()
  },
  countTokensBatch: {
    input: z23.object({ model: z23.string(), texts: z23.array(z23.string()) }),
    output: z23.array(z23.number())
  },
  calculateStats: {
    input: z23.object({
      workspaceId: z23.string(),
      messages: z23.array(UnixMessageSchema),
      model: z23.string()
    }),
    output: ChatStatsSchema
  }
};
var AWSCredentialStatusSchema = z23.object({
  region: z23.string().optional(),
  bearerTokenSet: z23.boolean(),
  accessKeyIdSet: z23.boolean(),
  secretAccessKeySet: z23.boolean()
});
var ProviderConfigInfoSchema = z23.object({
  apiKeySet: z23.boolean(),
  /** Whether this provider is configured and ready to use */
  isConfigured: z23.boolean(),
  baseUrl: z23.string().optional(),
  models: z23.array(z23.string()).optional(),
  /** OpenAI-specific fields */
  serviceTier: z23.enum(["auto", "default", "flex", "priority"]).optional(),
  /** AWS-specific fields (only present for bedrock provider) */
  aws: AWSCredentialStatusSchema.optional(),
  couponCodeSet: z23.boolean().optional()
});
var ProvidersConfigMapSchema = z23.record(z23.string(), ProviderConfigInfoSchema);
var providers = {
  setProviderConfig: {
    input: z23.object({
      provider: z23.string(),
      keyPath: z23.array(z23.string()),
      value: z23.string()
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  getConfig: {
    input: z23.void(),
    output: ProvidersConfigMapSchema
  },
  setModels: {
    input: z23.object({
      provider: z23.string(),
      models: z23.array(z23.string())
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  list: {
    input: z23.void(),
    output: z23.array(z23.string())
  },
  // Subscription: emits when provider config changes (API keys, models, etc.)
  onConfigChanged: {
    input: z23.void(),
    output: eventIterator(z23.void())
  }
};
var projects = {
  create: {
    input: z23.object({ projectPath: z23.string() }),
    output: ResultSchema(
      z23.object({
        projectConfig: ProjectConfigSchema,
        normalizedPath: z23.string()
      }),
      z23.string()
    )
  },
  pickDirectory: {
    input: z23.void(),
    output: z23.string().nullable()
  },
  remove: {
    input: z23.object({ projectPath: z23.string() }),
    output: ResultSchema(z23.void(), z23.string())
  },
  list: {
    input: z23.void(),
    output: z23.array(z23.tuple([z23.string(), ProjectConfigSchema]))
  },
  getFileCompletions: {
    input: z23.object({
      projectPath: z23.string(),
      query: z23.string(),
      limit: z23.number().int().positive().max(50).optional()
    }).strict(),
    output: z23.object({ paths: z23.array(z23.string()) })
  },
  runtimeAvailability: {
    input: z23.object({ projectPath: z23.string() }),
    output: RuntimeAvailabilitySchema
  },
  listBranches: {
    input: z23.object({ projectPath: z23.string() }),
    output: BranchListResultSchema
  },
  gitInit: {
    input: z23.object({ projectPath: z23.string() }),
    output: ResultSchema(z23.void(), z23.string())
  },
  mcp: {
    list: {
      input: z23.object({ projectPath: z23.string() }),
      output: MCPServerMapSchema
    },
    add: {
      input: MCPAddParamsSchema,
      output: ResultSchema(z23.void(), z23.string())
    },
    remove: {
      input: MCPRemoveParamsSchema,
      output: ResultSchema(z23.void(), z23.string())
    },
    test: {
      input: MCPTestParamsSchema,
      output: MCPTestResultSchema
    },
    setEnabled: {
      input: MCPSetEnabledParamsSchema,
      output: ResultSchema(z23.void(), z23.string())
    },
    setToolAllowlist: {
      input: MCPSetToolAllowlistParamsSchema,
      output: ResultSchema(z23.void(), z23.string())
    }
  },
  secrets: {
    get: {
      input: z23.object({ projectPath: z23.string() }),
      output: z23.array(SecretSchema)
    },
    update: {
      input: z23.object({
        projectPath: z23.string(),
        secrets: z23.array(SecretSchema)
      }),
      output: ResultSchema(z23.void(), z23.string())
    }
  },
  idleCompaction: {
    get: {
      input: z23.object({ projectPath: z23.string() }),
      output: z23.object({ hours: z23.number().nullable() })
    },
    set: {
      input: z23.object({
        projectPath: z23.string(),
        hours: z23.number().min(1).nullable()
      }),
      output: ResultSchema(z23.void(), z23.string())
    }
  },
  sections: {
    list: {
      input: z23.object({ projectPath: z23.string() }),
      output: z23.array(SectionConfigSchema)
    },
    create: {
      input: z23.object({
        projectPath: z23.string(),
        name: z23.string().min(1),
        color: z23.string().optional()
      }),
      output: ResultSchema(SectionConfigSchema, z23.string())
    },
    update: {
      input: z23.object({
        projectPath: z23.string(),
        sectionId: z23.string(),
        name: z23.string().min(1).optional(),
        color: z23.string().optional()
      }),
      output: ResultSchema(z23.void(), z23.string())
    },
    remove: {
      input: z23.object({
        projectPath: z23.string(),
        sectionId: z23.string()
      }),
      output: ResultSchema(z23.void(), z23.string())
    },
    reorder: {
      input: z23.object({
        projectPath: z23.string(),
        sectionIds: z23.array(z23.string())
      }),
      output: ResultSchema(z23.void(), z23.string())
    },
    assignWorkspace: {
      input: z23.object({
        projectPath: z23.string(),
        workspaceId: z23.string(),
        sectionId: z23.string().nullable()
      }),
      output: ResultSchema(z23.void(), z23.string())
    }
  }
};
var DebugLlmRequestSnapshotSchema = z23.object({
  capturedAt: z23.number(),
  workspaceId: z23.string(),
  messageId: z23.string().optional(),
  model: z23.string(),
  providerName: z23.string(),
  thinkingLevel: z23.string(),
  mode: z23.string().optional(),
  agentId: z23.string().optional(),
  maxOutputTokens: z23.number().optional(),
  systemMessage: z23.string(),
  messages: z23.array(z23.unknown()),
  response: z23.object({
    capturedAt: z23.number(),
    metadata: StreamEndEventSchema.shape.metadata,
    parts: z23.array(CompletedMessagePartSchema)
  }).strict().optional()
}).strict();
var workspace = {
  list: {
    input: z23.object({
      /** When true, only return archived workspaces. Default returns only non-archived. */
      archived: z23.boolean().optional()
    }).optional(),
    output: z23.array(FrontendWorkspaceMetadataSchema)
  },
  create: {
    input: z23.object({
      projectPath: z23.string(),
      branchName: z23.string(),
      /** Trunk branch to fork from - only required for worktree/SSH runtimes, ignored for local */
      trunkBranch: z23.string().optional(),
      /** Human-readable title (e.g., "Fix plan mode over SSH") - optional for backwards compat */
      title: z23.string().optional(),
      runtimeConfig: RuntimeConfigSchema.optional(),
      /** Section ID to assign the new workspace to (optional) */
      sectionId: z23.string().optional()
    }),
    output: z23.discriminatedUnion("success", [
      z23.object({ success: z23.literal(true), metadata: FrontendWorkspaceMetadataSchema }),
      z23.object({ success: z23.literal(false), error: z23.string() })
    ])
  },
  remove: {
    input: z23.object({
      workspaceId: z23.string(),
      options: z23.object({ force: z23.boolean().optional() }).optional()
    }),
    output: z23.object({ success: z23.boolean(), error: z23.string().optional() })
  },
  rename: {
    input: z23.object({ workspaceId: z23.string(), newName: z23.string() }),
    output: ResultSchema(z23.object({ newWorkspaceId: z23.string() }), z23.string())
  },
  updateTitle: {
    input: z23.object({ workspaceId: z23.string(), title: z23.string() }),
    output: ResultSchema(z23.void(), z23.string())
  },
  updateAgentAISettings: {
    input: z23.object({
      workspaceId: z23.string(),
      agentId: AgentIdSchema,
      aiSettings: WorkspaceAISettingsSchema
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  updateModeAISettings: {
    input: z23.object({
      workspaceId: z23.string(),
      mode: UIModeSchema,
      aiSettings: WorkspaceAISettingsSchema
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  archive: {
    input: z23.object({ workspaceId: z23.string() }),
    output: ResultSchema(z23.void(), z23.string())
  },
  unarchive: {
    input: z23.object({ workspaceId: z23.string() }),
    output: ResultSchema(z23.void(), z23.string())
  },
  fork: {
    input: z23.object({ sourceWorkspaceId: z23.string(), newName: z23.string() }),
    output: z23.discriminatedUnion("success", [
      z23.object({
        success: z23.literal(true),
        metadata: FrontendWorkspaceMetadataSchema,
        projectPath: z23.string()
      }),
      z23.object({ success: z23.literal(false), error: z23.string() })
    ])
  },
  sendMessage: {
    input: z23.object({
      workspaceId: z23.string(),
      message: z23.string(),
      options: SendMessageOptionsSchema.extend({
        fileParts: z23.array(FilePartSchema).optional()
      })
    }),
    output: ResultSchema(z23.object({}), SendMessageErrorSchema)
  },
  answerAskUserQuestion: {
    input: z23.object({
      workspaceId: z23.string(),
      toolCallId: z23.string(),
      answers: z23.record(z23.string(), z23.string())
    }).strict(),
    output: ResultSchema(z23.void(), z23.string())
  },
  resumeStream: {
    input: z23.object({
      workspaceId: z23.string(),
      options: SendMessageOptionsSchema
    }),
    output: ResultSchema(z23.void(), SendMessageErrorSchema)
  },
  interruptStream: {
    input: z23.object({
      workspaceId: z23.string(),
      options: z23.object({
        soft: z23.boolean().optional(),
        abandonPartial: z23.boolean().optional(),
        sendQueuedImmediately: z23.boolean().optional()
      }).optional()
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  clearQueue: {
    input: z23.object({ workspaceId: z23.string() }),
    output: ResultSchema(z23.void(), z23.string())
  },
  truncateHistory: {
    input: z23.object({
      workspaceId: z23.string(),
      percentage: z23.number().optional()
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  replaceChatHistory: {
    input: z23.object({
      workspaceId: z23.string(),
      summaryMessage: UnixMessageSchema,
      /** When true, delete the plan file (new + legacy paths) and clear plan tracking state. */
      deletePlanFile: z23.boolean().optional()
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  getDevcontainerInfo: {
    input: z23.object({ workspaceId: z23.string() }),
    output: z23.object({
      containerName: z23.string(),
      containerWorkspacePath: z23.string(),
      hostWorkspacePath: z23.string()
    }).nullable()
  },
  getInfo: {
    input: z23.object({ workspaceId: z23.string() }),
    output: FrontendWorkspaceMetadataSchema.nullable()
  },
  getLastLlmRequest: {
    input: z23.object({ workspaceId: z23.string() }),
    output: ResultSchema(DebugLlmRequestSnapshotSchema.nullable(), z23.string())
  },
  getFullReplay: {
    input: z23.object({ workspaceId: z23.string() }),
    output: z23.array(WorkspaceChatMessageSchema)
  },
  executeBash: {
    input: z23.object({
      workspaceId: z23.string(),
      script: z23.string(),
      options: z23.object({
        timeout_secs: z23.number().optional()
      }).optional()
    }),
    output: ResultSchema(BashToolResultSchema, z23.string())
  },
  getFileCompletions: {
    input: z23.object({
      workspaceId: z23.string(),
      query: z23.string(),
      limit: z23.number().int().positive().max(50).optional()
    }).strict(),
    output: z23.object({ paths: z23.array(z23.string()) })
  },
  // Subscriptions
  onChat: {
    input: z23.object({ workspaceId: z23.string() }),
    output: eventIterator(WorkspaceChatMessageSchema)
    // Stream event
  },
  onMetadata: {
    input: z23.void(),
    output: eventIterator(
      z23.object({
        workspaceId: z23.string(),
        metadata: FrontendWorkspaceMetadataSchema.nullable()
      })
    )
  },
  activity: {
    list: {
      input: z23.void(),
      output: z23.record(z23.string(), WorkspaceActivitySnapshotSchema)
    },
    subscribe: {
      input: z23.void(),
      output: eventIterator(
        z23.object({
          workspaceId: z23.string(),
          activity: WorkspaceActivitySnapshotSchema.nullable()
        })
      )
    }
  },
  /**
   * Get the current plan file content for a workspace.
   * Used by UI to refresh plan display when file is edited externally.
   */
  getPlanContent: {
    input: z23.object({ workspaceId: z23.string() }),
    output: ResultSchema(
      z23.object({
        content: z23.string(),
        path: z23.string()
      }),
      z23.string()
    )
  },
  backgroundBashes: {
    /**
     * Subscribe to background bash state changes for a workspace.
     * Emits full state on connect, then incremental updates.
     */
    subscribe: {
      input: z23.object({ workspaceId: z23.string() }),
      output: eventIterator(
        z23.object({
          /** Background processes (not including foreground ones being waited on) */
          processes: z23.array(BackgroundProcessInfoSchema),
          /** Tool call IDs of foreground bashes that can be sent to background */
          foregroundToolCallIds: z23.array(z23.string())
        })
      )
    },
    terminate: {
      input: z23.object({ workspaceId: z23.string(), processId: z23.string() }),
      output: ResultSchema(z23.void(), z23.string())
    },
    /**
     * Send a foreground bash process to background.
     * The process continues running but the agent stops waiting for it.
     */
    sendToBackground: {
      input: z23.object({ workspaceId: z23.string(), toolCallId: z23.string() }),
      output: ResultSchema(z23.void(), z23.string())
    },
    /**
     * Peek output for a background bash process without consuming the bash_output cursor.
     */
    getOutput: {
      input: z23.object({
        workspaceId: z23.string(),
        processId: z23.string(),
        fromOffset: z23.number().int().nonnegative().optional(),
        tailBytes: z23.number().int().positive().max(1e6).optional()
      }),
      output: ResultSchema(
        z23.object({
          status: z23.enum(["running", "exited", "killed", "failed"]),
          output: z23.string(),
          nextOffset: z23.number().int().nonnegative(),
          truncatedStart: z23.boolean()
        }),
        z23.string()
      )
    }
  },
  /**
   * Get post-compaction context state for a workspace.
   * Returns plan path (if exists) and tracked file paths that will be injected.
   */
  getPostCompactionState: {
    input: z23.object({ workspaceId: z23.string() }),
    output: z23.object({
      planPath: z23.string().nullable(),
      trackedFilePaths: z23.array(z23.string()),
      excludedItems: z23.array(z23.string())
    })
  },
  /**
   * Toggle whether a post-compaction item is excluded from injection.
   * Item IDs: "plan" for plan file, "file:<path>" for tracked files.
   */
  setPostCompactionExclusion: {
    input: z23.object({
      workspaceId: z23.string(),
      itemId: z23.string(),
      excluded: z23.boolean()
    }),
    output: ResultSchema(z23.void(), z23.string())
  },
  stats: {
    subscribe: {
      input: z23.object({ workspaceId: z23.string() }),
      output: eventIterator(WorkspaceStatsSnapshotSchema)
    },
    clear: {
      input: z23.object({ workspaceId: z23.string() }),
      output: ResultSchema(z23.void(), z23.string())
    }
  },
  getSessionUsage: {
    input: z23.object({ workspaceId: z23.string() }),
    output: SessionUsageFileSchema.optional()
  },
  /** Batch fetch session usage for multiple workspaces (for archived workspaces cost display) */
  getSessionUsageBatch: {
    input: z23.object({ workspaceIds: z23.array(z23.string()) }),
    output: z23.record(z23.string(), SessionUsageFileSchema.optional())
  },
  /** Per-workspace MCP configuration (overrides project-level mcp.jsonc) */
  mcp: {
    get: {
      input: z23.object({ workspaceId: z23.string() }),
      output: WorkspaceMCPOverridesSchema
    },
    set: {
      input: z23.object({
        workspaceId: z23.string(),
        overrides: WorkspaceMCPOverridesSchema
      }),
      output: ResultSchema(z23.void(), z23.string())
    }
  }
};
var tasks = {
  create: {
    input: z23.object({
      parentWorkspaceId: z23.string(),
      kind: z23.literal("agent"),
      agentId: AgentIdSchema.optional(),
      /** @deprecated Legacy alias for agentId (kept for downgrade compatibility). */
      agentType: z23.string().min(1).optional(),
      prompt: z23.string(),
      title: z23.string().min(1),
      modelString: z23.string().optional(),
      thinkingLevel: z23.string().optional()
    }).superRefine((value2, ctx) => {
      const hasAgentId = typeof value2.agentId === "string" && value2.agentId.trim().length > 0;
      const hasAgentType = typeof value2.agentType === "string" && value2.agentType.trim().length > 0;
      if (hasAgentId === hasAgentType) {
        ctx.addIssue({
          code: z23.ZodIssueCode.custom,
          message: "tasks.create: exactly one of agentId or agentType is required",
          path: ["agentId"]
        });
      }
    }),
    output: ResultSchema(
      z23.object({
        taskId: z23.string(),
        kind: z23.literal("agent"),
        status: z23.enum(["queued", "running"])
      }),
      z23.string()
    )
  }
};
var AgentDiscoveryInputSchema = z23.object({
  projectPath: z23.string().optional(),
  workspaceId: z23.string().optional(),
  /** When true, skip workspace worktree and discover from projectPath (but still use workspace runtime) */
  disableWorkspaceAgents: z23.boolean().optional()
}).refine((data) => Boolean(data.projectPath ?? data.workspaceId), {
  message: "Either projectPath or workspaceId must be provided"
});
var agents = {
  list: {
    input: AgentDiscoveryInputSchema,
    output: z23.array(AgentDefinitionDescriptorSchema)
  },
  get: {
    input: AgentDiscoveryInputSchema.and(z23.object({ agentId: AgentIdSchema })),
    output: AgentDefinitionPackageSchema
  }
};
var agentSkills = {
  list: {
    input: AgentDiscoveryInputSchema,
    output: z23.array(AgentSkillDescriptorSchema)
  },
  get: {
    input: AgentDiscoveryInputSchema.and(z23.object({ skillName: SkillNameSchema })),
    output: AgentSkillPackageSchema
  }
};
var nameGeneration = {
  generate: {
    input: z23.object({
      message: z23.string(),
      /** Models to try in order (defaults to small/cheap models like Haiku, GPT-Mini) */
      preferredModels: z23.array(z23.string()).optional(),
      /** User's selected model to try after preferred models (for Ollama/Bedrock/custom providers) */
      userModel: z23.string().optional()
    }),
    output: ResultSchema(
      z23.object({
        /** Short git-safe name with suffix (e.g., "plan-a1b2") */
        name: z23.string(),
        /** Human-readable title (e.g., "Fix plan mode over SSH") */
        title: z23.string(),
        modelUsed: z23.string()
      }),
      SendMessageErrorSchema
    )
  }
};
var window2 = {
  setTitle: {
    input: z23.object({ title: z23.string() }),
    output: z23.void()
  }
};
var terminal = {
  create: {
    input: TerminalCreateParamsSchema,
    output: TerminalSessionSchema
  },
  close: {
    input: z23.object({ sessionId: z23.string() }),
    output: z23.void()
  },
  resize: {
    input: TerminalResizeParamsSchema,
    output: z23.void()
  },
  sendInput: {
    input: z23.object({ sessionId: z23.string(), data: z23.string() }),
    output: z23.void()
  },
  onOutput: {
    input: z23.object({ sessionId: z23.string() }),
    output: eventIterator(z23.string())
  },
  /**
   * Attach to a terminal session with race-free state restore.
   * First yields { type: "screenState", data: string } with serialized screen (~4KB),
   * then yields { type: "output", data: string } for each live output chunk.
   * Guarantees no missed output between state snapshot and live stream.
   */
  attach: {
    input: z23.object({ sessionId: z23.string() }),
    output: eventIterator(
      z23.discriminatedUnion("type", [
        z23.object({ type: z23.literal("screenState"), data: z23.string() }),
        z23.object({ type: z23.literal("output"), data: z23.string() })
      ])
    )
  },
  onExit: {
    input: z23.object({ sessionId: z23.string() }),
    output: eventIterator(z23.number())
  },
  openWindow: {
    input: z23.object({
      workspaceId: z23.string(),
      /** Optional session ID to reattach to an existing terminal session (for pop-out handoff) */
      sessionId: z23.string().optional()
    }),
    output: z23.void()
  },
  closeWindow: {
    input: z23.object({ workspaceId: z23.string() }),
    output: z23.void()
  },
  /**
   * List active terminal sessions for a workspace.
   * Used by frontend to discover existing sessions to reattach to after reload.
   */
  listSessions: {
    input: z23.object({ workspaceId: z23.string() }),
    output: z23.array(z23.string())
  },
  /**
   * Open the native system terminal for a workspace.
   * Opens the user's preferred terminal emulator (Ghostty, Terminal.app, etc.)
   * with the working directory set to the workspace path.
   */
  openNative: {
    input: z23.object({ workspaceId: z23.string() }),
    output: z23.void()
  }
};
var ApiServerStatusSchema = z23.object({
  running: z23.boolean(),
  /** Base URL that is always connectable from the local machine (loopback for wildcard binds). */
  baseUrl: z23.string().nullable(),
  /** The host/interface the server is actually bound to. */
  bindHost: z23.string().nullable(),
  /** The port the server is listening on. */
  port: z23.number().int().min(0).max(65535).nullable(),
  /** Additional base URLs that may be reachable from other devices (LAN/VPN). */
  networkBaseUrls: z23.array(z23.url()),
  /** Auth token required for HTTP/WS API access. */
  token: z23.string().nullable(),
  /** Configured bind host from ~/.unix/config.json (if set). */
  configuredBindHost: z23.string().nullable(),
  /** Configured port from ~/.unix/config.json (if set). */
  configuredPort: z23.number().int().min(0).max(65535).nullable(),
  /** Whether the API server should serve the unix web UI at /. */
  configuredServeWebUi: z23.boolean()
});
var server = {
  getLaunchProject: {
    input: z23.void(),
    output: z23.string().nullable()
  },
  getSshHost: {
    input: z23.void(),
    output: z23.string().nullable()
  },
  setSshHost: {
    input: z23.object({ sshHost: z23.string().nullable() }),
    output: z23.void()
  },
  getApiServerStatus: {
    input: z23.void(),
    output: ApiServerStatusSchema
  },
  setApiServerSettings: {
    input: z23.object({
      bindHost: z23.string().nullable(),
      port: z23.number().int().min(0).max(65535).nullable(),
      serveWebUi: z23.boolean().nullable().optional()
    }),
    output: ApiServerStatusSchema
  }
};
var SubagentAiDefaultsEntrySchema = z23.object({
  modelString: z23.string().min(1).optional(),
  thinkingLevel: z23.enum(["off", "low", "medium", "high", "xhigh"]).optional()
}).strict();
var AgentAiDefaultsSchema = z23.record(z23.string().min(1), SubagentAiDefaultsEntrySchema);
var SubagentAiDefaultsSchema = z23.record(z23.string().min(1), SubagentAiDefaultsEntrySchema);
var config = {
  getConfig: {
    input: z23.void(),
    output: z23.object({
      taskSettings: z23.object({
        maxParallelAgentTasks: z23.number().int(),
        maxTaskNestingDepth: z23.number().int(),
        proposePlanImplementReplacesChatHistory: z23.boolean().optional(),
        bashOutputCompactionMinLines: z23.number().int().optional(),
        bashOutputCompactionMinTotalBytes: z23.number().int().optional(),
        bashOutputCompactionMaxKeptLines: z23.number().int().optional(),
        bashOutputCompactionTimeoutMs: z23.number().int().optional(),
        bashOutputCompactionHeuristicFallback: z23.boolean().optional()
      }),
      agentAiDefaults: AgentAiDefaultsSchema,
      // Legacy fields (downgrade compatibility)
      subagentAiDefaults: SubagentAiDefaultsSchema
    })
  },
  saveConfig: {
    input: z23.object({
      taskSettings: z23.object({
        maxParallelAgentTasks: z23.number().int(),
        maxTaskNestingDepth: z23.number().int(),
        proposePlanImplementReplacesChatHistory: z23.boolean().optional(),
        bashOutputCompactionMinLines: z23.number().int().optional(),
        bashOutputCompactionMinTotalBytes: z23.number().int().optional(),
        bashOutputCompactionMaxKeptLines: z23.number().int().optional(),
        bashOutputCompactionTimeoutMs: z23.number().int().optional(),
        bashOutputCompactionHeuristicFallback: z23.boolean().optional()
      }),
      agentAiDefaults: AgentAiDefaultsSchema.optional(),
      // Legacy field (downgrade compatibility)
      subagentAiDefaults: SubagentAiDefaultsSchema.optional()
    }),
    output: z23.void()
  },
  updateAgentAiDefaults: {
    input: z23.object({
      agentAiDefaults: AgentAiDefaultsSchema
    }),
    output: z23.void()
  }
};
var uiLayouts = {
  getAll: {
    input: z23.void(),
    output: LayoutPresetsConfigSchema
  },
  saveAll: {
    input: z23.object({
      layoutPresets: LayoutPresetsConfigSchema
    }).strict(),
    output: z23.void()
  }
};
var splashScreens = {
  getViewedSplashScreens: {
    input: z23.void(),
    output: z23.array(z23.string())
  },
  markSplashScreenViewed: {
    input: z23.object({
      splashId: z23.string()
    }),
    output: z23.void()
  }
};
var update = {
  check: {
    input: z23.void(),
    output: z23.void()
  },
  download: {
    input: z23.void(),
    output: z23.void()
  },
  install: {
    input: z23.void(),
    output: z23.void()
  },
  onStatus: {
    input: z23.void(),
    output: eventIterator(UpdateStatusSchema)
  }
};
var EditorTypeSchema = z23.enum(["vscode", "cursor", "zed", "custom"]);
var EditorConfigSchema = z23.object({
  editor: EditorTypeSchema,
  customCommand: z23.string().optional()
});
var StatsTabVariantSchema = z23.enum(["control", "stats"]);
var StatsTabOverrideSchema = z23.enum(["default", "on", "off"]);
var StatsTabStateSchema = z23.object({
  enabled: z23.boolean(),
  variant: StatsTabVariantSchema,
  override: StatsTabOverrideSchema
});
var features = {
  getStatsTabState: {
    input: z23.void(),
    output: StatsTabStateSchema
  },
  setStatsTabOverride: {
    input: z23.object({ override: StatsTabOverrideSchema }),
    output: StatsTabStateSchema
  }
};
var general = {
  listDirectory: {
    input: z23.object({ path: z23.string() }),
    output: ResultSchema(FileTreeNodeSchema)
  },
  /**
   * Create a directory at the specified path.
   * Creates parent directories recursively if they don't exist (like mkdir -p).
   */
  createDirectory: {
    input: z23.object({ path: z23.string() }),
    output: ResultSchema(z23.object({ normalizedPath: z23.string() }), z23.string())
  },
  ping: {
    input: z23.string(),
    output: z23.string()
  },
  /**
   * Test endpoint: emits numbered ticks at an interval.
   * Useful for verifying streaming works over HTTP and WebSocket.
   */
  tick: {
    input: z23.object({
      count: z23.number().int().min(1).max(100),
      intervalMs: z23.number().int().min(10).max(5e3)
    }),
    output: eventIterator(z23.object({ tick: z23.number(), timestamp: z23.number() }))
  },
  /**
   * Open a path in the user's configured code editor.
   * For SSH workspaces with useRemoteExtension enabled, uses Remote-SSH extension.
   *
   * @param workspaceId - The workspace (used to determine if SSH and get remote host)
   * @param targetPath - The path to open (workspace directory or specific file)
   * @param editorConfig - Editor configuration from user settings
   */
  openInEditor: {
    input: z23.object({
      workspaceId: z23.string(),
      targetPath: z23.string(),
      editorConfig: EditorConfigSchema
    }),
    output: ResultSchema(z23.void(), z23.string())
  }
};
var menu = {
  onOpenSettings: {
    input: z23.void(),
    output: eventIterator(z23.void())
  }
};
var voice = {
  transcribe: {
    input: z23.object({ audioBase64: z23.string() }),
    output: ResultSchema(z23.string(), z23.string())
  }
};
var debug = {
  /**
   * Trigger an artificial stream error for testing recovery.
   * Used by integration tests to simulate network errors mid-stream.
   */
  triggerStreamError: {
    input: z23.object({
      workspaceId: z23.string(),
      errorMessage: z23.string().optional()
    }),
    output: z23.boolean()
    // true if error was triggered on an active stream
  }
};

// node_modules/@ai-sdk/provider/dist/index.mjs
var marker = "vercel.ai.error";
var symbol = Symbol.for(marker);
var _a;
var _AISDKError = class _AISDKError2 extends Error {
  /**
   * Creates an AI SDK Error.
   *
   * @param {Object} params - The parameters for creating the error.
   * @param {string} params.name - The name of the error.
   * @param {string} params.message - The error message.
   * @param {unknown} [params.cause] - The underlying cause of the error.
   */
  constructor({
    name: name143,
    message,
    cause
  }) {
    super(message);
    this[_a] = true;
    this.name = name143;
    this.cause = cause;
  }
  /**
   * Checks if the given error is an AI SDK Error.
   * @param {unknown} error - The error to check.
   * @returns {boolean} True if the error is an AI SDK Error, false otherwise.
   */
  static isInstance(error) {
    return _AISDKError2.hasMarker(error, marker);
  }
  static hasMarker(error, marker153) {
    const markerSymbol = Symbol.for(marker153);
    return error != null && typeof error === "object" && markerSymbol in error && typeof error[markerSymbol] === "boolean" && error[markerSymbol] === true;
  }
};
_a = symbol;
var AISDKError = _AISDKError;
var name = "AI_APICallError";
var marker2 = `vercel.ai.error.${name}`;
var symbol2 = Symbol.for(marker2);
var _a2;
var APICallError = class extends AISDKError {
  constructor({
    message,
    url,
    requestBodyValues,
    statusCode,
    responseHeaders,
    responseBody,
    cause,
    isRetryable = statusCode != null && (statusCode === 408 || // request timeout
    statusCode === 409 || // conflict
    statusCode === 429 || // too many requests
    statusCode >= 500),
    // server error
    data
  }) {
    super({ name, message, cause });
    this[_a2] = true;
    this.url = url;
    this.requestBodyValues = requestBodyValues;
    this.statusCode = statusCode;
    this.responseHeaders = responseHeaders;
    this.responseBody = responseBody;
    this.isRetryable = isRetryable;
    this.data = data;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker2);
  }
};
_a2 = symbol2;
var name2 = "AI_EmptyResponseBodyError";
var marker3 = `vercel.ai.error.${name2}`;
var symbol3 = Symbol.for(marker3);
var _a3;
var EmptyResponseBodyError = class extends AISDKError {
  // used in isInstance
  constructor({ message = "Empty response body" } = {}) {
    super({ name: name2, message });
    this[_a3] = true;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker3);
  }
};
_a3 = symbol3;
function getErrorMessage(error) {
  if (error == null) {
    return "unknown error";
  }
  if (typeof error === "string") {
    return error;
  }
  if (error instanceof Error) {
    return error.message;
  }
  return JSON.stringify(error);
}
var name3 = "AI_InvalidArgumentError";
var marker4 = `vercel.ai.error.${name3}`;
var symbol4 = Symbol.for(marker4);
var _a4;
var InvalidArgumentError2 = class extends AISDKError {
  constructor({
    message,
    cause,
    argument
  }) {
    super({ name: name3, message, cause });
    this[_a4] = true;
    this.argument = argument;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker4);
  }
};
_a4 = symbol4;
var name4 = "AI_InvalidPromptError";
var marker5 = `vercel.ai.error.${name4}`;
var symbol5 = Symbol.for(marker5);
var _a5;
var InvalidPromptError = class extends AISDKError {
  constructor({
    prompt,
    message,
    cause
  }) {
    super({ name: name4, message: `Invalid prompt: ${message}`, cause });
    this[_a5] = true;
    this.prompt = prompt;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker5);
  }
};
_a5 = symbol5;
var name5 = "AI_InvalidResponseDataError";
var marker6 = `vercel.ai.error.${name5}`;
var symbol6 = Symbol.for(marker6);
var _a6;
_a6 = symbol6;
var name6 = "AI_JSONParseError";
var marker7 = `vercel.ai.error.${name6}`;
var symbol7 = Symbol.for(marker7);
var _a7;
var JSONParseError = class extends AISDKError {
  constructor({ text: text2, cause }) {
    super({
      name: name6,
      message: `JSON parsing failed: Text: ${text2}.
Error message: ${getErrorMessage(cause)}`,
      cause
    });
    this[_a7] = true;
    this.text = text2;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker7);
  }
};
_a7 = symbol7;
var name7 = "AI_LoadAPIKeyError";
var marker8 = `vercel.ai.error.${name7}`;
var symbol8 = Symbol.for(marker8);
var _a8;
_a8 = symbol8;
var name8 = "AI_LoadSettingError";
var marker9 = `vercel.ai.error.${name8}`;
var symbol9 = Symbol.for(marker9);
var _a9;
_a9 = symbol9;
var name9 = "AI_NoContentGeneratedError";
var marker10 = `vercel.ai.error.${name9}`;
var symbol10 = Symbol.for(marker10);
var _a10;
_a10 = symbol10;
var name10 = "AI_NoSuchModelError";
var marker11 = `vercel.ai.error.${name10}`;
var symbol11 = Symbol.for(marker11);
var _a11;
_a11 = symbol11;
var name11 = "AI_TooManyEmbeddingValuesForCallError";
var marker12 = `vercel.ai.error.${name11}`;
var symbol12 = Symbol.for(marker12);
var _a12;
_a12 = symbol12;
var name12 = "AI_TypeValidationError";
var marker13 = `vercel.ai.error.${name12}`;
var symbol13 = Symbol.for(marker13);
var _a13;
var _TypeValidationError = class _TypeValidationError2 extends AISDKError {
  constructor({ value: value2, cause }) {
    super({
      name: name12,
      message: `Type validation failed: Value: ${JSON.stringify(value2)}.
Error message: ${getErrorMessage(cause)}`,
      cause
    });
    this[_a13] = true;
    this.value = value2;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker13);
  }
  /**
   * Wraps an error into a TypeValidationError.
   * If the cause is already a TypeValidationError with the same value, it returns the cause.
   * Otherwise, it creates a new TypeValidationError.
   *
   * @param {Object} params - The parameters for wrapping the error.
   * @param {unknown} params.value - The value that failed validation.
   * @param {unknown} params.cause - The original error or cause of the validation failure.
   * @returns {TypeValidationError} A TypeValidationError instance.
   */
  static wrap({
    value: value2,
    cause
  }) {
    return _TypeValidationError2.isInstance(cause) && cause.value === value2 ? cause : new _TypeValidationError2({ value: value2, cause });
  }
};
_a13 = symbol13;
var TypeValidationError = _TypeValidationError;
var name13 = "AI_UnsupportedFunctionalityError";
var marker14 = `vercel.ai.error.${name13}`;
var symbol14 = Symbol.for(marker14);
var _a14;
var UnsupportedFunctionalityError = class extends AISDKError {
  constructor({
    functionality,
    message = `'${functionality}' functionality not supported.`
  }) {
    super({ name: name13, message });
    this[_a14] = true;
    this.functionality = functionality;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker14);
  }
};
_a14 = symbol14;
function isJSONValue(value2) {
  if (value2 === null || typeof value2 === "string" || typeof value2 === "number" || typeof value2 === "boolean") {
    return true;
  }
  if (Array.isArray(value2)) {
    return value2.every(isJSONValue);
  }
  if (typeof value2 === "object") {
    return Object.entries(value2).every(
      ([key, val]) => typeof key === "string" && isJSONValue(val)
    );
  }
  return false;
}
function isJSONArray(value2) {
  return Array.isArray(value2) && value2.every(isJSONValue);
}
function isJSONObject(value2) {
  return value2 != null && typeof value2 === "object" && Object.entries(value2).every(
    ([key, val]) => typeof key === "string" && isJSONValue(val)
  );
}

// node_modules/eventsource-parser/dist/index.js
var ParseError = class extends Error {
  constructor(message, options) {
    super(message), this.name = "ParseError", this.type = options.type, this.field = options.field, this.value = options.value, this.line = options.line;
  }
};
function noop(_arg) {
}
function createParser(callbacks) {
  if (typeof callbacks == "function")
    throw new TypeError(
      "`callbacks` must be an object, got a function instead. Did you mean `{onEvent: fn}`?"
    );
  const { onEvent = noop, onError: onError2 = noop, onRetry = noop, onComment } = callbacks;
  let incompleteLine = "", isFirstChunk = true, id, data = "", eventType = "";
  function feed(newChunk) {
    const chunk = isFirstChunk ? newChunk.replace(/^\xEF\xBB\xBF/, "") : newChunk, [complete, incomplete] = splitLines(`${incompleteLine}${chunk}`);
    for (const line of complete)
      parseLine(line);
    incompleteLine = incomplete, isFirstChunk = false;
  }
  function parseLine(line) {
    if (line === "") {
      dispatchEvent();
      return;
    }
    if (line.startsWith(":")) {
      onComment && onComment(line.slice(line.startsWith(": ") ? 2 : 1));
      return;
    }
    const fieldSeparatorIndex = line.indexOf(":");
    if (fieldSeparatorIndex !== -1) {
      const field = line.slice(0, fieldSeparatorIndex), offset = line[fieldSeparatorIndex + 1] === " " ? 2 : 1, value2 = line.slice(fieldSeparatorIndex + offset);
      processField(field, value2, line);
      return;
    }
    processField(line, "", line);
  }
  function processField(field, value2, line) {
    switch (field) {
      case "event":
        eventType = value2;
        break;
      case "data":
        data = `${data}${value2}
`;
        break;
      case "id":
        id = value2.includes("\0") ? void 0 : value2;
        break;
      case "retry":
        /^\d+$/.test(value2) ? onRetry(parseInt(value2, 10)) : onError2(
          new ParseError(`Invalid \`retry\` value: "${value2}"`, {
            type: "invalid-retry",
            value: value2,
            line
          })
        );
        break;
      default:
        onError2(
          new ParseError(
            `Unknown field "${field.length > 20 ? `${field.slice(0, 20)}\u2026` : field}"`,
            { type: "unknown-field", field, value: value2, line }
          )
        );
        break;
    }
  }
  function dispatchEvent() {
    data.length > 0 && onEvent({
      id,
      event: eventType || void 0,
      // If the data buffer's last character is a U+000A LINE FEED (LF) character,
      // then remove the last character from the data buffer.
      data: data.endsWith(`
`) ? data.slice(0, -1) : data
    }), id = void 0, data = "", eventType = "";
  }
  function reset(options = {}) {
    incompleteLine && options.consume && parseLine(incompleteLine), isFirstChunk = true, id = void 0, data = "", eventType = "", incompleteLine = "";
  }
  return { feed, reset };
}
function splitLines(chunk) {
  const lines = [];
  let incompleteLine = "", searchIndex = 0;
  for (; searchIndex < chunk.length; ) {
    const crIndex = chunk.indexOf("\r", searchIndex), lfIndex = chunk.indexOf(`
`, searchIndex);
    let lineEnd = -1;
    if (crIndex !== -1 && lfIndex !== -1 ? lineEnd = Math.min(crIndex, lfIndex) : crIndex !== -1 ? crIndex === chunk.length - 1 ? lineEnd = -1 : lineEnd = crIndex : lfIndex !== -1 && (lineEnd = lfIndex), lineEnd === -1) {
      incompleteLine = chunk.slice(searchIndex);
      break;
    } else {
      const line = chunk.slice(searchIndex, lineEnd);
      lines.push(line), searchIndex = lineEnd + 1, chunk[searchIndex - 1] === "\r" && chunk[searchIndex] === `
` && searchIndex++;
    }
  }
  return [lines, incompleteLine];
}

// node_modules/eventsource-parser/dist/stream.js
var EventSourceParserStream = class extends TransformStream {
  constructor({ onError: onError2, onRetry, onComment } = {}) {
    let parser;
    super({
      start(controller) {
        parser = createParser({
          onEvent: (event) => {
            controller.enqueue(event);
          },
          onError(error) {
            onError2 === "terminate" ? controller.error(error) : typeof onError2 == "function" && onError2(error);
          },
          onRetry,
          onComment
        });
      },
      transform(chunk) {
        parser.feed(chunk);
      }
    });
  }
};

// node_modules/@ai-sdk/provider-utils/dist/index.mjs
import * as z42 from "zod/v4";
import { ZodFirstPartyTypeKind as ZodFirstPartyTypeKind3 } from "zod/v3";
import { ZodFirstPartyTypeKind as ZodFirstPartyTypeKind2 } from "zod/v3";
import {
  ZodFirstPartyTypeKind as ZodFirstPartyTypeKind22
} from "zod/v3";
function combineHeaders(...headers) {
  return headers.reduce(
    (combinedHeaders, currentHeaders) => ({
      ...combinedHeaders,
      ...currentHeaders != null ? currentHeaders : {}
    }),
    {}
  );
}
async function delay(delayInMs, options) {
  if (delayInMs == null) {
    return Promise.resolve();
  }
  const signal = options == null ? void 0 : options.abortSignal;
  return new Promise((resolve22, reject) => {
    if (signal == null ? void 0 : signal.aborted) {
      reject(createAbortError());
      return;
    }
    const timeoutId = setTimeout(() => {
      cleanup();
      resolve22();
    }, delayInMs);
    const cleanup = () => {
      clearTimeout(timeoutId);
      signal == null ? void 0 : signal.removeEventListener("abort", onAbort);
    };
    const onAbort = () => {
      cleanup();
      reject(createAbortError());
    };
    signal == null ? void 0 : signal.addEventListener("abort", onAbort);
  });
}
function createAbortError() {
  return new DOMException("Delay was aborted", "AbortError");
}
function extractResponseHeaders(response) {
  return Object.fromEntries([...response.headers]);
}
var createIdGenerator = ({
  prefix,
  size = 16,
  alphabet = "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz",
  separator = "-"
} = {}) => {
  const generator = () => {
    const alphabetLength = alphabet.length;
    const chars = new Array(size);
    for (let i = 0; i < size; i++) {
      chars[i] = alphabet[Math.random() * alphabetLength | 0];
    }
    return chars.join("");
  };
  if (prefix == null) {
    return generator;
  }
  if (alphabet.includes(separator)) {
    throw new InvalidArgumentError2({
      argument: "separator",
      message: `The separator "${separator}" must not be part of the alphabet "${alphabet}".`
    });
  }
  return () => `${prefix}${separator}${generator()}`;
};
var generateId = createIdGenerator();
function getErrorMessage2(error) {
  if (error == null) {
    return "unknown error";
  }
  if (typeof error === "string") {
    return error;
  }
  if (error instanceof Error) {
    return error.message;
  }
  return JSON.stringify(error);
}
function isAbortError(error) {
  return (error instanceof Error || error instanceof DOMException) && (error.name === "AbortError" || error.name === "ResponseAborted" || // Next.js
  error.name === "TimeoutError");
}
var FETCH_FAILED_ERROR_MESSAGES = ["fetch failed", "failed to fetch"];
function handleFetchError({
  error,
  url,
  requestBodyValues
}) {
  if (isAbortError(error)) {
    return error;
  }
  if (error instanceof TypeError && FETCH_FAILED_ERROR_MESSAGES.includes(error.message.toLowerCase())) {
    const cause = error.cause;
    if (cause != null) {
      return new APICallError({
        message: `Cannot connect to API: ${cause.message}`,
        cause,
        url,
        requestBodyValues,
        isRetryable: true
        // retry when network error
      });
    }
  }
  return error;
}
function getRuntimeEnvironmentUserAgent(globalThisAny = globalThis) {
  var _a17, _b8, _c;
  if (globalThisAny.window) {
    return `runtime/browser`;
  }
  if ((_a17 = globalThisAny.navigator) == null ? void 0 : _a17.userAgent) {
    return `runtime/${globalThisAny.navigator.userAgent.toLowerCase()}`;
  }
  if ((_c = (_b8 = globalThisAny.process) == null ? void 0 : _b8.versions) == null ? void 0 : _c.node) {
    return `runtime/node.js/${globalThisAny.process.version.substring(0)}`;
  }
  if (globalThisAny.EdgeRuntime) {
    return `runtime/vercel-edge`;
  }
  return "runtime/unknown";
}
function normalizeHeaders(headers) {
  if (headers == null) {
    return {};
  }
  const normalized = {};
  if (headers instanceof Headers) {
    headers.forEach((value2, key) => {
      normalized[key.toLowerCase()] = value2;
    });
  } else {
    if (!Array.isArray(headers)) {
      headers = Object.entries(headers);
    }
    for (const [key, value2] of headers) {
      if (value2 != null) {
        normalized[key.toLowerCase()] = value2;
      }
    }
  }
  return normalized;
}
function withUserAgentSuffix(headers, ...userAgentSuffixParts) {
  const normalizedHeaders = new Headers(normalizeHeaders(headers));
  const currentUserAgentHeader = normalizedHeaders.get("user-agent") || "";
  normalizedHeaders.set(
    "user-agent",
    [currentUserAgentHeader, ...userAgentSuffixParts].filter(Boolean).join(" ")
  );
  return Object.fromEntries(normalizedHeaders.entries());
}
var VERSION = true ? "3.0.18" : "0.0.0-test";
var getOriginalFetch = () => globalThis.fetch;
var getFromApi = async ({
  url,
  headers = {},
  successfulResponseHandler,
  failedResponseHandler,
  abortSignal,
  fetch: fetch2 = getOriginalFetch()
}) => {
  try {
    const response = await fetch2(url, {
      method: "GET",
      headers: withUserAgentSuffix(
        headers,
        `ai-sdk/provider-utils/${VERSION}`,
        getRuntimeEnvironmentUserAgent()
      ),
      signal: abortSignal
    });
    const responseHeaders = extractResponseHeaders(response);
    if (!response.ok) {
      let errorInformation;
      try {
        errorInformation = await failedResponseHandler({
          response,
          url,
          requestBodyValues: {}
        });
      } catch (error) {
        if (isAbortError(error) || APICallError.isInstance(error)) {
          throw error;
        }
        throw new APICallError({
          message: "Failed to process error response",
          cause: error,
          statusCode: response.status,
          url,
          responseHeaders,
          requestBodyValues: {}
        });
      }
      throw errorInformation.value;
    }
    try {
      return await successfulResponseHandler({
        response,
        url,
        requestBodyValues: {}
      });
    } catch (error) {
      if (error instanceof Error) {
        if (isAbortError(error) || APICallError.isInstance(error)) {
          throw error;
        }
      }
      throw new APICallError({
        message: "Failed to process successful response",
        cause: error,
        statusCode: response.status,
        url,
        responseHeaders,
        requestBodyValues: {}
      });
    }
  } catch (error) {
    throw handleFetchError({ error, url, requestBodyValues: {} });
  }
};
function isUrlSupported({
  mediaType,
  url,
  supportedUrls
}) {
  url = url.toLowerCase();
  mediaType = mediaType.toLowerCase();
  return Object.entries(supportedUrls).map(([key, value2]) => {
    const mediaType2 = key.toLowerCase();
    return mediaType2 === "*" || mediaType2 === "*/*" ? { mediaTypePrefix: "", regexes: value2 } : { mediaTypePrefix: mediaType2.replace(/\*/, ""), regexes: value2 };
  }).filter(({ mediaTypePrefix }) => mediaType.startsWith(mediaTypePrefix)).flatMap(({ regexes }) => regexes).some((pattern) => pattern.test(url));
}
function loadOptionalSetting({
  settingValue,
  environmentVariableName
}) {
  if (typeof settingValue === "string") {
    return settingValue;
  }
  if (settingValue != null || typeof process === "undefined") {
    return void 0;
  }
  settingValue = process.env[environmentVariableName];
  if (settingValue == null || typeof settingValue !== "string") {
    return void 0;
  }
  return settingValue;
}
var suspectProtoRx = /"__proto__"\s*:/;
var suspectConstructorRx = /"constructor"\s*:/;
function _parse(text2) {
  const obj = JSON.parse(text2);
  if (obj === null || typeof obj !== "object") {
    return obj;
  }
  if (suspectProtoRx.test(text2) === false && suspectConstructorRx.test(text2) === false) {
    return obj;
  }
  return filter(obj);
}
function filter(obj) {
  let next = [obj];
  while (next.length) {
    const nodes = next;
    next = [];
    for (const node of nodes) {
      if (Object.prototype.hasOwnProperty.call(node, "__proto__")) {
        throw new SyntaxError("Object contains forbidden prototype property");
      }
      if (Object.prototype.hasOwnProperty.call(node, "constructor") && Object.prototype.hasOwnProperty.call(node.constructor, "prototype")) {
        throw new SyntaxError("Object contains forbidden prototype property");
      }
      for (const key in node) {
        const value2 = node[key];
        if (value2 && typeof value2 === "object") {
          next.push(value2);
        }
      }
    }
  }
  return obj;
}
function secureJsonParse(text2) {
  const { stackTraceLimit } = Error;
  try {
    Error.stackTraceLimit = 0;
  } catch (e) {
    return _parse(text2);
  }
  try {
    return _parse(text2);
  } finally {
    Error.stackTraceLimit = stackTraceLimit;
  }
}
var validatorSymbol = Symbol.for("vercel.ai.validator");
function validator(validate) {
  return { [validatorSymbol]: true, validate };
}
function isValidator(value2) {
  return typeof value2 === "object" && value2 !== null && validatorSymbol in value2 && value2[validatorSymbol] === true && "validate" in value2;
}
function lazyValidator(createValidator) {
  let validator2;
  return () => {
    if (validator2 == null) {
      validator2 = createValidator();
    }
    return validator2;
  };
}
function asValidator(value2) {
  return isValidator(value2) ? value2 : typeof value2 === "function" ? value2() : standardSchemaValidator(value2);
}
function standardSchemaValidator(standardSchema) {
  return validator(async (value2) => {
    const result = await standardSchema["~standard"].validate(value2);
    return result.issues == null ? { success: true, value: result.value } : {
      success: false,
      error: new TypeValidationError({
        value: value2,
        cause: result.issues
      })
    };
  });
}
async function validateTypes({
  value: value2,
  schema
}) {
  const result = await safeValidateTypes({ value: value2, schema });
  if (!result.success) {
    throw TypeValidationError.wrap({ value: value2, cause: result.error });
  }
  return result.value;
}
async function safeValidateTypes({
  value: value2,
  schema
}) {
  const validator2 = asValidator(schema);
  try {
    if (validator2.validate == null) {
      return { success: true, value: value2, rawValue: value2 };
    }
    const result = await validator2.validate(value2);
    if (result.success) {
      return { success: true, value: result.value, rawValue: value2 };
    }
    return {
      success: false,
      error: TypeValidationError.wrap({ value: value2, cause: result.error }),
      rawValue: value2
    };
  } catch (error) {
    return {
      success: false,
      error: TypeValidationError.wrap({ value: value2, cause: error }),
      rawValue: value2
    };
  }
}
async function parseJSON({
  text: text2,
  schema
}) {
  try {
    const value2 = secureJsonParse(text2);
    if (schema == null) {
      return value2;
    }
    return validateTypes({ value: value2, schema });
  } catch (error) {
    if (JSONParseError.isInstance(error) || TypeValidationError.isInstance(error)) {
      throw error;
    }
    throw new JSONParseError({ text: text2, cause: error });
  }
}
async function safeParseJSON({
  text: text2,
  schema
}) {
  try {
    const value2 = secureJsonParse(text2);
    if (schema == null) {
      return { success: true, value: value2, rawValue: value2 };
    }
    return await safeValidateTypes({ value: value2, schema });
  } catch (error) {
    return {
      success: false,
      error: JSONParseError.isInstance(error) ? error : new JSONParseError({ text: text2, cause: error }),
      rawValue: void 0
    };
  }
}
function parseJsonEventStream({
  stream,
  schema
}) {
  return stream.pipeThrough(new TextDecoderStream()).pipeThrough(new EventSourceParserStream()).pipeThrough(
    new TransformStream({
      async transform({ data }, controller) {
        if (data === "[DONE]") {
          return;
        }
        controller.enqueue(await safeParseJSON({ text: data, schema }));
      }
    })
  );
}
var getOriginalFetch2 = () => globalThis.fetch;
var postJsonToApi = async ({
  url,
  headers,
  body,
  failedResponseHandler,
  successfulResponseHandler,
  abortSignal,
  fetch: fetch2
}) => postToApi({
  url,
  headers: {
    "Content-Type": "application/json",
    ...headers
  },
  body: {
    content: JSON.stringify(body),
    values: body
  },
  failedResponseHandler,
  successfulResponseHandler,
  abortSignal,
  fetch: fetch2
});
var postToApi = async ({
  url,
  headers = {},
  body,
  successfulResponseHandler,
  failedResponseHandler,
  abortSignal,
  fetch: fetch2 = getOriginalFetch2()
}) => {
  try {
    const response = await fetch2(url, {
      method: "POST",
      headers: withUserAgentSuffix(
        headers,
        `ai-sdk/provider-utils/${VERSION}`,
        getRuntimeEnvironmentUserAgent()
      ),
      body: body.content,
      signal: abortSignal
    });
    const responseHeaders = extractResponseHeaders(response);
    if (!response.ok) {
      let errorInformation;
      try {
        errorInformation = await failedResponseHandler({
          response,
          url,
          requestBodyValues: body.values
        });
      } catch (error) {
        if (isAbortError(error) || APICallError.isInstance(error)) {
          throw error;
        }
        throw new APICallError({
          message: "Failed to process error response",
          cause: error,
          statusCode: response.status,
          url,
          responseHeaders,
          requestBodyValues: body.values
        });
      }
      throw errorInformation.value;
    }
    try {
      return await successfulResponseHandler({
        response,
        url,
        requestBodyValues: body.values
      });
    } catch (error) {
      if (error instanceof Error) {
        if (isAbortError(error) || APICallError.isInstance(error)) {
          throw error;
        }
      }
      throw new APICallError({
        message: "Failed to process successful response",
        cause: error,
        statusCode: response.status,
        url,
        responseHeaders,
        requestBodyValues: body.values
      });
    }
  } catch (error) {
    throw handleFetchError({ error, url, requestBodyValues: body.values });
  }
};
async function resolve(value2) {
  if (typeof value2 === "function") {
    value2 = value2();
  }
  return Promise.resolve(value2);
}
var createJsonErrorResponseHandler = ({
  errorSchema,
  errorToMessage,
  isRetryable
}) => async ({ response, url, requestBodyValues }) => {
  const responseBody = await response.text();
  const responseHeaders = extractResponseHeaders(response);
  if (responseBody.trim() === "") {
    return {
      responseHeaders,
      value: new APICallError({
        message: response.statusText,
        url,
        requestBodyValues,
        statusCode: response.status,
        responseHeaders,
        responseBody,
        isRetryable: isRetryable == null ? void 0 : isRetryable(response)
      })
    };
  }
  try {
    const parsedError = await parseJSON({
      text: responseBody,
      schema: errorSchema
    });
    return {
      responseHeaders,
      value: new APICallError({
        message: errorToMessage(parsedError),
        url,
        requestBodyValues,
        statusCode: response.status,
        responseHeaders,
        responseBody,
        data: parsedError,
        isRetryable: isRetryable == null ? void 0 : isRetryable(response, parsedError)
      })
    };
  } catch (parseError) {
    return {
      responseHeaders,
      value: new APICallError({
        message: response.statusText,
        url,
        requestBodyValues,
        statusCode: response.status,
        responseHeaders,
        responseBody,
        isRetryable: isRetryable == null ? void 0 : isRetryable(response)
      })
    };
  }
};
var createEventSourceResponseHandler = (chunkSchema) => async ({ response }) => {
  const responseHeaders = extractResponseHeaders(response);
  if (response.body == null) {
    throw new EmptyResponseBodyError({});
  }
  return {
    responseHeaders,
    value: parseJsonEventStream({
      stream: response.body,
      schema: chunkSchema
    })
  };
};
var createJsonResponseHandler = (responseSchema) => async ({ response, url, requestBodyValues }) => {
  const responseBody = await response.text();
  const parsedResult = await safeParseJSON({
    text: responseBody,
    schema: responseSchema
  });
  const responseHeaders = extractResponseHeaders(response);
  if (!parsedResult.success) {
    throw new APICallError({
      message: "Invalid JSON response",
      cause: parsedResult.error,
      statusCode: response.status,
      responseHeaders,
      responseBody,
      url,
      requestBodyValues
    });
  }
  return {
    responseHeaders,
    value: parsedResult.value,
    rawValue: parsedResult.rawValue
  };
};
var getRelativePath2 = (pathA, pathB) => {
  let i = 0;
  for (; i < pathA.length && i < pathB.length; i++) {
    if (pathA[i] !== pathB[i]) break;
  }
  return [(pathA.length - i).toString(), ...pathB.slice(i)].join("/");
};
var ignoreOverride2 = Symbol(
  "Let zodToJsonSchema decide on which parser to use"
);
var defaultOptions2 = {
  name: void 0,
  $refStrategy: "root",
  basePath: ["#"],
  effectStrategy: "input",
  pipeStrategy: "all",
  dateStrategy: "format:date-time",
  mapStrategy: "entries",
  removeAdditionalStrategy: "passthrough",
  allowedAdditionalProperties: true,
  rejectedAdditionalProperties: false,
  definitionPath: "definitions",
  strictUnions: false,
  definitions: {},
  errorMessages: false,
  patternStrategy: "escape",
  applyRegexFlags: false,
  emailStrategy: "format:email",
  base64Strategy: "contentEncoding:base64",
  nameStrategy: "ref"
};
var getDefaultOptions2 = (options) => typeof options === "string" ? {
  ...defaultOptions2,
  name: options
} : {
  ...defaultOptions2,
  ...options
};
function parseAnyDef2() {
  return {};
}
function parseArrayDef2(def, refs) {
  var _a17, _b8, _c;
  const res = {
    type: "array"
  };
  if (((_a17 = def.type) == null ? void 0 : _a17._def) && ((_c = (_b8 = def.type) == null ? void 0 : _b8._def) == null ? void 0 : _c.typeName) !== ZodFirstPartyTypeKind2.ZodAny) {
    res.items = parseDef2(def.type._def, {
      ...refs,
      currentPath: [...refs.currentPath, "items"]
    });
  }
  if (def.minLength) {
    res.minItems = def.minLength.value;
  }
  if (def.maxLength) {
    res.maxItems = def.maxLength.value;
  }
  if (def.exactLength) {
    res.minItems = def.exactLength.value;
    res.maxItems = def.exactLength.value;
  }
  return res;
}
function parseBigintDef2(def) {
  const res = {
    type: "integer",
    format: "int64"
  };
  if (!def.checks) return res;
  for (const check of def.checks) {
    switch (check.kind) {
      case "min":
        if (check.inclusive) {
          res.minimum = check.value;
        } else {
          res.exclusiveMinimum = check.value;
        }
        break;
      case "max":
        if (check.inclusive) {
          res.maximum = check.value;
        } else {
          res.exclusiveMaximum = check.value;
        }
        break;
      case "multipleOf":
        res.multipleOf = check.value;
        break;
    }
  }
  return res;
}
function parseBooleanDef2() {
  return { type: "boolean" };
}
function parseBrandedDef2(_def, refs) {
  return parseDef2(_def.type._def, refs);
}
var parseCatchDef2 = (def, refs) => {
  return parseDef2(def.innerType._def, refs);
};
function parseDateDef2(def, refs, overrideDateStrategy) {
  const strategy = overrideDateStrategy != null ? overrideDateStrategy : refs.dateStrategy;
  if (Array.isArray(strategy)) {
    return {
      anyOf: strategy.map((item, i) => parseDateDef2(def, refs, item))
    };
  }
  switch (strategy) {
    case "string":
    case "format:date-time":
      return {
        type: "string",
        format: "date-time"
      };
    case "format:date":
      return {
        type: "string",
        format: "date"
      };
    case "integer":
      return integerDateParser2(def);
  }
}
var integerDateParser2 = (def) => {
  const res = {
    type: "integer",
    format: "unix-time"
  };
  for (const check of def.checks) {
    switch (check.kind) {
      case "min":
        res.minimum = check.value;
        break;
      case "max":
        res.maximum = check.value;
        break;
    }
  }
  return res;
};
function parseDefaultDef2(_def, refs) {
  return {
    ...parseDef2(_def.innerType._def, refs),
    default: _def.defaultValue()
  };
}
function parseEffectsDef2(_def, refs) {
  return refs.effectStrategy === "input" ? parseDef2(_def.schema._def, refs) : parseAnyDef2();
}
function parseEnumDef2(def) {
  return {
    type: "string",
    enum: Array.from(def.values)
  };
}
var isJsonSchema7AllOfType2 = (type2) => {
  if ("type" in type2 && type2.type === "string") return false;
  return "allOf" in type2;
};
function parseIntersectionDef2(def, refs) {
  const allOf = [
    parseDef2(def.left._def, {
      ...refs,
      currentPath: [...refs.currentPath, "allOf", "0"]
    }),
    parseDef2(def.right._def, {
      ...refs,
      currentPath: [...refs.currentPath, "allOf", "1"]
    })
  ].filter((x) => !!x);
  const mergedAllOf = [];
  allOf.forEach((schema) => {
    if (isJsonSchema7AllOfType2(schema)) {
      mergedAllOf.push(...schema.allOf);
    } else {
      let nestedSchema = schema;
      if ("additionalProperties" in schema && schema.additionalProperties === false) {
        const { additionalProperties, ...rest } = schema;
        nestedSchema = rest;
      }
      mergedAllOf.push(nestedSchema);
    }
  });
  return mergedAllOf.length ? { allOf: mergedAllOf } : void 0;
}
function parseLiteralDef2(def) {
  const parsedType = typeof def.value;
  if (parsedType !== "bigint" && parsedType !== "number" && parsedType !== "boolean" && parsedType !== "string") {
    return {
      type: Array.isArray(def.value) ? "array" : "object"
    };
  }
  return {
    type: parsedType === "bigint" ? "integer" : parsedType,
    const: def.value
  };
}
var emojiRegex2 = void 0;
var zodPatterns2 = {
  /**
   * `c` was changed to `[cC]` to replicate /i flag
   */
  cuid: /^[cC][^\s-]{8,}$/,
  cuid2: /^[0-9a-z]+$/,
  ulid: /^[0-9A-HJKMNP-TV-Z]{26}$/,
  /**
   * `a-z` was added to replicate /i flag
   */
  email: /^(?!\.)(?!.*\.\.)([a-zA-Z0-9_'+\-\.]*)[a-zA-Z0-9_+-]@([a-zA-Z0-9][a-zA-Z0-9\-]*\.)+[a-zA-Z]{2,}$/,
  /**
   * Constructed a valid Unicode RegExp
   *
   * Lazily instantiate since this type of regex isn't supported
   * in all envs (e.g. React Native).
   *
   * See:
   * https://github.com/colinhacks/zod/issues/2433
   * Fix in Zod:
   * https://github.com/colinhacks/zod/commit/9340fd51e48576a75adc919bff65dbc4a5d4c99b
   */
  emoji: () => {
    if (emojiRegex2 === void 0) {
      emojiRegex2 = RegExp(
        "^(\\p{Extended_Pictographic}|\\p{Emoji_Component})+$",
        "u"
      );
    }
    return emojiRegex2;
  },
  /**
   * Unused
   */
  uuid: /^[0-9a-fA-F]{8}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{4}\b-[0-9a-fA-F]{12}$/,
  /**
   * Unused
   */
  ipv4: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$/,
  ipv4Cidr: /^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\/(3[0-2]|[12]?[0-9])$/,
  /**
   * Unused
   */
  ipv6: /^(([a-f0-9]{1,4}:){7}|::([a-f0-9]{1,4}:){0,6}|([a-f0-9]{1,4}:){1}:([a-f0-9]{1,4}:){0,5}|([a-f0-9]{1,4}:){2}:([a-f0-9]{1,4}:){0,4}|([a-f0-9]{1,4}:){3}:([a-f0-9]{1,4}:){0,3}|([a-f0-9]{1,4}:){4}:([a-f0-9]{1,4}:){0,2}|([a-f0-9]{1,4}:){5}:([a-f0-9]{1,4}:){0,1})([a-f0-9]{1,4}|(((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2}))\.){3}((25[0-5])|(2[0-4][0-9])|(1[0-9]{2})|([0-9]{1,2})))$/,
  ipv6Cidr: /^(([0-9a-fA-F]{1,4}:){7,7}[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,7}:|([0-9a-fA-F]{1,4}:){1,6}:[0-9a-fA-F]{1,4}|([0-9a-fA-F]{1,4}:){1,5}(:[0-9a-fA-F]{1,4}){1,2}|([0-9a-fA-F]{1,4}:){1,4}(:[0-9a-fA-F]{1,4}){1,3}|([0-9a-fA-F]{1,4}:){1,3}(:[0-9a-fA-F]{1,4}){1,4}|([0-9a-fA-F]{1,4}:){1,2}(:[0-9a-fA-F]{1,4}){1,5}|[0-9a-fA-F]{1,4}:((:[0-9a-fA-F]{1,4}){1,6})|:((:[0-9a-fA-F]{1,4}){1,7}|:)|fe80:(:[0-9a-fA-F]{0,4}){0,4}%[0-9a-zA-Z]{1,}|::(ffff(:0{1,4}){0,1}:){0,1}((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])|([0-9a-fA-F]{1,4}:){1,4}:((25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9])\.){3,3}(25[0-5]|(2[0-4]|1{0,1}[0-9]){0,1}[0-9]))\/(12[0-8]|1[01][0-9]|[1-9]?[0-9])$/,
  base64: /^([0-9a-zA-Z+/]{4})*(([0-9a-zA-Z+/]{2}==)|([0-9a-zA-Z+/]{3}=))?$/,
  base64url: /^([0-9a-zA-Z-_]{4})*(([0-9a-zA-Z-_]{2}(==)?)|([0-9a-zA-Z-_]{3}(=)?))?$/,
  nanoid: /^[a-zA-Z0-9_-]{21}$/,
  jwt: /^[A-Za-z0-9-_]+\.[A-Za-z0-9-_]+\.[A-Za-z0-9-_]*$/
};
function parseStringDef2(def, refs) {
  const res = {
    type: "string"
  };
  if (def.checks) {
    for (const check of def.checks) {
      switch (check.kind) {
        case "min":
          res.minLength = typeof res.minLength === "number" ? Math.max(res.minLength, check.value) : check.value;
          break;
        case "max":
          res.maxLength = typeof res.maxLength === "number" ? Math.min(res.maxLength, check.value) : check.value;
          break;
        case "email":
          switch (refs.emailStrategy) {
            case "format:email":
              addFormat2(res, "email", check.message, refs);
              break;
            case "format:idn-email":
              addFormat2(res, "idn-email", check.message, refs);
              break;
            case "pattern:zod":
              addPattern2(res, zodPatterns2.email, check.message, refs);
              break;
          }
          break;
        case "url":
          addFormat2(res, "uri", check.message, refs);
          break;
        case "uuid":
          addFormat2(res, "uuid", check.message, refs);
          break;
        case "regex":
          addPattern2(res, check.regex, check.message, refs);
          break;
        case "cuid":
          addPattern2(res, zodPatterns2.cuid, check.message, refs);
          break;
        case "cuid2":
          addPattern2(res, zodPatterns2.cuid2, check.message, refs);
          break;
        case "startsWith":
          addPattern2(
            res,
            RegExp(`^${escapeLiteralCheckValue2(check.value, refs)}`),
            check.message,
            refs
          );
          break;
        case "endsWith":
          addPattern2(
            res,
            RegExp(`${escapeLiteralCheckValue2(check.value, refs)}$`),
            check.message,
            refs
          );
          break;
        case "datetime":
          addFormat2(res, "date-time", check.message, refs);
          break;
        case "date":
          addFormat2(res, "date", check.message, refs);
          break;
        case "time":
          addFormat2(res, "time", check.message, refs);
          break;
        case "duration":
          addFormat2(res, "duration", check.message, refs);
          break;
        case "length":
          res.minLength = typeof res.minLength === "number" ? Math.max(res.minLength, check.value) : check.value;
          res.maxLength = typeof res.maxLength === "number" ? Math.min(res.maxLength, check.value) : check.value;
          break;
        case "includes": {
          addPattern2(
            res,
            RegExp(escapeLiteralCheckValue2(check.value, refs)),
            check.message,
            refs
          );
          break;
        }
        case "ip": {
          if (check.version !== "v6") {
            addFormat2(res, "ipv4", check.message, refs);
          }
          if (check.version !== "v4") {
            addFormat2(res, "ipv6", check.message, refs);
          }
          break;
        }
        case "base64url":
          addPattern2(res, zodPatterns2.base64url, check.message, refs);
          break;
        case "jwt":
          addPattern2(res, zodPatterns2.jwt, check.message, refs);
          break;
        case "cidr": {
          if (check.version !== "v6") {
            addPattern2(res, zodPatterns2.ipv4Cidr, check.message, refs);
          }
          if (check.version !== "v4") {
            addPattern2(res, zodPatterns2.ipv6Cidr, check.message, refs);
          }
          break;
        }
        case "emoji":
          addPattern2(res, zodPatterns2.emoji(), check.message, refs);
          break;
        case "ulid": {
          addPattern2(res, zodPatterns2.ulid, check.message, refs);
          break;
        }
        case "base64": {
          switch (refs.base64Strategy) {
            case "format:binary": {
              addFormat2(res, "binary", check.message, refs);
              break;
            }
            case "contentEncoding:base64": {
              res.contentEncoding = "base64";
              break;
            }
            case "pattern:zod": {
              addPattern2(res, zodPatterns2.base64, check.message, refs);
              break;
            }
          }
          break;
        }
        case "nanoid": {
          addPattern2(res, zodPatterns2.nanoid, check.message, refs);
        }
        case "toLowerCase":
        case "toUpperCase":
        case "trim":
          break;
        default:
          /* @__PURE__ */ ((_) => {
          })(check);
      }
    }
  }
  return res;
}
function escapeLiteralCheckValue2(literal, refs) {
  return refs.patternStrategy === "escape" ? escapeNonAlphaNumeric2(literal) : literal;
}
var ALPHA_NUMERIC2 = new Set(
  "ABCDEFGHIJKLMNOPQRSTUVXYZabcdefghijklmnopqrstuvxyz0123456789"
);
function escapeNonAlphaNumeric2(source) {
  let result = "";
  for (let i = 0; i < source.length; i++) {
    if (!ALPHA_NUMERIC2.has(source[i])) {
      result += "\\";
    }
    result += source[i];
  }
  return result;
}
function addFormat2(schema, value2, message, refs) {
  var _a17;
  if (schema.format || ((_a17 = schema.anyOf) == null ? void 0 : _a17.some((x) => x.format))) {
    if (!schema.anyOf) {
      schema.anyOf = [];
    }
    if (schema.format) {
      schema.anyOf.push({
        format: schema.format
      });
      delete schema.format;
    }
    schema.anyOf.push({
      format: value2,
      ...message && refs.errorMessages && { errorMessage: { format: message } }
    });
  } else {
    schema.format = value2;
  }
}
function addPattern2(schema, regex, message, refs) {
  var _a17;
  if (schema.pattern || ((_a17 = schema.allOf) == null ? void 0 : _a17.some((x) => x.pattern))) {
    if (!schema.allOf) {
      schema.allOf = [];
    }
    if (schema.pattern) {
      schema.allOf.push({
        pattern: schema.pattern
      });
      delete schema.pattern;
    }
    schema.allOf.push({
      pattern: stringifyRegExpWithFlags2(regex, refs),
      ...message && refs.errorMessages && { errorMessage: { pattern: message } }
    });
  } else {
    schema.pattern = stringifyRegExpWithFlags2(regex, refs);
  }
}
function stringifyRegExpWithFlags2(regex, refs) {
  var _a17;
  if (!refs.applyRegexFlags || !regex.flags) {
    return regex.source;
  }
  const flags = {
    i: regex.flags.includes("i"),
    // Case-insensitive
    m: regex.flags.includes("m"),
    // `^` and `$` matches adjacent to newline characters
    s: regex.flags.includes("s")
    // `.` matches newlines
  };
  const source = flags.i ? regex.source.toLowerCase() : regex.source;
  let pattern = "";
  let isEscaped = false;
  let inCharGroup = false;
  let inCharRange = false;
  for (let i = 0; i < source.length; i++) {
    if (isEscaped) {
      pattern += source[i];
      isEscaped = false;
      continue;
    }
    if (flags.i) {
      if (inCharGroup) {
        if (source[i].match(/[a-z]/)) {
          if (inCharRange) {
            pattern += source[i];
            pattern += `${source[i - 2]}-${source[i]}`.toUpperCase();
            inCharRange = false;
          } else if (source[i + 1] === "-" && ((_a17 = source[i + 2]) == null ? void 0 : _a17.match(/[a-z]/))) {
            pattern += source[i];
            inCharRange = true;
          } else {
            pattern += `${source[i]}${source[i].toUpperCase()}`;
          }
          continue;
        }
      } else if (source[i].match(/[a-z]/)) {
        pattern += `[${source[i]}${source[i].toUpperCase()}]`;
        continue;
      }
    }
    if (flags.m) {
      if (source[i] === "^") {
        pattern += `(^|(?<=[\r
]))`;
        continue;
      } else if (source[i] === "$") {
        pattern += `($|(?=[\r
]))`;
        continue;
      }
    }
    if (flags.s && source[i] === ".") {
      pattern += inCharGroup ? `${source[i]}\r
` : `[${source[i]}\r
]`;
      continue;
    }
    pattern += source[i];
    if (source[i] === "\\") {
      isEscaped = true;
    } else if (inCharGroup && source[i] === "]") {
      inCharGroup = false;
    } else if (!inCharGroup && source[i] === "[") {
      inCharGroup = true;
    }
  }
  try {
    new RegExp(pattern);
  } catch (e) {
    console.warn(
      `Could not convert regex pattern at ${refs.currentPath.join(
        "/"
      )} to a flag-independent form! Falling back to the flag-ignorant source`
    );
    return regex.source;
  }
  return pattern;
}
function parseRecordDef2(def, refs) {
  var _a17, _b8, _c, _d, _e, _f;
  const schema = {
    type: "object",
    additionalProperties: (_a17 = parseDef2(def.valueType._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    })) != null ? _a17 : refs.allowedAdditionalProperties
  };
  if (((_b8 = def.keyType) == null ? void 0 : _b8._def.typeName) === ZodFirstPartyTypeKind22.ZodString && ((_c = def.keyType._def.checks) == null ? void 0 : _c.length)) {
    const { type: type2, ...keyType } = parseStringDef2(def.keyType._def, refs);
    return {
      ...schema,
      propertyNames: keyType
    };
  } else if (((_d = def.keyType) == null ? void 0 : _d._def.typeName) === ZodFirstPartyTypeKind22.ZodEnum) {
    return {
      ...schema,
      propertyNames: {
        enum: def.keyType._def.values
      }
    };
  } else if (((_e = def.keyType) == null ? void 0 : _e._def.typeName) === ZodFirstPartyTypeKind22.ZodBranded && def.keyType._def.type._def.typeName === ZodFirstPartyTypeKind22.ZodString && ((_f = def.keyType._def.type._def.checks) == null ? void 0 : _f.length)) {
    const { type: type2, ...keyType } = parseBrandedDef2(
      def.keyType._def,
      refs
    );
    return {
      ...schema,
      propertyNames: keyType
    };
  }
  return schema;
}
function parseMapDef2(def, refs) {
  if (refs.mapStrategy === "record") {
    return parseRecordDef2(def, refs);
  }
  const keys = parseDef2(def.keyType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items", "items", "0"]
  }) || parseAnyDef2();
  const values = parseDef2(def.valueType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items", "items", "1"]
  }) || parseAnyDef2();
  return {
    type: "array",
    maxItems: 125,
    items: {
      type: "array",
      items: [keys, values],
      minItems: 2,
      maxItems: 2
    }
  };
}
function parseNativeEnumDef2(def) {
  const object2 = def.values;
  const actualKeys = Object.keys(def.values).filter((key) => {
    return typeof object2[object2[key]] !== "number";
  });
  const actualValues = actualKeys.map((key) => object2[key]);
  const parsedTypes = Array.from(
    new Set(actualValues.map((values) => typeof values))
  );
  return {
    type: parsedTypes.length === 1 ? parsedTypes[0] === "string" ? "string" : "number" : ["string", "number"],
    enum: actualValues
  };
}
function parseNeverDef2() {
  return { not: parseAnyDef2() };
}
function parseNullDef2() {
  return {
    type: "null"
  };
}
var primitiveMappings2 = {
  ZodString: "string",
  ZodNumber: "number",
  ZodBigInt: "integer",
  ZodBoolean: "boolean",
  ZodNull: "null"
};
function parseUnionDef2(def, refs) {
  const options = def.options instanceof Map ? Array.from(def.options.values()) : def.options;
  if (options.every(
    (x) => x._def.typeName in primitiveMappings2 && (!x._def.checks || !x._def.checks.length)
  )) {
    const types = options.reduce((types2, x) => {
      const type2 = primitiveMappings2[x._def.typeName];
      return type2 && !types2.includes(type2) ? [...types2, type2] : types2;
    }, []);
    return {
      type: types.length > 1 ? types : types[0]
    };
  } else if (options.every((x) => x._def.typeName === "ZodLiteral" && !x.description)) {
    const types = options.reduce(
      (acc, x) => {
        const type2 = typeof x._def.value;
        switch (type2) {
          case "string":
          case "number":
          case "boolean":
            return [...acc, type2];
          case "bigint":
            return [...acc, "integer"];
          case "object":
            if (x._def.value === null) return [...acc, "null"];
          case "symbol":
          case "undefined":
          case "function":
          default:
            return acc;
        }
      },
      []
    );
    if (types.length === options.length) {
      const uniqueTypes = types.filter((x, i, a) => a.indexOf(x) === i);
      return {
        type: uniqueTypes.length > 1 ? uniqueTypes : uniqueTypes[0],
        enum: options.reduce(
          (acc, x) => {
            return acc.includes(x._def.value) ? acc : [...acc, x._def.value];
          },
          []
        )
      };
    }
  } else if (options.every((x) => x._def.typeName === "ZodEnum")) {
    return {
      type: "string",
      enum: options.reduce(
        (acc, x) => [
          ...acc,
          ...x._def.values.filter((x2) => !acc.includes(x2))
        ],
        []
      )
    };
  }
  return asAnyOf2(def, refs);
}
var asAnyOf2 = (def, refs) => {
  const anyOf = (def.options instanceof Map ? Array.from(def.options.values()) : def.options).map(
    (x, i) => parseDef2(x._def, {
      ...refs,
      currentPath: [...refs.currentPath, "anyOf", `${i}`]
    })
  ).filter(
    (x) => !!x && (!refs.strictUnions || typeof x === "object" && Object.keys(x).length > 0)
  );
  return anyOf.length ? { anyOf } : void 0;
};
function parseNullableDef2(def, refs) {
  if (["ZodString", "ZodNumber", "ZodBigInt", "ZodBoolean", "ZodNull"].includes(
    def.innerType._def.typeName
  ) && (!def.innerType._def.checks || !def.innerType._def.checks.length)) {
    return {
      type: [
        primitiveMappings2[def.innerType._def.typeName],
        "null"
      ]
    };
  }
  const base = parseDef2(def.innerType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", "0"]
  });
  return base && { anyOf: [base, { type: "null" }] };
}
function parseNumberDef2(def) {
  const res = {
    type: "number"
  };
  if (!def.checks) return res;
  for (const check of def.checks) {
    switch (check.kind) {
      case "int":
        res.type = "integer";
        break;
      case "min":
        if (check.inclusive) {
          res.minimum = check.value;
        } else {
          res.exclusiveMinimum = check.value;
        }
        break;
      case "max":
        if (check.inclusive) {
          res.maximum = check.value;
        } else {
          res.exclusiveMaximum = check.value;
        }
        break;
      case "multipleOf":
        res.multipleOf = check.value;
        break;
    }
  }
  return res;
}
function parseObjectDef2(def, refs) {
  const result = {
    type: "object",
    properties: {}
  };
  const required = [];
  const shape = def.shape();
  for (const propName in shape) {
    let propDef = shape[propName];
    if (propDef === void 0 || propDef._def === void 0) {
      continue;
    }
    const propOptional = safeIsOptional2(propDef);
    const parsedDef = parseDef2(propDef._def, {
      ...refs,
      currentPath: [...refs.currentPath, "properties", propName],
      propertyPath: [...refs.currentPath, "properties", propName]
    });
    if (parsedDef === void 0) {
      continue;
    }
    result.properties[propName] = parsedDef;
    if (!propOptional) {
      required.push(propName);
    }
  }
  if (required.length) {
    result.required = required;
  }
  const additionalProperties = decideAdditionalProperties2(def, refs);
  if (additionalProperties !== void 0) {
    result.additionalProperties = additionalProperties;
  }
  return result;
}
function decideAdditionalProperties2(def, refs) {
  if (def.catchall._def.typeName !== "ZodNever") {
    return parseDef2(def.catchall._def, {
      ...refs,
      currentPath: [...refs.currentPath, "additionalProperties"]
    });
  }
  switch (def.unknownKeys) {
    case "passthrough":
      return refs.allowedAdditionalProperties;
    case "strict":
      return refs.rejectedAdditionalProperties;
    case "strip":
      return refs.removeAdditionalStrategy === "strict" ? refs.allowedAdditionalProperties : refs.rejectedAdditionalProperties;
  }
}
function safeIsOptional2(schema) {
  try {
    return schema.isOptional();
  } catch (e) {
    return true;
  }
}
var parseOptionalDef2 = (def, refs) => {
  var _a17;
  if (refs.currentPath.toString() === ((_a17 = refs.propertyPath) == null ? void 0 : _a17.toString())) {
    return parseDef2(def.innerType._def, refs);
  }
  const innerSchema = parseDef2(def.innerType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "anyOf", "1"]
  });
  return innerSchema ? { anyOf: [{ not: parseAnyDef2() }, innerSchema] } : parseAnyDef2();
};
var parsePipelineDef2 = (def, refs) => {
  if (refs.pipeStrategy === "input") {
    return parseDef2(def.in._def, refs);
  } else if (refs.pipeStrategy === "output") {
    return parseDef2(def.out._def, refs);
  }
  const a = parseDef2(def.in._def, {
    ...refs,
    currentPath: [...refs.currentPath, "allOf", "0"]
  });
  const b = parseDef2(def.out._def, {
    ...refs,
    currentPath: [...refs.currentPath, "allOf", a ? "1" : "0"]
  });
  return {
    allOf: [a, b].filter((x) => x !== void 0)
  };
};
function parsePromiseDef2(def, refs) {
  return parseDef2(def.type._def, refs);
}
function parseSetDef2(def, refs) {
  const items = parseDef2(def.valueType._def, {
    ...refs,
    currentPath: [...refs.currentPath, "items"]
  });
  const schema = {
    type: "array",
    uniqueItems: true,
    items
  };
  if (def.minSize) {
    schema.minItems = def.minSize.value;
  }
  if (def.maxSize) {
    schema.maxItems = def.maxSize.value;
  }
  return schema;
}
function parseTupleDef2(def, refs) {
  if (def.rest) {
    return {
      type: "array",
      minItems: def.items.length,
      items: def.items.map(
        (x, i) => parseDef2(x._def, {
          ...refs,
          currentPath: [...refs.currentPath, "items", `${i}`]
        })
      ).reduce(
        (acc, x) => x === void 0 ? acc : [...acc, x],
        []
      ),
      additionalItems: parseDef2(def.rest._def, {
        ...refs,
        currentPath: [...refs.currentPath, "additionalItems"]
      })
    };
  } else {
    return {
      type: "array",
      minItems: def.items.length,
      maxItems: def.items.length,
      items: def.items.map(
        (x, i) => parseDef2(x._def, {
          ...refs,
          currentPath: [...refs.currentPath, "items", `${i}`]
        })
      ).reduce(
        (acc, x) => x === void 0 ? acc : [...acc, x],
        []
      )
    };
  }
}
function parseUndefinedDef2() {
  return {
    not: parseAnyDef2()
  };
}
function parseUnknownDef2() {
  return parseAnyDef2();
}
var parseReadonlyDef2 = (def, refs) => {
  return parseDef2(def.innerType._def, refs);
};
var selectParser2 = (def, typeName, refs) => {
  switch (typeName) {
    case ZodFirstPartyTypeKind3.ZodString:
      return parseStringDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodNumber:
      return parseNumberDef2(def);
    case ZodFirstPartyTypeKind3.ZodObject:
      return parseObjectDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodBigInt:
      return parseBigintDef2(def);
    case ZodFirstPartyTypeKind3.ZodBoolean:
      return parseBooleanDef2();
    case ZodFirstPartyTypeKind3.ZodDate:
      return parseDateDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodUndefined:
      return parseUndefinedDef2();
    case ZodFirstPartyTypeKind3.ZodNull:
      return parseNullDef2();
    case ZodFirstPartyTypeKind3.ZodArray:
      return parseArrayDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodUnion:
    case ZodFirstPartyTypeKind3.ZodDiscriminatedUnion:
      return parseUnionDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodIntersection:
      return parseIntersectionDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodTuple:
      return parseTupleDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodRecord:
      return parseRecordDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodLiteral:
      return parseLiteralDef2(def);
    case ZodFirstPartyTypeKind3.ZodEnum:
      return parseEnumDef2(def);
    case ZodFirstPartyTypeKind3.ZodNativeEnum:
      return parseNativeEnumDef2(def);
    case ZodFirstPartyTypeKind3.ZodNullable:
      return parseNullableDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodOptional:
      return parseOptionalDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodMap:
      return parseMapDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodSet:
      return parseSetDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodLazy:
      return () => def.getter()._def;
    case ZodFirstPartyTypeKind3.ZodPromise:
      return parsePromiseDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodNaN:
    case ZodFirstPartyTypeKind3.ZodNever:
      return parseNeverDef2();
    case ZodFirstPartyTypeKind3.ZodEffects:
      return parseEffectsDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodAny:
      return parseAnyDef2();
    case ZodFirstPartyTypeKind3.ZodUnknown:
      return parseUnknownDef2();
    case ZodFirstPartyTypeKind3.ZodDefault:
      return parseDefaultDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodBranded:
      return parseBrandedDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodReadonly:
      return parseReadonlyDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodCatch:
      return parseCatchDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodPipeline:
      return parsePipelineDef2(def, refs);
    case ZodFirstPartyTypeKind3.ZodFunction:
    case ZodFirstPartyTypeKind3.ZodVoid:
    case ZodFirstPartyTypeKind3.ZodSymbol:
      return void 0;
    default:
      return /* @__PURE__ */ ((_) => void 0)(typeName);
  }
};
function parseDef2(def, refs, forceResolution = false) {
  var _a17;
  const seenItem = refs.seen.get(def);
  if (refs.override) {
    const overrideResult = (_a17 = refs.override) == null ? void 0 : _a17.call(
      refs,
      def,
      refs,
      seenItem,
      forceResolution
    );
    if (overrideResult !== ignoreOverride2) {
      return overrideResult;
    }
  }
  if (seenItem && !forceResolution) {
    const seenSchema = get$ref2(seenItem, refs);
    if (seenSchema !== void 0) {
      return seenSchema;
    }
  }
  const newItem = { def, path: refs.currentPath, jsonSchema: void 0 };
  refs.seen.set(def, newItem);
  const jsonSchemaOrGetter = selectParser2(def, def.typeName, refs);
  const jsonSchema2 = typeof jsonSchemaOrGetter === "function" ? parseDef2(jsonSchemaOrGetter(), refs) : jsonSchemaOrGetter;
  if (jsonSchema2) {
    addMeta2(def, refs, jsonSchema2);
  }
  if (refs.postProcess) {
    const postProcessResult = refs.postProcess(jsonSchema2, def, refs);
    newItem.jsonSchema = jsonSchema2;
    return postProcessResult;
  }
  newItem.jsonSchema = jsonSchema2;
  return jsonSchema2;
}
var get$ref2 = (item, refs) => {
  switch (refs.$refStrategy) {
    case "root":
      return { $ref: item.path.join("/") };
    case "relative":
      return { $ref: getRelativePath2(refs.currentPath, item.path) };
    case "none":
    case "seen": {
      if (item.path.length < refs.currentPath.length && item.path.every((value2, index) => refs.currentPath[index] === value2)) {
        console.warn(
          `Recursive reference detected at ${refs.currentPath.join(
            "/"
          )}! Defaulting to any`
        );
        return parseAnyDef2();
      }
      return refs.$refStrategy === "seen" ? parseAnyDef2() : void 0;
    }
  }
};
var addMeta2 = (def, refs, jsonSchema2) => {
  if (def.description) {
    jsonSchema2.description = def.description;
  }
  return jsonSchema2;
};
var getRefs2 = (options) => {
  const _options = getDefaultOptions2(options);
  const currentPath = _options.name !== void 0 ? [..._options.basePath, _options.definitionPath, _options.name] : _options.basePath;
  return {
    ..._options,
    currentPath,
    propertyPath: void 0,
    seen: new Map(
      Object.entries(_options.definitions).map(([name16, def]) => [
        def._def,
        {
          def: def._def,
          path: [..._options.basePath, _options.definitionPath, name16],
          // Resolution of references will be forced even though seen, so it's ok that the schema is undefined here for now.
          jsonSchema: void 0
        }
      ])
    )
  };
};
var zodToJsonSchema2 = (schema, options) => {
  var _a17;
  const refs = getRefs2(options);
  let definitions = typeof options === "object" && options.definitions ? Object.entries(options.definitions).reduce(
    (acc, [name24, schema2]) => {
      var _a24;
      return {
        ...acc,
        [name24]: (_a24 = parseDef2(
          schema2._def,
          {
            ...refs,
            currentPath: [...refs.basePath, refs.definitionPath, name24]
          },
          true
        )) != null ? _a24 : parseAnyDef2()
      };
    },
    {}
  ) : void 0;
  const name16 = typeof options === "string" ? options : (options == null ? void 0 : options.nameStrategy) === "title" ? void 0 : options == null ? void 0 : options.name;
  const main = (_a17 = parseDef2(
    schema._def,
    name16 === void 0 ? refs : {
      ...refs,
      currentPath: [...refs.basePath, refs.definitionPath, name16]
    },
    false
  )) != null ? _a17 : parseAnyDef2();
  const title = typeof options === "object" && options.name !== void 0 && options.nameStrategy === "title" ? options.name : void 0;
  if (title !== void 0) {
    main.title = title;
  }
  const combined = name16 === void 0 ? definitions ? {
    ...main,
    [refs.definitionPath]: definitions
  } : main : {
    $ref: [
      ...refs.$refStrategy === "relative" ? [] : refs.basePath,
      refs.definitionPath,
      name16
    ].join("/"),
    [refs.definitionPath]: {
      ...definitions,
      [name16]: main
    }
  };
  combined.$schema = "http://json-schema.org/draft-07/schema#";
  return combined;
};
var zod_to_json_schema_default = zodToJsonSchema2;
function zod3Schema(zodSchema2, options) {
  var _a17;
  const useReferences = (_a17 = options == null ? void 0 : options.useReferences) != null ? _a17 : false;
  return jsonSchema(
    // defer json schema creation to avoid unnecessary computation when only validation is needed
    () => zod_to_json_schema_default(zodSchema2, {
      $refStrategy: useReferences ? "root" : "none"
    }),
    {
      validate: async (value2) => {
        const result = await zodSchema2.safeParseAsync(value2);
        return result.success ? { success: true, value: result.data } : { success: false, error: result.error };
      }
    }
  );
}
function zod4Schema(zodSchema2, options) {
  var _a17;
  const useReferences = (_a17 = options == null ? void 0 : options.useReferences) != null ? _a17 : false;
  return jsonSchema(
    // defer json schema creation to avoid unnecessary computation when only validation is needed
    () => z42.toJSONSchema(zodSchema2, {
      target: "draft-7",
      io: "output",
      reused: useReferences ? "ref" : "inline"
    }),
    {
      validate: async (value2) => {
        const result = await z42.safeParseAsync(zodSchema2, value2);
        return result.success ? { success: true, value: result.data } : { success: false, error: result.error };
      }
    }
  );
}
function isZod4Schema(zodSchema2) {
  return "_zod" in zodSchema2;
}
function zodSchema(zodSchema2, options) {
  if (isZod4Schema(zodSchema2)) {
    return zod4Schema(zodSchema2, options);
  } else {
    return zod3Schema(zodSchema2, options);
  }
}
var schemaSymbol = Symbol.for("vercel.ai.schema");
function jsonSchema(jsonSchema2, {
  validate
} = {}) {
  return {
    [schemaSymbol]: true,
    _type: void 0,
    // should never be used directly
    [validatorSymbol]: true,
    get jsonSchema() {
      if (typeof jsonSchema2 === "function") {
        jsonSchema2 = jsonSchema2();
      }
      return jsonSchema2;
    },
    validate
  };
}
function isSchema(value2) {
  return typeof value2 === "object" && value2 !== null && schemaSymbol in value2 && value2[schemaSymbol] === true && "jsonSchema" in value2 && "validate" in value2;
}
function asSchema(schema) {
  return schema == null ? jsonSchema({
    properties: {},
    additionalProperties: false
  }) : isSchema(schema) ? schema : typeof schema === "function" ? schema() : zodSchema(schema);
}
var { btoa: btoa2, atob: atob2 } = globalThis;
function convertBase64ToUint8Array(base64String) {
  const base64Url = base64String.replace(/-/g, "+").replace(/_/g, "/");
  const latin1string = atob2(base64Url);
  return Uint8Array.from(latin1string, (byte) => byte.codePointAt(0));
}
function convertUint8ArrayToBase64(array) {
  let latin1string = "";
  for (let i = 0; i < array.length; i++) {
    latin1string += String.fromCodePoint(array[i]);
  }
  return btoa2(latin1string);
}
function withoutTrailingSlash(url) {
  return url == null ? void 0 : url.replace(/\/$/, "");
}

// node_modules/@ai-sdk/gateway/dist/index.mjs
import { z as z24 } from "zod/v4";
import { z as z25 } from "zod/v4";
import { z as z32 } from "zod/v4";
import { z as z43 } from "zod/v4";
import { z as z52 } from "zod/v4";
import { z as z62 } from "zod/v4";
var import_oidc = __toESM(require_dist(), 1);
var import_oidc2 = __toESM(require_dist(), 1);
import { z as z72 } from "zod/v4";
var marker15 = "vercel.ai.gateway.error";
var symbol15 = Symbol.for(marker15);
var _a15;
var _b;
var GatewayError = class _GatewayError extends (_b = Error, _a15 = symbol15, _b) {
  constructor({
    message,
    statusCode = 500,
    cause
  }) {
    super(message);
    this[_a15] = true;
    this.statusCode = statusCode;
    this.cause = cause;
  }
  /**
   * Checks if the given error is a Gateway Error.
   * @param {unknown} error - The error to check.
   * @returns {boolean} True if the error is a Gateway Error, false otherwise.
   */
  static isInstance(error) {
    return _GatewayError.hasMarker(error);
  }
  static hasMarker(error) {
    return typeof error === "object" && error !== null && symbol15 in error && error[symbol15] === true;
  }
};
var name14 = "GatewayAuthenticationError";
var marker22 = `vercel.ai.gateway.error.${name14}`;
var symbol22 = Symbol.for(marker22);
var _a22;
var _b2;
var GatewayAuthenticationError = class _GatewayAuthenticationError extends (_b2 = GatewayError, _a22 = symbol22, _b2) {
  constructor({
    message = "Authentication failed",
    statusCode = 401,
    cause
  } = {}) {
    super({ message, statusCode, cause });
    this[_a22] = true;
    this.name = name14;
    this.type = "authentication_error";
  }
  static isInstance(error) {
    return GatewayError.hasMarker(error) && symbol22 in error;
  }
  /**
   * Creates a contextual error message when authentication fails
   */
  static createContextualError({
    apiKeyProvided,
    oidcTokenProvided,
    message = "Authentication failed",
    statusCode = 401,
    cause
  }) {
    let contextualMessage;
    if (apiKeyProvided) {
      contextualMessage = `AI Gateway authentication failed: Invalid API key.

Create a new API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys

Provide via 'apiKey' option or 'AI_GATEWAY_API_KEY' environment variable.`;
    } else if (oidcTokenProvided) {
      contextualMessage = `AI Gateway authentication failed: Invalid OIDC token.

Run 'npx vercel link' to link your project, then 'vc env pull' to fetch the token.

Alternatively, use an API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys`;
    } else {
      contextualMessage = `AI Gateway authentication failed: No authentication provided.

Option 1 - API key:
Create an API key: https://vercel.com/d?to=%2F%5Bteam%5D%2F%7E%2Fai%2Fapi-keys
Provide via 'apiKey' option or 'AI_GATEWAY_API_KEY' environment variable.

Option 2 - OIDC token:
Run 'npx vercel link' to link your project, then 'vc env pull' to fetch the token.`;
    }
    return new _GatewayAuthenticationError({
      message: contextualMessage,
      statusCode,
      cause
    });
  }
};
var name22 = "GatewayInvalidRequestError";
var marker32 = `vercel.ai.gateway.error.${name22}`;
var symbol32 = Symbol.for(marker32);
var _a32;
var _b3;
var GatewayInvalidRequestError = class extends (_b3 = GatewayError, _a32 = symbol32, _b3) {
  constructor({
    message = "Invalid request",
    statusCode = 400,
    cause
  } = {}) {
    super({ message, statusCode, cause });
    this[_a32] = true;
    this.name = name22;
    this.type = "invalid_request_error";
  }
  static isInstance(error) {
    return GatewayError.hasMarker(error) && symbol32 in error;
  }
};
var name32 = "GatewayRateLimitError";
var marker42 = `vercel.ai.gateway.error.${name32}`;
var symbol42 = Symbol.for(marker42);
var _a42;
var _b4;
var GatewayRateLimitError = class extends (_b4 = GatewayError, _a42 = symbol42, _b4) {
  constructor({
    message = "Rate limit exceeded",
    statusCode = 429,
    cause
  } = {}) {
    super({ message, statusCode, cause });
    this[_a42] = true;
    this.name = name32;
    this.type = "rate_limit_exceeded";
  }
  static isInstance(error) {
    return GatewayError.hasMarker(error) && symbol42 in error;
  }
};
var name42 = "GatewayModelNotFoundError";
var marker52 = `vercel.ai.gateway.error.${name42}`;
var symbol52 = Symbol.for(marker52);
var modelNotFoundParamSchema = lazyValidator(
  () => zodSchema(
    z25.object({
      modelId: z25.string()
    })
  )
);
var _a52;
var _b5;
var GatewayModelNotFoundError = class extends (_b5 = GatewayError, _a52 = symbol52, _b5) {
  constructor({
    message = "Model not found",
    statusCode = 404,
    modelId,
    cause
  } = {}) {
    super({ message, statusCode, cause });
    this[_a52] = true;
    this.name = name42;
    this.type = "model_not_found";
    this.modelId = modelId;
  }
  static isInstance(error) {
    return GatewayError.hasMarker(error) && symbol52 in error;
  }
};
var name52 = "GatewayInternalServerError";
var marker62 = `vercel.ai.gateway.error.${name52}`;
var symbol62 = Symbol.for(marker62);
var _a62;
var _b6;
var GatewayInternalServerError = class extends (_b6 = GatewayError, _a62 = symbol62, _b6) {
  constructor({
    message = "Internal server error",
    statusCode = 500,
    cause
  } = {}) {
    super({ message, statusCode, cause });
    this[_a62] = true;
    this.name = name52;
    this.type = "internal_server_error";
  }
  static isInstance(error) {
    return GatewayError.hasMarker(error) && symbol62 in error;
  }
};
var name62 = "GatewayResponseError";
var marker72 = `vercel.ai.gateway.error.${name62}`;
var symbol72 = Symbol.for(marker72);
var _a72;
var _b7;
var GatewayResponseError = class extends (_b7 = GatewayError, _a72 = symbol72, _b7) {
  constructor({
    message = "Invalid response from Gateway",
    statusCode = 502,
    response,
    validationError,
    cause
  } = {}) {
    super({ message, statusCode, cause });
    this[_a72] = true;
    this.name = name62;
    this.type = "response_error";
    this.response = response;
    this.validationError = validationError;
  }
  static isInstance(error) {
    return GatewayError.hasMarker(error) && symbol72 in error;
  }
};
async function createGatewayErrorFromResponse({
  response,
  statusCode,
  defaultMessage = "Gateway request failed",
  cause,
  authMethod
}) {
  const parseResult = await safeValidateTypes({
    value: response,
    schema: gatewayErrorResponseSchema
  });
  if (!parseResult.success) {
    return new GatewayResponseError({
      message: `Invalid error response format: ${defaultMessage}`,
      statusCode,
      response,
      validationError: parseResult.error,
      cause
    });
  }
  const validatedResponse = parseResult.value;
  const errorType = validatedResponse.error.type;
  const message = validatedResponse.error.message;
  switch (errorType) {
    case "authentication_error":
      return GatewayAuthenticationError.createContextualError({
        apiKeyProvided: authMethod === "api-key",
        oidcTokenProvided: authMethod === "oidc",
        statusCode,
        cause
      });
    case "invalid_request_error":
      return new GatewayInvalidRequestError({ message, statusCode, cause });
    case "rate_limit_exceeded":
      return new GatewayRateLimitError({ message, statusCode, cause });
    case "model_not_found": {
      const modelResult = await safeValidateTypes({
        value: validatedResponse.error.param,
        schema: modelNotFoundParamSchema
      });
      return new GatewayModelNotFoundError({
        message,
        statusCode,
        modelId: modelResult.success ? modelResult.value.modelId : void 0,
        cause
      });
    }
    case "internal_server_error":
      return new GatewayInternalServerError({ message, statusCode, cause });
    default:
      return new GatewayInternalServerError({ message, statusCode, cause });
  }
}
var gatewayErrorResponseSchema = lazyValidator(
  () => zodSchema(
    z24.object({
      error: z24.object({
        message: z24.string(),
        type: z24.string().nullish(),
        param: z24.unknown().nullish(),
        code: z24.union([z24.string(), z24.number()]).nullish()
      })
    })
  )
);
function asGatewayError(error, authMethod) {
  var _a83;
  if (GatewayError.isInstance(error)) {
    return error;
  }
  if (APICallError.isInstance(error)) {
    return createGatewayErrorFromResponse({
      response: extractApiCallResponse(error),
      statusCode: (_a83 = error.statusCode) != null ? _a83 : 500,
      defaultMessage: "Gateway request failed",
      cause: error,
      authMethod
    });
  }
  return createGatewayErrorFromResponse({
    response: {},
    statusCode: 500,
    defaultMessage: error instanceof Error ? `Gateway request failed: ${error.message}` : "Unknown Gateway error",
    cause: error,
    authMethod
  });
}
function extractApiCallResponse(error) {
  if (error.data !== void 0) {
    return error.data;
  }
  if (error.responseBody != null) {
    try {
      return JSON.parse(error.responseBody);
    } catch (e) {
      return error.responseBody;
    }
  }
  return {};
}
var GATEWAY_AUTH_METHOD_HEADER = "ai-gateway-auth-method";
async function parseAuthMethod(headers) {
  const result = await safeValidateTypes({
    value: headers[GATEWAY_AUTH_METHOD_HEADER],
    schema: gatewayAuthMethodSchema
  });
  return result.success ? result.value : void 0;
}
var gatewayAuthMethodSchema = lazyValidator(
  () => zodSchema(z32.union([z32.literal("api-key"), z32.literal("oidc")]))
);
var GatewayFetchMetadata = class {
  constructor(config2) {
    this.config = config2;
  }
  async getAvailableModels() {
    try {
      const { value: value2 } = await getFromApi({
        url: `${this.config.baseURL}/config`,
        headers: await resolve(this.config.headers()),
        successfulResponseHandler: createJsonResponseHandler(
          gatewayAvailableModelsResponseSchema
        ),
        failedResponseHandler: createJsonErrorResponseHandler({
          errorSchema: z43.any(),
          errorToMessage: (data) => data
        }),
        fetch: this.config.fetch
      });
      return value2;
    } catch (error) {
      throw await asGatewayError(error);
    }
  }
  async getCredits() {
    try {
      const baseUrl = new URL(this.config.baseURL);
      const { value: value2 } = await getFromApi({
        url: `${baseUrl.origin}/v1/credits`,
        headers: await resolve(this.config.headers()),
        successfulResponseHandler: createJsonResponseHandler(
          gatewayCreditsResponseSchema
        ),
        failedResponseHandler: createJsonErrorResponseHandler({
          errorSchema: z43.any(),
          errorToMessage: (data) => data
        }),
        fetch: this.config.fetch
      });
      return value2;
    } catch (error) {
      throw await asGatewayError(error);
    }
  }
};
var gatewayAvailableModelsResponseSchema = lazyValidator(
  () => zodSchema(
    z43.object({
      models: z43.array(
        z43.object({
          id: z43.string(),
          name: z43.string(),
          description: z43.string().nullish(),
          pricing: z43.object({
            input: z43.string(),
            output: z43.string(),
            input_cache_read: z43.string().nullish(),
            input_cache_write: z43.string().nullish()
          }).transform(
            ({ input, output, input_cache_read, input_cache_write }) => ({
              input,
              output,
              ...input_cache_read ? { cachedInputTokens: input_cache_read } : {},
              ...input_cache_write ? { cacheCreationInputTokens: input_cache_write } : {}
            })
          ).nullish(),
          specification: z43.object({
            specificationVersion: z43.literal("v2"),
            provider: z43.string(),
            modelId: z43.string()
          }),
          modelType: z43.enum(["language", "embedding", "image"]).nullish()
        })
      )
    })
  )
);
var gatewayCreditsResponseSchema = lazyValidator(
  () => zodSchema(
    z43.object({
      balance: z43.string(),
      total_used: z43.string()
    }).transform(({ balance, total_used }) => ({
      balance,
      totalUsed: total_used
    }))
  )
);
var GatewayLanguageModel = class {
  constructor(modelId, config2) {
    this.modelId = modelId;
    this.config = config2;
    this.specificationVersion = "v2";
    this.supportedUrls = { "*/*": [/.*/] };
  }
  get provider() {
    return this.config.provider;
  }
  async getArgs(options) {
    const { abortSignal: _abortSignal, ...optionsWithoutSignal } = options;
    return {
      args: this.maybeEncodeFileParts(optionsWithoutSignal),
      warnings: []
    };
  }
  async doGenerate(options) {
    const { args: args2, warnings } = await this.getArgs(options);
    const { abortSignal } = options;
    const resolvedHeaders = await resolve(this.config.headers());
    try {
      const {
        responseHeaders,
        value: responseBody,
        rawValue: rawResponse
      } = await postJsonToApi({
        url: this.getUrl(),
        headers: combineHeaders(
          resolvedHeaders,
          options.headers,
          this.getModelConfigHeaders(this.modelId, false),
          await resolve(this.config.o11yHeaders)
        ),
        body: args2,
        successfulResponseHandler: createJsonResponseHandler(z52.any()),
        failedResponseHandler: createJsonErrorResponseHandler({
          errorSchema: z52.any(),
          errorToMessage: (data) => data
        }),
        ...abortSignal && { abortSignal },
        fetch: this.config.fetch
      });
      return {
        ...responseBody,
        request: { body: args2 },
        response: { headers: responseHeaders, body: rawResponse },
        warnings
      };
    } catch (error) {
      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));
    }
  }
  async doStream(options) {
    const { args: args2, warnings } = await this.getArgs(options);
    const { abortSignal } = options;
    const resolvedHeaders = await resolve(this.config.headers());
    try {
      const { value: response, responseHeaders } = await postJsonToApi({
        url: this.getUrl(),
        headers: combineHeaders(
          resolvedHeaders,
          options.headers,
          this.getModelConfigHeaders(this.modelId, true),
          await resolve(this.config.o11yHeaders)
        ),
        body: args2,
        successfulResponseHandler: createEventSourceResponseHandler(z52.any()),
        failedResponseHandler: createJsonErrorResponseHandler({
          errorSchema: z52.any(),
          errorToMessage: (data) => data
        }),
        ...abortSignal && { abortSignal },
        fetch: this.config.fetch
      });
      return {
        stream: response.pipeThrough(
          new TransformStream({
            start(controller) {
              if (warnings.length > 0) {
                controller.enqueue({ type: "stream-start", warnings });
              }
            },
            transform(chunk, controller) {
              if (chunk.success) {
                const streamPart = chunk.value;
                if (streamPart.type === "raw" && !options.includeRawChunks) {
                  return;
                }
                if (streamPart.type === "response-metadata" && streamPart.timestamp && typeof streamPart.timestamp === "string") {
                  streamPart.timestamp = new Date(streamPart.timestamp);
                }
                controller.enqueue(streamPart);
              } else {
                controller.error(
                  chunk.error
                );
              }
            }
          })
        ),
        request: { body: args2 },
        response: { headers: responseHeaders }
      };
    } catch (error) {
      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));
    }
  }
  isFilePart(part) {
    return part && typeof part === "object" && "type" in part && part.type === "file";
  }
  /**
   * Encodes file parts in the prompt to base64. Mutates the passed options
   * instance directly to avoid copying the file data.
   * @param options - The options to encode.
   * @returns The options with the file parts encoded.
   */
  maybeEncodeFileParts(options) {
    for (const message of options.prompt) {
      for (const part of message.content) {
        if (this.isFilePart(part)) {
          const filePart = part;
          if (filePart.data instanceof Uint8Array) {
            const buffer = Uint8Array.from(filePart.data);
            const base64Data = Buffer.from(buffer).toString("base64");
            filePart.data = new URL(
              `data:${filePart.mediaType || "application/octet-stream"};base64,${base64Data}`
            );
          }
        }
      }
    }
    return options;
  }
  getUrl() {
    return `${this.config.baseURL}/language-model`;
  }
  getModelConfigHeaders(modelId, streaming) {
    return {
      "ai-language-model-specification-version": "2",
      "ai-language-model-id": modelId,
      "ai-language-model-streaming": String(streaming)
    };
  }
};
var GatewayEmbeddingModel = class {
  constructor(modelId, config2) {
    this.modelId = modelId;
    this.config = config2;
    this.specificationVersion = "v2";
    this.maxEmbeddingsPerCall = 2048;
    this.supportsParallelCalls = true;
  }
  get provider() {
    return this.config.provider;
  }
  async doEmbed({
    values,
    headers,
    abortSignal,
    providerOptions
  }) {
    var _a83;
    const resolvedHeaders = await resolve(this.config.headers());
    try {
      const {
        responseHeaders,
        value: responseBody,
        rawValue
      } = await postJsonToApi({
        url: this.getUrl(),
        headers: combineHeaders(
          resolvedHeaders,
          headers != null ? headers : {},
          this.getModelConfigHeaders(),
          await resolve(this.config.o11yHeaders)
        ),
        body: {
          input: values.length === 1 ? values[0] : values,
          ...providerOptions ? { providerOptions } : {}
        },
        successfulResponseHandler: createJsonResponseHandler(
          gatewayEmbeddingResponseSchema
        ),
        failedResponseHandler: createJsonErrorResponseHandler({
          errorSchema: z62.any(),
          errorToMessage: (data) => data
        }),
        ...abortSignal && { abortSignal },
        fetch: this.config.fetch
      });
      return {
        embeddings: responseBody.embeddings,
        usage: (_a83 = responseBody.usage) != null ? _a83 : void 0,
        providerMetadata: responseBody.providerMetadata,
        response: { headers: responseHeaders, body: rawValue }
      };
    } catch (error) {
      throw await asGatewayError(error, await parseAuthMethod(resolvedHeaders));
    }
  }
  getUrl() {
    return `${this.config.baseURL}/embedding-model`;
  }
  getModelConfigHeaders() {
    return {
      "ai-embedding-model-specification-version": "2",
      "ai-model-id": this.modelId
    };
  }
};
var gatewayEmbeddingResponseSchema = lazyValidator(
  () => zodSchema(
    z62.object({
      embeddings: z62.array(z62.array(z62.number())),
      usage: z62.object({ tokens: z62.number() }).nullish(),
      providerMetadata: z62.record(z62.string(), z62.record(z62.string(), z62.unknown())).optional()
    })
  )
);
var GatewayImageModel = class {
  constructor(modelId, config2) {
    this.modelId = modelId;
    this.config = config2;
    this.specificationVersion = "v2";
    this.maxImagesPerCall = Number.MAX_SAFE_INTEGER;
  }
  get provider() {
    return this.config.provider;
  }
  async doGenerate({
    prompt,
    n,
    size,
    aspectRatio,
    seed,
    providerOptions,
    headers,
    abortSignal
  }) {
    var _a83;
    const resolvedHeaders = await resolve(this.config.headers());
    try {
      const {
        responseHeaders,
        value: responseBody,
        rawValue
      } = await postJsonToApi({
        url: this.getUrl(),
        headers: combineHeaders(
          resolvedHeaders,
          headers != null ? headers : {},
          this.getModelConfigHeaders(),
          await resolve(this.config.o11yHeaders)
        ),
        body: {
          prompt,
          n,
          ...size && { size },
          ...aspectRatio && { aspectRatio },
          ...seed && { seed },
          ...providerOptions && { providerOptions }
        },
        successfulResponseHandler: createJsonResponseHandler(
          gatewayImageResponseSchema
        ),
        failedResponseHandler: createJsonErrorResponseHandler({
          errorSchema: z72.any(),
          errorToMessage: (data) => data
        }),
        ...abortSignal && { abortSignal },
        fetch: this.config.fetch
      });
      return {
        images: responseBody.images,
        // Always base64 strings from server
        warnings: (_a83 = responseBody.warnings) != null ? _a83 : [],
        providerMetadata: responseBody.providerMetadata,
        response: {
          timestamp: /* @__PURE__ */ new Date(),
          modelId: this.modelId,
          headers: responseHeaders
        }
      };
    } catch (error) {
      throw asGatewayError(error, await parseAuthMethod(resolvedHeaders));
    }
  }
  getUrl() {
    return `${this.config.baseURL}/image-model`;
  }
  getModelConfigHeaders() {
    return {
      "ai-image-model-specification-version": "2",
      "ai-model-id": this.modelId
    };
  }
};
var providerMetadataEntrySchema = z72.object({
  images: z72.array(z72.unknown()).optional()
}).catchall(z72.unknown());
var gatewayImageResponseSchema = z72.object({
  images: z72.array(z72.string()),
  // Always base64 strings over the wire
  warnings: z72.array(
    z72.object({
      type: z72.literal("other"),
      message: z72.string()
    })
  ).optional(),
  providerMetadata: z72.record(z72.string(), providerMetadataEntrySchema).optional()
});
async function getVercelRequestId() {
  var _a83;
  return (_a83 = (0, import_oidc.getContext)().headers) == null ? void 0 : _a83["x-vercel-id"];
}
var VERSION2 = true ? "2.0.18" : "0.0.0-test";
var AI_GATEWAY_PROTOCOL_VERSION = "0.0.1";
function createGatewayProvider(options = {}) {
  var _a83, _b8;
  let pendingMetadata = null;
  let metadataCache = null;
  const cacheRefreshMillis = (_a83 = options.metadataCacheRefreshMillis) != null ? _a83 : 1e3 * 60 * 5;
  let lastFetchTime = 0;
  const baseURL = (_b8 = withoutTrailingSlash(options.baseURL)) != null ? _b8 : "https://ai-gateway.vercel.sh/v1/ai";
  const getHeaders = async () => {
    const auth = await getGatewayAuthToken(options);
    if (auth) {
      return withUserAgentSuffix(
        {
          Authorization: `Bearer ${auth.token}`,
          "ai-gateway-protocol-version": AI_GATEWAY_PROTOCOL_VERSION,
          [GATEWAY_AUTH_METHOD_HEADER]: auth.authMethod,
          ...options.headers
        },
        `ai-sdk/gateway/${VERSION2}`
      );
    }
    throw GatewayAuthenticationError.createContextualError({
      apiKeyProvided: false,
      oidcTokenProvided: false,
      statusCode: 401
    });
  };
  const createO11yHeaders = () => {
    const deploymentId = loadOptionalSetting({
      settingValue: void 0,
      environmentVariableName: "VERCEL_DEPLOYMENT_ID"
    });
    const environment = loadOptionalSetting({
      settingValue: void 0,
      environmentVariableName: "VERCEL_ENV"
    });
    const region = loadOptionalSetting({
      settingValue: void 0,
      environmentVariableName: "VERCEL_REGION"
    });
    return async () => {
      const requestId = await getVercelRequestId();
      return {
        ...deploymentId && { "ai-o11y-deployment-id": deploymentId },
        ...environment && { "ai-o11y-environment": environment },
        ...region && { "ai-o11y-region": region },
        ...requestId && { "ai-o11y-request-id": requestId }
      };
    };
  };
  const createLanguageModel = (modelId) => {
    return new GatewayLanguageModel(modelId, {
      provider: "gateway",
      baseURL,
      headers: getHeaders,
      fetch: options.fetch,
      o11yHeaders: createO11yHeaders()
    });
  };
  const getAvailableModels = async () => {
    var _a93, _b9, _c;
    const now = (_c = (_b9 = (_a93 = options._internal) == null ? void 0 : _a93.currentDate) == null ? void 0 : _b9.call(_a93).getTime()) != null ? _c : Date.now();
    if (!pendingMetadata || now - lastFetchTime > cacheRefreshMillis) {
      lastFetchTime = now;
      pendingMetadata = new GatewayFetchMetadata({
        baseURL,
        headers: getHeaders,
        fetch: options.fetch
      }).getAvailableModels().then((metadata) => {
        metadataCache = metadata;
        return metadata;
      }).catch(async (error) => {
        throw await asGatewayError(
          error,
          await parseAuthMethod(await getHeaders())
        );
      });
    }
    return metadataCache ? Promise.resolve(metadataCache) : pendingMetadata;
  };
  const getCredits = async () => {
    return new GatewayFetchMetadata({
      baseURL,
      headers: getHeaders,
      fetch: options.fetch
    }).getCredits().catch(async (error) => {
      throw await asGatewayError(
        error,
        await parseAuthMethod(await getHeaders())
      );
    });
  };
  const provider = function(modelId) {
    if (new.target) {
      throw new Error(
        "The Gateway Provider model function cannot be called with the new keyword."
      );
    }
    return createLanguageModel(modelId);
  };
  provider.getAvailableModels = getAvailableModels;
  provider.getCredits = getCredits;
  provider.imageModel = (modelId) => {
    return new GatewayImageModel(modelId, {
      provider: "gateway",
      baseURL,
      headers: getHeaders,
      fetch: options.fetch,
      o11yHeaders: createO11yHeaders()
    });
  };
  provider.languageModel = createLanguageModel;
  provider.textEmbeddingModel = (modelId) => {
    return new GatewayEmbeddingModel(modelId, {
      provider: "gateway",
      baseURL,
      headers: getHeaders,
      fetch: options.fetch,
      o11yHeaders: createO11yHeaders()
    });
  };
  return provider;
}
var gateway = createGatewayProvider();
async function getGatewayAuthToken(options) {
  const apiKey = loadOptionalSetting({
    settingValue: options.apiKey,
    environmentVariableName: "AI_GATEWAY_API_KEY"
  });
  if (apiKey) {
    return {
      token: apiKey,
      authMethod: "api-key"
    };
  }
  try {
    const oidcToken = await (0, import_oidc2.getVercelOidcToken)();
    return {
      token: oidcToken,
      authMethod: "oidc"
    };
  } catch (e) {
    return null;
  }
}

// node_modules/ai/dist/index.mjs
import { z as z26 } from "zod/v4";
import { z as z63 } from "zod/v4";
import { z as z53 } from "zod/v4";
import { z as z33 } from "zod/v4";
import { z as z27 } from "zod/v4";
import { z as z44 } from "zod/v4";

// node_modules/@opentelemetry/api/build/esm/platform/node/globalThis.js
var _globalThis = typeof globalThis === "object" ? globalThis : global;

// node_modules/@opentelemetry/api/build/esm/version.js
var VERSION3 = "1.9.0";

// node_modules/@opentelemetry/api/build/esm/internal/semver.js
var re = /^(\d+)\.(\d+)\.(\d+)(-(.+))?$/;
function _makeCompatibilityCheck(ownVersion) {
  var acceptedVersions = /* @__PURE__ */ new Set([ownVersion]);
  var rejectedVersions = /* @__PURE__ */ new Set();
  var myVersionMatch = ownVersion.match(re);
  if (!myVersionMatch) {
    return function() {
      return false;
    };
  }
  var ownVersionParsed = {
    major: +myVersionMatch[1],
    minor: +myVersionMatch[2],
    patch: +myVersionMatch[3],
    prerelease: myVersionMatch[4]
  };
  if (ownVersionParsed.prerelease != null) {
    return function isExactmatch(globalVersion) {
      return globalVersion === ownVersion;
    };
  }
  function _reject(v) {
    rejectedVersions.add(v);
    return false;
  }
  function _accept(v) {
    acceptedVersions.add(v);
    return true;
  }
  return function isCompatible2(globalVersion) {
    if (acceptedVersions.has(globalVersion)) {
      return true;
    }
    if (rejectedVersions.has(globalVersion)) {
      return false;
    }
    var globalVersionMatch = globalVersion.match(re);
    if (!globalVersionMatch) {
      return _reject(globalVersion);
    }
    var globalVersionParsed = {
      major: +globalVersionMatch[1],
      minor: +globalVersionMatch[2],
      patch: +globalVersionMatch[3],
      prerelease: globalVersionMatch[4]
    };
    if (globalVersionParsed.prerelease != null) {
      return _reject(globalVersion);
    }
    if (ownVersionParsed.major !== globalVersionParsed.major) {
      return _reject(globalVersion);
    }
    if (ownVersionParsed.major === 0) {
      if (ownVersionParsed.minor === globalVersionParsed.minor && ownVersionParsed.patch <= globalVersionParsed.patch) {
        return _accept(globalVersion);
      }
      return _reject(globalVersion);
    }
    if (ownVersionParsed.minor <= globalVersionParsed.minor) {
      return _accept(globalVersion);
    }
    return _reject(globalVersion);
  };
}
var isCompatible = _makeCompatibilityCheck(VERSION3);

// node_modules/@opentelemetry/api/build/esm/internal/global-utils.js
var major = VERSION3.split(".")[0];
var GLOBAL_OPENTELEMETRY_API_KEY = Symbol.for("opentelemetry.js.api." + major);
var _global = _globalThis;
function registerGlobal(type2, instance, diag, allowOverride) {
  var _a17;
  if (allowOverride === void 0) {
    allowOverride = false;
  }
  var api = _global[GLOBAL_OPENTELEMETRY_API_KEY] = (_a17 = _global[GLOBAL_OPENTELEMETRY_API_KEY]) !== null && _a17 !== void 0 ? _a17 : {
    version: VERSION3
  };
  if (!allowOverride && api[type2]) {
    var err = new Error("@opentelemetry/api: Attempted duplicate registration of API: " + type2);
    diag.error(err.stack || err.message);
    return false;
  }
  if (api.version !== VERSION3) {
    var err = new Error("@opentelemetry/api: Registration of version v" + api.version + " for " + type2 + " does not match previously registered API v" + VERSION3);
    diag.error(err.stack || err.message);
    return false;
  }
  api[type2] = instance;
  diag.debug("@opentelemetry/api: Registered a global for " + type2 + " v" + VERSION3 + ".");
  return true;
}
function getGlobal(type2) {
  var _a17, _b8;
  var globalVersion = (_a17 = _global[GLOBAL_OPENTELEMETRY_API_KEY]) === null || _a17 === void 0 ? void 0 : _a17.version;
  if (!globalVersion || !isCompatible(globalVersion)) {
    return;
  }
  return (_b8 = _global[GLOBAL_OPENTELEMETRY_API_KEY]) === null || _b8 === void 0 ? void 0 : _b8[type2];
}
function unregisterGlobal(type2, diag) {
  diag.debug("@opentelemetry/api: Unregistering a global for " + type2 + " v" + VERSION3 + ".");
  var api = _global[GLOBAL_OPENTELEMETRY_API_KEY];
  if (api) {
    delete api[type2];
  }
}

// node_modules/@opentelemetry/api/build/esm/diag/ComponentLogger.js
var __read = function(o, n) {
  var m = typeof Symbol === "function" && o[Symbol.iterator];
  if (!m) return o;
  var i = m.call(o), r, ar = [], e;
  try {
    while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
  } catch (error) {
    e = { error };
  } finally {
    try {
      if (r && !r.done && (m = i["return"])) m.call(i);
    } finally {
      if (e) throw e.error;
    }
  }
  return ar;
};
var __spreadArray = function(to, from, pack) {
  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {
    if (ar || !(i in from)) {
      if (!ar) ar = Array.prototype.slice.call(from, 0, i);
      ar[i] = from[i];
    }
  }
  return to.concat(ar || Array.prototype.slice.call(from));
};
var DiagComponentLogger = (
  /** @class */
  (function() {
    function DiagComponentLogger2(props) {
      this._namespace = props.namespace || "DiagComponentLogger";
    }
    DiagComponentLogger2.prototype.debug = function() {
      var args2 = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        args2[_i] = arguments[_i];
      }
      return logProxy("debug", this._namespace, args2);
    };
    DiagComponentLogger2.prototype.error = function() {
      var args2 = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        args2[_i] = arguments[_i];
      }
      return logProxy("error", this._namespace, args2);
    };
    DiagComponentLogger2.prototype.info = function() {
      var args2 = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        args2[_i] = arguments[_i];
      }
      return logProxy("info", this._namespace, args2);
    };
    DiagComponentLogger2.prototype.warn = function() {
      var args2 = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        args2[_i] = arguments[_i];
      }
      return logProxy("warn", this._namespace, args2);
    };
    DiagComponentLogger2.prototype.verbose = function() {
      var args2 = [];
      for (var _i = 0; _i < arguments.length; _i++) {
        args2[_i] = arguments[_i];
      }
      return logProxy("verbose", this._namespace, args2);
    };
    return DiagComponentLogger2;
  })()
);
function logProxy(funcName, namespace, args2) {
  var logger = getGlobal("diag");
  if (!logger) {
    return;
  }
  args2.unshift(namespace);
  return logger[funcName].apply(logger, __spreadArray([], __read(args2), false));
}

// node_modules/@opentelemetry/api/build/esm/diag/types.js
var DiagLogLevel;
(function(DiagLogLevel2) {
  DiagLogLevel2[DiagLogLevel2["NONE"] = 0] = "NONE";
  DiagLogLevel2[DiagLogLevel2["ERROR"] = 30] = "ERROR";
  DiagLogLevel2[DiagLogLevel2["WARN"] = 50] = "WARN";
  DiagLogLevel2[DiagLogLevel2["INFO"] = 60] = "INFO";
  DiagLogLevel2[DiagLogLevel2["DEBUG"] = 70] = "DEBUG";
  DiagLogLevel2[DiagLogLevel2["VERBOSE"] = 80] = "VERBOSE";
  DiagLogLevel2[DiagLogLevel2["ALL"] = 9999] = "ALL";
})(DiagLogLevel || (DiagLogLevel = {}));

// node_modules/@opentelemetry/api/build/esm/diag/internal/logLevelLogger.js
function createLogLevelDiagLogger(maxLevel, logger) {
  if (maxLevel < DiagLogLevel.NONE) {
    maxLevel = DiagLogLevel.NONE;
  } else if (maxLevel > DiagLogLevel.ALL) {
    maxLevel = DiagLogLevel.ALL;
  }
  logger = logger || {};
  function _filterFunc(funcName, theLevel) {
    var theFunc = logger[funcName];
    if (typeof theFunc === "function" && maxLevel >= theLevel) {
      return theFunc.bind(logger);
    }
    return function() {
    };
  }
  return {
    error: _filterFunc("error", DiagLogLevel.ERROR),
    warn: _filterFunc("warn", DiagLogLevel.WARN),
    info: _filterFunc("info", DiagLogLevel.INFO),
    debug: _filterFunc("debug", DiagLogLevel.DEBUG),
    verbose: _filterFunc("verbose", DiagLogLevel.VERBOSE)
  };
}

// node_modules/@opentelemetry/api/build/esm/api/diag.js
var __read2 = function(o, n) {
  var m = typeof Symbol === "function" && o[Symbol.iterator];
  if (!m) return o;
  var i = m.call(o), r, ar = [], e;
  try {
    while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
  } catch (error) {
    e = { error };
  } finally {
    try {
      if (r && !r.done && (m = i["return"])) m.call(i);
    } finally {
      if (e) throw e.error;
    }
  }
  return ar;
};
var __spreadArray2 = function(to, from, pack) {
  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {
    if (ar || !(i in from)) {
      if (!ar) ar = Array.prototype.slice.call(from, 0, i);
      ar[i] = from[i];
    }
  }
  return to.concat(ar || Array.prototype.slice.call(from));
};
var API_NAME = "diag";
var DiagAPI = (
  /** @class */
  (function() {
    function DiagAPI2() {
      function _logProxy(funcName) {
        return function() {
          var args2 = [];
          for (var _i = 0; _i < arguments.length; _i++) {
            args2[_i] = arguments[_i];
          }
          var logger = getGlobal("diag");
          if (!logger)
            return;
          return logger[funcName].apply(logger, __spreadArray2([], __read2(args2), false));
        };
      }
      var self = this;
      var setLogger = function(logger, optionsOrLogLevel) {
        var _a17, _b8, _c;
        if (optionsOrLogLevel === void 0) {
          optionsOrLogLevel = { logLevel: DiagLogLevel.INFO };
        }
        if (logger === self) {
          var err = new Error("Cannot use diag as the logger for itself. Please use a DiagLogger implementation like ConsoleDiagLogger or a custom implementation");
          self.error((_a17 = err.stack) !== null && _a17 !== void 0 ? _a17 : err.message);
          return false;
        }
        if (typeof optionsOrLogLevel === "number") {
          optionsOrLogLevel = {
            logLevel: optionsOrLogLevel
          };
        }
        var oldLogger = getGlobal("diag");
        var newLogger = createLogLevelDiagLogger((_b8 = optionsOrLogLevel.logLevel) !== null && _b8 !== void 0 ? _b8 : DiagLogLevel.INFO, logger);
        if (oldLogger && !optionsOrLogLevel.suppressOverrideMessage) {
          var stack = (_c = new Error().stack) !== null && _c !== void 0 ? _c : "<failed to generate stacktrace>";
          oldLogger.warn("Current logger will be overwritten from " + stack);
          newLogger.warn("Current logger will overwrite one already registered from " + stack);
        }
        return registerGlobal("diag", newLogger, self, true);
      };
      self.setLogger = setLogger;
      self.disable = function() {
        unregisterGlobal(API_NAME, self);
      };
      self.createComponentLogger = function(options) {
        return new DiagComponentLogger(options);
      };
      self.verbose = _logProxy("verbose");
      self.debug = _logProxy("debug");
      self.info = _logProxy("info");
      self.warn = _logProxy("warn");
      self.error = _logProxy("error");
    }
    DiagAPI2.instance = function() {
      if (!this._instance) {
        this._instance = new DiagAPI2();
      }
      return this._instance;
    };
    return DiagAPI2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/context/context.js
function createContextKey(description) {
  return Symbol.for(description);
}
var BaseContext = (
  /** @class */
  /* @__PURE__ */ (function() {
    function BaseContext2(parentContext) {
      var self = this;
      self._currentContext = parentContext ? new Map(parentContext) : /* @__PURE__ */ new Map();
      self.getValue = function(key) {
        return self._currentContext.get(key);
      };
      self.setValue = function(key, value2) {
        var context = new BaseContext2(self._currentContext);
        context._currentContext.set(key, value2);
        return context;
      };
      self.deleteValue = function(key) {
        var context = new BaseContext2(self._currentContext);
        context._currentContext.delete(key);
        return context;
      };
    }
    return BaseContext2;
  })()
);
var ROOT_CONTEXT = new BaseContext();

// node_modules/@opentelemetry/api/build/esm/context/NoopContextManager.js
var __read3 = function(o, n) {
  var m = typeof Symbol === "function" && o[Symbol.iterator];
  if (!m) return o;
  var i = m.call(o), r, ar = [], e;
  try {
    while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
  } catch (error) {
    e = { error };
  } finally {
    try {
      if (r && !r.done && (m = i["return"])) m.call(i);
    } finally {
      if (e) throw e.error;
    }
  }
  return ar;
};
var __spreadArray3 = function(to, from, pack) {
  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {
    if (ar || !(i in from)) {
      if (!ar) ar = Array.prototype.slice.call(from, 0, i);
      ar[i] = from[i];
    }
  }
  return to.concat(ar || Array.prototype.slice.call(from));
};
var NoopContextManager = (
  /** @class */
  (function() {
    function NoopContextManager2() {
    }
    NoopContextManager2.prototype.active = function() {
      return ROOT_CONTEXT;
    };
    NoopContextManager2.prototype.with = function(_context, fn, thisArg) {
      var args2 = [];
      for (var _i = 3; _i < arguments.length; _i++) {
        args2[_i - 3] = arguments[_i];
      }
      return fn.call.apply(fn, __spreadArray3([thisArg], __read3(args2), false));
    };
    NoopContextManager2.prototype.bind = function(_context, target) {
      return target;
    };
    NoopContextManager2.prototype.enable = function() {
      return this;
    };
    NoopContextManager2.prototype.disable = function() {
      return this;
    };
    return NoopContextManager2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/api/context.js
var __read4 = function(o, n) {
  var m = typeof Symbol === "function" && o[Symbol.iterator];
  if (!m) return o;
  var i = m.call(o), r, ar = [], e;
  try {
    while ((n === void 0 || n-- > 0) && !(r = i.next()).done) ar.push(r.value);
  } catch (error) {
    e = { error };
  } finally {
    try {
      if (r && !r.done && (m = i["return"])) m.call(i);
    } finally {
      if (e) throw e.error;
    }
  }
  return ar;
};
var __spreadArray4 = function(to, from, pack) {
  if (pack || arguments.length === 2) for (var i = 0, l = from.length, ar; i < l; i++) {
    if (ar || !(i in from)) {
      if (!ar) ar = Array.prototype.slice.call(from, 0, i);
      ar[i] = from[i];
    }
  }
  return to.concat(ar || Array.prototype.slice.call(from));
};
var API_NAME2 = "context";
var NOOP_CONTEXT_MANAGER = new NoopContextManager();
var ContextAPI = (
  /** @class */
  (function() {
    function ContextAPI2() {
    }
    ContextAPI2.getInstance = function() {
      if (!this._instance) {
        this._instance = new ContextAPI2();
      }
      return this._instance;
    };
    ContextAPI2.prototype.setGlobalContextManager = function(contextManager) {
      return registerGlobal(API_NAME2, contextManager, DiagAPI.instance());
    };
    ContextAPI2.prototype.active = function() {
      return this._getContextManager().active();
    };
    ContextAPI2.prototype.with = function(context, fn, thisArg) {
      var _a17;
      var args2 = [];
      for (var _i = 3; _i < arguments.length; _i++) {
        args2[_i - 3] = arguments[_i];
      }
      return (_a17 = this._getContextManager()).with.apply(_a17, __spreadArray4([context, fn, thisArg], __read4(args2), false));
    };
    ContextAPI2.prototype.bind = function(context, target) {
      return this._getContextManager().bind(context, target);
    };
    ContextAPI2.prototype._getContextManager = function() {
      return getGlobal(API_NAME2) || NOOP_CONTEXT_MANAGER;
    };
    ContextAPI2.prototype.disable = function() {
      this._getContextManager().disable();
      unregisterGlobal(API_NAME2, DiagAPI.instance());
    };
    return ContextAPI2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/trace/trace_flags.js
var TraceFlags;
(function(TraceFlags2) {
  TraceFlags2[TraceFlags2["NONE"] = 0] = "NONE";
  TraceFlags2[TraceFlags2["SAMPLED"] = 1] = "SAMPLED";
})(TraceFlags || (TraceFlags = {}));

// node_modules/@opentelemetry/api/build/esm/trace/invalid-span-constants.js
var INVALID_SPANID = "0000000000000000";
var INVALID_TRACEID = "00000000000000000000000000000000";
var INVALID_SPAN_CONTEXT = {
  traceId: INVALID_TRACEID,
  spanId: INVALID_SPANID,
  traceFlags: TraceFlags.NONE
};

// node_modules/@opentelemetry/api/build/esm/trace/NonRecordingSpan.js
var NonRecordingSpan = (
  /** @class */
  (function() {
    function NonRecordingSpan2(_spanContext) {
      if (_spanContext === void 0) {
        _spanContext = INVALID_SPAN_CONTEXT;
      }
      this._spanContext = _spanContext;
    }
    NonRecordingSpan2.prototype.spanContext = function() {
      return this._spanContext;
    };
    NonRecordingSpan2.prototype.setAttribute = function(_key, _value) {
      return this;
    };
    NonRecordingSpan2.prototype.setAttributes = function(_attributes) {
      return this;
    };
    NonRecordingSpan2.prototype.addEvent = function(_name, _attributes) {
      return this;
    };
    NonRecordingSpan2.prototype.addLink = function(_link) {
      return this;
    };
    NonRecordingSpan2.prototype.addLinks = function(_links) {
      return this;
    };
    NonRecordingSpan2.prototype.setStatus = function(_status) {
      return this;
    };
    NonRecordingSpan2.prototype.updateName = function(_name) {
      return this;
    };
    NonRecordingSpan2.prototype.end = function(_endTime) {
    };
    NonRecordingSpan2.prototype.isRecording = function() {
      return false;
    };
    NonRecordingSpan2.prototype.recordException = function(_exception, _time) {
    };
    return NonRecordingSpan2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/trace/context-utils.js
var SPAN_KEY = createContextKey("OpenTelemetry Context Key SPAN");
function getSpan(context) {
  return context.getValue(SPAN_KEY) || void 0;
}
function getActiveSpan() {
  return getSpan(ContextAPI.getInstance().active());
}
function setSpan(context, span) {
  return context.setValue(SPAN_KEY, span);
}
function deleteSpan(context) {
  return context.deleteValue(SPAN_KEY);
}
function setSpanContext(context, spanContext) {
  return setSpan(context, new NonRecordingSpan(spanContext));
}
function getSpanContext(context) {
  var _a17;
  return (_a17 = getSpan(context)) === null || _a17 === void 0 ? void 0 : _a17.spanContext();
}

// node_modules/@opentelemetry/api/build/esm/trace/spancontext-utils.js
var VALID_TRACEID_REGEX = /^([0-9a-f]{32})$/i;
var VALID_SPANID_REGEX = /^[0-9a-f]{16}$/i;
function isValidTraceId(traceId) {
  return VALID_TRACEID_REGEX.test(traceId) && traceId !== INVALID_TRACEID;
}
function isValidSpanId(spanId) {
  return VALID_SPANID_REGEX.test(spanId) && spanId !== INVALID_SPANID;
}
function isSpanContextValid(spanContext) {
  return isValidTraceId(spanContext.traceId) && isValidSpanId(spanContext.spanId);
}
function wrapSpanContext(spanContext) {
  return new NonRecordingSpan(spanContext);
}

// node_modules/@opentelemetry/api/build/esm/trace/NoopTracer.js
var contextApi = ContextAPI.getInstance();
var NoopTracer = (
  /** @class */
  (function() {
    function NoopTracer2() {
    }
    NoopTracer2.prototype.startSpan = function(name16, options, context) {
      if (context === void 0) {
        context = contextApi.active();
      }
      var root = Boolean(options === null || options === void 0 ? void 0 : options.root);
      if (root) {
        return new NonRecordingSpan();
      }
      var parentFromContext = context && getSpanContext(context);
      if (isSpanContext(parentFromContext) && isSpanContextValid(parentFromContext)) {
        return new NonRecordingSpan(parentFromContext);
      } else {
        return new NonRecordingSpan();
      }
    };
    NoopTracer2.prototype.startActiveSpan = function(name16, arg2, arg3, arg4) {
      var opts;
      var ctx;
      var fn;
      if (arguments.length < 2) {
        return;
      } else if (arguments.length === 2) {
        fn = arg2;
      } else if (arguments.length === 3) {
        opts = arg2;
        fn = arg3;
      } else {
        opts = arg2;
        ctx = arg3;
        fn = arg4;
      }
      var parentContext = ctx !== null && ctx !== void 0 ? ctx : contextApi.active();
      var span = this.startSpan(name16, opts, parentContext);
      var contextWithSpanSet = setSpan(parentContext, span);
      return contextApi.with(contextWithSpanSet, fn, void 0, span);
    };
    return NoopTracer2;
  })()
);
function isSpanContext(spanContext) {
  return typeof spanContext === "object" && typeof spanContext["spanId"] === "string" && typeof spanContext["traceId"] === "string" && typeof spanContext["traceFlags"] === "number";
}

// node_modules/@opentelemetry/api/build/esm/trace/ProxyTracer.js
var NOOP_TRACER = new NoopTracer();
var ProxyTracer = (
  /** @class */
  (function() {
    function ProxyTracer2(_provider, name16, version, options) {
      this._provider = _provider;
      this.name = name16;
      this.version = version;
      this.options = options;
    }
    ProxyTracer2.prototype.startSpan = function(name16, options, context) {
      return this._getTracer().startSpan(name16, options, context);
    };
    ProxyTracer2.prototype.startActiveSpan = function(_name, _options, _context, _fn) {
      var tracer = this._getTracer();
      return Reflect.apply(tracer.startActiveSpan, tracer, arguments);
    };
    ProxyTracer2.prototype._getTracer = function() {
      if (this._delegate) {
        return this._delegate;
      }
      var tracer = this._provider.getDelegateTracer(this.name, this.version, this.options);
      if (!tracer) {
        return NOOP_TRACER;
      }
      this._delegate = tracer;
      return this._delegate;
    };
    return ProxyTracer2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/trace/NoopTracerProvider.js
var NoopTracerProvider = (
  /** @class */
  (function() {
    function NoopTracerProvider2() {
    }
    NoopTracerProvider2.prototype.getTracer = function(_name, _version, _options) {
      return new NoopTracer();
    };
    return NoopTracerProvider2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/trace/ProxyTracerProvider.js
var NOOP_TRACER_PROVIDER = new NoopTracerProvider();
var ProxyTracerProvider = (
  /** @class */
  (function() {
    function ProxyTracerProvider2() {
    }
    ProxyTracerProvider2.prototype.getTracer = function(name16, version, options) {
      var _a17;
      return (_a17 = this.getDelegateTracer(name16, version, options)) !== null && _a17 !== void 0 ? _a17 : new ProxyTracer(this, name16, version, options);
    };
    ProxyTracerProvider2.prototype.getDelegate = function() {
      var _a17;
      return (_a17 = this._delegate) !== null && _a17 !== void 0 ? _a17 : NOOP_TRACER_PROVIDER;
    };
    ProxyTracerProvider2.prototype.setDelegate = function(delegate) {
      this._delegate = delegate;
    };
    ProxyTracerProvider2.prototype.getDelegateTracer = function(name16, version, options) {
      var _a17;
      return (_a17 = this._delegate) === null || _a17 === void 0 ? void 0 : _a17.getTracer(name16, version, options);
    };
    return ProxyTracerProvider2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/trace/status.js
var SpanStatusCode;
(function(SpanStatusCode2) {
  SpanStatusCode2[SpanStatusCode2["UNSET"] = 0] = "UNSET";
  SpanStatusCode2[SpanStatusCode2["OK"] = 1] = "OK";
  SpanStatusCode2[SpanStatusCode2["ERROR"] = 2] = "ERROR";
})(SpanStatusCode || (SpanStatusCode = {}));

// node_modules/@opentelemetry/api/build/esm/api/trace.js
var API_NAME3 = "trace";
var TraceAPI = (
  /** @class */
  (function() {
    function TraceAPI2() {
      this._proxyTracerProvider = new ProxyTracerProvider();
      this.wrapSpanContext = wrapSpanContext;
      this.isSpanContextValid = isSpanContextValid;
      this.deleteSpan = deleteSpan;
      this.getSpan = getSpan;
      this.getActiveSpan = getActiveSpan;
      this.getSpanContext = getSpanContext;
      this.setSpan = setSpan;
      this.setSpanContext = setSpanContext;
    }
    TraceAPI2.getInstance = function() {
      if (!this._instance) {
        this._instance = new TraceAPI2();
      }
      return this._instance;
    };
    TraceAPI2.prototype.setGlobalTracerProvider = function(provider) {
      var success = registerGlobal(API_NAME3, this._proxyTracerProvider, DiagAPI.instance());
      if (success) {
        this._proxyTracerProvider.setDelegate(provider);
      }
      return success;
    };
    TraceAPI2.prototype.getTracerProvider = function() {
      return getGlobal(API_NAME3) || this._proxyTracerProvider;
    };
    TraceAPI2.prototype.getTracer = function(name16, version) {
      return this.getTracerProvider().getTracer(name16, version);
    };
    TraceAPI2.prototype.disable = function() {
      unregisterGlobal(API_NAME3, DiagAPI.instance());
      this._proxyTracerProvider = new ProxyTracerProvider();
    };
    return TraceAPI2;
  })()
);

// node_modules/@opentelemetry/api/build/esm/trace-api.js
var trace = TraceAPI.getInstance();

// node_modules/ai/dist/index.mjs
import { z as z73 } from "zod/v4";
import { z as z82 } from "zod/v4";
var __defProp2 = Object.defineProperty;
var __export2 = (target, all) => {
  for (var name16 in all)
    __defProp2(target, name16, { get: all[name16], enumerable: true });
};
var name15 = "AI_NoOutputSpecifiedError";
var marker16 = `vercel.ai.error.${name15}`;
var symbol16 = Symbol.for(marker16);
var _a16;
_a16 = symbol16;
function formatWarning(warning) {
  const prefix = "AI SDK Warning:";
  switch (warning.type) {
    case "unsupported-setting": {
      let message = `${prefix} The "${warning.setting}" setting is not supported by this model`;
      if (warning.details) {
        message += ` - ${warning.details}`;
      }
      return message;
    }
    case "unsupported-tool": {
      const toolName = "name" in warning.tool ? warning.tool.name : "unknown tool";
      let message = `${prefix} The tool "${toolName}" is not supported by this model`;
      if (warning.details) {
        message += ` - ${warning.details}`;
      }
      return message;
    }
    case "other": {
      return `${prefix} ${warning.message}`;
    }
    default: {
      return `${prefix} ${JSON.stringify(warning, null, 2)}`;
    }
  }
}
var FIRST_WARNING_INFO_MESSAGE = "AI SDK Warning System: To turn off warning logging, set the AI_SDK_LOG_WARNINGS global to false.";
var hasLoggedBefore = false;
var logWarnings = (warnings) => {
  if (warnings.length === 0) {
    return;
  }
  const logger = globalThis.AI_SDK_LOG_WARNINGS;
  if (logger === false) {
    return;
  }
  if (typeof logger === "function") {
    logger(warnings);
    return;
  }
  if (!hasLoggedBefore) {
    hasLoggedBefore = true;
    console.info(FIRST_WARNING_INFO_MESSAGE);
  }
  for (const warning of warnings) {
    console.warn(formatWarning(warning));
  }
};
var name23 = "AI_InvalidArgumentError";
var marker23 = `vercel.ai.error.${name23}`;
var symbol23 = Symbol.for(marker23);
var _a23;
var InvalidArgumentError3 = class extends AISDKError {
  constructor({
    parameter,
    value: value2,
    message
  }) {
    super({
      name: name23,
      message: `Invalid argument for parameter ${parameter}: ${message}`
    });
    this[_a23] = true;
    this.parameter = parameter;
    this.value = value2;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker23);
  }
};
_a23 = symbol23;
var name33 = "AI_InvalidStreamPartError";
var marker33 = `vercel.ai.error.${name33}`;
var symbol33 = Symbol.for(marker33);
var _a33;
_a33 = symbol33;
var name43 = "AI_InvalidToolInputError";
var marker43 = `vercel.ai.error.${name43}`;
var symbol43 = Symbol.for(marker43);
var _a43;
_a43 = symbol43;
var name53 = "AI_NoImageGeneratedError";
var marker53 = `vercel.ai.error.${name53}`;
var symbol53 = Symbol.for(marker53);
var _a53;
_a53 = symbol53;
var name63 = "AI_NoObjectGeneratedError";
var marker63 = `vercel.ai.error.${name63}`;
var symbol63 = Symbol.for(marker63);
var _a63;
var NoObjectGeneratedError = class extends AISDKError {
  constructor({
    message = "No object generated.",
    cause,
    text: text2,
    response,
    usage,
    finishReason
  }) {
    super({ name: name63, message, cause });
    this[_a63] = true;
    this.text = text2;
    this.response = response;
    this.usage = usage;
    this.finishReason = finishReason;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker63);
  }
};
_a63 = symbol63;
var name72 = "AI_NoOutputGeneratedError";
var marker73 = `vercel.ai.error.${name72}`;
var symbol73 = Symbol.for(marker73);
var _a73;
_a73 = symbol73;
var name82 = "AI_NoSuchToolError";
var marker82 = `vercel.ai.error.${name82}`;
var symbol82 = Symbol.for(marker82);
var _a82;
_a82 = symbol82;
var name92 = "AI_ToolCallRepairError";
var marker92 = `vercel.ai.error.${name92}`;
var symbol92 = Symbol.for(marker92);
var _a92;
_a92 = symbol92;
var UnsupportedModelVersionError = class extends AISDKError {
  constructor(options) {
    super({
      name: "AI_UnsupportedModelVersionError",
      message: `Unsupported model version ${options.version} for provider "${options.provider}" and model "${options.modelId}". AI SDK 5 only supports models that implement specification version "v2".`
    });
    this.version = options.version;
    this.provider = options.provider;
    this.modelId = options.modelId;
  }
};
var name102 = "AI_InvalidDataContentError";
var marker102 = `vercel.ai.error.${name102}`;
var symbol102 = Symbol.for(marker102);
var _a102;
_a102 = symbol102;
var name112 = "AI_InvalidMessageRoleError";
var marker112 = `vercel.ai.error.${name112}`;
var symbol112 = Symbol.for(marker112);
var _a112;
var InvalidMessageRoleError = class extends AISDKError {
  constructor({
    role,
    message = `Invalid message role: '${role}'. Must be one of: "system", "user", "assistant", "tool".`
  }) {
    super({ name: name112, message });
    this[_a112] = true;
    this.role = role;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker112);
  }
};
_a112 = symbol112;
var name122 = "AI_MessageConversionError";
var marker122 = `vercel.ai.error.${name122}`;
var symbol122 = Symbol.for(marker122);
var _a122;
_a122 = symbol122;
var name132 = "AI_DownloadError";
var marker132 = `vercel.ai.error.${name132}`;
var symbol132 = Symbol.for(marker132);
var _a132;
var DownloadError = class extends AISDKError {
  constructor({
    url,
    statusCode,
    statusText,
    cause,
    message = cause == null ? `Failed to download ${url}: ${statusCode} ${statusText}` : `Failed to download ${url}: ${cause}`
  }) {
    super({ name: name132, message, cause });
    this[_a132] = true;
    this.url = url;
    this.statusCode = statusCode;
    this.statusText = statusText;
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker132);
  }
};
_a132 = symbol132;
var name142 = "AI_RetryError";
var marker142 = `vercel.ai.error.${name142}`;
var symbol142 = Symbol.for(marker142);
var _a142;
var RetryError = class extends AISDKError {
  constructor({
    message,
    reason,
    errors
  }) {
    super({ name: name142, message });
    this[_a142] = true;
    this.reason = reason;
    this.errors = errors;
    this.lastError = errors[errors.length - 1];
  }
  static isInstance(error) {
    return AISDKError.hasMarker(error, marker142);
  }
};
_a142 = symbol142;
function resolveLanguageModel(model) {
  if (typeof model !== "string") {
    if (model.specificationVersion !== "v2") {
      throw new UnsupportedModelVersionError({
        version: model.specificationVersion,
        provider: model.provider,
        modelId: model.modelId
      });
    }
    return model;
  }
  return getGlobalProvider().languageModel(model);
}
function getGlobalProvider() {
  var _a162;
  return (_a162 = globalThis.AI_SDK_DEFAULT_PROVIDER) != null ? _a162 : gateway;
}
var imageMediaTypeSignatures = [
  {
    mediaType: "image/gif",
    bytesPrefix: [71, 73, 70]
    // GIF
  },
  {
    mediaType: "image/png",
    bytesPrefix: [137, 80, 78, 71]
    // PNG
  },
  {
    mediaType: "image/jpeg",
    bytesPrefix: [255, 216]
    // JPEG
  },
  {
    mediaType: "image/webp",
    bytesPrefix: [
      82,
      73,
      70,
      70,
      // "RIFF"
      null,
      null,
      null,
      null,
      // file size (variable)
      87,
      69,
      66,
      80
      // "WEBP"
    ]
  },
  {
    mediaType: "image/bmp",
    bytesPrefix: [66, 77]
  },
  {
    mediaType: "image/tiff",
    bytesPrefix: [73, 73, 42, 0]
  },
  {
    mediaType: "image/tiff",
    bytesPrefix: [77, 77, 0, 42]
  },
  {
    mediaType: "image/avif",
    bytesPrefix: [
      0,
      0,
      0,
      32,
      102,
      116,
      121,
      112,
      97,
      118,
      105,
      102
    ]
  },
  {
    mediaType: "image/heic",
    bytesPrefix: [
      0,
      0,
      0,
      32,
      102,
      116,
      121,
      112,
      104,
      101,
      105,
      99
    ]
  }
];
var stripID3 = (data) => {
  const bytes = typeof data === "string" ? convertBase64ToUint8Array(data) : data;
  const id3Size = (bytes[6] & 127) << 21 | (bytes[7] & 127) << 14 | (bytes[8] & 127) << 7 | bytes[9] & 127;
  return bytes.slice(id3Size + 10);
};
function stripID3TagsIfPresent(data) {
  const hasId3 = typeof data === "string" && data.startsWith("SUQz") || typeof data !== "string" && data.length > 10 && data[0] === 73 && // 'I'
  data[1] === 68 && // 'D'
  data[2] === 51;
  return hasId3 ? stripID3(data) : data;
}
function detectMediaType({
  data,
  signatures
}) {
  const processedData = stripID3TagsIfPresent(data);
  const bytes = typeof processedData === "string" ? convertBase64ToUint8Array(
    processedData.substring(0, Math.min(processedData.length, 24))
  ) : processedData;
  for (const signature of signatures) {
    if (bytes.length >= signature.bytesPrefix.length && signature.bytesPrefix.every(
      (byte, index) => byte === null || bytes[index] === byte
    )) {
      return signature.mediaType;
    }
  }
  return void 0;
}
var VERSION4 = true ? "5.0.106" : "0.0.0-test";
var download = async ({ url }) => {
  var _a162;
  const urlText = url.toString();
  try {
    const response = await fetch(urlText, {
      headers: withUserAgentSuffix(
        {},
        `ai-sdk/${VERSION4}`,
        getRuntimeEnvironmentUserAgent()
      )
    });
    if (!response.ok) {
      throw new DownloadError({
        url: urlText,
        statusCode: response.status,
        statusText: response.statusText
      });
    }
    return {
      data: new Uint8Array(await response.arrayBuffer()),
      mediaType: (_a162 = response.headers.get("content-type")) != null ? _a162 : void 0
    };
  } catch (error) {
    if (DownloadError.isInstance(error)) {
      throw error;
    }
    throw new DownloadError({ url: urlText, cause: error });
  }
};
var createDefaultDownloadFunction = (download2 = download) => (requestedDownloads) => Promise.all(
  requestedDownloads.map(
    async (requestedDownload) => requestedDownload.isUrlSupportedByModel ? null : download2(requestedDownload)
  )
);
function splitDataUrl(dataUrl) {
  try {
    const [header, base64Content] = dataUrl.split(",");
    return {
      mediaType: header.split(";")[0].split(":")[1],
      base64Content
    };
  } catch (error) {
    return {
      mediaType: void 0,
      base64Content: void 0
    };
  }
}
var dataContentSchema = z26.union([
  z26.string(),
  z26.instanceof(Uint8Array),
  z26.instanceof(ArrayBuffer),
  z26.custom(
    // Buffer might not be available in some environments such as CloudFlare:
    (value2) => {
      var _a162, _b8;
      return (_b8 = (_a162 = globalThis.Buffer) == null ? void 0 : _a162.isBuffer(value2)) != null ? _b8 : false;
    },
    { message: "Must be a Buffer" }
  )
]);
function convertToLanguageModelV2DataContent(content) {
  if (content instanceof Uint8Array) {
    return { data: content, mediaType: void 0 };
  }
  if (content instanceof ArrayBuffer) {
    return { data: new Uint8Array(content), mediaType: void 0 };
  }
  if (typeof content === "string") {
    try {
      content = new URL(content);
    } catch (error) {
    }
  }
  if (content instanceof URL && content.protocol === "data:") {
    const { mediaType: dataUrlMediaType, base64Content } = splitDataUrl(
      content.toString()
    );
    if (dataUrlMediaType == null || base64Content == null) {
      throw new AISDKError({
        name: "InvalidDataContentError",
        message: `Invalid data URL format in content ${content.toString()}`
      });
    }
    return { data: base64Content, mediaType: dataUrlMediaType };
  }
  return { data: content, mediaType: void 0 };
}
function convertDataContentToBase64String(content) {
  if (typeof content === "string") {
    return content;
  }
  if (content instanceof ArrayBuffer) {
    return convertUint8ArrayToBase64(new Uint8Array(content));
  }
  return convertUint8ArrayToBase64(content);
}
async function convertToLanguageModelPrompt({
  prompt,
  supportedUrls,
  download: download2 = createDefaultDownloadFunction()
}) {
  const downloadedAssets = await downloadAssets(
    prompt.messages,
    download2,
    supportedUrls
  );
  return [
    ...prompt.system != null ? [{ role: "system", content: prompt.system }] : [],
    ...prompt.messages.map(
      (message) => convertToLanguageModelMessage({ message, downloadedAssets })
    )
  ];
}
function convertToLanguageModelMessage({
  message,
  downloadedAssets
}) {
  const role = message.role;
  switch (role) {
    case "system": {
      return {
        role: "system",
        content: message.content,
        providerOptions: message.providerOptions
      };
    }
    case "user": {
      if (typeof message.content === "string") {
        return {
          role: "user",
          content: [{ type: "text", text: message.content }],
          providerOptions: message.providerOptions
        };
      }
      return {
        role: "user",
        content: message.content.map((part) => convertPartToLanguageModelPart(part, downloadedAssets)).filter((part) => part.type !== "text" || part.text !== ""),
        providerOptions: message.providerOptions
      };
    }
    case "assistant": {
      if (typeof message.content === "string") {
        return {
          role: "assistant",
          content: [{ type: "text", text: message.content }],
          providerOptions: message.providerOptions
        };
      }
      return {
        role: "assistant",
        content: message.content.filter(
          // remove empty text parts (no text, and no provider options):
          (part) => part.type !== "text" || part.text !== "" || part.providerOptions != null
        ).map((part) => {
          const providerOptions = part.providerOptions;
          switch (part.type) {
            case "file": {
              const { data, mediaType } = convertToLanguageModelV2DataContent(
                part.data
              );
              return {
                type: "file",
                data,
                filename: part.filename,
                mediaType: mediaType != null ? mediaType : part.mediaType,
                providerOptions
              };
            }
            case "reasoning": {
              return {
                type: "reasoning",
                text: part.text,
                providerOptions
              };
            }
            case "text": {
              return {
                type: "text",
                text: part.text,
                providerOptions
              };
            }
            case "tool-call": {
              return {
                type: "tool-call",
                toolCallId: part.toolCallId,
                toolName: part.toolName,
                input: part.input,
                providerExecuted: part.providerExecuted,
                providerOptions
              };
            }
            case "tool-result": {
              return {
                type: "tool-result",
                toolCallId: part.toolCallId,
                toolName: part.toolName,
                output: part.output,
                providerOptions
              };
            }
          }
        }),
        providerOptions: message.providerOptions
      };
    }
    case "tool": {
      return {
        role: "tool",
        content: message.content.map((part) => ({
          type: "tool-result",
          toolCallId: part.toolCallId,
          toolName: part.toolName,
          output: part.output,
          providerOptions: part.providerOptions
        })),
        providerOptions: message.providerOptions
      };
    }
    default: {
      const _exhaustiveCheck = role;
      throw new InvalidMessageRoleError({ role: _exhaustiveCheck });
    }
  }
}
async function downloadAssets(messages, download2, supportedUrls) {
  const plannedDownloads = messages.filter((message) => message.role === "user").map((message) => message.content).filter(
    (content) => Array.isArray(content)
  ).flat().filter(
    (part) => part.type === "image" || part.type === "file"
  ).map((part) => {
    var _a162;
    const mediaType = (_a162 = part.mediaType) != null ? _a162 : part.type === "image" ? "image/*" : void 0;
    let data = part.type === "image" ? part.image : part.data;
    if (typeof data === "string") {
      try {
        data = new URL(data);
      } catch (ignored) {
      }
    }
    return { mediaType, data };
  }).filter(
    (part) => part.data instanceof URL
  ).map((part) => ({
    url: part.data,
    isUrlSupportedByModel: part.mediaType != null && isUrlSupported({
      url: part.data.toString(),
      mediaType: part.mediaType,
      supportedUrls
    })
  }));
  const downloadedFiles = await download2(plannedDownloads);
  return Object.fromEntries(
    downloadedFiles.map(
      (file, index) => file == null ? null : [
        plannedDownloads[index].url.toString(),
        { data: file.data, mediaType: file.mediaType }
      ]
    ).filter((file) => file != null)
  );
}
function convertPartToLanguageModelPart(part, downloadedAssets) {
  var _a162;
  if (part.type === "text") {
    return {
      type: "text",
      text: part.text,
      providerOptions: part.providerOptions
    };
  }
  let originalData;
  const type2 = part.type;
  switch (type2) {
    case "image":
      originalData = part.image;
      break;
    case "file":
      originalData = part.data;
      break;
    default:
      throw new Error(`Unsupported part type: ${type2}`);
  }
  const { data: convertedData, mediaType: convertedMediaType } = convertToLanguageModelV2DataContent(originalData);
  let mediaType = convertedMediaType != null ? convertedMediaType : part.mediaType;
  let data = convertedData;
  if (data instanceof URL) {
    const downloadedFile = downloadedAssets[data.toString()];
    if (downloadedFile) {
      data = downloadedFile.data;
      mediaType != null ? mediaType : mediaType = downloadedFile.mediaType;
    }
  }
  switch (type2) {
    case "image": {
      if (data instanceof Uint8Array || typeof data === "string") {
        mediaType = (_a162 = detectMediaType({ data, signatures: imageMediaTypeSignatures })) != null ? _a162 : mediaType;
      }
      return {
        type: "file",
        mediaType: mediaType != null ? mediaType : "image/*",
        // any image
        filename: void 0,
        data,
        providerOptions: part.providerOptions
      };
    }
    case "file": {
      if (mediaType == null) {
        throw new Error(`Media type is missing for file part`);
      }
      return {
        type: "file",
        mediaType,
        filename: part.filename,
        data,
        providerOptions: part.providerOptions
      };
    }
  }
}
function prepareCallSettings({
  maxOutputTokens,
  temperature,
  topP,
  topK,
  presencePenalty,
  frequencyPenalty,
  seed,
  stopSequences
}) {
  if (maxOutputTokens != null) {
    if (!Number.isInteger(maxOutputTokens)) {
      throw new InvalidArgumentError3({
        parameter: "maxOutputTokens",
        value: maxOutputTokens,
        message: "maxOutputTokens must be an integer"
      });
    }
    if (maxOutputTokens < 1) {
      throw new InvalidArgumentError3({
        parameter: "maxOutputTokens",
        value: maxOutputTokens,
        message: "maxOutputTokens must be >= 1"
      });
    }
  }
  if (temperature != null) {
    if (typeof temperature !== "number") {
      throw new InvalidArgumentError3({
        parameter: "temperature",
        value: temperature,
        message: "temperature must be a number"
      });
    }
  }
  if (topP != null) {
    if (typeof topP !== "number") {
      throw new InvalidArgumentError3({
        parameter: "topP",
        value: topP,
        message: "topP must be a number"
      });
    }
  }
  if (topK != null) {
    if (typeof topK !== "number") {
      throw new InvalidArgumentError3({
        parameter: "topK",
        value: topK,
        message: "topK must be a number"
      });
    }
  }
  if (presencePenalty != null) {
    if (typeof presencePenalty !== "number") {
      throw new InvalidArgumentError3({
        parameter: "presencePenalty",
        value: presencePenalty,
        message: "presencePenalty must be a number"
      });
    }
  }
  if (frequencyPenalty != null) {
    if (typeof frequencyPenalty !== "number") {
      throw new InvalidArgumentError3({
        parameter: "frequencyPenalty",
        value: frequencyPenalty,
        message: "frequencyPenalty must be a number"
      });
    }
  }
  if (seed != null) {
    if (!Number.isInteger(seed)) {
      throw new InvalidArgumentError3({
        parameter: "seed",
        value: seed,
        message: "seed must be an integer"
      });
    }
  }
  return {
    maxOutputTokens,
    temperature,
    topP,
    topK,
    presencePenalty,
    frequencyPenalty,
    stopSequences,
    seed
  };
}
var jsonValueSchema = z27.lazy(
  () => z27.union([
    z27.null(),
    z27.string(),
    z27.number(),
    z27.boolean(),
    z27.record(z27.string(), jsonValueSchema),
    z27.array(jsonValueSchema)
  ])
);
var providerMetadataSchema = z33.record(
  z33.string(),
  z33.record(z33.string(), jsonValueSchema)
);
var textPartSchema = z44.object({
  type: z44.literal("text"),
  text: z44.string(),
  providerOptions: providerMetadataSchema.optional()
});
var imagePartSchema = z44.object({
  type: z44.literal("image"),
  image: z44.union([dataContentSchema, z44.instanceof(URL)]),
  mediaType: z44.string().optional(),
  providerOptions: providerMetadataSchema.optional()
});
var filePartSchema = z44.object({
  type: z44.literal("file"),
  data: z44.union([dataContentSchema, z44.instanceof(URL)]),
  filename: z44.string().optional(),
  mediaType: z44.string(),
  providerOptions: providerMetadataSchema.optional()
});
var reasoningPartSchema = z44.object({
  type: z44.literal("reasoning"),
  text: z44.string(),
  providerOptions: providerMetadataSchema.optional()
});
var toolCallPartSchema = z44.object({
  type: z44.literal("tool-call"),
  toolCallId: z44.string(),
  toolName: z44.string(),
  input: z44.unknown(),
  providerOptions: providerMetadataSchema.optional(),
  providerExecuted: z44.boolean().optional()
});
var outputSchema = z44.discriminatedUnion("type", [
  z44.object({
    type: z44.literal("text"),
    value: z44.string()
  }),
  z44.object({
    type: z44.literal("json"),
    value: jsonValueSchema
  }),
  z44.object({
    type: z44.literal("error-text"),
    value: z44.string()
  }),
  z44.object({
    type: z44.literal("error-json"),
    value: jsonValueSchema
  }),
  z44.object({
    type: z44.literal("content"),
    value: z44.array(
      z44.union([
        z44.object({
          type: z44.literal("text"),
          text: z44.string()
        }),
        z44.object({
          type: z44.literal("media"),
          data: z44.string(),
          mediaType: z44.string()
        })
      ])
    )
  })
]);
var toolResultPartSchema = z44.object({
  type: z44.literal("tool-result"),
  toolCallId: z44.string(),
  toolName: z44.string(),
  output: outputSchema,
  providerOptions: providerMetadataSchema.optional()
});
var systemModelMessageSchema = z53.object(
  {
    role: z53.literal("system"),
    content: z53.string(),
    providerOptions: providerMetadataSchema.optional()
  }
);
var userModelMessageSchema = z53.object({
  role: z53.literal("user"),
  content: z53.union([
    z53.string(),
    z53.array(z53.union([textPartSchema, imagePartSchema, filePartSchema]))
  ]),
  providerOptions: providerMetadataSchema.optional()
});
var assistantModelMessageSchema = z53.object({
  role: z53.literal("assistant"),
  content: z53.union([
    z53.string(),
    z53.array(
      z53.union([
        textPartSchema,
        filePartSchema,
        reasoningPartSchema,
        toolCallPartSchema,
        toolResultPartSchema
      ])
    )
  ]),
  providerOptions: providerMetadataSchema.optional()
});
var toolModelMessageSchema = z53.object({
  role: z53.literal("tool"),
  content: z53.array(toolResultPartSchema),
  providerOptions: providerMetadataSchema.optional()
});
var modelMessageSchema = z53.union([
  systemModelMessageSchema,
  userModelMessageSchema,
  assistantModelMessageSchema,
  toolModelMessageSchema
]);
async function standardizePrompt(prompt) {
  if (prompt.prompt == null && prompt.messages == null) {
    throw new InvalidPromptError({
      prompt,
      message: "prompt or messages must be defined"
    });
  }
  if (prompt.prompt != null && prompt.messages != null) {
    throw new InvalidPromptError({
      prompt,
      message: "prompt and messages cannot be defined at the same time"
    });
  }
  if (prompt.system != null && typeof prompt.system !== "string") {
    throw new InvalidPromptError({
      prompt,
      message: "system must be a string"
    });
  }
  let messages;
  if (prompt.prompt != null && typeof prompt.prompt === "string") {
    messages = [{ role: "user", content: prompt.prompt }];
  } else if (prompt.prompt != null && Array.isArray(prompt.prompt)) {
    messages = prompt.prompt;
  } else if (prompt.messages != null) {
    messages = prompt.messages;
  } else {
    throw new InvalidPromptError({
      prompt,
      message: "prompt or messages must be defined"
    });
  }
  if (messages.length === 0) {
    throw new InvalidPromptError({
      prompt,
      message: "messages must not be empty"
    });
  }
  const validationResult = await safeValidateTypes({
    value: messages,
    schema: z63.array(modelMessageSchema)
  });
  if (!validationResult.success) {
    throw new InvalidPromptError({
      prompt,
      message: "The messages must be a ModelMessage[]. If you have passed a UIMessage[], you can use convertToModelMessages to convert them.",
      cause: validationResult.error
    });
  }
  return {
    messages,
    system: prompt.system
  };
}
function wrapGatewayError(error) {
  if (GatewayAuthenticationError.isInstance(error) || GatewayModelNotFoundError.isInstance(error)) {
    return new AISDKError({
      name: "GatewayError",
      message: "Vercel AI Gateway access failed. If you want to use AI SDK providers directly, use the providers, e.g. @ai-sdk/openai, or register a different global default provider.",
      cause: error
    });
  }
  return error;
}
function assembleOperationName({
  operationId,
  telemetry: telemetry2
}) {
  return {
    // standardized operation and resource name:
    "operation.name": `${operationId}${(telemetry2 == null ? void 0 : telemetry2.functionId) != null ? ` ${telemetry2.functionId}` : ""}`,
    "resource.name": telemetry2 == null ? void 0 : telemetry2.functionId,
    // detailed, AI SDK specific data:
    "ai.operationId": operationId,
    "ai.telemetry.functionId": telemetry2 == null ? void 0 : telemetry2.functionId
  };
}
function getBaseTelemetryAttributes({
  model,
  settings,
  telemetry: telemetry2,
  headers
}) {
  var _a162;
  return {
    "ai.model.provider": model.provider,
    "ai.model.id": model.modelId,
    // settings:
    ...Object.entries(settings).reduce((attributes, [key, value2]) => {
      attributes[`ai.settings.${key}`] = value2;
      return attributes;
    }, {}),
    // add metadata as attributes:
    ...Object.entries((_a162 = telemetry2 == null ? void 0 : telemetry2.metadata) != null ? _a162 : {}).reduce(
      (attributes, [key, value2]) => {
        attributes[`ai.telemetry.metadata.${key}`] = value2;
        return attributes;
      },
      {}
    ),
    // request headers
    ...Object.entries(headers != null ? headers : {}).reduce((attributes, [key, value2]) => {
      if (value2 !== void 0) {
        attributes[`ai.request.headers.${key}`] = value2;
      }
      return attributes;
    }, {})
  };
}
var noopTracer = {
  startSpan() {
    return noopSpan;
  },
  startActiveSpan(name16, arg1, arg2, arg3) {
    if (typeof arg1 === "function") {
      return arg1(noopSpan);
    }
    if (typeof arg2 === "function") {
      return arg2(noopSpan);
    }
    if (typeof arg3 === "function") {
      return arg3(noopSpan);
    }
  }
};
var noopSpan = {
  spanContext() {
    return noopSpanContext;
  },
  setAttribute() {
    return this;
  },
  setAttributes() {
    return this;
  },
  addEvent() {
    return this;
  },
  addLink() {
    return this;
  },
  addLinks() {
    return this;
  },
  setStatus() {
    return this;
  },
  updateName() {
    return this;
  },
  end() {
    return this;
  },
  isRecording() {
    return false;
  },
  recordException() {
    return this;
  }
};
var noopSpanContext = {
  traceId: "",
  spanId: "",
  traceFlags: 0
};
function getTracer({
  isEnabled = false,
  tracer
} = {}) {
  if (!isEnabled) {
    return noopTracer;
  }
  if (tracer) {
    return tracer;
  }
  return trace.getTracer("ai");
}
function recordSpan({
  name: name16,
  tracer,
  attributes,
  fn,
  endWhenDone = true
}) {
  return tracer.startActiveSpan(name16, { attributes }, async (span) => {
    try {
      const result = await fn(span);
      if (endWhenDone) {
        span.end();
      }
      return result;
    } catch (error) {
      try {
        recordErrorOnSpan(span, error);
      } finally {
        span.end();
      }
      throw error;
    }
  });
}
function recordErrorOnSpan(span, error) {
  if (error instanceof Error) {
    span.recordException({
      name: error.name,
      message: error.message,
      stack: error.stack
    });
    span.setStatus({
      code: SpanStatusCode.ERROR,
      message: error.message
    });
  } else {
    span.setStatus({ code: SpanStatusCode.ERROR });
  }
}
function selectTelemetryAttributes({
  telemetry: telemetry2,
  attributes
}) {
  if ((telemetry2 == null ? void 0 : telemetry2.isEnabled) !== true) {
    return {};
  }
  return Object.entries(attributes).reduce((attributes2, [key, value2]) => {
    if (value2 == null) {
      return attributes2;
    }
    if (typeof value2 === "object" && "input" in value2 && typeof value2.input === "function") {
      if ((telemetry2 == null ? void 0 : telemetry2.recordInputs) === false) {
        return attributes2;
      }
      const result = value2.input();
      return result == null ? attributes2 : { ...attributes2, [key]: result };
    }
    if (typeof value2 === "object" && "output" in value2 && typeof value2.output === "function") {
      if ((telemetry2 == null ? void 0 : telemetry2.recordOutputs) === false) {
        return attributes2;
      }
      const result = value2.output();
      return result == null ? attributes2 : { ...attributes2, [key]: result };
    }
    return { ...attributes2, [key]: value2 };
  }, {});
}
function stringifyForTelemetry(prompt) {
  return JSON.stringify(
    prompt.map((message) => ({
      ...message,
      content: typeof message.content === "string" ? message.content : message.content.map(
        (part) => part.type === "file" ? {
          ...part,
          data: part.data instanceof Uint8Array ? convertDataContentToBase64String(part.data) : part.data
        } : part
      )
    }))
  );
}
function getRetryDelayInMs({
  error,
  exponentialBackoffDelay
}) {
  const headers = error.responseHeaders;
  if (!headers)
    return exponentialBackoffDelay;
  let ms;
  const retryAfterMs = headers["retry-after-ms"];
  if (retryAfterMs) {
    const timeoutMs = parseFloat(retryAfterMs);
    if (!Number.isNaN(timeoutMs)) {
      ms = timeoutMs;
    }
  }
  const retryAfter = headers["retry-after"];
  if (retryAfter && ms === void 0) {
    const timeoutSeconds = parseFloat(retryAfter);
    if (!Number.isNaN(timeoutSeconds)) {
      ms = timeoutSeconds * 1e3;
    } else {
      ms = Date.parse(retryAfter) - Date.now();
    }
  }
  if (ms != null && !Number.isNaN(ms) && 0 <= ms && (ms < 60 * 1e3 || ms < exponentialBackoffDelay)) {
    return ms;
  }
  return exponentialBackoffDelay;
}
var retryWithExponentialBackoffRespectingRetryHeaders = ({
  maxRetries = 2,
  initialDelayInMs = 2e3,
  backoffFactor = 2,
  abortSignal
} = {}) => async (f) => _retryWithExponentialBackoff(f, {
  maxRetries,
  delayInMs: initialDelayInMs,
  backoffFactor,
  abortSignal
});
async function _retryWithExponentialBackoff(f, {
  maxRetries,
  delayInMs,
  backoffFactor,
  abortSignal
}, errors = []) {
  try {
    return await f();
  } catch (error) {
    if (isAbortError(error)) {
      throw error;
    }
    if (maxRetries === 0) {
      throw error;
    }
    const errorMessage = getErrorMessage2(error);
    const newErrors = [...errors, error];
    const tryNumber = newErrors.length;
    if (tryNumber > maxRetries) {
      throw new RetryError({
        message: `Failed after ${tryNumber} attempts. Last error: ${errorMessage}`,
        reason: "maxRetriesExceeded",
        errors: newErrors
      });
    }
    if (error instanceof Error && APICallError.isInstance(error) && error.isRetryable === true && tryNumber <= maxRetries) {
      await delay(
        getRetryDelayInMs({
          error,
          exponentialBackoffDelay: delayInMs
        }),
        { abortSignal }
      );
      return _retryWithExponentialBackoff(
        f,
        {
          maxRetries,
          delayInMs: backoffFactor * delayInMs,
          backoffFactor,
          abortSignal
        },
        newErrors
      );
    }
    if (tryNumber === 1) {
      throw error;
    }
    throw new RetryError({
      message: `Failed after ${tryNumber} attempts with non-retryable error: '${errorMessage}'`,
      reason: "errorNotRetryable",
      errors: newErrors
    });
  }
}
function prepareRetries({
  maxRetries,
  abortSignal
}) {
  if (maxRetries != null) {
    if (!Number.isInteger(maxRetries)) {
      throw new InvalidArgumentError3({
        parameter: "maxRetries",
        value: maxRetries,
        message: "maxRetries must be an integer"
      });
    }
    if (maxRetries < 0) {
      throw new InvalidArgumentError3({
        parameter: "maxRetries",
        value: maxRetries,
        message: "maxRetries must be >= 0"
      });
    }
  }
  const maxRetriesResult = maxRetries != null ? maxRetries : 2;
  return {
    maxRetries: maxRetriesResult,
    retry: retryWithExponentialBackoffRespectingRetryHeaders({
      maxRetries: maxRetriesResult,
      abortSignal
    })
  };
}
function extractTextContent(content) {
  const parts = content.filter(
    (content2) => content2.type === "text"
  );
  if (parts.length === 0) {
    return void 0;
  }
  return parts.map((content2) => content2.text).join("");
}
var originalGenerateId = createIdGenerator({
  prefix: "aitxt",
  size: 24
});
function prepareHeaders(headers, defaultHeaders) {
  const responseHeaders = new Headers(headers != null ? headers : {});
  for (const [key, value2] of Object.entries(defaultHeaders)) {
    if (!responseHeaders.has(key)) {
      responseHeaders.set(key, value2);
    }
  }
  return responseHeaders;
}
var JsonToSseTransformStream = class extends TransformStream {
  constructor() {
    super({
      transform(part, controller) {
        controller.enqueue(`data: ${JSON.stringify(part)}

`);
      },
      flush(controller) {
        controller.enqueue("data: [DONE]\n\n");
      }
    });
  }
};
var uiMessageChunkSchema = lazyValidator(
  () => zodSchema(
    z73.union([
      z73.strictObject({
        type: z73.literal("text-start"),
        id: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("text-delta"),
        id: z73.string(),
        delta: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("text-end"),
        id: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("error"),
        errorText: z73.string()
      }),
      z73.strictObject({
        type: z73.literal("tool-input-start"),
        toolCallId: z73.string(),
        toolName: z73.string(),
        providerExecuted: z73.boolean().optional(),
        dynamic: z73.boolean().optional()
      }),
      z73.strictObject({
        type: z73.literal("tool-input-delta"),
        toolCallId: z73.string(),
        inputTextDelta: z73.string()
      }),
      z73.strictObject({
        type: z73.literal("tool-input-available"),
        toolCallId: z73.string(),
        toolName: z73.string(),
        input: z73.unknown(),
        providerExecuted: z73.boolean().optional(),
        providerMetadata: providerMetadataSchema.optional(),
        dynamic: z73.boolean().optional()
      }),
      z73.strictObject({
        type: z73.literal("tool-input-error"),
        toolCallId: z73.string(),
        toolName: z73.string(),
        input: z73.unknown(),
        providerExecuted: z73.boolean().optional(),
        providerMetadata: providerMetadataSchema.optional(),
        dynamic: z73.boolean().optional(),
        errorText: z73.string()
      }),
      z73.strictObject({
        type: z73.literal("tool-output-available"),
        toolCallId: z73.string(),
        output: z73.unknown(),
        providerExecuted: z73.boolean().optional(),
        dynamic: z73.boolean().optional(),
        preliminary: z73.boolean().optional()
      }),
      z73.strictObject({
        type: z73.literal("tool-output-error"),
        toolCallId: z73.string(),
        errorText: z73.string(),
        providerExecuted: z73.boolean().optional(),
        dynamic: z73.boolean().optional()
      }),
      z73.strictObject({
        type: z73.literal("reasoning-start"),
        id: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("reasoning-delta"),
        id: z73.string(),
        delta: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("reasoning-end"),
        id: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("source-url"),
        sourceId: z73.string(),
        url: z73.string(),
        title: z73.string().optional(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("source-document"),
        sourceId: z73.string(),
        mediaType: z73.string(),
        title: z73.string(),
        filename: z73.string().optional(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.literal("file"),
        url: z73.string(),
        mediaType: z73.string(),
        providerMetadata: providerMetadataSchema.optional()
      }),
      z73.strictObject({
        type: z73.custom(
          (value2) => typeof value2 === "string" && value2.startsWith("data-"),
          { message: 'Type must start with "data-"' }
        ),
        id: z73.string().optional(),
        data: z73.unknown(),
        transient: z73.boolean().optional()
      }),
      z73.strictObject({
        type: z73.literal("start-step")
      }),
      z73.strictObject({
        type: z73.literal("finish-step")
      }),
      z73.strictObject({
        type: z73.literal("start"),
        messageId: z73.string().optional(),
        messageMetadata: z73.unknown().optional()
      }),
      z73.strictObject({
        type: z73.literal("finish"),
        finishReason: z73.enum([
          "stop",
          "length",
          "content-filter",
          "tool-calls",
          "error",
          "other",
          "unknown"
        ]).optional(),
        messageMetadata: z73.unknown().optional()
      }),
      z73.strictObject({
        type: z73.literal("abort")
      }),
      z73.strictObject({
        type: z73.literal("message-metadata"),
        messageMetadata: z73.unknown()
      })
    ])
  )
);
function fixJson(input) {
  const stack = ["ROOT"];
  let lastValidIndex = -1;
  let literalStart = null;
  function processValueStart(char, i, swapState) {
    {
      switch (char) {
        case '"': {
          lastValidIndex = i;
          stack.pop();
          stack.push(swapState);
          stack.push("INSIDE_STRING");
          break;
        }
        case "f":
        case "t":
        case "n": {
          lastValidIndex = i;
          literalStart = i;
          stack.pop();
          stack.push(swapState);
          stack.push("INSIDE_LITERAL");
          break;
        }
        case "-": {
          stack.pop();
          stack.push(swapState);
          stack.push("INSIDE_NUMBER");
          break;
        }
        case "0":
        case "1":
        case "2":
        case "3":
        case "4":
        case "5":
        case "6":
        case "7":
        case "8":
        case "9": {
          lastValidIndex = i;
          stack.pop();
          stack.push(swapState);
          stack.push("INSIDE_NUMBER");
          break;
        }
        case "{": {
          lastValidIndex = i;
          stack.pop();
          stack.push(swapState);
          stack.push("INSIDE_OBJECT_START");
          break;
        }
        case "[": {
          lastValidIndex = i;
          stack.pop();
          stack.push(swapState);
          stack.push("INSIDE_ARRAY_START");
          break;
        }
      }
    }
  }
  function processAfterObjectValue(char, i) {
    switch (char) {
      case ",": {
        stack.pop();
        stack.push("INSIDE_OBJECT_AFTER_COMMA");
        break;
      }
      case "}": {
        lastValidIndex = i;
        stack.pop();
        break;
      }
    }
  }
  function processAfterArrayValue(char, i) {
    switch (char) {
      case ",": {
        stack.pop();
        stack.push("INSIDE_ARRAY_AFTER_COMMA");
        break;
      }
      case "]": {
        lastValidIndex = i;
        stack.pop();
        break;
      }
    }
  }
  for (let i = 0; i < input.length; i++) {
    const char = input[i];
    const currentState = stack[stack.length - 1];
    switch (currentState) {
      case "ROOT":
        processValueStart(char, i, "FINISH");
        break;
      case "INSIDE_OBJECT_START": {
        switch (char) {
          case '"': {
            stack.pop();
            stack.push("INSIDE_OBJECT_KEY");
            break;
          }
          case "}": {
            lastValidIndex = i;
            stack.pop();
            break;
          }
        }
        break;
      }
      case "INSIDE_OBJECT_AFTER_COMMA": {
        switch (char) {
          case '"': {
            stack.pop();
            stack.push("INSIDE_OBJECT_KEY");
            break;
          }
        }
        break;
      }
      case "INSIDE_OBJECT_KEY": {
        switch (char) {
          case '"': {
            stack.pop();
            stack.push("INSIDE_OBJECT_AFTER_KEY");
            break;
          }
        }
        break;
      }
      case "INSIDE_OBJECT_AFTER_KEY": {
        switch (char) {
          case ":": {
            stack.pop();
            stack.push("INSIDE_OBJECT_BEFORE_VALUE");
            break;
          }
        }
        break;
      }
      case "INSIDE_OBJECT_BEFORE_VALUE": {
        processValueStart(char, i, "INSIDE_OBJECT_AFTER_VALUE");
        break;
      }
      case "INSIDE_OBJECT_AFTER_VALUE": {
        processAfterObjectValue(char, i);
        break;
      }
      case "INSIDE_STRING": {
        switch (char) {
          case '"': {
            stack.pop();
            lastValidIndex = i;
            break;
          }
          case "\\": {
            stack.push("INSIDE_STRING_ESCAPE");
            break;
          }
          default: {
            lastValidIndex = i;
          }
        }
        break;
      }
      case "INSIDE_ARRAY_START": {
        switch (char) {
          case "]": {
            lastValidIndex = i;
            stack.pop();
            break;
          }
          default: {
            lastValidIndex = i;
            processValueStart(char, i, "INSIDE_ARRAY_AFTER_VALUE");
            break;
          }
        }
        break;
      }
      case "INSIDE_ARRAY_AFTER_VALUE": {
        switch (char) {
          case ",": {
            stack.pop();
            stack.push("INSIDE_ARRAY_AFTER_COMMA");
            break;
          }
          case "]": {
            lastValidIndex = i;
            stack.pop();
            break;
          }
          default: {
            lastValidIndex = i;
            break;
          }
        }
        break;
      }
      case "INSIDE_ARRAY_AFTER_COMMA": {
        processValueStart(char, i, "INSIDE_ARRAY_AFTER_VALUE");
        break;
      }
      case "INSIDE_STRING_ESCAPE": {
        stack.pop();
        lastValidIndex = i;
        break;
      }
      case "INSIDE_NUMBER": {
        switch (char) {
          case "0":
          case "1":
          case "2":
          case "3":
          case "4":
          case "5":
          case "6":
          case "7":
          case "8":
          case "9": {
            lastValidIndex = i;
            break;
          }
          case "e":
          case "E":
          case "-":
          case ".": {
            break;
          }
          case ",": {
            stack.pop();
            if (stack[stack.length - 1] === "INSIDE_ARRAY_AFTER_VALUE") {
              processAfterArrayValue(char, i);
            }
            if (stack[stack.length - 1] === "INSIDE_OBJECT_AFTER_VALUE") {
              processAfterObjectValue(char, i);
            }
            break;
          }
          case "}": {
            stack.pop();
            if (stack[stack.length - 1] === "INSIDE_OBJECT_AFTER_VALUE") {
              processAfterObjectValue(char, i);
            }
            break;
          }
          case "]": {
            stack.pop();
            if (stack[stack.length - 1] === "INSIDE_ARRAY_AFTER_VALUE") {
              processAfterArrayValue(char, i);
            }
            break;
          }
          default: {
            stack.pop();
            break;
          }
        }
        break;
      }
      case "INSIDE_LITERAL": {
        const partialLiteral = input.substring(literalStart, i + 1);
        if (!"false".startsWith(partialLiteral) && !"true".startsWith(partialLiteral) && !"null".startsWith(partialLiteral)) {
          stack.pop();
          if (stack[stack.length - 1] === "INSIDE_OBJECT_AFTER_VALUE") {
            processAfterObjectValue(char, i);
          } else if (stack[stack.length - 1] === "INSIDE_ARRAY_AFTER_VALUE") {
            processAfterArrayValue(char, i);
          }
        } else {
          lastValidIndex = i;
        }
        break;
      }
    }
  }
  let result = input.slice(0, lastValidIndex + 1);
  for (let i = stack.length - 1; i >= 0; i--) {
    const state = stack[i];
    switch (state) {
      case "INSIDE_STRING": {
        result += '"';
        break;
      }
      case "INSIDE_OBJECT_KEY":
      case "INSIDE_OBJECT_AFTER_KEY":
      case "INSIDE_OBJECT_AFTER_COMMA":
      case "INSIDE_OBJECT_START":
      case "INSIDE_OBJECT_BEFORE_VALUE":
      case "INSIDE_OBJECT_AFTER_VALUE": {
        result += "}";
        break;
      }
      case "INSIDE_ARRAY_START":
      case "INSIDE_ARRAY_AFTER_COMMA":
      case "INSIDE_ARRAY_AFTER_VALUE": {
        result += "]";
        break;
      }
      case "INSIDE_LITERAL": {
        const partialLiteral = input.substring(literalStart, input.length);
        if ("true".startsWith(partialLiteral)) {
          result += "true".slice(partialLiteral.length);
        } else if ("false".startsWith(partialLiteral)) {
          result += "false".slice(partialLiteral.length);
        } else if ("null".startsWith(partialLiteral)) {
          result += "null".slice(partialLiteral.length);
        }
      }
    }
  }
  return result;
}
async function parsePartialJson(jsonText) {
  if (jsonText === void 0) {
    return { value: void 0, state: "undefined-input" };
  }
  let result = await safeParseJSON({ text: jsonText });
  if (result.success) {
    return { value: result.value, state: "successful-parse" };
  }
  result = await safeParseJSON({ text: fixJson(jsonText) });
  if (result.success) {
    return { value: result.value, state: "repaired-parse" };
  }
  return { value: void 0, state: "failed-parse" };
}
function createAsyncIterableStream(source) {
  const stream = source.pipeThrough(new TransformStream());
  stream[Symbol.asyncIterator] = function() {
    const reader = this.getReader();
    let finished = false;
    async function cleanup(cancelStream) {
      var _a162;
      finished = true;
      try {
        if (cancelStream) {
          await ((_a162 = reader.cancel) == null ? void 0 : _a162.call(reader));
        }
      } finally {
        try {
          reader.releaseLock();
        } catch (e) {
        }
      }
    }
    return {
      /**
       * Reads the next chunk from the stream.
       * @returns A promise resolving to the next IteratorResult.
       */
      async next() {
        if (finished) {
          return { done: true, value: void 0 };
        }
        const { done, value: value2 } = await reader.read();
        if (done) {
          await cleanup(true);
          return { done: true, value: void 0 };
        }
        return { done: false, value: value2 };
      },
      /**
       * Called on early exit (e.g., break from for-await).
       * Ensures the stream is cancelled and resources are released.
       * @returns A promise resolving to a completed IteratorResult.
       */
      async return() {
        await cleanup(true);
        return { done: true, value: void 0 };
      },
      /**
       * Called on early exit with error.
       * Ensures the stream is cancelled and resources are released, then rethrows the error.
       * @param err The error to throw.
       * @returns A promise that rejects with the provided error.
       */
      async throw(err) {
        await cleanup(true);
        throw err;
      }
    };
  };
  return stream;
}
var originalGenerateId2 = createIdGenerator({
  prefix: "aitxt",
  size: 24
});
function extractReasoningContent(content) {
  const parts = content.filter(
    (content2) => content2.type === "reasoning"
  );
  return parts.length === 0 ? void 0 : parts.map((content2) => content2.text).join("\n");
}
var noSchemaOutputStrategy = {
  type: "no-schema",
  jsonSchema: void 0,
  async validatePartialResult({ value: value2, textDelta }) {
    return { success: true, value: { partial: value2, textDelta } };
  },
  async validateFinalResult(value2, context) {
    return value2 === void 0 ? {
      success: false,
      error: new NoObjectGeneratedError({
        message: "No object generated: response did not match schema.",
        text: context.text,
        response: context.response,
        usage: context.usage,
        finishReason: context.finishReason
      })
    } : { success: true, value: value2 };
  },
  createElementStream() {
    throw new UnsupportedFunctionalityError({
      functionality: "element streams in no-schema mode"
    });
  }
};
var objectOutputStrategy = (schema) => ({
  type: "object",
  jsonSchema: schema.jsonSchema,
  async validatePartialResult({ value: value2, textDelta }) {
    return {
      success: true,
      value: {
        // Note: currently no validation of partial results:
        partial: value2,
        textDelta
      }
    };
  },
  async validateFinalResult(value2) {
    return safeValidateTypes({ value: value2, schema });
  },
  createElementStream() {
    throw new UnsupportedFunctionalityError({
      functionality: "element streams in object mode"
    });
  }
});
var arrayOutputStrategy = (schema) => {
  const { $schema, ...itemSchema } = schema.jsonSchema;
  return {
    type: "array",
    // wrap in object that contains array of elements, since most LLMs will not
    // be able to generate an array directly:
    // possible future optimization: use arrays directly when model supports grammar-guided generation
    jsonSchema: {
      $schema: "http://json-schema.org/draft-07/schema#",
      type: "object",
      properties: {
        elements: { type: "array", items: itemSchema }
      },
      required: ["elements"],
      additionalProperties: false
    },
    async validatePartialResult({
      value: value2,
      latestObject,
      isFirstDelta,
      isFinalDelta
    }) {
      var _a162;
      if (!isJSONObject(value2) || !isJSONArray(value2.elements)) {
        return {
          success: false,
          error: new TypeValidationError({
            value: value2,
            cause: "value must be an object that contains an array of elements"
          })
        };
      }
      const inputArray = value2.elements;
      const resultArray = [];
      for (let i = 0; i < inputArray.length; i++) {
        const element = inputArray[i];
        const result = await safeValidateTypes({ value: element, schema });
        if (i === inputArray.length - 1 && !isFinalDelta) {
          continue;
        }
        if (!result.success) {
          return result;
        }
        resultArray.push(result.value);
      }
      const publishedElementCount = (_a162 = latestObject == null ? void 0 : latestObject.length) != null ? _a162 : 0;
      let textDelta = "";
      if (isFirstDelta) {
        textDelta += "[";
      }
      if (publishedElementCount > 0) {
        textDelta += ",";
      }
      textDelta += resultArray.slice(publishedElementCount).map((element) => JSON.stringify(element)).join(",");
      if (isFinalDelta) {
        textDelta += "]";
      }
      return {
        success: true,
        value: {
          partial: resultArray,
          textDelta
        }
      };
    },
    async validateFinalResult(value2) {
      if (!isJSONObject(value2) || !isJSONArray(value2.elements)) {
        return {
          success: false,
          error: new TypeValidationError({
            value: value2,
            cause: "value must be an object that contains an array of elements"
          })
        };
      }
      const inputArray = value2.elements;
      for (const element of inputArray) {
        const result = await safeValidateTypes({ value: element, schema });
        if (!result.success) {
          return result;
        }
      }
      return { success: true, value: inputArray };
    },
    createElementStream(originalStream) {
      let publishedElements = 0;
      return createAsyncIterableStream(
        originalStream.pipeThrough(
          new TransformStream({
            transform(chunk, controller) {
              switch (chunk.type) {
                case "object": {
                  const array = chunk.object;
                  for (; publishedElements < array.length; publishedElements++) {
                    controller.enqueue(array[publishedElements]);
                  }
                  break;
                }
                case "text-delta":
                case "finish":
                case "error":
                  break;
                default: {
                  const _exhaustiveCheck = chunk;
                  throw new Error(
                    `Unsupported chunk type: ${_exhaustiveCheck}`
                  );
                }
              }
            }
          })
        )
      );
    }
  };
};
var enumOutputStrategy = (enumValues) => {
  return {
    type: "enum",
    // wrap in object that contains result, since most LLMs will not
    // be able to generate an enum value directly:
    // possible future optimization: use enums directly when model supports top-level enums
    jsonSchema: {
      $schema: "http://json-schema.org/draft-07/schema#",
      type: "object",
      properties: {
        result: { type: "string", enum: enumValues }
      },
      required: ["result"],
      additionalProperties: false
    },
    async validateFinalResult(value2) {
      if (!isJSONObject(value2) || typeof value2.result !== "string") {
        return {
          success: false,
          error: new TypeValidationError({
            value: value2,
            cause: 'value must be an object that contains a string in the "result" property.'
          })
        };
      }
      const result = value2.result;
      return enumValues.includes(result) ? { success: true, value: result } : {
        success: false,
        error: new TypeValidationError({
          value: value2,
          cause: "value must be a string in the enum"
        })
      };
    },
    async validatePartialResult({ value: value2, textDelta }) {
      if (!isJSONObject(value2) || typeof value2.result !== "string") {
        return {
          success: false,
          error: new TypeValidationError({
            value: value2,
            cause: 'value must be an object that contains a string in the "result" property.'
          })
        };
      }
      const result = value2.result;
      const possibleEnumValues = enumValues.filter(
        (enumValue) => enumValue.startsWith(result)
      );
      if (value2.result.length === 0 || possibleEnumValues.length === 0) {
        return {
          success: false,
          error: new TypeValidationError({
            value: value2,
            cause: "value must be a string in the enum"
          })
        };
      }
      return {
        success: true,
        value: {
          partial: possibleEnumValues.length > 1 ? result : possibleEnumValues[0],
          textDelta
        }
      };
    },
    createElementStream() {
      throw new UnsupportedFunctionalityError({
        functionality: "element streams in enum mode"
      });
    }
  };
};
function getOutputStrategy({
  output,
  schema,
  enumValues
}) {
  switch (output) {
    case "object":
      return objectOutputStrategy(asSchema(schema));
    case "array":
      return arrayOutputStrategy(asSchema(schema));
    case "enum":
      return enumOutputStrategy(enumValues);
    case "no-schema":
      return noSchemaOutputStrategy;
    default: {
      const _exhaustiveCheck = output;
      throw new Error(`Unsupported output: ${_exhaustiveCheck}`);
    }
  }
}
async function parseAndValidateObjectResult(result, outputStrategy, context) {
  const parseResult = await safeParseJSON({ text: result });
  if (!parseResult.success) {
    throw new NoObjectGeneratedError({
      message: "No object generated: could not parse the response.",
      cause: parseResult.error,
      text: result,
      response: context.response,
      usage: context.usage,
      finishReason: context.finishReason
    });
  }
  const validationResult = await outputStrategy.validateFinalResult(
    parseResult.value,
    {
      text: result,
      response: context.response,
      usage: context.usage
    }
  );
  if (!validationResult.success) {
    throw new NoObjectGeneratedError({
      message: "No object generated: response did not match schema.",
      cause: validationResult.error,
      text: result,
      response: context.response,
      usage: context.usage,
      finishReason: context.finishReason
    });
  }
  return validationResult.value;
}
async function parseAndValidateObjectResultWithRepair(result, outputStrategy, repairText, context) {
  try {
    return await parseAndValidateObjectResult(result, outputStrategy, context);
  } catch (error) {
    if (repairText != null && NoObjectGeneratedError.isInstance(error) && (JSONParseError.isInstance(error.cause) || TypeValidationError.isInstance(error.cause))) {
      const repairedText = await repairText({
        text: result,
        error: error.cause
      });
      if (repairedText === null) {
        throw error;
      }
      return await parseAndValidateObjectResult(
        repairedText,
        outputStrategy,
        context
      );
    }
    throw error;
  }
}
function validateObjectGenerationInput({
  output,
  schema,
  schemaName,
  schemaDescription,
  enumValues
}) {
  if (output != null && output !== "object" && output !== "array" && output !== "enum" && output !== "no-schema") {
    throw new InvalidArgumentError3({
      parameter: "output",
      value: output,
      message: "Invalid output type."
    });
  }
  if (output === "no-schema") {
    if (schema != null) {
      throw new InvalidArgumentError3({
        parameter: "schema",
        value: schema,
        message: "Schema is not supported for no-schema output."
      });
    }
    if (schemaDescription != null) {
      throw new InvalidArgumentError3({
        parameter: "schemaDescription",
        value: schemaDescription,
        message: "Schema description is not supported for no-schema output."
      });
    }
    if (schemaName != null) {
      throw new InvalidArgumentError3({
        parameter: "schemaName",
        value: schemaName,
        message: "Schema name is not supported for no-schema output."
      });
    }
    if (enumValues != null) {
      throw new InvalidArgumentError3({
        parameter: "enumValues",
        value: enumValues,
        message: "Enum values are not supported for no-schema output."
      });
    }
  }
  if (output === "object") {
    if (schema == null) {
      throw new InvalidArgumentError3({
        parameter: "schema",
        value: schema,
        message: "Schema is required for object output."
      });
    }
    if (enumValues != null) {
      throw new InvalidArgumentError3({
        parameter: "enumValues",
        value: enumValues,
        message: "Enum values are not supported for object output."
      });
    }
  }
  if (output === "array") {
    if (schema == null) {
      throw new InvalidArgumentError3({
        parameter: "schema",
        value: schema,
        message: "Element schema is required for array output."
      });
    }
    if (enumValues != null) {
      throw new InvalidArgumentError3({
        parameter: "enumValues",
        value: enumValues,
        message: "Enum values are not supported for array output."
      });
    }
  }
  if (output === "enum") {
    if (schema != null) {
      throw new InvalidArgumentError3({
        parameter: "schema",
        value: schema,
        message: "Schema is not supported for enum output."
      });
    }
    if (schemaDescription != null) {
      throw new InvalidArgumentError3({
        parameter: "schemaDescription",
        value: schemaDescription,
        message: "Schema description is not supported for enum output."
      });
    }
    if (schemaName != null) {
      throw new InvalidArgumentError3({
        parameter: "schemaName",
        value: schemaName,
        message: "Schema name is not supported for enum output."
      });
    }
    if (enumValues == null) {
      throw new InvalidArgumentError3({
        parameter: "enumValues",
        value: enumValues,
        message: "Enum values are required for enum output."
      });
    }
    for (const value2 of enumValues) {
      if (typeof value2 !== "string") {
        throw new InvalidArgumentError3({
          parameter: "enumValues",
          value: value2,
          message: "Enum values must be strings."
        });
      }
    }
  }
}
var originalGenerateId3 = createIdGenerator({ prefix: "aiobj", size: 24 });
async function generateObject(options) {
  const {
    model: modelArg,
    output = "object",
    system,
    prompt,
    messages,
    maxRetries: maxRetriesArg,
    abortSignal,
    headers,
    experimental_repairText: repairText,
    experimental_telemetry: telemetry2,
    experimental_download: download2,
    providerOptions,
    _internal: {
      generateId: generateId3 = originalGenerateId3,
      currentDate = () => /* @__PURE__ */ new Date()
    } = {},
    ...settings
  } = options;
  const model = resolveLanguageModel(modelArg);
  const enumValues = "enum" in options ? options.enum : void 0;
  const {
    schema: inputSchema,
    schemaDescription,
    schemaName
  } = "schema" in options ? options : {};
  validateObjectGenerationInput({
    output,
    schema: inputSchema,
    schemaName,
    schemaDescription,
    enumValues
  });
  const { maxRetries, retry } = prepareRetries({
    maxRetries: maxRetriesArg,
    abortSignal
  });
  const outputStrategy = getOutputStrategy({
    output,
    schema: inputSchema,
    enumValues
  });
  const callSettings = prepareCallSettings(settings);
  const headersWithUserAgent = withUserAgentSuffix(
    headers != null ? headers : {},
    `ai/${VERSION4}`
  );
  const baseTelemetryAttributes = getBaseTelemetryAttributes({
    model,
    telemetry: telemetry2,
    headers: headersWithUserAgent,
    settings: { ...callSettings, maxRetries }
  });
  const tracer = getTracer(telemetry2);
  try {
    return await recordSpan({
      name: "ai.generateObject",
      attributes: selectTelemetryAttributes({
        telemetry: telemetry2,
        attributes: {
          ...assembleOperationName({
            operationId: "ai.generateObject",
            telemetry: telemetry2
          }),
          ...baseTelemetryAttributes,
          // specific settings that only make sense on the outer level:
          "ai.prompt": {
            input: () => JSON.stringify({ system, prompt, messages })
          },
          "ai.schema": outputStrategy.jsonSchema != null ? { input: () => JSON.stringify(outputStrategy.jsonSchema) } : void 0,
          "ai.schema.name": schemaName,
          "ai.schema.description": schemaDescription,
          "ai.settings.output": outputStrategy.type
        }
      }),
      tracer,
      fn: async (span) => {
        var _a162;
        let result;
        let finishReason;
        let usage;
        let warnings;
        let response;
        let request;
        let resultProviderMetadata;
        let reasoning;
        const standardizedPrompt = await standardizePrompt({
          system,
          prompt,
          messages
        });
        const promptMessages = await convertToLanguageModelPrompt({
          prompt: standardizedPrompt,
          supportedUrls: await model.supportedUrls,
          download: download2
        });
        const generateResult = await retry(
          () => recordSpan({
            name: "ai.generateObject.doGenerate",
            attributes: selectTelemetryAttributes({
              telemetry: telemetry2,
              attributes: {
                ...assembleOperationName({
                  operationId: "ai.generateObject.doGenerate",
                  telemetry: telemetry2
                }),
                ...baseTelemetryAttributes,
                "ai.prompt.messages": {
                  input: () => stringifyForTelemetry(promptMessages)
                },
                // standardized gen-ai llm span attributes:
                "gen_ai.system": model.provider,
                "gen_ai.request.model": model.modelId,
                "gen_ai.request.frequency_penalty": callSettings.frequencyPenalty,
                "gen_ai.request.max_tokens": callSettings.maxOutputTokens,
                "gen_ai.request.presence_penalty": callSettings.presencePenalty,
                "gen_ai.request.temperature": callSettings.temperature,
                "gen_ai.request.top_k": callSettings.topK,
                "gen_ai.request.top_p": callSettings.topP
              }
            }),
            tracer,
            fn: async (span2) => {
              var _a17, _b8, _c, _d, _e, _f, _g, _h;
              const result2 = await model.doGenerate({
                responseFormat: {
                  type: "json",
                  schema: outputStrategy.jsonSchema,
                  name: schemaName,
                  description: schemaDescription
                },
                ...prepareCallSettings(settings),
                prompt: promptMessages,
                providerOptions,
                abortSignal,
                headers: headersWithUserAgent
              });
              const responseData = {
                id: (_b8 = (_a17 = result2.response) == null ? void 0 : _a17.id) != null ? _b8 : generateId3(),
                timestamp: (_d = (_c = result2.response) == null ? void 0 : _c.timestamp) != null ? _d : currentDate(),
                modelId: (_f = (_e = result2.response) == null ? void 0 : _e.modelId) != null ? _f : model.modelId,
                headers: (_g = result2.response) == null ? void 0 : _g.headers,
                body: (_h = result2.response) == null ? void 0 : _h.body
              };
              const text2 = extractTextContent(result2.content);
              const reasoning2 = extractReasoningContent(result2.content);
              if (text2 === void 0) {
                throw new NoObjectGeneratedError({
                  message: "No object generated: the model did not return a response.",
                  response: responseData,
                  usage: result2.usage,
                  finishReason: result2.finishReason
                });
              }
              span2.setAttributes(
                selectTelemetryAttributes({
                  telemetry: telemetry2,
                  attributes: {
                    "ai.response.finishReason": result2.finishReason,
                    "ai.response.object": { output: () => text2 },
                    "ai.response.id": responseData.id,
                    "ai.response.model": responseData.modelId,
                    "ai.response.timestamp": responseData.timestamp.toISOString(),
                    "ai.response.providerMetadata": JSON.stringify(
                      result2.providerMetadata
                    ),
                    // TODO rename telemetry attributes to inputTokens and outputTokens
                    "ai.usage.promptTokens": result2.usage.inputTokens,
                    "ai.usage.completionTokens": result2.usage.outputTokens,
                    // standardized gen-ai llm span attributes:
                    "gen_ai.response.finish_reasons": [result2.finishReason],
                    "gen_ai.response.id": responseData.id,
                    "gen_ai.response.model": responseData.modelId,
                    "gen_ai.usage.input_tokens": result2.usage.inputTokens,
                    "gen_ai.usage.output_tokens": result2.usage.outputTokens
                  }
                })
              );
              return {
                ...result2,
                objectText: text2,
                reasoning: reasoning2,
                responseData
              };
            }
          })
        );
        result = generateResult.objectText;
        finishReason = generateResult.finishReason;
        usage = generateResult.usage;
        warnings = generateResult.warnings;
        resultProviderMetadata = generateResult.providerMetadata;
        request = (_a162 = generateResult.request) != null ? _a162 : {};
        response = generateResult.responseData;
        reasoning = generateResult.reasoning;
        logWarnings(warnings);
        const object2 = await parseAndValidateObjectResultWithRepair(
          result,
          outputStrategy,
          repairText,
          {
            response,
            usage,
            finishReason
          }
        );
        span.setAttributes(
          selectTelemetryAttributes({
            telemetry: telemetry2,
            attributes: {
              "ai.response.finishReason": finishReason,
              "ai.response.object": {
                output: () => JSON.stringify(object2)
              },
              "ai.response.providerMetadata": JSON.stringify(
                resultProviderMetadata
              ),
              // TODO rename telemetry attributes to inputTokens and outputTokens
              "ai.usage.promptTokens": usage.inputTokens,
              "ai.usage.completionTokens": usage.outputTokens
            }
          })
        );
        return new DefaultGenerateObjectResult({
          object: object2,
          reasoning,
          finishReason,
          usage,
          warnings,
          request,
          response,
          providerMetadata: resultProviderMetadata
        });
      }
    });
  } catch (error) {
    throw wrapGatewayError(error);
  }
}
var DefaultGenerateObjectResult = class {
  constructor(options) {
    this.object = options.object;
    this.finishReason = options.finishReason;
    this.usage = options.usage;
    this.warnings = options.warnings;
    this.providerMetadata = options.providerMetadata;
    this.response = options.response;
    this.request = options.request;
    this.reasoning = options.reasoning;
  }
  toJsonResponse(init) {
    var _a162;
    return new Response(JSON.stringify(this.object), {
      status: (_a162 = init == null ? void 0 : init.status) != null ? _a162 : 200,
      headers: prepareHeaders(init == null ? void 0 : init.headers, {
        "content-type": "application/json; charset=utf-8"
      })
    });
  }
};
var originalGenerateId4 = createIdGenerator({ prefix: "aiobj", size: 24 });
var output_exports = {};
__export2(output_exports, {
  object: () => object,
  text: () => text
});
var text = () => ({
  type: "text",
  responseFormat: { type: "text" },
  async parsePartial({ text: text2 }) {
    return { partial: text2 };
  },
  async parseOutput({ text: text2 }) {
    return text2;
  }
});
var object = ({
  schema: inputSchema
}) => {
  const schema = asSchema(inputSchema);
  return {
    type: "object",
    responseFormat: {
      type: "json",
      schema: schema.jsonSchema
    },
    async parsePartial({ text: text2 }) {
      const result = await parsePartialJson(text2);
      switch (result.state) {
        case "failed-parse":
        case "undefined-input":
          return void 0;
        case "repaired-parse":
        case "successful-parse":
          return {
            // Note: currently no validation of partial results:
            partial: result.value
          };
        default: {
          const _exhaustiveCheck = result.state;
          throw new Error(`Unsupported parse state: ${_exhaustiveCheck}`);
        }
      }
    },
    async parseOutput({ text: text2 }, context) {
      const parseResult = await safeParseJSON({ text: text2 });
      if (!parseResult.success) {
        throw new NoObjectGeneratedError({
          message: "No object generated: could not parse the response.",
          cause: parseResult.error,
          text: text2,
          response: context.response,
          usage: context.usage,
          finishReason: context.finishReason
        });
      }
      const validationResult = await safeValidateTypes({
        value: parseResult.value,
        schema
      });
      if (!validationResult.success) {
        throw new NoObjectGeneratedError({
          message: "No object generated: response did not match schema.",
          cause: validationResult.error,
          text: text2,
          response: context.response,
          usage: context.usage,
          finishReason: context.finishReason
        });
      }
      return validationResult.value;
    }
  };
};
var name152 = "AI_NoSuchProviderError";
var marker152 = `vercel.ai.error.${name152}`;
var symbol152 = Symbol.for(marker152);
var _a152;
_a152 = symbol152;
var uiMessagesSchema = lazyValidator(
  () => zodSchema(
    z82.array(
      z82.object({
        id: z82.string(),
        role: z82.enum(["system", "user", "assistant"]),
        metadata: z82.unknown().optional(),
        parts: z82.array(
          z82.union([
            z82.object({
              type: z82.literal("text"),
              text: z82.string(),
              state: z82.enum(["streaming", "done"]).optional(),
              providerMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.literal("reasoning"),
              text: z82.string(),
              state: z82.enum(["streaming", "done"]).optional(),
              providerMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.literal("source-url"),
              sourceId: z82.string(),
              url: z82.string(),
              title: z82.string().optional(),
              providerMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.literal("source-document"),
              sourceId: z82.string(),
              mediaType: z82.string(),
              title: z82.string(),
              filename: z82.string().optional(),
              providerMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.literal("file"),
              mediaType: z82.string(),
              filename: z82.string().optional(),
              url: z82.string(),
              providerMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.literal("step-start")
            }),
            z82.object({
              type: z82.string().startsWith("data-"),
              id: z82.string().optional(),
              data: z82.unknown()
            }),
            z82.object({
              type: z82.literal("dynamic-tool"),
              toolName: z82.string(),
              toolCallId: z82.string(),
              state: z82.literal("input-streaming"),
              input: z82.unknown().optional(),
              providerExecuted: z82.boolean().optional(),
              output: z82.never().optional(),
              errorText: z82.never().optional()
            }),
            z82.object({
              type: z82.literal("dynamic-tool"),
              toolName: z82.string(),
              toolCallId: z82.string(),
              state: z82.literal("input-available"),
              input: z82.unknown(),
              providerExecuted: z82.boolean().optional(),
              output: z82.never().optional(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.literal("dynamic-tool"),
              toolName: z82.string(),
              toolCallId: z82.string(),
              state: z82.literal("output-available"),
              input: z82.unknown(),
              providerExecuted: z82.boolean().optional(),
              output: z82.unknown(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional(),
              preliminary: z82.boolean().optional()
            }),
            z82.object({
              type: z82.literal("dynamic-tool"),
              toolName: z82.string(),
              toolCallId: z82.string(),
              state: z82.literal("output-error"),
              input: z82.unknown(),
              providerExecuted: z82.boolean().optional(),
              output: z82.never().optional(),
              errorText: z82.string(),
              callProviderMetadata: providerMetadataSchema.optional()
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("input-streaming"),
              providerExecuted: z82.boolean().optional(),
              input: z82.unknown().optional(),
              output: z82.never().optional(),
              errorText: z82.never().optional(),
              approval: z82.never().optional()
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("input-available"),
              providerExecuted: z82.boolean().optional(),
              input: z82.unknown(),
              output: z82.never().optional(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional(),
              approval: z82.never().optional()
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("approval-requested"),
              input: z82.unknown(),
              providerExecuted: z82.boolean().optional(),
              output: z82.never().optional(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional(),
              approval: z82.object({
                id: z82.string(),
                approved: z82.never().optional(),
                reason: z82.never().optional()
              })
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("approval-responded"),
              input: z82.unknown(),
              providerExecuted: z82.boolean().optional(),
              output: z82.never().optional(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional(),
              approval: z82.object({
                id: z82.string(),
                approved: z82.boolean(),
                reason: z82.string().optional()
              })
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("output-available"),
              providerExecuted: z82.boolean().optional(),
              input: z82.unknown(),
              output: z82.unknown(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional(),
              preliminary: z82.boolean().optional(),
              approval: z82.object({
                id: z82.string(),
                approved: z82.literal(true),
                reason: z82.string().optional()
              }).optional()
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("output-error"),
              providerExecuted: z82.boolean().optional(),
              input: z82.unknown(),
              output: z82.never().optional(),
              errorText: z82.string(),
              callProviderMetadata: providerMetadataSchema.optional(),
              approval: z82.object({
                id: z82.string(),
                approved: z82.literal(true),
                reason: z82.string().optional()
              }).optional()
            }),
            z82.object({
              type: z82.string().startsWith("tool-"),
              toolCallId: z82.string(),
              state: z82.literal("output-denied"),
              providerExecuted: z82.boolean().optional(),
              input: z82.unknown(),
              output: z82.never().optional(),
              errorText: z82.never().optional(),
              callProviderMetadata: providerMetadataSchema.optional(),
              approval: z82.object({
                id: z82.string(),
                approved: z82.literal(false),
                reason: z82.string().optional()
              })
            })
          ])
        ).nonempty("Message must contain at least one part")
      })
    ).nonempty("Messages array must not be empty")
  )
);

// src/node/services/workspaceTitleGenerator.ts
import { z as z28 } from "zod";

// src/node/services/log.ts
import * as fs from "fs";
import * as path from "path";

// node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/vendor/ansi-styles/index.js
var ANSI_BACKGROUND_OFFSET = 10;
var wrapAnsi16 = (offset = 0) => (code) => `\x1B[${code + offset}m`;
var wrapAnsi256 = (offset = 0) => (code) => `\x1B[${38 + offset};5;${code}m`;
var wrapAnsi16m = (offset = 0) => (red, green, blue) => `\x1B[${38 + offset};2;${red};${green};${blue}m`;
var styles = {
  modifier: {
    reset: [0, 0],
    // 21 isn't widely supported and 22 does the same thing
    bold: [1, 22],
    dim: [2, 22],
    italic: [3, 23],
    underline: [4, 24],
    overline: [53, 55],
    inverse: [7, 27],
    hidden: [8, 28],
    strikethrough: [9, 29]
  },
  color: {
    black: [30, 39],
    red: [31, 39],
    green: [32, 39],
    yellow: [33, 39],
    blue: [34, 39],
    magenta: [35, 39],
    cyan: [36, 39],
    white: [37, 39],
    // Bright color
    blackBright: [90, 39],
    gray: [90, 39],
    // Alias of `blackBright`
    grey: [90, 39],
    // Alias of `blackBright`
    redBright: [91, 39],
    greenBright: [92, 39],
    yellowBright: [93, 39],
    blueBright: [94, 39],
    magentaBright: [95, 39],
    cyanBright: [96, 39],
    whiteBright: [97, 39]
  },
  bgColor: {
    bgBlack: [40, 49],
    bgRed: [41, 49],
    bgGreen: [42, 49],
    bgYellow: [43, 49],
    bgBlue: [44, 49],
    bgMagenta: [45, 49],
    bgCyan: [46, 49],
    bgWhite: [47, 49],
    // Bright color
    bgBlackBright: [100, 49],
    bgGray: [100, 49],
    // Alias of `bgBlackBright`
    bgGrey: [100, 49],
    // Alias of `bgBlackBright`
    bgRedBright: [101, 49],
    bgGreenBright: [102, 49],
    bgYellowBright: [103, 49],
    bgBlueBright: [104, 49],
    bgMagentaBright: [105, 49],
    bgCyanBright: [106, 49],
    bgWhiteBright: [107, 49]
  }
};
var modifierNames = Object.keys(styles.modifier);
var foregroundColorNames = Object.keys(styles.color);
var backgroundColorNames = Object.keys(styles.bgColor);
var colorNames = [...foregroundColorNames, ...backgroundColorNames];
function assembleStyles() {
  const codes = /* @__PURE__ */ new Map();
  for (const [groupName, group] of Object.entries(styles)) {
    for (const [styleName, style] of Object.entries(group)) {
      styles[styleName] = {
        open: `\x1B[${style[0]}m`,
        close: `\x1B[${style[1]}m`
      };
      group[styleName] = styles[styleName];
      codes.set(style[0], style[1]);
    }
    Object.defineProperty(styles, groupName, {
      value: group,
      enumerable: false
    });
  }
  Object.defineProperty(styles, "codes", {
    value: codes,
    enumerable: false
  });
  styles.color.close = "\x1B[39m";
  styles.bgColor.close = "\x1B[49m";
  styles.color.ansi = wrapAnsi16();
  styles.color.ansi256 = wrapAnsi256();
  styles.color.ansi16m = wrapAnsi16m();
  styles.bgColor.ansi = wrapAnsi16(ANSI_BACKGROUND_OFFSET);
  styles.bgColor.ansi256 = wrapAnsi256(ANSI_BACKGROUND_OFFSET);
  styles.bgColor.ansi16m = wrapAnsi16m(ANSI_BACKGROUND_OFFSET);
  Object.defineProperties(styles, {
    rgbToAnsi256: {
      value(red, green, blue) {
        if (red === green && green === blue) {
          if (red < 8) {
            return 16;
          }
          if (red > 248) {
            return 231;
          }
          return Math.round((red - 8) / 247 * 24) + 232;
        }
        return 16 + 36 * Math.round(red / 255 * 5) + 6 * Math.round(green / 255 * 5) + Math.round(blue / 255 * 5);
      },
      enumerable: false
    },
    hexToRgb: {
      value(hex) {
        const matches = /[a-f\d]{6}|[a-f\d]{3}/i.exec(hex.toString(16));
        if (!matches) {
          return [0, 0, 0];
        }
        let [colorString] = matches;
        if (colorString.length === 3) {
          colorString = [...colorString].map((character) => character + character).join("");
        }
        const integer = Number.parseInt(colorString, 16);
        return [
          /* eslint-disable no-bitwise */
          integer >> 16 & 255,
          integer >> 8 & 255,
          integer & 255
          /* eslint-enable no-bitwise */
        ];
      },
      enumerable: false
    },
    hexToAnsi256: {
      value: (hex) => styles.rgbToAnsi256(...styles.hexToRgb(hex)),
      enumerable: false
    },
    ansi256ToAnsi: {
      value(code) {
        if (code < 8) {
          return 30 + code;
        }
        if (code < 16) {
          return 90 + (code - 8);
        }
        let red;
        let green;
        let blue;
        if (code >= 232) {
          red = ((code - 232) * 10 + 8) / 255;
          green = red;
          blue = red;
        } else {
          code -= 16;
          const remainder = code % 36;
          red = Math.floor(code / 36) / 5;
          green = Math.floor(remainder / 6) / 5;
          blue = remainder % 6 / 5;
        }
        const value2 = Math.max(red, green, blue) * 2;
        if (value2 === 0) {
          return 30;
        }
        let result = 30 + (Math.round(blue) << 2 | Math.round(green) << 1 | Math.round(red));
        if (value2 === 2) {
          result += 60;
        }
        return result;
      },
      enumerable: false
    },
    rgbToAnsi: {
      value: (red, green, blue) => styles.ansi256ToAnsi(styles.rgbToAnsi256(red, green, blue)),
      enumerable: false
    },
    hexToAnsi: {
      value: (hex) => styles.ansi256ToAnsi(styles.hexToAnsi256(hex)),
      enumerable: false
    }
  });
  return styles;
}
var ansiStyles = assembleStyles();
var ansi_styles_default = ansiStyles;

// node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/vendor/supports-color/index.js
import process2 from "node:process";
import os2 from "node:os";
import tty from "node:tty";
function hasFlag(flag, argv = globalThis.Deno ? globalThis.Deno.args : process2.argv) {
  const prefix = flag.startsWith("-") ? "" : flag.length === 1 ? "-" : "--";
  const position = argv.indexOf(prefix + flag);
  const terminatorPosition = argv.indexOf("--");
  return position !== -1 && (terminatorPosition === -1 || position < terminatorPosition);
}
var { env } = process2;
var flagForceColor;
if (hasFlag("no-color") || hasFlag("no-colors") || hasFlag("color=false") || hasFlag("color=never")) {
  flagForceColor = 0;
} else if (hasFlag("color") || hasFlag("colors") || hasFlag("color=true") || hasFlag("color=always")) {
  flagForceColor = 1;
}
function envForceColor() {
  if ("FORCE_COLOR" in env) {
    if (env.FORCE_COLOR === "true") {
      return 1;
    }
    if (env.FORCE_COLOR === "false") {
      return 0;
    }
    return env.FORCE_COLOR.length === 0 ? 1 : Math.min(Number.parseInt(env.FORCE_COLOR, 10), 3);
  }
}
function translateLevel(level) {
  if (level === 0) {
    return false;
  }
  return {
    level,
    hasBasic: true,
    has256: level >= 2,
    has16m: level >= 3
  };
}
function _supportsColor(haveStream, { streamIsTTY, sniffFlags = true } = {}) {
  const noFlagForceColor = envForceColor();
  if (noFlagForceColor !== void 0) {
    flagForceColor = noFlagForceColor;
  }
  const forceColor = sniffFlags ? flagForceColor : noFlagForceColor;
  if (forceColor === 0) {
    return 0;
  }
  if (sniffFlags) {
    if (hasFlag("color=16m") || hasFlag("color=full") || hasFlag("color=truecolor")) {
      return 3;
    }
    if (hasFlag("color=256")) {
      return 2;
    }
  }
  if ("TF_BUILD" in env && "AGENT_NAME" in env) {
    return 1;
  }
  if (haveStream && !streamIsTTY && forceColor === void 0) {
    return 0;
  }
  const min = forceColor || 0;
  if (env.TERM === "dumb") {
    return min;
  }
  if (process2.platform === "win32") {
    const osRelease = os2.release().split(".");
    if (Number(osRelease[0]) >= 10 && Number(osRelease[2]) >= 10586) {
      return Number(osRelease[2]) >= 14931 ? 3 : 2;
    }
    return 1;
  }
  if ("CI" in env) {
    if (["GITHUB_ACTIONS", "GITEA_ACTIONS", "CIRCLECI"].some((key) => key in env)) {
      return 3;
    }
    if (["TRAVIS", "APPVEYOR", "GITLAB_CI", "BUILDKITE", "DRONE"].some((sign) => sign in env) || env.CI_NAME === "codeship") {
      return 1;
    }
    return min;
  }
  if ("TEAMCITY_VERSION" in env) {
    return /^(9\.(0*[1-9]\d*)\.|\d{2,}\.)/.test(env.TEAMCITY_VERSION) ? 1 : 0;
  }
  if (env.COLORTERM === "truecolor") {
    return 3;
  }
  if (env.TERM === "xterm-kitty") {
    return 3;
  }
  if (env.TERM === "xterm-ghostty") {
    return 3;
  }
  if (env.TERM === "wezterm") {
    return 3;
  }
  if ("TERM_PROGRAM" in env) {
    const version = Number.parseInt((env.TERM_PROGRAM_VERSION || "").split(".")[0], 10);
    switch (env.TERM_PROGRAM) {
      case "iTerm.app": {
        return version >= 3 ? 3 : 2;
      }
      case "Apple_Terminal": {
        return 2;
      }
    }
  }
  if (/-256(color)?$/i.test(env.TERM)) {
    return 2;
  }
  if (/^screen|^xterm|^vt100|^vt220|^rxvt|color|ansi|cygwin|linux/i.test(env.TERM)) {
    return 1;
  }
  if ("COLORTERM" in env) {
    return 1;
  }
  return min;
}
function createSupportsColor(stream, options = {}) {
  const level = _supportsColor(stream, {
    streamIsTTY: stream && stream.isTTY,
    ...options
  });
  return translateLevel(level);
}
var supportsColor = {
  stdout: createSupportsColor({ isTTY: tty.isatty(1) }),
  stderr: createSupportsColor({ isTTY: tty.isatty(2) })
};
var supports_color_default = supportsColor;

// node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/utilities.js
function stringReplaceAll(string, substring, replacer) {
  let index = string.indexOf(substring);
  if (index === -1) {
    return string;
  }
  const substringLength = substring.length;
  let endIndex = 0;
  let returnValue = "";
  do {
    returnValue += string.slice(endIndex, index) + substring + replacer;
    endIndex = index + substringLength;
    index = string.indexOf(substring, endIndex);
  } while (index !== -1);
  returnValue += string.slice(endIndex);
  return returnValue;
}
function stringEncaseCRLFWithFirstIndex(string, prefix, postfix, index) {
  let endIndex = 0;
  let returnValue = "";
  do {
    const gotCR = string[index - 1] === "\r";
    returnValue += string.slice(endIndex, gotCR ? index - 1 : index) + prefix + (gotCR ? "\r\n" : "\n") + postfix;
    endIndex = index + 1;
    index = string.indexOf("\n", endIndex);
  } while (index !== -1);
  returnValue += string.slice(endIndex);
  return returnValue;
}

// node_modules/.pnpm/chalk@5.6.2/node_modules/chalk/source/index.js
var { stdout: stdoutColor, stderr: stderrColor } = supports_color_default;
var GENERATOR = Symbol("GENERATOR");
var STYLER = Symbol("STYLER");
var IS_EMPTY = Symbol("IS_EMPTY");
var levelMapping = [
  "ansi",
  "ansi",
  "ansi256",
  "ansi16m"
];
var styles2 = /* @__PURE__ */ Object.create(null);
var applyOptions = (object2, options = {}) => {
  if (options.level && !(Number.isInteger(options.level) && options.level >= 0 && options.level <= 3)) {
    throw new Error("The `level` option should be an integer from 0 to 3");
  }
  const colorLevel = stdoutColor ? stdoutColor.level : 0;
  object2.level = options.level === void 0 ? colorLevel : options.level;
};
var chalkFactory = (options) => {
  const chalk2 = (...strings) => strings.join(" ");
  applyOptions(chalk2, options);
  Object.setPrototypeOf(chalk2, createChalk.prototype);
  return chalk2;
};
function createChalk(options) {
  return chalkFactory(options);
}
Object.setPrototypeOf(createChalk.prototype, Function.prototype);
for (const [styleName, style] of Object.entries(ansi_styles_default)) {
  styles2[styleName] = {
    get() {
      const builder = createBuilder(this, createStyler(style.open, style.close, this[STYLER]), this[IS_EMPTY]);
      Object.defineProperty(this, styleName, { value: builder });
      return builder;
    }
  };
}
styles2.visible = {
  get() {
    const builder = createBuilder(this, this[STYLER], true);
    Object.defineProperty(this, "visible", { value: builder });
    return builder;
  }
};
var getModelAnsi = (model, level, type2, ...arguments_) => {
  if (model === "rgb") {
    if (level === "ansi16m") {
      return ansi_styles_default[type2].ansi16m(...arguments_);
    }
    if (level === "ansi256") {
      return ansi_styles_default[type2].ansi256(ansi_styles_default.rgbToAnsi256(...arguments_));
    }
    return ansi_styles_default[type2].ansi(ansi_styles_default.rgbToAnsi(...arguments_));
  }
  if (model === "hex") {
    return getModelAnsi("rgb", level, type2, ...ansi_styles_default.hexToRgb(...arguments_));
  }
  return ansi_styles_default[type2][model](...arguments_);
};
var usedModels = ["rgb", "hex", "ansi256"];
for (const model of usedModels) {
  styles2[model] = {
    get() {
      const { level } = this;
      return function(...arguments_) {
        const styler = createStyler(getModelAnsi(model, levelMapping[level], "color", ...arguments_), ansi_styles_default.color.close, this[STYLER]);
        return createBuilder(this, styler, this[IS_EMPTY]);
      };
    }
  };
  const bgModel = "bg" + model[0].toUpperCase() + model.slice(1);
  styles2[bgModel] = {
    get() {
      const { level } = this;
      return function(...arguments_) {
        const styler = createStyler(getModelAnsi(model, levelMapping[level], "bgColor", ...arguments_), ansi_styles_default.bgColor.close, this[STYLER]);
        return createBuilder(this, styler, this[IS_EMPTY]);
      };
    }
  };
}
var proto = Object.defineProperties(() => {
}, {
  ...styles2,
  level: {
    enumerable: true,
    get() {
      return this[GENERATOR].level;
    },
    set(level) {
      this[GENERATOR].level = level;
    }
  }
});
var createStyler = (open, close, parent) => {
  let openAll;
  let closeAll;
  if (parent === void 0) {
    openAll = open;
    closeAll = close;
  } else {
    openAll = parent.openAll + open;
    closeAll = close + parent.closeAll;
  }
  return {
    open,
    close,
    openAll,
    closeAll,
    parent
  };
};
var createBuilder = (self, _styler, _isEmpty) => {
  const builder = (...arguments_) => applyStyle(builder, arguments_.length === 1 ? "" + arguments_[0] : arguments_.join(" "));
  Object.setPrototypeOf(builder, proto);
  builder[GENERATOR] = self;
  builder[STYLER] = _styler;
  builder[IS_EMPTY] = _isEmpty;
  return builder;
};
var applyStyle = (self, string) => {
  if (self.level <= 0 || !string) {
    return self[IS_EMPTY] ? "" : string;
  }
  let styler = self[STYLER];
  if (styler === void 0) {
    return string;
  }
  const { openAll, closeAll } = styler;
  if (string.includes("\x1B")) {
    while (styler !== void 0) {
      string = stringReplaceAll(string, styler.close, styler.open);
      styler = styler.parent;
    }
  }
  const lfIndex = string.indexOf("\n");
  if (lfIndex !== -1) {
    string = stringEncaseCRLFWithFirstIndex(string, closeAll, openAll, lfIndex);
  }
  return openAll + string + closeAll;
};
Object.defineProperties(createChalk.prototype, styles2);
var chalk = createChalk();
var chalkStderr = createChalk({ level: stderrColor ? stderrColor.level : 0 });
var source_default = chalk;

// src/common/utils/env.ts
function parseBoolEnv(value2) {
  if (!value2) return false;
  const normalized = value2.toLowerCase();
  return normalized === "1" || normalized === "true" || normalized === "yes";
}

// src/common/constants/paths.ts
import { homedir } from "os";
import { join } from "path";
var UNIX_DIR_NAME = ".unix";
function getUnixHome() {
  if (process.env.UNIX_ROOT) {
    return process.env.UNIX_ROOT;
  }
  const baseName = UNIX_DIR_NAME;
  const suffix = process.env.NODE_ENV === "development" ? "-dev" : "";
  return join(homedir(), baseName + suffix);
}

// src/node/services/log.ts
var _debugObjDir = null;
function getDebugObjDir() {
  _debugObjDir ??= path.join(getUnixHome(), "debug_obj");
  return _debugObjDir;
}
var LOG_LEVEL_PRIORITY = {
  error: 0,
  warn: 1,
  info: 2,
  debug: 3
};
function getDefaultLogLevel() {
  const envLevel = process.env.UNIX_LOG_LEVEL?.toLowerCase();
  if (envLevel && envLevel in LOG_LEVEL_PRIORITY) {
    return envLevel;
  }
  if (parseBoolEnv(process.env.UNIX_DEBUG)) {
    return "debug";
  }
  const isElectron = "electron" in process.versions;
  return isElectron ? "info" : "error";
}
var currentLogLevel = getDefaultLogLevel();
function shouldLog(level) {
  return LOG_LEVEL_PRIORITY[level] <= LOG_LEVEL_PRIORITY[currentLogLevel];
}
function isDebugMode() {
  return currentLogLevel === "debug";
}
function supportsColor2() {
  return process.stdout.isTTY ?? false;
}
var chalkDim = typeof source_default.dim === "function" ? source_default.dim : (text2) => text2;
var chalkCyan = typeof source_default.cyan === "function" ? source_default.cyan : (text2) => text2;
var chalkGray = typeof source_default.gray === "function" ? source_default.gray : (text2) => text2;
var chalkRed = typeof source_default.red === "function" ? source_default.red : (text2) => text2;
var chalkYellow = typeof source_default.yellow === "function" ? source_default.yellow : (text2) => text2;
function getTimestamp() {
  const now = /* @__PURE__ */ new Date();
  let hours = now.getHours();
  const minutes = now.getMinutes();
  const milliseconds = now.getMilliseconds();
  const ampm = hours >= 12 ? "PM" : "AM";
  hours = hours % 12;
  hours = hours ? hours : 12;
  const mm = String(minutes).padStart(2, "0");
  const ms = String(milliseconds).padStart(3, "0");
  return `${hours}:${mm}.${ms}${ampm}`;
}
function getCallerLocation() {
  const error = new Error();
  const stack = error.stack?.split("\n");
  if (stack && stack.length > 4) {
    const callerLine = stack[4];
    const match = /\((.+):(\d+):\d+\)/.exec(callerLine) ?? /at (.+):(\d+):\d+/.exec(callerLine);
    if (match) {
      const [, filePath, lineNum] = match;
      const relativePath = filePath.replace(/^.*\/unix\//, "");
      return `${relativePath}:${lineNum}`;
    }
  }
  return "unknown:0";
}
function safePipeLog(level, ...args2) {
  if (!shouldLog(level)) {
    return;
  }
  const timestamp = getTimestamp();
  const location = getCallerLocation();
  const useColor = supportsColor2();
  let prefix;
  if (useColor) {
    const coloredTimestamp = chalkDim(timestamp);
    const coloredLocation = chalkCyan(location);
    if (level === "error") {
      prefix = `${coloredTimestamp} ${coloredLocation}`;
    } else if (level === "warn") {
      prefix = `${coloredTimestamp} ${coloredLocation}`;
    } else if (level === "debug") {
      prefix = `${coloredTimestamp} ${chalkGray(location)}`;
    } else {
      prefix = `${coloredTimestamp} ${coloredLocation}`;
    }
  } else {
    prefix = `${timestamp} ${location}`;
  }
  try {
    if (level === "error") {
      if (useColor) {
        console.error(
          prefix,
          ...args2.map((arg) => typeof arg === "string" ? chalkRed(arg) : arg)
        );
      } else {
        console.error(prefix, ...args2);
      }
    } else if (level === "warn") {
      if (useColor) {
        console.error(
          prefix,
          ...args2.map((arg) => typeof arg === "string" ? chalkYellow(arg) : arg)
        );
      } else {
        console.error(prefix, ...args2);
      }
    } else {
      console.log(prefix, ...args2);
    }
  } catch (error) {
    const errorCode = error && typeof error === "object" && "code" in error ? error.code : void 0;
    const errorMessage = error && typeof error === "object" && "message" in error ? String(error.message) : "Unknown error";
    if (errorCode !== "EPIPE") {
      try {
        const stream = level === "error" || level === "warn" ? process.stderr : process.stdout;
        stream.write(`${timestamp} ${location} Console error: ${errorMessage}
`);
      } catch {
      }
    }
  }
}
function debugObject(filename, obj) {
  if (!isDebugMode()) {
    return;
  }
  try {
    const debugObjDir = getDebugObjDir();
    fs.mkdirSync(debugObjDir, { recursive: true });
    const filePath = path.join(debugObjDir, filename);
    const dirPath = path.dirname(filePath);
    fs.mkdirSync(dirPath, { recursive: true });
    fs.writeFileSync(filePath, JSON.stringify(obj, null, 2), "utf-8");
    safePipeLog("debug", `Dumped object to ${filePath}`);
  } catch (error) {
    safePipeLog("error", `Failed to dump debug object to ${filename}:`, error);
  }
}
function isPlainObject(value2) {
  if (!value2 || typeof value2 !== "object") {
    return false;
  }
  if (Array.isArray(value2)) {
    return false;
  }
  if (value2 instanceof Error) {
    return false;
  }
  const proto2 = Object.getPrototypeOf(value2);
  return proto2 === Object.prototype || proto2 === null;
}
function normalizeFields(fields) {
  return fields && Object.keys(fields).length > 0 ? fields : void 0;
}
function mergeLogFields(base, extra) {
  return normalizeFields({ ...base ?? {}, ...extra ?? {} });
}
var baseLogger = {
  debug_obj: debugObject,
  setLevel: (level) => {
    currentLogLevel = level;
  },
  getLevel: () => currentLogLevel,
  isDebugMode
};
function appendFieldsToArgs(args2, fields) {
  if (!fields) {
    return args2;
  }
  if (args2.length === 0) {
    return [fields];
  }
  const lastArg = args2[args2.length - 1];
  if (isPlainObject(lastArg)) {
    return [...args2.slice(0, -1), { ...fields, ...lastArg }];
  }
  return [...args2, fields];
}
function createLogger(boundFields) {
  const normalizedFields = normalizeFields(boundFields);
  const logAtLevel = (level) => (...args2) => {
    safePipeLog(level, ...appendFieldsToArgs(args2, normalizedFields));
  };
  return {
    ...baseLogger,
    info: logAtLevel("info"),
    warn: logAtLevel("warn"),
    error: logAtLevel("error"),
    debug: logAtLevel("debug"),
    withFields: (fields) => createLogger(mergeLogFields(normalizedFields, fields))
  };
}
var log = createLogger();

// src/common/types/result.ts
function Ok(data) {
  return { success: true, data };
}
function Err(error) {
  return { success: false, error };
}

// src/node/services/workspaceTitleGenerator.ts
import crypto from "crypto";

// src/common/utils/ai/modelDisplay.ts
function formatModelDisplayName(modelName) {
  const bedrockParsed = parseBedrockModelName(modelName);
  if (bedrockParsed) {
    modelName = bedrockParsed;
  }
  const lower = modelName.toLowerCase();
  if (lower.startsWith("claude-")) {
    const parts = lower.replace("claude-", "").split("-");
    const tiers = ["sonnet", "opus", "haiku"];
    if (parts.length >= 3 && tiers.includes(parts[0])) {
      const tier = capitalize(parts[0]);
      const version = formatVersion(parts.slice(1));
      return `${tier} ${version}`;
    }
    if (parts.length >= 3) {
      const tierIdx = parts.findIndex((p) => tiers.includes(p));
      if (tierIdx > 0) {
        const tier = capitalize(parts[tierIdx]);
        const version = formatVersion(parts.slice(0, tierIdx));
        return `${tier} ${version}`;
      }
    }
    if (parts.length === 2 && tiers.includes(parts[0])) {
      const tier = capitalize(parts[0]);
      return `${tier} ${parts[1]}`;
    }
  }
  if (lower.startsWith("gpt-")) {
    const parts = lower.split("-");
    if (parts.length >= 2) {
      const base = `GPT-${parts[1]}`;
      const rest = parts.slice(2).map(capitalize).join(" ");
      return rest ? `${base} ${rest}` : base;
    }
  }
  if (lower.startsWith("gemini-")) {
    const parts = lower.replace("gemini-", "").split("-");
    const versionParts = [];
    const nameParts = [];
    for (const part of parts) {
      if (versionParts.length < 2 && /^\d+$/.test(part)) {
        versionParts.push(part);
      } else {
        nameParts.push(capitalize(part));
      }
    }
    const version = versionParts.length > 0 ? versionParts.join(".") : "";
    const name16 = nameParts.join(" ");
    if (version && name16) {
      return `Gemini ${version} ${name16}`;
    } else if (version) {
      return `Gemini ${version}`;
    } else if (name16) {
      return `Gemini ${name16}`;
    }
  }
  const [baseName, size] = modelName.split(":");
  if (size) {
    const formatted = baseName.split(/(\d+\.?\d*)/).map((part, idx) => {
      if (idx === 0) return capitalize(part);
      if (/^\d+\.?\d*$/.test(part)) return ` ${part}`;
      return part;
    }).join("");
    return `${formatted.trim()} (${size.toUpperCase()})`;
  }
  return modelName.split("-").map(capitalize).join(" ");
}
function capitalize(str) {
  if (!str) return str;
  return str.charAt(0).toUpperCase() + str.slice(1);
}
function formatVersion(parts) {
  return parts.join(".");
}
function parseBedrockModelName(modelId) {
  if (!modelId.includes(".")) {
    return null;
  }
  const dotParts = modelId.split(".");
  if (dotParts.length < 2) {
    return null;
  }
  const knownVendors = ["anthropic", "amazon", "meta", "cohere", "mistral", "ai21"];
  const knownRegionPrefixes = ["global", "us", "eu", "ap", "sa"];
  const firstPart = dotParts[0].toLowerCase();
  const secondPart = dotParts.length > 1 ? dotParts[1].toLowerCase() : "";
  const isVendor = knownVendors.includes(firstPart);
  const isRegionPrefix = knownRegionPrefixes.some(
    (prefix) => firstPart === prefix || firstPart.startsWith(`${prefix}-`)
  );
  const secondPartIsVendor = knownVendors.includes(secondPart);
  if (!isVendor && !(isRegionPrefix && secondPartIsVendor)) {
    return null;
  }
  const rawModelName = dotParts[dotParts.length - 1];
  const withoutVersion = rawModelName.split(":")[0];
  const dateVersionPattern = /-\d{8}-v\d+$/;
  const versionOnlyPattern = /-v\d+$/;
  const cleanedName = withoutVersion.replace(dateVersionPattern, "").replace(versionOnlyPattern, "");
  return cleanedName;
}

// src/common/constants/knownModels.ts
var MODEL_DEFINITIONS = {
  COPILOT_SONNET: {
    provider: "github-copilot",
    providerModelId: "claude-sonnet-4.5",
    aliases: ["copilot", "copilot-sonnet"],
    warm: true,
    tokenizerOverride: "anthropic/claude-sonnet-4.5"
  },
  COPILOT_GPT: {
    provider: "github-copilot",
    providerModelId: "gpt-4o",
    aliases: ["copilot-gpt"],
    warm: true,
    tokenizerOverride: "openai/gpt-5"
  },
  // Direct Copilot API (non-airgapped environments)
  COPILOT_DIRECT_SONNET: {
    provider: "github-copilot-direct",
    providerModelId: "claude-sonnet-4.5",
    aliases: ["copilot-direct", "copilot-direct-sonnet"],
    warm: false,
    tokenizerOverride: "anthropic/claude-sonnet-4.5"
  },
  COPILOT_DIRECT_GPT: {
    provider: "github-copilot-direct",
    providerModelId: "gpt-4o",
    aliases: ["copilot-direct-gpt"],
    warm: false,
    tokenizerOverride: "openai/gpt-5"
  },
  OPUS: {
    provider: "anthropic",
    providerModelId: "claude-opus-4-5",
    aliases: ["opus"],
    warm: true
  },
  SONNET: {
    provider: "anthropic",
    providerModelId: "claude-sonnet-4-5",
    aliases: ["sonnet"],
    warm: true,
    tokenizerOverride: "anthropic/claude-sonnet-4.5"
  },
  HAIKU: {
    provider: "anthropic",
    providerModelId: "claude-haiku-4-5",
    aliases: ["haiku"],
    tokenizerOverride: "anthropic/claude-3.5-haiku"
  },
  GPT: {
    provider: "openai",
    providerModelId: "gpt-5.2",
    aliases: ["gpt"],
    warm: true,
    tokenizerOverride: "openai/gpt-5"
  },
  GPT_PRO: {
    provider: "openai",
    providerModelId: "gpt-5.2-pro",
    aliases: ["gpt-pro"]
  },
  GPT_52_CODEX: {
    provider: "openai",
    providerModelId: "gpt-5.2-codex",
    aliases: ["codex"],
    warm: true,
    tokenizerOverride: "openai/gpt-5"
  },
  GPT_CODEX: {
    provider: "openai",
    providerModelId: "gpt-5.1-codex",
    aliases: ["codex-5.1"],
    warm: true,
    tokenizerOverride: "openai/gpt-5"
  },
  GPT_MINI: {
    provider: "openai",
    providerModelId: "gpt-5.1-codex-mini",
    aliases: ["codex-mini"]
  },
  GPT_CODEX_MAX: {
    provider: "openai",
    providerModelId: "gpt-5.1-codex-max",
    aliases: ["codex-max"],
    warm: true,
    tokenizerOverride: "openai/gpt-5"
  },
  GEMINI_3_PRO: {
    provider: "google",
    providerModelId: "gemini-3-pro-preview",
    aliases: ["gemini", "gemini-3", "gemini-3-pro"],
    tokenizerOverride: "google/gemini-2.5-pro"
  },
  GEMINI_3_FLASH: {
    provider: "google",
    providerModelId: "gemini-3-flash-preview",
    aliases: ["gemini-3-flash"],
    tokenizerOverride: "google/gemini-2.5-pro"
  },
  GROK_4_1: {
    provider: "xai",
    providerModelId: "grok-4-1-fast",
    aliases: ["grok", "grok-4", "grok-4.1", "grok-4-1"]
  },
  GROK_CODE: {
    provider: "xai",
    providerModelId: "grok-code-fast-1",
    aliases: ["grok-code"]
  }
};
var MODEL_DEFINITION_ENTRIES = Object.entries(MODEL_DEFINITIONS);
var KNOWN_MODELS = Object.fromEntries(
  MODEL_DEFINITION_ENTRIES.map(([key, definition]) => toKnownModelEntry(key, definition))
);
function toKnownModelEntry(key, definition) {
  return [
    key,
    {
      ...definition,
      id: `${definition.provider}:${definition.providerModelId}`
    }
  ];
}
function getKnownModel(key) {
  return KNOWN_MODELS[key];
}
var DEFAULT_MODEL_KEY = "COPILOT_SONNET";
var DEFAULT_MODEL = KNOWN_MODELS[DEFAULT_MODEL_KEY].id;
var DEFAULT_WARM_MODELS = Object.values(KNOWN_MODELS).filter((model) => model.warm).map((model) => model.id);
var MODEL_ABBREVIATIONS = Object.fromEntries(
  Object.values(KNOWN_MODELS).flatMap((model) => (model.aliases ?? []).map((alias) => [alias, model.id])).sort(([a], [b]) => a.localeCompare(b))
);
var TOKENIZER_MODEL_OVERRIDES = Object.fromEntries(
  Object.values(KNOWN_MODELS).filter((model) => Boolean(model.tokenizerOverride)).map((model) => [model.id, model.tokenizerOverride])
);
var MODEL_NAMES = Object.entries(
  KNOWN_MODELS
).reduce(
  (acc, [key, model]) => {
    if (!acc[model.provider]) {
      const emptyRecord = {};
      acc[model.provider] = emptyRecord;
    }
    acc[model.provider][key] = model.providerModelId;
    return acc;
  },
  {}
);
var KNOWN_MODEL_OPTIONS = Object.values(KNOWN_MODELS).map((model) => ({
  label: formatModelDisplayName(model.providerModelId),
  value: model.id
}));
var MODEL_ABBREVIATION_EXAMPLES = ["opus", "sonnet"].map((abbrev) => ({
  abbrev,
  displayName: formatModelDisplayName(MODEL_ABBREVIATIONS[abbrev]?.split(":")[1] ?? abbrev)
}));

// src/node/services/workspaceTitleGenerator.ts
var DEFAULT_NAME_GENERATION_MODELS = [getKnownModel("HAIKU").id, getKnownModel("GPT_MINI").id];
var workspaceIdentitySchema = z28.object({
  name: z28.string().regex(/^[a-z0-9-]+$/).min(2).max(20).describe(
    "Codebase area (1-2 words): lowercase, hyphens only, e.g. 'sidebar', 'auth', 'config'"
  ),
  title: z28.string().min(5).max(60).describe("Human-readable title (2-5 words): verb-noun format like 'Fix plan mode'")
});
function toOpenRouterVariant(modelId) {
  const [provider, model] = modelId.split(":");
  if (!provider || !model) return modelId;
  return `openrouter:${provider}/${model}`;
}
async function selectModelForNameGeneration(aiService, preferredModels = DEFAULT_NAME_GENERATION_MODELS, userModel) {
  for (const modelId of preferredModels) {
    const result = await aiService.createModel(modelId);
    if (result.success) {
      return modelId;
    }
  }
  for (const modelId of preferredModels) {
    const openRouterVariant = toOpenRouterVariant(modelId);
    const result = await aiService.createModel(openRouterVariant);
    if (result.success) {
      return openRouterVariant;
    }
  }
  if (userModel) {
    const result = await aiService.createModel(userModel);
    if (result.success) {
      return userModel;
    }
  }
  const knownModelIds = Object.values(KNOWN_MODELS).map((m) => m.id);
  for (const modelId of knownModelIds) {
    const directResult = await aiService.createModel(modelId);
    if (directResult.success) {
      return modelId;
    }
    const openRouterVariant = toOpenRouterVariant(modelId);
    const openRouterResult = await aiService.createModel(openRouterVariant);
    if (openRouterResult.success) {
      return openRouterVariant;
    }
  }
  return null;
}
var CROCKFORD_ALPHABET = "0123456789abcdefghjkmnpqrstvwxyz";
function generateNameSuffix() {
  const bytes = crypto.randomBytes(3);
  const value2 = bytes[0] << 12 | bytes[1] << 4 | bytes[2] >> 4;
  return CROCKFORD_ALPHABET[value2 >> 15 & 31] + CROCKFORD_ALPHABET[value2 >> 10 & 31] + CROCKFORD_ALPHABET[value2 >> 5 & 31] + CROCKFORD_ALPHABET[value2 & 31];
}
async function generateWorkspaceIdentity(message, modelString, aiService) {
  try {
    const modelResult = await aiService.createModel(modelString);
    if (!modelResult.success) {
      return Err(modelResult.error);
    }
    const result = await generateObject({
      model: modelResult.data,
      schema: workspaceIdentitySchema,
      mode: "json",
      prompt: `Generate a workspace name and title for this development task:

"${message}"

Requirements:
- name: The area of the codebase being worked on (1-2 words, git-safe: lowercase, hyphens only). Random bytes will be appended for uniqueness, so focus on the area not the specific task. Examples: "sidebar", "auth", "config", "api"
- title: A 2-5 word description in verb-noun format. Examples: "Fix plan mode", "Add user authentication", "Refactor sidebar layout"`
    });
    const suffix = generateNameSuffix();
    const sanitizedName = sanitizeBranchName(result.object.name, 20);
    const nameWithSuffix = `${sanitizedName}-${suffix}`;
    return Ok({
      name: nameWithSuffix,
      title: result.object.title.trim()
    });
  } catch (error) {
    const messageText = error instanceof Error ? error.message : String(error);
    log.error("Failed to generate workspace identity with AI", error);
    return Err({ type: "unknown", raw: `Failed to generate workspace identity: ${messageText}` });
  }
}
function sanitizeBranchName(name16, maxLength) {
  return name16.toLowerCase().replace(/[^a-z0-9]+/g, "-").replace(/^-+|-+$/g, "").replace(/-+/g, "-").substring(0, maxLength);
}

// src/node/orpc/authMiddleware.ts
init_dist5();
import { timingSafeEqual } from "crypto";
function safeEq(a, b) {
  const bufA = Buffer.from(a);
  const bufB = Buffer.from(b);
  const maxLen = Math.max(bufA.length, bufB.length);
  const paddedA = Buffer.alloc(maxLen);
  const paddedB = Buffer.alloc(maxLen);
  bufA.copy(paddedA);
  bufB.copy(paddedB);
  const bytesMatch = timingSafeEqual(paddedA, paddedB);
  return bytesMatch && bufA.length === bufB.length;
}
function extractBearerToken(header) {
  const h = Array.isArray(header) ? header[0] : header;
  if (!h?.toLowerCase().startsWith("bearer ")) return null;
  return h.slice(7).trim() || null;
}
function createAuthMiddleware(authToken) {
  if (!authToken?.trim()) {
    return os.middleware(({ next }) => next());
  }
  const expectedToken = authToken.trim();
  return os.$context().errors({
    UNAUTHORIZED: {
      message: "Invalid or missing auth token"
    }
  }).middleware(({ context, errors, next }) => {
    const presentedToken = extractBearerToken(context.headers?.authorization);
    if (!presentedToken || !safeEq(presentedToken, expectedToken)) {
      throw errors.UNAUTHORIZED();
    }
    return next();
  });
}

// src/common/utils/asyncMessageQueue.ts
function createAsyncMessageQueue() {
  const queue = [];
  let resolveNext = null;
  let ended = false;
  const push = (msg) => {
    if (ended) return;
    queue.push(msg);
    if (resolveNext) {
      const resolve3 = resolveNext;
      resolveNext = null;
      resolve3();
    }
  };
  async function* iterate() {
    while (!ended) {
      while (queue.length > 0) {
        yield queue.shift();
      }
      await new Promise((resolve3) => {
        resolveNext = resolve3;
      });
    }
    while (queue.length > 0) {
      yield queue.shift();
    }
  }
  const end = () => {
    ended = true;
    if (resolveNext) {
      resolveNext();
    }
  };
  return { push, iterate, end };
}

// src/node/runtime/runtimeFactory.ts
import * as fs10 from "fs/promises";
import * as path18 from "path";

// src/node/runtime/initHook.ts
import * as fs2 from "fs";
import * as fsPromises from "fs/promises";
import * as path2 from "path";

// src/common/types/runtime.ts
var RUNTIME_MODE = {
  LOCAL: "local",
  WORKTREE: "worktree",
  SSH: "ssh",
  DOCKER: "docker",
  DEVCONTAINER: "devcontainer"
};
var RUNTIME_MODES_REQUIRING_GIT = [
  RUNTIME_MODE.WORKTREE,
  RUNTIME_MODE.SSH,
  RUNTIME_MODE.DOCKER,
  RUNTIME_MODE.DEVCONTAINER
];
function isSSHRuntime(config2) {
  return config2?.type === "ssh";
}
function hasSrcBaseDir(config2) {
  if (!config2) return false;
  return "srcBaseDir" in config2 && typeof config2.srcBaseDir === "string";
}

// src/node/runtime/initHook.ts
async function checkInitHookExists(projectPath) {
  const hookPath = path2.join(projectPath, ".unix", "init");
  try {
    await fsPromises.access(hookPath, fs2.constants.X_OK);
    return true;
  } catch {
    return false;
  }
}
function getInitHookPath(projectPath) {
  return path2.join(projectPath, ".unix", "init");
}
function getUnixEnv(projectPath, runtime, workspaceName, options) {
  if (!projectPath) {
    throw new Error("getUnixEnv: projectPath is required");
  }
  if (!workspaceName) {
    throw new Error("getUnixEnv: workspaceName is required");
  }
  const env3 = {
    UNIX_PROJECT_PATH: projectPath,
    UNIX_RUNTIME: runtime,
    UNIX_WORKSPACE_NAME: workspaceName
  };
  if (options?.modelString) {
    env3.UNIX_MODEL_STRING = options.modelString;
  }
  if (options?.thinkingLevel !== void 0) {
    env3.UNIX_THINKING_LEVEL = options.thinkingLevel;
  }
  if (options?.costsUsd !== void 0) {
    env3.UNIX_COSTS_USD = options.costsUsd.toFixed(2);
  }
  return env3;
}
var LineBuffer = class {
  constructor(logLine) {
    this.buffer = "";
    this.logLine = logLine;
  }
  /**
   * Process a chunk of data, splitting on newlines and logging complete lines
   */
  append(data) {
    this.buffer += data;
    const lines = this.buffer.split("\n");
    this.buffer = lines.pop() ?? "";
    for (const line of lines) {
      if (line) this.logLine(line);
    }
  }
  /**
   * Flush any remaining buffered data (called when stream closes)
   */
  flush() {
    if (this.buffer) {
      this.logLine(this.buffer);
      this.buffer = "";
    }
  }
};
function createLineBufferedLoggers(initLogger) {
  const stdoutBuffer = new LineBuffer((line) => initLogger.logStdout(line));
  const stderrBuffer = new LineBuffer((line) => initLogger.logStderr(line));
  return {
    stdout: {
      append: (data) => stdoutBuffer.append(data),
      flush: () => stdoutBuffer.flush()
    },
    stderr: {
      append: (data) => stderrBuffer.append(data),
      flush: () => stderrBuffer.flush()
    }
  };
}
async function runInitHookOnRuntime(runtime, hookPath, workspacePath, muxEnv, initLogger, abortSignal) {
  initLogger.logStep(`Running init hook: ${hookPath}`);
  const hookStream = await runtime.exec(hookPath, {
    cwd: workspacePath,
    timeout: 3600,
    // 1 hour - generous timeout for init hooks
    abortSignal,
    env: muxEnv
  });
  const loggers = createLineBufferedLoggers(initLogger);
  const stdoutReader = hookStream.stdout.getReader();
  const stderrReader = hookStream.stderr.getReader();
  const decoder = new TextDecoder();
  const readStdout = async () => {
    try {
      while (true) {
        const { done, value: value2 } = await stdoutReader.read();
        if (done) break;
        loggers.stdout.append(decoder.decode(value2, { stream: true }));
      }
      loggers.stdout.flush();
    } finally {
      stdoutReader.releaseLock();
    }
  };
  const readStderr = async () => {
    try {
      while (true) {
        const { done, value: value2 } = await stderrReader.read();
        if (done) break;
        loggers.stderr.append(decoder.decode(value2, { stream: true }));
      }
      loggers.stderr.flush();
    } finally {
      stderrReader.releaseLock();
    }
  };
  const [exitCode] = await Promise.all([hookStream.exitCode, readStdout(), readStderr()]);
  initLogger.logComplete(exitCode);
}

// src/common/utils/errors.ts
function getErrorMessage3(error) {
  return error instanceof Error ? error.message : String(error);
}

// src/node/runtime/LocalBaseRuntime.ts
import { spawn } from "child_process";
import * as fs3 from "fs";
import * as fsPromises2 from "fs/promises";
import * as path5 from "path";
import { Readable, Writable } from "stream";

// src/node/runtime/Runtime.ts
var RuntimeError = class extends Error {
  constructor(message, type2, cause) {
    super(message);
    this.type = type2;
    this.cause = cause;
    this.name = "RuntimeError";
  }
};

// src/common/constants/env.ts
var NON_INTERACTIVE_ENV_VARS = {
  // Prevent interactive editors from blocking execution
  // Critical for git operations like rebase/commit that try to open editors
  GIT_EDITOR: "true",
  // Git-specific editor (highest priority)
  GIT_SEQUENCE_EDITOR: "true",
  // For interactive rebase sequences
  EDITOR: "true",
  // General fallback for non-git commands
  VISUAL: "true",
  // Another common editor environment variable
  // Prevent git from prompting for credentials
  GIT_TERMINAL_PROMPT: "0"
  // Disables git credential prompts
};

// src/node/utils/main/bashPath.ts
import { execSync } from "child_process";
import { existsSync } from "fs";
import path3 from "path";
var WIN_PATH = path3.win32;
var BASH_PATH_ERROR_COOLDOWN_MS = 3e4;
var cachedBashPath = null;
var cachedBashPathError = null;
var defaultExecSync = (command, options) => execSync(command, options);
function parseWhereOutput(output) {
  return output.split(/\r?\n/).map((line) => line.trim()).filter((line) => line.length > 0);
}
function isWslLauncherPath(p) {
  const normalized = WIN_PATH.normalize(p).toLowerCase();
  return normalized.endsWith("\\windows\\system32\\bash.exe") || normalized.endsWith("\\windows\\system32\\wsl.exe");
}
function looksLikeGitForWindowsBash(bashPath, existsSyncFn) {
  if (isWslLauncherPath(bashPath)) {
    return false;
  }
  const normalized = WIN_PATH.normalize(bashPath);
  const lower = normalized.toLowerCase();
  if (lower.endsWith("\\usr\\bin\\bash.exe")) {
    const root = WIN_PATH.dirname(WIN_PATH.dirname(WIN_PATH.dirname(normalized)));
    return existsSyncFn(WIN_PATH.join(root, "cmd", "git.exe"));
  }
  if (lower.endsWith("\\bin\\bash.exe")) {
    const root = WIN_PATH.dirname(WIN_PATH.dirname(normalized));
    return existsSyncFn(WIN_PATH.join(root, "cmd", "git.exe"));
  }
  let dir = WIN_PATH.dirname(normalized);
  for (let i = 0; i < 4; i++) {
    if (existsSyncFn(WIN_PATH.join(dir, "cmd", "git.exe"))) {
      return true;
    }
    const parent = WIN_PATH.dirname(dir);
    if (parent === dir) {
      break;
    }
    dir = parent;
  }
  return false;
}
function findGitRootFromGitExePath(gitExePath, existsSyncFn) {
  let dir = WIN_PATH.dirname(WIN_PATH.dirname(WIN_PATH.normalize(gitExePath)));
  for (let i = 0; i < 4; i++) {
    if (existsSyncFn(WIN_PATH.join(dir, "cmd", "git.exe"))) {
      return dir;
    }
    const parent = WIN_PATH.dirname(dir);
    if (parent === dir) {
      break;
    }
    dir = parent;
  }
  return null;
}
function findWindowsBash(params) {
  const { env: env3, execSyncFn, existsSyncFn } = params;
  const gitRoots = [
    // Git for Windows default paths
    "C:\\Program Files\\Git",
    "C:\\Program Files (x86)\\Git",
    // Chocolatey installation
    "C:\\tools\\git"
  ];
  if (env3.LOCALAPPDATA) {
    gitRoots.push(WIN_PATH.join(env3.LOCALAPPDATA, "Programs", "Git"));
  }
  if (env3.USERPROFILE) {
    gitRoots.push(WIN_PATH.join(env3.USERPROFILE, "scoop", "apps", "git", "current"));
  }
  const commonPaths = gitRoots.flatMap((root) => [
    WIN_PATH.join(root, "bin", "bash.exe"),
    WIN_PATH.join(root, "usr", "bin", "bash.exe")
  ]);
  for (const bashPath of commonPaths) {
    if (existsSyncFn(bashPath) && looksLikeGitForWindowsBash(bashPath, existsSyncFn)) {
      return bashPath;
    }
  }
  try {
    const result = execSyncFn("where git", {
      encoding: "utf8",
      stdio: ["pipe", "pipe", "ignore"],
      windowsHide: true
    });
    for (const gitExePath of parseWhereOutput(result)) {
      if (!existsSyncFn(gitExePath)) {
        continue;
      }
      const gitRoot = findGitRootFromGitExePath(gitExePath, existsSyncFn);
      if (!gitRoot) {
        continue;
      }
      const candidateBashPaths = [
        WIN_PATH.join(gitRoot, "bin", "bash.exe"),
        WIN_PATH.join(gitRoot, "usr", "bin", "bash.exe")
      ];
      for (const bashPath of candidateBashPaths) {
        if (existsSyncFn(bashPath) && looksLikeGitForWindowsBash(bashPath, existsSyncFn)) {
          return bashPath;
        }
      }
    }
  } catch {
  }
  try {
    const result = execSyncFn("where bash", {
      encoding: "utf8",
      stdio: ["pipe", "pipe", "ignore"],
      windowsHide: true
    });
    for (const bashPath of parseWhereOutput(result)) {
      if (!existsSyncFn(bashPath)) {
        continue;
      }
      if (looksLikeGitForWindowsBash(bashPath, existsSyncFn)) {
        return bashPath;
      }
    }
  } catch {
  }
  return null;
}
function getBashPathForPlatform(params) {
  if (params.platform !== "win32") {
    return "bash";
  }
  const bashPath = findWindowsBash({
    env: params.env ?? process.env,
    execSyncFn: params.execSyncFn ?? defaultExecSync,
    existsSyncFn: params.existsSyncFn ?? existsSync
  });
  if (!bashPath) {
    throw new Error(
      "Git Bash not found. On Windows, unix requires Git for Windows (Git Bash). WSL is not supported. Install Git for Windows from https://git-scm.com/download/win"
    );
  }
  return bashPath;
}
function getBashPath(params = {}) {
  const platform2 = params.platform ?? process.platform;
  if (platform2 !== "win32") {
    return "bash";
  }
  if (cachedBashPath !== null) {
    return cachedBashPath;
  }
  const nowFn = params.nowFn ?? Date.now;
  const now = nowFn();
  if (cachedBashPathError && now - cachedBashPathError.lastCheckedMs < BASH_PATH_ERROR_COOLDOWN_MS) {
    throw new Error(cachedBashPathError.message);
  }
  try {
    cachedBashPath = getBashPathForPlatform({
      platform: platform2,
      env: params.env,
      execSyncFn: params.execSyncFn,
      existsSyncFn: params.existsSyncFn
    });
    cachedBashPathError = null;
    return cachedBashPath;
  } catch (error) {
    const message = error instanceof Error ? error.message : String(error);
    cachedBashPathError = { message, lastCheckedMs: now };
    throw error;
  }
}

// src/common/utils/shell.ts
function shellQuote(value2) {
  if (value2.length === 0) return "''";
  return "'" + value2.replace(/'/g, `'"'"'`) + "'";
}

// src/common/constants/exitCodes.ts
var EXIT_CODE_ABORTED = -997;
var EXIT_CODE_TIMEOUT = -998;

// src/node/utils/disposableExec.ts
import { exec, execFileSync } from "child_process";
function killProcessTree(pid) {
  if (!Number.isFinite(pid) || pid <= 0) {
    return;
  }
  if (process.platform === "win32") {
    try {
      execFileSync("taskkill", ["/PID", String(pid), "/T", "/F"], {
        stdio: "ignore",
        windowsHide: true
      });
    } catch {
    }
    return;
  }
  try {
    process.kill(-pid, "SIGKILL");
  } catch {
    try {
      process.kill(pid, "SIGKILL");
    } catch {
    }
  }
}
var DisposableProcess = class {
  constructor(process3) {
    this.process = process3;
    this.cleanupCallbacks = [];
    this.disposed = false;
  }
  /**
   * Register cleanup callback to run when process is disposed.
   * If already disposed, runs immediately.
   */
  addCleanup(callback) {
    if (this.disposed) {
      try {
        callback();
      } catch {
      }
    } else {
      this.cleanupCallbacks.push(callback);
    }
  }
  /**
   * Get the underlying child process
   */
  get underlying() {
    return this.process;
  }
  /**
   * Cleanup: kill process + run all cleanup callbacks immediately.
   * Safe to call multiple times (idempotent).
   */
  [Symbol.dispose]() {
    if (this.disposed) return;
    this.disposed = true;
    if (!this.process.killed && this.process.exitCode === null && this.process.signalCode === null) {
      if (this.process.pid !== void 0) {
        killProcessTree(this.process.pid);
      } else {
        try {
          this.process.kill("SIGKILL");
        } catch {
        }
      }
    }
    for (const callback of this.cleanupCallbacks) {
      try {
        callback();
      } catch {
      }
    }
    this.cleanupCallbacks = [];
  }
};
var DisposableExec = class {
  constructor(promise, child) {
    this.promise = promise;
    this.child = child;
  }
  [Symbol.dispose]() {
    const hasExited = this.child.exitCode !== null || this.child.signalCode !== null;
    if (!hasExited && !this.child.killed) {
      this.child.kill();
    }
  }
  get result() {
    return this.promise;
  }
};
function execAsync(command, options) {
  const child = exec(command, { shell: options?.shell });
  const promise = new Promise((resolve3, reject) => {
    let stdout = "";
    let stderr = "";
    let exitCode = null;
    let exitSignal = null;
    child.stdout?.on("data", (data) => {
      stdout += data;
    });
    child.stderr?.on("data", (data) => {
      stderr += data;
    });
    child.on("exit", (code, signal) => {
      exitCode = code;
      exitSignal = signal;
    });
    child.on("close", () => {
      if (exitCode === 0 && exitSignal === null) {
        resolve3({ stdout, stderr });
      } else {
        const errorMsg = stderr.trim() || (exitSignal ? `Command killed by signal ${exitSignal}` : `Command failed with exit code ${exitCode ?? "unknown"}`);
        const error = new Error(errorMsg);
        error.code = exitCode;
        error.signal = exitSignal;
        error.stdout = stdout;
        error.stderr = stderr;
        reject(error);
      }
    });
    child.on("error", reject);
  });
  return new DisposableExec(promise, child);
}

// src/node/runtime/tildeExpansion.ts
import path4 from "path";

// src/node/utils/paths.main.ts
import { platform, env as env2 } from "node:process";
function isWindowsPlatform() {
  return platform === "win32";
}
function getSeparator() {
  return isWindowsPlatform() ? "\\" : "/";
}
function getHomeDir() {
  if (isWindowsPlatform()) {
    return env2.USERPROFILE ?? "";
  }
  return env2.HOME ?? "";
}
var PlatformPaths = class {
  /**
   * Get the appropriate path separator for the current platform
   */
  static get separator() {
    return getSeparator();
  }
  /**
   * Extract basename from path (OS-aware)
   */
  static basename(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return filePath;
    }
    const lastSlash = isWindowsPlatform() ? Math.max(filePath.lastIndexOf("/"), filePath.lastIndexOf("\\")) : filePath.lastIndexOf("/");
    if (lastSlash === -1) {
      return filePath;
    }
    return filePath.slice(lastSlash + 1);
  }
  /**
   * Split path into components (OS-aware)
   */
  static parse(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return { root: "", segments: [], basename: filePath };
    }
    const original = filePath;
    let root = "";
    let dir = "";
    let base = "";
    const lastSlash = isWindowsPlatform() ? Math.max(original.lastIndexOf("/"), original.lastIndexOf("\\")) : original.lastIndexOf("/");
    if (lastSlash === -1) {
      base = original;
      dir = "";
    } else {
      base = original.slice(lastSlash + 1);
      dir = original.slice(0, lastSlash);
    }
    if (isWindowsPlatform()) {
      const driveMatch = /^[A-Za-z]:[\\/]/.exec(original);
      if (driveMatch) {
        root = driveMatch[0];
        if (dir.startsWith(root)) {
          dir = dir.slice(root.length);
        }
      } else if (original.startsWith("\\\\")) {
        root = "\\\\";
        if (dir.startsWith(root)) {
          dir = dir.slice(root.length);
        }
      }
      if (!root && original.startsWith("/")) {
        root = "/";
        if (dir.startsWith(root)) {
          dir = dir.slice(root.length);
        }
      }
    } else if (original.startsWith("/")) {
      root = "/";
      if (dir.startsWith(root)) {
        dir = dir.slice(root.length);
      }
    }
    const separatorRegex = isWindowsPlatform() ? /[\\/]+/ : /\/+/;
    const segments = dir ? dir.split(separatorRegex).filter(Boolean) : [];
    return {
      root,
      segments,
      basename: base
    };
  }
  /**
   * Format path for display with fish-style abbreviation (OS-aware)
   * Abbreviates all directory components except the last one to their first letter
   */
  static abbreviate(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return filePath;
    }
    const { root, segments, basename } = this.parse(filePath);
    const abbreviated = segments.map((seg) => seg.length > 0 ? seg[0] : seg);
    if (!root && abbreviated.length === 0) {
      return basename;
    }
    const sep = isWindowsPlatform() ? filePath.includes("\\") ? "\\" : "/" : "/";
    const joined = [...abbreviated, basename].filter(Boolean).join(sep);
    if (!root) {
      return joined;
    }
    const rootEndsWithSep = root.endsWith("\\") || root.endsWith("/");
    return rootEndsWithSep ? root + joined : root + sep + joined;
  }
  /**
   * Split an abbreviated path into directory path and basename
   */
  static splitAbbreviated(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return { dirPath: "", basename: filePath };
    }
    const sep = isWindowsPlatform() ? filePath.includes("\\") ? "\\" : "/" : "/";
    const lastSlash = filePath.lastIndexOf(sep);
    if (lastSlash === -1) {
      return { dirPath: "", basename: filePath };
    }
    return {
      dirPath: filePath.slice(0, lastSlash + 1),
      basename: filePath.slice(lastSlash + 1)
    };
  }
  /**
   * Format home directory path for display (shows ~ on Unix, full path on Windows)
   */
  static formatHome(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return filePath;
    }
    const home = getHomeDir();
    if (!home) {
      return filePath;
    }
    if (filePath.startsWith(home)) {
      return filePath.replace(home, "~");
    }
    return filePath;
  }
  /**
   * Expand user home in path (cross-platform)
   * Handles ~ on Unix and %USERPROFILE% on Windows
   */
  static expandHome(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return filePath;
    }
    const muxRoot = env2.UNIX_ROOT;
    if (muxRoot) {
      const normalizedMuxRoot = muxRoot.replace(/[\\/]+$/g, "");
      const sep = getSeparator();
      const prefixes = ["~/.unix", "~\\.unix"];
      for (const prefix of prefixes) {
        if (filePath === prefix) {
          return normalizedMuxRoot;
        }
        const slashPrefix = `${prefix}/`;
        const backslashPrefix = `${prefix}\\`;
        if (filePath.startsWith(slashPrefix) || filePath.startsWith(backslashPrefix)) {
          const rest = filePath.slice(prefix.length + 1);
          const normalizedRest = rest.replace(/[\\/]+/g, sep);
          return normalizedMuxRoot + (normalizedRest ? sep + normalizedRest : "");
        }
      }
    }
    if (filePath === "~") {
      return getHomeDir() || filePath;
    }
    if (filePath.startsWith("~/") || filePath.startsWith("~\\")) {
      const home = getHomeDir();
      if (!home) return filePath;
      const sep = getSeparator();
      const rest = filePath.slice(2);
      return home + (rest ? sep + rest.replace(/[\\/]+/g, sep) : "");
    }
    if (isWindowsPlatform() && filePath.includes("%USERPROFILE%")) {
      const home = getHomeDir();
      if (!home) return filePath;
      return filePath.replace(/%USERPROFILE%/g, home);
    }
    return filePath;
  }
  /**
   * Get project name from path (OS-aware)
   * Extracts the final directory name from a project path
   */
  static getProjectName(projectPath) {
    return this.basename(projectPath) || "unknown";
  }
};

// src/node/runtime/tildeExpansion.ts
function expandTilde(filePath) {
  const muxPrefixes = ["~/.unix", "~\\.unix", "~/.cmux", "~\\.cmux"];
  for (const prefix of muxPrefixes) {
    if (!filePath.startsWith(prefix)) {
      continue;
    }
    const nextChar = filePath.at(prefix.length);
    if (nextChar !== void 0 && nextChar !== "/" && nextChar !== "\\") {
      continue;
    }
    const unixHome = getUnixHome();
    const suffix = filePath.slice(prefix.length).replace(/^[/\\]+/, "");
    const normalizedSuffix = suffix.replace(/[/\\]+/g, path4.sep);
    return normalizedSuffix ? path4.join(unixHome, normalizedSuffix) : unixHome;
  }
  return PlatformPaths.expandHome(filePath);
}
function expandTildeForSSH(path21) {
  if (path21 === "~") {
    return '"$HOME"';
  } else if (path21.startsWith("~/")) {
    const pathAfterTilde = path21.slice(2);
    const escaped = pathAfterTilde.replace(/\\/g, "\\\\").replace(/"/g, '\\"').replace(/\$/g, "\\$").replace(/`/g, "\\`");
    return `"$HOME/${escaped}"`;
  } else {
    return `"${path21.replace(/\\/g, "\\\\").replace(/"/g, '\\"').replace(/\$/g, "\\$").replace(/`/g, "\\`")}"`;
  }
}
function cdCommandForSSH(path21) {
  return `cd ${expandTildeForSSH(path21)}`;
}

// src/node/runtime/LocalBaseRuntime.ts
var LocalBaseRuntime = class {
  async exec(command, options) {
    const startTime = performance.now();
    const cwd = options.cwd;
    try {
      await fsPromises2.access(cwd);
    } catch (err) {
      throw new RuntimeError(
        `Working directory does not exist: ${cwd}`,
        "exec",
        err instanceof Error ? err : void 0
      );
    }
    const bashPath = getBashPath();
    const spawnCommand = bashPath;
    const nonInteractivePrelude = Object.entries(NON_INTERACTIVE_ENV_VARS).map(([key, value2]) => `export ${key}=${shellQuote(value2)}`).join("\n");
    const spawnArgs = ["-c", `${nonInteractivePrelude}
${command}`];
    const defaultPath = "/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin";
    const effectivePath = (options.env?.PATH && options.env.PATH.length > 0 ? options.env.PATH : process.env.PATH) ?? defaultPath;
    const childProcess = spawn(spawnCommand, spawnArgs, {
      cwd,
      env: {
        ...process.env,
        ...options.env ?? {},
        ...NON_INTERACTIVE_ENV_VARS,
        PATH: effectivePath
      },
      stdio: ["pipe", "pipe", "pipe"],
      // CRITICAL: Spawn as detached process group leader to enable cleanup of background processes.
      // When a bash script spawns background processes (e.g., `sleep 100 &`), we need to kill
      // the entire process group (including all backgrounded children) via process.kill(-pid).
      // NOTE: detached:true does NOT cause bash to wait for background jobs when using 'exit' event
      // instead of 'close' event. The 'exit' event fires when bash exits, ignoring background children.
      detached: true,
      // Prevent console window from appearing on Windows (WSL bash spawns steal focus otherwise)
      windowsHide: true
    });
    const disposable = new DisposableProcess(childProcess);
    const stdout = Readable.toWeb(childProcess.stdout);
    const stderr = Readable.toWeb(childProcess.stderr);
    const stdin = Writable.toWeb(childProcess.stdin);
    let timedOut = false;
    let aborted = false;
    const exitCode = new Promise((resolve3, reject) => {
      childProcess.on("exit", (code) => {
        if (childProcess.pid !== void 0) {
          killProcessTree(childProcess.pid);
        }
        if (aborted || options.abortSignal?.aborted) {
          resolve3(EXIT_CODE_ABORTED);
          return;
        }
        if (timedOut) {
          resolve3(EXIT_CODE_TIMEOUT);
          return;
        }
        resolve3(code ?? 0);
      });
      childProcess.on("error", (err) => {
        reject(new RuntimeError(`Failed to execute command: ${err.message}`, "exec", err));
      });
    });
    const duration = exitCode.then(() => performance.now() - startTime);
    void exitCode.catch(() => void 0);
    void duration.catch(() => void 0);
    disposable.addCleanup(() => {
      if (childProcess.pid === void 0) return;
      killProcessTree(childProcess.pid);
    });
    if (options.abortSignal) {
      options.abortSignal.addEventListener("abort", () => {
        aborted = true;
        disposable[Symbol.dispose]();
      });
    }
    if (options.timeout !== void 0) {
      const timeoutHandle = setTimeout(() => {
        timedOut = true;
        disposable[Symbol.dispose]();
      }, options.timeout * 1e3);
      void exitCode.catch(() => void 0).finally(() => clearTimeout(timeoutHandle));
    }
    return { stdout, stderr, stdin, exitCode, duration };
  }
  readFile(filePath, _abortSignal) {
    const expandedPath = expandTilde(filePath);
    const nodeStream = fs3.createReadStream(expandedPath);
    const webStream = Readable.toWeb(nodeStream);
    return new ReadableStream({
      async start(controller) {
        try {
          const reader = webStream.getReader();
          while (true) {
            const { done, value: value2 } = await reader.read();
            if (done) break;
            controller.enqueue(value2);
          }
          controller.close();
        } catch (err) {
          controller.error(
            new RuntimeError(
              `Failed to read file ${filePath}: ${err instanceof Error ? err.message : String(err)}`,
              "file_io",
              err instanceof Error ? err : void 0
            )
          );
        }
      }
    });
  }
  writeFile(filePath, _abortSignal) {
    const expandedPath = expandTilde(filePath);
    let tempPath;
    let writer;
    let resolvedPath;
    let originalMode;
    return new WritableStream({
      async start() {
        try {
          resolvedPath = await fsPromises2.realpath(expandedPath);
          const stat3 = await fsPromises2.stat(resolvedPath);
          originalMode = stat3.mode;
        } catch {
          resolvedPath = expandedPath;
          originalMode = void 0;
        }
        const parentDir = path5.dirname(resolvedPath);
        await fsPromises2.mkdir(parentDir, { recursive: true });
        tempPath = `${resolvedPath}.tmp.${Date.now()}`;
        const nodeStream = fs3.createWriteStream(tempPath);
        const webStream = Writable.toWeb(nodeStream);
        writer = webStream.getWriter();
      },
      async write(chunk) {
        await writer.write(chunk);
      },
      async close() {
        await writer.close();
        try {
          if (originalMode !== void 0) {
            await fsPromises2.chmod(tempPath, originalMode);
          }
          await fsPromises2.rename(tempPath, resolvedPath);
        } catch (err) {
          throw new RuntimeError(
            `Failed to write file ${filePath}: ${err instanceof Error ? err.message : String(err)}`,
            "file_io",
            err instanceof Error ? err : void 0
          );
        }
      },
      async abort(reason) {
        await writer.abort();
        try {
          await fsPromises2.unlink(tempPath);
        } catch {
        }
        throw new RuntimeError(
          `Failed to write file ${filePath}: ${String(reason)}`,
          "file_io"
        );
      }
    });
  }
  async stat(filePath, _abortSignal) {
    const expandedPath = expandTilde(filePath);
    try {
      const stats = await fsPromises2.stat(expandedPath);
      return {
        size: stats.size,
        modifiedTime: stats.mtime,
        isDirectory: stats.isDirectory()
      };
    } catch (err) {
      throw new RuntimeError(
        `Failed to stat ${filePath}: ${err instanceof Error ? err.message : String(err)}`,
        "file_io",
        err instanceof Error ? err : void 0
      );
    }
  }
  async ensureDir(dirPath) {
    const expandedPath = expandTilde(dirPath);
    try {
      await fsPromises2.mkdir(expandedPath, { recursive: true });
    } catch (err) {
      throw new RuntimeError(
        `Failed to create directory ${dirPath}: ${err instanceof Error ? err.message : String(err)}`,
        "file_io",
        err instanceof Error ? err : void 0
      );
    }
  }
  resolvePath(filePath) {
    const expanded = expandTilde(filePath);
    return Promise.resolve(path5.resolve(expanded));
  }
  normalizePath(targetPath, basePath) {
    const target = targetPath.trim();
    if (target === ".") {
      return path5.resolve(basePath);
    }
    const expanded = expandTilde(target);
    return path5.resolve(basePath, expanded);
  }
  /**
   * Get the runtime's temp directory.
   * Uses OS temp dir on local systems.
   */
  tempDir() {
    const isWindows = process.platform === "win32";
    return Promise.resolve(isWindows ? process.env.TEMP ?? "C:\\Temp" : "/tmp");
  }
  getUnixHome() {
    return "~/.unix";
  }
  /**
   * Local runtimes are always ready.
   */
  ensureReady() {
    return Promise.resolve({ ready: true });
  }
  /**
   * Helper to run .unix/init hook if it exists and is executable.
   * Shared between WorktreeRuntime and LocalRuntime.
   * @param workspacePath - Path to the workspace directory
   * @param muxEnv - UNIX_ environment variables (from getUnixEnv)
   * @param initLogger - Logger for streaming output
   */
  async runInitHook(workspacePath, muxEnv, initLogger) {
    const projectPath = muxEnv.UNIX_PROJECT_PATH;
    const hookPath = getInitHookPath(projectPath);
    initLogger.logStep(`Running init hook: ${hookPath}`);
    const loggers = createLineBufferedLoggers(initLogger);
    return new Promise((resolve3) => {
      const bashPath = getBashPath();
      const proc = spawn(bashPath, ["-c", `"${hookPath}"`], {
        cwd: workspacePath,
        stdio: ["ignore", "pipe", "pipe"],
        env: {
          ...process.env,
          ...muxEnv
        },
        // Prevent console window from appearing on Windows
        windowsHide: true
      });
      proc.stdout.on("data", (data) => {
        loggers.stdout.append(data.toString());
      });
      proc.stderr.on("data", (data) => {
        loggers.stderr.append(data.toString());
      });
      proc.on("close", (code) => {
        loggers.stdout.flush();
        loggers.stderr.flush();
        initLogger.logComplete(code ?? 0);
        resolve3();
      });
      proc.on("error", (err) => {
        initLogger.logStderr(`Error running init hook: ${err.message}`);
        initLogger.logComplete(-1);
        resolve3();
      });
    });
  }
};

// src/node/runtime/LocalRuntime.ts
var LocalRuntime = class extends LocalBaseRuntime {
  constructor(projectPath) {
    super();
    this.projectPath = projectPath;
  }
  /**
   * For LocalRuntime, the workspace path is always the project path itself.
   * The workspaceName parameter is ignored since there's only one workspace per project.
   */
  getWorkspacePath(_projectPath, _workspaceName) {
    return this.projectPath;
  }
  /**
   * Creating a workspace is a no-op for LocalRuntime since we use the project directory directly.
   * We just verify the directory exists.
   */
  async createWorkspace(params) {
    const { initLogger } = params;
    try {
      initLogger.logStep("Using project directory directly (no worktree isolation)");
      try {
        await this.stat(this.projectPath);
      } catch {
        return {
          success: false,
          error: `Project directory does not exist: ${this.projectPath}`
        };
      }
      initLogger.logStep("Project directory verified");
      return { success: true, workspacePath: this.projectPath };
    } catch (error) {
      return {
        success: false,
        error: getErrorMessage3(error)
      };
    }
  }
  async initWorkspace(params) {
    const { projectPath, branchName, workspacePath, initLogger, env: env3, skipInitHook } = params;
    try {
      if (skipInitHook) {
        initLogger.logStep("Skipping .unix/init hook (disabled for this task)");
        initLogger.logComplete(0);
        return { success: true };
      }
      const hookExists = await checkInitHookExists(projectPath);
      if (hookExists) {
        const muxEnv = { ...env3, ...getUnixEnv(projectPath, "local", branchName) };
        await this.runInitHook(workspacePath, muxEnv, initLogger);
      } else {
        initLogger.logComplete(0);
      }
      return { success: true };
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(`Initialization failed: ${errorMsg}`);
      initLogger.logComplete(-1);
      return {
        success: false,
        error: errorMsg
      };
    }
  }
  /**
   * Renaming is a no-op for LocalRuntime - the workspace path is always the project directory.
   * Returns success so the metadata (workspace name) can be updated in config.
   */
  // eslint-disable-next-line @typescript-eslint/require-await
  async renameWorkspace(_projectPath, _oldName, _newName, _abortSignal) {
    return { success: true, oldPath: this.projectPath, newPath: this.projectPath };
  }
  /**
   * Deleting is a no-op for LocalRuntime - we never delete the user's project directory.
   * Returns success so the workspace entry can be removed from config.
   */
  // eslint-disable-next-line @typescript-eslint/require-await
  async deleteWorkspace(_projectPath, _workspaceName, _force, _abortSignal) {
    return { success: true, deletedPath: this.projectPath };
  }
  /**
   * Fork for LocalRuntime creates a new workspace entry pointing to the same project directory.
   * Since LocalRuntime doesn't create separate directories, "forking" just means:
   * 1. A new workspace ID with the new name
   * 2. Copied chat history (handled by workspaceService)
   * 3. Same project directory as source
   *
   * This enables conversation branching without git worktree overhead.
   */
  async forkWorkspace(params) {
    const { initLogger } = params;
    initLogger.logStep("Creating conversation fork (no worktree isolation)");
    try {
      await this.stat(this.projectPath);
    } catch {
      return {
        success: false,
        error: `Project directory does not exist: ${this.projectPath}`
      };
    }
    initLogger.logStep("Project directory verified");
    return {
      success: true,
      workspacePath: this.projectPath
      // sourceBranch is optional for LocalRuntime since no git operations are involved
    };
  }
};

// src/node/worktree/WorktreeManager.ts
import * as fsPromises3 from "fs/promises";
import * as path7 from "path";

// src/node/git.ts
import * as fs4 from "fs";
import * as path6 from "path";
var STALE_LOCK_AGE_MS = 5e3;
function cleanStaleLock(repoPath) {
  const lockPath = path6.join(repoPath, ".git", "index.lock");
  try {
    const stat3 = fs4.statSync(lockPath);
    const ageMs = Date.now() - stat3.mtimeMs;
    if (ageMs > STALE_LOCK_AGE_MS) {
      fs4.unlinkSync(lockPath);
      log.info(`Removed stale git index.lock (age: ${Math.round(ageMs / 1e3)}s) at ${lockPath}`);
    }
  } catch {
  }
}
async function listLocalBranches(projectPath) {
  var _stack = [];
  try {
    const proc = __using(_stack, execAsync(
      `git -C "${projectPath}" for-each-ref --format="%(refname:short)" refs/heads`
    ));
    const { stdout } = await proc.result;
    return stdout.split("\n").map((line) => line.trim()).filter((line) => line.length > 0).sort((a, b) => a.localeCompare(b));
  } catch (_) {
    var _error = _, _hasError = true;
  } finally {
    __callDispose(_stack, _error, _hasError);
  }
}
async function getCurrentBranch(projectPath) {
  try {
    var _stack = [];
    try {
      const proc = __using(_stack, execAsync(`git -C "${projectPath}" rev-parse --abbrev-ref HEAD`));
      const { stdout } = await proc.result;
      const branch = stdout.trim();
      if (!branch || branch === "HEAD") {
        return null;
      }
      return branch;
    } catch (_) {
      var _error = _, _hasError = true;
    } finally {
      __callDispose(_stack, _error, _hasError);
    }
  } catch {
    return null;
  }
}

// src/common/utils/planStorage.ts
var DEFAULT_UNIX_HOME = "~/.unix";
function getPlanFilePath(workspaceName, projectName, unixHome = DEFAULT_UNIX_HOME) {
  return `${unixHome}/plans/${projectName}/${workspaceName}.md`;
}
function getLegacyPlanFilePath(workspaceId) {
  return `${DEFAULT_UNIX_HOME}/plans/${workspaceId}.md`;
}

// src/node/utils/runtime/helpers.ts
function getProjectName(projectPath) {
  return PlatformPaths.getProjectName(projectPath);
}
async function execBuffered(runtime, command, options) {
  const stream = await runtime.exec(command, options);
  if (options.stdin !== void 0) {
    const writer = stream.stdin.getWriter();
    try {
      await writer.write(new TextEncoder().encode(options.stdin));
      await writer.close();
    } catch (err) {
      writer.releaseLock();
      throw err;
    }
  } else {
    await stream.stdin.close();
  }
  const [stdout, stderr, exitCode, duration] = await Promise.all([
    streamToString(stream.stdout),
    streamToString(stream.stderr),
    stream.exitCode,
    stream.duration
  ]);
  return { stdout, stderr, exitCode, duration };
}
async function readFileString(runtime, path21, abortSignal) {
  const stream = runtime.readFile(path21, abortSignal);
  return streamToString(stream);
}
async function streamToString(stream) {
  const reader = stream.getReader();
  const decoder = new TextDecoder("utf-8");
  let result = "";
  try {
    while (true) {
      const { done, value: value2 } = await reader.read();
      if (done) break;
      result += decoder.decode(value2, { stream: true });
    }
    result += decoder.decode();
    return result;
  } finally {
    reader.releaseLock();
  }
}
async function readPlanFile(runtime, workspaceName, projectName, workspaceId) {
  const unixHome = runtime.getUnixHome();
  const planPath = getPlanFilePath(workspaceName, projectName, unixHome);
  const legacyPath = getLegacyPlanFilePath(workspaceId);
  const resolvedPath = await runtime.resolvePath(planPath);
  try {
    const content = await readFileString(runtime, planPath);
    return { content, exists: true, path: resolvedPath };
  } catch {
    try {
      const content = await readFileString(runtime, legacyPath);
      try {
        const planDir = planPath.substring(0, planPath.lastIndexOf("/"));
        await execBuffered(runtime, `mkdir -p "${planDir}" && mv "${legacyPath}" "${planPath}"`, {
          cwd: "/tmp",
          timeout: 5
        });
      } catch {
      }
      return { content, exists: true, path: resolvedPath };
    } catch {
      return { content: "", exists: false, path: resolvedPath };
    }
  }
}

// src/node/utils/paths.ts
import { execFileSync as execFileSync2 } from "child_process";
function toPosixPath(windowsPath) {
  if (process.platform !== "win32") return windowsPath;
  try {
    return execFileSync2("cygpath", ["-u", windowsPath], { encoding: "utf8" }).trim();
  } catch {
    return windowsPath;
  }
}

// src/node/worktree/WorktreeManager.ts
var WorktreeManager = class {
  constructor(srcBaseDir) {
    this.srcBaseDir = expandTilde(srcBaseDir);
  }
  getWorkspacePath(projectPath, workspaceName) {
    const projectName = getProjectName(projectPath);
    return path7.join(this.srcBaseDir, projectName, workspaceName);
  }
  async createWorkspace(params) {
    const { projectPath, branchName, trunkBranch, initLogger } = params;
    cleanStaleLock(projectPath);
    try {
      const workspacePath = this.getWorkspacePath(projectPath, branchName);
      initLogger.logStep("Creating git worktree...");
      const parentDir = path7.dirname(workspacePath);
      try {
        await fsPromises3.access(parentDir);
      } catch {
        await fsPromises3.mkdir(parentDir, { recursive: true });
      }
      try {
        await fsPromises3.access(workspacePath);
        return {
          success: false,
          error: `Workspace already exists at ${workspacePath}`
        };
      } catch {
      }
      const localBranches = await listLocalBranches(projectPath);
      const branchExists = localBranches.includes(branchName);
      const fetchedOrigin = await this.fetchOriginTrunk(projectPath, trunkBranch, initLogger);
      const shouldUseOrigin = fetchedOrigin && await this.canFastForwardToOrigin(projectPath, trunkBranch, initLogger);
      if (branchExists) {
        var _stack = [];
        try {
          const proc = __using(_stack, execAsync(
            `git -C "${projectPath}" worktree add "${workspacePath}" "${branchName}"`
          ));
          await proc.result;
        } catch (_) {
          var _error = _, _hasError = true;
        } finally {
          __callDispose(_stack, _error, _hasError);
        }
      } else {
        var _stack2 = [];
        try {
          const newBranchBase = shouldUseOrigin ? `origin/${trunkBranch}` : trunkBranch;
          const proc = __using(_stack2, execAsync(
            `git -C "${projectPath}" worktree add -b "${branchName}" "${workspacePath}" "${newBranchBase}"`
          ));
          await proc.result;
        } catch (_2) {
          var _error2 = _2, _hasError2 = true;
        } finally {
          __callDispose(_stack2, _error2, _hasError2);
        }
      }
      initLogger.logStep("Worktree created successfully");
      if (shouldUseOrigin && branchExists) {
        await this.fastForwardToOrigin(workspacePath, trunkBranch, initLogger);
      }
      return { success: true, workspacePath };
    } catch (error) {
      return {
        success: false,
        error: getErrorMessage3(error)
      };
    }
  }
  /**
   * Fetch trunk branch from origin before worktree creation.
   * Returns true if fetch succeeded (origin is available for branching).
   */
  async fetchOriginTrunk(projectPath, trunkBranch, initLogger) {
    try {
      var _stack = [];
      try {
        initLogger.logStep(`Fetching latest from origin/${trunkBranch}...`);
        const fetchProc = __using(_stack, execAsync(`git -C "${projectPath}" fetch origin "${trunkBranch}"`));
        await fetchProc.result;
        initLogger.logStep("Fetched latest from origin");
        return true;
      } catch (_) {
        var _error = _, _hasError = true;
      } finally {
        __callDispose(_stack, _error, _hasError);
      }
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      if (errorMsg.includes("couldn't find remote ref")) {
        initLogger.logStep(`Branch "${trunkBranch}" not found on origin; using local state.`);
      } else {
        initLogger.logStderr(
          `Note: Could not fetch from origin (${errorMsg}), using local branch state`
        );
      }
      return false;
    }
  }
  /**
   * Check if local trunk can fast-forward to origin/<trunk>.
   * Returns true if local is behind or equal to origin (safe to use origin).
   * Returns false if local is ahead or diverged (preserve local state).
   */
  async canFastForwardToOrigin(projectPath, trunkBranch, initLogger) {
    try {
      var _stack = [];
      try {
        const proc = __using(_stack, execAsync(
          `git -C "${projectPath}" merge-base --is-ancestor "${trunkBranch}" "origin/${trunkBranch}"`
        ));
        await proc.result;
        return true;
      } catch (_) {
        var _error = _, _hasError = true;
      } finally {
        __callDispose(_stack, _error, _hasError);
      }
    } catch {
      initLogger.logStderr(
        `Note: Local ${trunkBranch} is ahead of or diverged from origin, using local state`
      );
      return false;
    }
  }
  /**
   * Fast-forward merge to latest origin/<trunkBranch> after checkout.
   * Best-effort operation for existing branches that may be behind origin.
   */
  async fastForwardToOrigin(workspacePath, trunkBranch, initLogger) {
    try {
      var _stack = [];
      try {
        initLogger.logStep("Fast-forward merging...");
        const mergeProc = __using(_stack, execAsync(
          `git -C "${workspacePath}" merge --ff-only "origin/${trunkBranch}"`
        ));
        await mergeProc.result;
        initLogger.logStep("Fast-forwarded to latest origin successfully");
      } catch (_) {
        var _error = _, _hasError = true;
      } finally {
        __callDispose(_stack, _error, _hasError);
      }
    } catch (mergeError) {
      const errorMsg = getErrorMessage3(mergeError);
      initLogger.logStderr(`Note: Fast-forward failed (${errorMsg}), using local branch state`);
    }
  }
  async renameWorkspace(projectPath, oldName, newName) {
    cleanStaleLock(projectPath);
    const oldPath = this.getWorkspacePath(projectPath, oldName);
    const newPath = this.getWorkspacePath(projectPath, newName);
    try {
      var _stack2 = [];
      try {
        const moveProc = __using(_stack2, execAsync(`git -C "${projectPath}" worktree move "${oldPath}" "${newPath}"`));
        await moveProc.result;
        try {
          var _stack = [];
          try {
            const branchProc = __using(_stack, execAsync(`git -C "${newPath}" branch -m "${oldName}" "${newName}"`));
            await branchProc.result;
          } catch (_) {
            var _error = _, _hasError = true;
          } finally {
            __callDispose(_stack, _error, _hasError);
          }
        } catch {
        }
        return { success: true, oldPath, newPath };
      } catch (_2) {
        var _error2 = _2, _hasError2 = true;
      } finally {
        __callDispose(_stack2, _error2, _hasError2);
      }
    } catch (error) {
      return { success: false, error: `Failed to rename workspace: ${getErrorMessage3(error)}` };
    }
  }
  async deleteWorkspace(projectPath, workspaceName, force) {
    cleanStaleLock(projectPath);
    const isInPlace = projectPath === workspaceName;
    const shouldDeleteBranch = !isInPlace;
    const tryDeleteBranch = async () => {
      if (!shouldDeleteBranch) return;
      const branchToDelete = workspaceName.trim();
      if (!branchToDelete) {
        log.debug("Skipping git branch deletion: empty workspace name", {
          projectPath,
          workspaceName
        });
        return;
      }
      let localBranches;
      try {
        localBranches = await listLocalBranches(projectPath);
      } catch (error) {
        log.debug("Failed to list local branches; skipping branch deletion", {
          projectPath,
          workspaceName: branchToDelete,
          error: getErrorMessage3(error)
        });
        return;
      }
      if (!localBranches.includes(branchToDelete)) {
        log.debug("Skipping git branch deletion: branch does not exist locally", {
          projectPath,
          workspaceName: branchToDelete
        });
        return;
      }
      const protectedBranches = /* @__PURE__ */ new Set(["main", "master", "trunk", "develop", "default"]);
      if (localBranches.length === 1) {
        protectedBranches.add(localBranches[0]);
      }
      const currentBranch = await getCurrentBranch(projectPath);
      if (currentBranch) {
        protectedBranches.add(currentBranch);
      }
      try {
        var _stack6 = [];
        try {
          const originHeadProc = __using(_stack6, execAsync(
            `git -C "${projectPath}" symbolic-ref refs/remotes/origin/HEAD`
          ));
          const { stdout } = await originHeadProc.result;
          const ref = stdout.trim();
          const prefix = "refs/remotes/origin/";
          if (ref.startsWith(prefix)) {
            protectedBranches.add(ref.slice(prefix.length));
          }
        } catch (_6) {
          var _error6 = _6, _hasError6 = true;
        } finally {
          __callDispose(_stack6, _error6, _hasError6);
        }
      } catch {
      }
      if (protectedBranches.has(branchToDelete)) {
        log.debug("Skipping git branch deletion: protected branch", {
          projectPath,
          workspaceName: branchToDelete
        });
        return;
      }
      try {
        var _stack7 = [];
        try {
          const worktreeProc = __using(_stack7, execAsync(`git -C "${projectPath}" worktree list --porcelain`));
          const { stdout } = await worktreeProc.result;
          const needle = `branch refs/heads/${branchToDelete}`;
          const isCheckedOut = stdout.split("\n").some((line) => line.trim() === needle);
          if (isCheckedOut) {
            log.debug("Skipping git branch deletion: branch still checked out by a worktree", {
              projectPath,
              workspaceName: branchToDelete
            });
            return;
          }
        } catch (_7) {
          var _error7 = _7, _hasError7 = true;
        } finally {
          __callDispose(_stack7, _error7, _hasError7);
        }
      } catch (error) {
        log.debug("Failed to check worktree list before branch deletion; proceeding", {
          projectPath,
          workspaceName: branchToDelete,
          error: getErrorMessage3(error)
        });
      }
      const deleteFlag = force ? "-D" : "-d";
      try {
        var _stack8 = [];
        try {
          const deleteProc = __using(_stack8, execAsync(
            `git -C "${projectPath}" branch ${deleteFlag} "${branchToDelete}"`
          ));
          await deleteProc.result;
        } catch (_8) {
          var _error8 = _8, _hasError8 = true;
        } finally {
          __callDispose(_stack8, _error8, _hasError8);
        }
      } catch (error) {
        log.debug("Failed to delete git branch after removing worktree", {
          projectPath,
          workspaceName: branchToDelete,
          error: getErrorMessage3(error)
        });
      }
    };
    const deletedPath = this.getWorkspacePath(projectPath, workspaceName);
    try {
      await fsPromises3.access(deletedPath);
    } catch {
      if (!isInPlace) {
        try {
          var _stack = [];
          try {
            const pruneProc = __using(_stack, execAsync(`git -C "${projectPath}" worktree prune`));
            await pruneProc.result;
          } catch (_) {
            var _error = _, _hasError = true;
          } finally {
            __callDispose(_stack, _error, _hasError);
          }
        } catch {
        }
      }
      await tryDeleteBranch();
      return { success: true, deletedPath };
    }
    if (isInPlace) {
      return { success: true, deletedPath };
    }
    try {
      var _stack2 = [];
      try {
        const forceFlag = force ? " --force" : "";
        const proc = __using(_stack2, execAsync(
          `git -C "${projectPath}" worktree remove${forceFlag} "${deletedPath}"`
        ));
        await proc.result;
        await tryDeleteBranch();
        return { success: true, deletedPath };
      } catch (_2) {
        var _error2 = _2, _hasError2 = true;
      } finally {
        __callDispose(_stack2, _error2, _hasError2);
      }
    } catch (error) {
      const message = getErrorMessage3(error);
      const normalizedError = message.toLowerCase();
      const looksLikeMissingWorktree = normalizedError.includes("not a working tree") || normalizedError.includes("does not exist") || normalizedError.includes("no such file");
      if (looksLikeMissingWorktree) {
        try {
          var _stack3 = [];
          try {
            const pruneProc = __using(_stack3, execAsync(`git -C "${projectPath}" worktree prune`));
            await pruneProc.result;
          } catch (_3) {
            var _error3 = _3, _hasError3 = true;
          } finally {
            __callDispose(_stack3, _error3, _hasError3);
          }
        } catch {
        }
        await tryDeleteBranch();
        return { success: true, deletedPath };
      }
      if (force) {
        try {
          var _stack5 = [];
          try {
            try {
              var _stack4 = [];
              try {
                const pruneProc = __using(_stack4, execAsync(`git -C "${projectPath}" worktree prune`));
                await pruneProc.result;
              } catch (_4) {
                var _error4 = _4, _hasError4 = true;
              } finally {
                __callDispose(_stack4, _error4, _hasError4);
              }
            } catch {
            }
            const rmProc = __using(_stack5, execAsync(`rm -rf "${toPosixPath(deletedPath)}"`, {
              shell: getBashPath()
            }));
            await rmProc.result;
            await tryDeleteBranch();
            return { success: true, deletedPath };
          } catch (_5) {
            var _error5 = _5, _hasError5 = true;
          } finally {
            __callDispose(_stack5, _error5, _hasError5);
          }
        } catch (rmError) {
          return {
            success: false,
            error: `Failed to remove worktree via git and rm: ${getErrorMessage3(rmError)}`
          };
        }
      }
      return { success: false, error: `Failed to remove worktree: ${message}` };
    }
  }
  async forkWorkspace(params) {
    const { projectPath, sourceWorkspaceName, newWorkspaceName, initLogger } = params;
    const sourceWorkspacePath = this.getWorkspacePath(projectPath, sourceWorkspaceName);
    try {
      var _stack = [];
      try {
        const proc = __using(_stack, execAsync(`git -C "${sourceWorkspacePath}" branch --show-current`));
        const { stdout } = await proc.result;
        const sourceBranch = stdout.trim();
        if (!sourceBranch) {
          return {
            success: false,
            error: "Failed to detect branch in source workspace"
          };
        }
        const createResult = await this.createWorkspace({
          projectPath,
          branchName: newWorkspaceName,
          trunkBranch: sourceBranch,
          // Fork from source branch instead of main/master
          initLogger
        });
        if (!createResult.success || !createResult.workspacePath) {
          return {
            success: false,
            error: createResult.error ?? "Failed to create workspace"
          };
        }
        return {
          success: true,
          workspacePath: createResult.workspacePath,
          sourceBranch
        };
      } catch (_) {
        var _error = _, _hasError = true;
      } finally {
        __callDispose(_stack, _error, _hasError);
      }
    } catch (error) {
      return {
        success: false,
        error: getErrorMessage3(error)
      };
    }
  }
};

// src/node/runtime/WorktreeRuntime.ts
var WorktreeRuntime = class extends LocalBaseRuntime {
  constructor(srcBaseDir) {
    super();
    this.worktreeManager = new WorktreeManager(srcBaseDir);
  }
  getWorkspacePath(projectPath, workspaceName) {
    return this.worktreeManager.getWorkspacePath(projectPath, workspaceName);
  }
  async createWorkspace(params) {
    return this.worktreeManager.createWorkspace({
      projectPath: params.projectPath,
      branchName: params.branchName,
      trunkBranch: params.trunkBranch,
      initLogger: params.initLogger
    });
  }
  async initWorkspace(params) {
    const { projectPath, branchName, workspacePath, initLogger, env: env3, skipInitHook } = params;
    try {
      if (skipInitHook) {
        initLogger.logStep("Skipping .unix/init hook (disabled for this task)");
        initLogger.logComplete(0);
        return { success: true };
      }
      const hookExists = await checkInitHookExists(projectPath);
      if (hookExists) {
        const muxEnv = { ...env3, ...getUnixEnv(projectPath, "worktree", branchName) };
        await this.runInitHook(workspacePath, muxEnv, initLogger);
      } else {
        initLogger.logComplete(0);
      }
      return { success: true };
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(`Initialization failed: ${errorMsg}`);
      initLogger.logComplete(-1);
      return {
        success: false,
        error: errorMsg
      };
    }
  }
  async renameWorkspace(projectPath, oldName, newName, _abortSignal) {
    return this.worktreeManager.renameWorkspace(projectPath, oldName, newName);
  }
  async deleteWorkspace(projectPath, workspaceName, force, _abortSignal) {
    return this.worktreeManager.deleteWorkspace(projectPath, workspaceName, force);
  }
  async forkWorkspace(params) {
    return this.worktreeManager.forkWorkspace(params);
  }
};

// src/node/runtime/SSHRuntime.ts
import { spawn as spawn2 } from "child_process";
import * as path8 from "path";

// src/node/runtime/RemoteRuntime.ts
import { Readable as Readable2 } from "stream";

// src/node/utils/streamErrors.ts
function normalizeError(error) {
  if (error instanceof Error) {
    return error;
  }
  if (typeof error === "string") {
    return new Error(error);
  }
  return new Error("Unknown error");
}
function getErrorCode(error) {
  if (!error || typeof error !== "object") {
    return void 0;
  }
  if ("code" in error && typeof error.code === "string") {
    return error.code;
  }
  return void 0;
}
function isIgnorableStreamError(error) {
  const code = getErrorCode(error);
  return code === "EPIPE" || code === "ECONNRESET";
}
function attachStreamErrorHandler(emitter, label, options = {}) {
  const handler = (error) => {
    const normalized = normalizeError(error);
    const info = {
      label,
      code: getErrorCode(error),
      message: normalized.message
    };
    if (isIgnorableStreamError(error)) {
      options.logger?.debug("Ignored stream error", info, normalized);
      options.onIgnorable?.(normalized, info);
      return;
    }
    options.logger?.warn("Stream error", info, normalized);
    options.onUnexpected?.(normalized, info);
  };
  emitter.on("error", handler);
  return () => {
    emitter.removeListener("error", handler);
  };
}

// src/node/runtime/streamUtils.ts
var shescape = {
  quote(value2) {
    const s = String(value2);
    if (s.length === 0) return "''";
    return "'" + s.replace(/'/g, `'"'"'`) + "'";
  }
};
async function streamToString2(stream) {
  const reader = stream.getReader();
  const decoder = new TextDecoder("utf-8");
  let result = "";
  try {
    while (true) {
      const { done, value: value2 } = await reader.read();
      if (done) break;
      result += decoder.decode(value2, { stream: true });
    }
    result += decoder.decode();
    return result;
  } finally {
    reader.releaseLock();
  }
}

// src/node/runtime/RemoteRuntime.ts
var RemoteRuntime = class {
  /**
   * Called when exec completes with an exit code.
   * Subclasses can use this for connection pool health tracking.
   * @param stderr - Captured stderr for error reporting (e.g., SSH connection failures)
   */
  onExitCode(_exitCode, _options, _stderr) {
  }
  /**
   * Execute command with streaming I/O.
   * Shared implementation that delegates process spawning to subclass.
   */
  async exec(command, options) {
    const startTime = performance.now();
    if (options.abortSignal?.aborted) {
      throw new RuntimeError("Operation aborted before execution", "exec");
    }
    const parts = [];
    parts.push(this.cdCommand(options.cwd));
    const envVars = { ...options.env, ...NON_INTERACTIVE_ENV_VARS };
    for (const [key, value2] of Object.entries(envVars)) {
      parts.push(`export ${key}=${shescape.quote(value2)}`);
    }
    parts.push(command);
    let fullCommand = parts.join(" && ");
    fullCommand = `bash -c ${shescape.quote(fullCommand)}`;
    if (options.timeout !== void 0) {
      const remoteTimeout = Math.ceil(options.timeout) + 1;
      fullCommand = `timeout -s KILL ${remoteTimeout} ${fullCommand}`;
    }
    const { process: childProcess } = await this.spawnRemoteProcess(fullCommand, options);
    if (childProcess.stdin) {
      attachStreamErrorHandler(childProcess.stdin, `${this.commandPrefix} stdin`, {
        logger: log
      });
    }
    const disposable = new DisposableProcess(childProcess);
    let timedOut = false;
    let aborted = false;
    let stderrForErrorReporting = "";
    const exitCode = new Promise((resolve3, reject) => {
      childProcess.on("close", (code, signal) => {
        if (aborted || options.abortSignal?.aborted) {
          resolve3(EXIT_CODE_ABORTED);
          return;
        }
        if (timedOut) {
          resolve3(EXIT_CODE_TIMEOUT);
          return;
        }
        const finalExitCode = code ?? (signal ? -1 : 0);
        this.onExitCode(finalExitCode, options, stderrForErrorReporting);
        resolve3(finalExitCode);
      });
      childProcess.on("error", (err) => {
        reject(
          new RuntimeError(
            `Failed to execute ${this.commandPrefix} command: ${err.message}`,
            "exec",
            err
          )
        );
      });
    });
    const duration = exitCode.then(() => performance.now() - startTime);
    if (options.abortSignal) {
      options.abortSignal.addEventListener("abort", () => {
        aborted = true;
        disposable[Symbol.dispose]();
      });
    }
    if (options.timeout !== void 0) {
      const timeoutHandle = setTimeout(() => {
        timedOut = true;
        disposable[Symbol.dispose]();
      }, options.timeout * 1e3);
      void exitCode.finally(() => clearTimeout(timeoutHandle));
    }
    const stdout = Readable2.toWeb(childProcess.stdout);
    const stderr = Readable2.toWeb(childProcess.stderr);
    childProcess.stderr?.on("data", (data) => {
      stderrForErrorReporting += data.toString();
    });
    const stdin = new WritableStream({
      write: async (chunk) => {
        const nodeStdin = childProcess.stdin;
        if (!nodeStdin || nodeStdin.destroyed) {
          return;
        }
        await new Promise((resolve3, reject) => {
          const onError2 = (err) => {
            nodeStdin.off("error", onError2);
            reject(err);
          };
          nodeStdin.on("error", onError2);
          nodeStdin.write(Buffer.from(chunk), (err) => {
            nodeStdin.off("error", onError2);
            if (err) {
              reject(err);
              return;
            }
            resolve3();
          });
        });
      },
      close: async () => {
        const nodeStdin = childProcess.stdin;
        if (!nodeStdin || nodeStdin.destroyed || nodeStdin.writableEnded) {
          return;
        }
        await new Promise((resolve3) => {
          const onError2 = () => {
            cleanup();
            resolve3();
          };
          const onFinish2 = () => {
            cleanup();
            resolve3();
          };
          const cleanup = () => {
            nodeStdin.removeListener("error", onError2);
            nodeStdin.removeListener("finish", onFinish2);
          };
          nodeStdin.once("error", onError2);
          nodeStdin.once("finish", onFinish2);
          try {
            nodeStdin.end();
          } catch {
            onError2();
          }
        });
      },
      abort: () => {
        childProcess.stdin?.destroy();
      }
    });
    log.debug(`${this.commandPrefix} command: ${fullCommand}`);
    return { stdout, stderr, stdin, exitCode, duration };
  }
  /**
   * Read file contents as a stream via exec.
   */
  readFile(filePath, abortSignal) {
    return new ReadableStream({
      start: async (controller) => {
        try {
          const stream = await this.exec(`cat ${this.quoteForRemote(filePath)}`, {
            cwd: this.getBasePath(),
            timeout: 300,
            abortSignal
          });
          const reader = stream.stdout.getReader();
          const exitCodePromise = stream.exitCode;
          while (true) {
            const { done, value: value2 } = await reader.read();
            if (done) break;
            controller.enqueue(value2);
          }
          const code = await exitCodePromise;
          if (code !== 0) {
            const stderr = await streamToString2(stream.stderr);
            throw new RuntimeError(`Failed to read file ${filePath}: ${stderr}`, "file_io");
          }
          controller.close();
        } catch (err) {
          if (err instanceof RuntimeError) {
            controller.error(err);
          } else {
            controller.error(
              new RuntimeError(
                `Failed to read file ${filePath}: ${err instanceof Error ? err.message : String(err)}`,
                "file_io",
                err instanceof Error ? err : void 0
              )
            );
          }
        }
      }
    });
  }
  /**
   * Write file contents atomically via exec.
   * Uses temp file + mv for atomic write.
   */
  writeFile(filePath, abortSignal) {
    const quotedPath = this.quoteForRemote(filePath);
    const tempPath = `${filePath}.tmp.${Date.now()}`;
    const quotedTempPath = this.quoteForRemote(tempPath);
    const writeCommand = this.buildWriteCommand(quotedPath, quotedTempPath);
    let execPromise = null;
    const getExecStream = () => {
      execPromise ??= this.exec(writeCommand, {
        cwd: this.getBasePath(),
        timeout: 300,
        abortSignal
      });
      return execPromise;
    };
    return new WritableStream({
      write: async (chunk) => {
        const stream = await getExecStream();
        const writer = stream.stdin.getWriter();
        try {
          await writer.write(chunk);
        } finally {
          writer.releaseLock();
        }
      },
      close: async () => {
        const stream = await getExecStream();
        await stream.stdin.close();
        const exitCode = await stream.exitCode;
        if (exitCode !== 0) {
          const stderr = await streamToString2(stream.stderr);
          throw new RuntimeError(`Failed to write file ${filePath}: ${stderr}`, "file_io");
        }
      },
      abort: async (reason) => {
        const stream = await getExecStream();
        await stream.stdin.abort();
        throw new RuntimeError(`Failed to write file ${filePath}: ${String(reason)}`, "file_io");
      }
    });
  }
  /**
   * Build the write command for atomic file writes.
   * Can be overridden by subclasses for special handling (e.g., SSH symlink preservation).
   */
  buildWriteCommand(quotedPath, quotedTempPath) {
    return `mkdir -p $(dirname ${quotedPath}) && cat > ${quotedTempPath} && mv ${quotedTempPath} ${quotedPath}`;
  }
  /**
   * Ensure a directory exists (mkdir -p semantics).
   */
  async ensureDir(dirPath) {
    const stream = await this.exec(`mkdir -p ${this.quoteForRemote(dirPath)}`, {
      cwd: "/",
      timeout: 10
    });
    await stream.stdin.close();
    const [stdout, stderr, exitCode] = await Promise.all([
      streamToString2(stream.stdout),
      streamToString2(stream.stderr),
      stream.exitCode
    ]);
    if (exitCode !== 0) {
      const extra = stderr.trim() || stdout.trim();
      throw new RuntimeError(
        `Failed to create directory ${dirPath}: exit code ${exitCode}${extra ? `: ${extra}` : ""}`,
        "file_io"
      );
    }
  }
  /**
   * Get file statistics via exec.
   */
  async stat(filePath, abortSignal) {
    const stream = await this.exec(`stat -c '%s %Y %F' ${this.quoteForRemote(filePath)}`, {
      cwd: this.getBasePath(),
      timeout: 10,
      abortSignal
    });
    const [stdout, stderr, exitCode] = await Promise.all([
      streamToString2(stream.stdout),
      streamToString2(stream.stderr),
      stream.exitCode
    ]);
    if (exitCode !== 0) {
      throw new RuntimeError(`Failed to stat ${filePath}: ${stderr}`, "file_io");
    }
    const parts = stdout.trim().split(" ");
    if (parts.length < 3) {
      throw new RuntimeError(`Failed to parse stat output for ${filePath}: ${stdout}`, "file_io");
    }
    const size = parseInt(parts[0], 10);
    const mtime = parseInt(parts[1], 10);
    const fileType = parts.slice(2).join(" ");
    return {
      size,
      modifiedTime: new Date(mtime * 1e3),
      isDirectory: fileType === "directory"
    };
  }
  /**
   * Normalize path for comparison (POSIX semantics).
   * Shared between SSH and Docker.
   */
  normalizePath(targetPath, basePath) {
    const target = targetPath.trim();
    let base = basePath.trim();
    if (base.length > 1 && base.endsWith("/")) {
      base = base.slice(0, -1);
    }
    if (target === ".") {
      return base;
    }
    if (target.startsWith("/") || target === "~" || target.startsWith("~/")) {
      let normalizedTarget2 = target;
      if (normalizedTarget2.length > 1 && normalizedTarget2.endsWith("/")) {
        normalizedTarget2 = normalizedTarget2.slice(0, -1);
      }
      return normalizedTarget2;
    }
    const normalizedTarget = base.endsWith("/") ? base + target : base + "/" + target;
    if (normalizedTarget.length > 1 && normalizedTarget.endsWith("/")) {
      return normalizedTarget.slice(0, -1);
    }
    return normalizedTarget;
  }
  /**
   * Return /tmp as the temp directory for remote runtimes.
   */
  tempDir() {
    return Promise.resolve("/tmp");
  }
  getUnixHome() {
    return "~/.unix";
  }
  // Abstract methods that subclasses must implement
  /**
   * Remote runtimes are always ready (SSH connections are re-established as needed).
   * Subclasses (LatticeSSHRuntime, DockerRuntime) may override for provisioning checks.
   */
  ensureReady() {
    return Promise.resolve({ ready: true });
  }
};

// src/node/runtime/gitBundleSync.ts
async function getOriginUrlForBundle(projectPath, initLogger, logErrors) {
  try {
    var _stack = [];
    try {
      const proc = __using(_stack, execAsync(`git -C "${projectPath}" remote get-url origin`));
      const { stdout } = await proc.result;
      const url = stdout.trim();
      if (url && !url.includes(".bundle") && !url.includes(".unix-bundle")) {
        return { originUrl: url };
      }
      return { originUrl: null };
    } catch (_) {
      var _error = _, _hasError = true;
    } finally {
      __callDispose(_stack, _error, _hasError);
    }
  } catch (error) {
    if (logErrors) {
      initLogger.logStderr(`Could not get origin URL: ${getErrorMessage3(error)}`);
    } else {
      log.debug("Could not get origin URL", { error: getErrorMessage3(error) });
    }
    return { originUrl: null };
  }
}
var TRACKING_BRANCHES_COMMAND = "for branch in $(git for-each-ref --format='%(refname:short)' refs/remotes/origin/ | grep -v 'origin/HEAD'); do localname=${branch#origin/}; git show-ref --verify --quiet refs/heads/$localname || git branch $localname $branch; done";
async function syncProjectViaGitBundle(params) {
  const {
    projectPath,
    workspacePath,
    remoteTmpDir,
    remoteBundlePath,
    exec: exec3,
    quoteRemotePath,
    initLogger,
    logOriginErrors,
    abortSignal,
    createRemoteBundle,
    cloneStep
  } = params;
  if (abortSignal?.aborted) {
    throw new Error("Sync operation aborted before starting");
  }
  const { originUrl } = await getOriginUrlForBundle(
    projectPath,
    initLogger,
    logOriginErrors ?? false
  );
  initLogger.logStep("Creating git bundle...");
  let createResult;
  try {
    createResult = await createRemoteBundle({ remoteBundlePath, initLogger, abortSignal });
  } catch (error) {
    try {
      const rmStream = await exec3(`rm -f ${quoteRemotePath(remoteBundlePath)}`, {
        cwd: remoteTmpDir,
        timeout: 10,
        abortSignal
      });
      await rmStream.exitCode;
    } catch {
    }
    throw error;
  }
  try {
    initLogger.logStep(cloneStep);
    const cloneStream = await exec3(
      `git clone --quiet ${quoteRemotePath(remoteBundlePath)} ${quoteRemotePath(workspacePath)}`,
      {
        cwd: remoteTmpDir,
        timeout: 300,
        abortSignal
      }
    );
    const [cloneStdout, cloneStderr, cloneExitCode] = await Promise.all([
      streamToString2(cloneStream.stdout),
      streamToString2(cloneStream.stderr),
      cloneStream.exitCode
    ]);
    if (cloneExitCode !== 0) {
      throw new Error(`Failed to clone repository: ${cloneStderr || cloneStdout}`);
    }
    initLogger.logStep("Creating local tracking branches...");
    const trackingStream = await exec3(TRACKING_BRANCHES_COMMAND, {
      cwd: workspacePath,
      timeout: 30,
      abortSignal
    });
    await trackingStream.exitCode;
    if (originUrl) {
      initLogger.logStep(`Setting origin remote to ${originUrl}...`);
      const setOriginStream = await exec3(`git remote set-url origin ${shescape.quote(originUrl)}`, {
        cwd: workspacePath,
        timeout: 10,
        abortSignal
      });
      const setOriginExitCode = await setOriginStream.exitCode;
      if (setOriginExitCode !== 0) {
        const stderr = await streamToString2(setOriginStream.stderr);
        log.debug("Failed to set origin remote", { stderr });
      }
    } else {
      initLogger.logStep("Removing bundle origin remote...");
      const removeOriginStream = await exec3(`git remote remove origin 2>/dev/null || true`, {
        cwd: workspacePath,
        timeout: 10,
        abortSignal
      });
      await removeOriginStream.exitCode;
    }
    initLogger.logStep("Cleaning up bundle file...");
    const rmStream = await exec3(`rm -f ${quoteRemotePath(remoteBundlePath)}`, {
      cwd: remoteTmpDir,
      timeout: 10,
      abortSignal
    });
    const rmExitCode = await rmStream.exitCode;
    if (rmExitCode !== 0) {
      log.debug("Failed to remove remote bundle file", { remoteBundlePath });
    }
    if (createResult && "cleanupLocal" in createResult && createResult.cleanupLocal) {
      await createResult.cleanupLocal();
    }
    initLogger.logStep("Repository cloned successfully");
  } catch (error) {
    try {
      const rmStream = await exec3(`rm -f ${quoteRemotePath(remoteBundlePath)}`, {
        cwd: remoteTmpDir,
        timeout: 10,
        abortSignal
      });
      await rmStream.exitCode;
    } catch {
    }
    try {
      if (createResult && "cleanupLocal" in createResult && createResult.cleanupLocal) {
        await createResult.cleanupLocal();
      }
    } catch {
    }
    throw error;
  }
}

// src/node/runtime/SSHRuntime.ts
function logSSHBackoffWait(initLogger, waitMs) {
  const secs = Math.max(1, Math.ceil(waitMs / 1e3));
  initLogger.logStep(`SSH unavailable; retrying in ${secs}s...`);
}
async function pipeReadableToWebWritable(readable, writable, abortSignal) {
  if (!readable) {
    throw new Error("Missing git bundle output stream");
  }
  const writer = writable.getWriter();
  try {
    for await (const chunk of readable) {
      if (abortSignal?.aborted) {
        throw new Error("Bundle creation aborted");
      }
      const data = typeof chunk === "string" ? Buffer.from(chunk) : chunk instanceof Uint8Array ? chunk : Buffer.from(chunk);
      await writer.write(data);
    }
    await writer.close();
  } catch (error) {
    try {
      await writer.abort(error);
    } catch {
      writer.releaseLock();
    }
    throw error;
  }
}
function createAbortController(timeoutMs, abortSignal) {
  const controller = new AbortController();
  let timedOut = false;
  const onAbort = () => controller.abort();
  if (abortSignal) {
    if (abortSignal.aborted) {
      controller.abort();
    } else {
      abortSignal.addEventListener("abort", onAbort, { once: true });
    }
  }
  const timeoutHandle = timeoutMs === void 0 ? void 0 : setTimeout(() => {
    timedOut = true;
    controller.abort();
  }, timeoutMs);
  return {
    signal: controller.signal,
    didTimeout: () => timedOut,
    dispose: () => {
      if (timeoutHandle) {
        clearTimeout(timeoutHandle);
      }
      abortSignal?.removeEventListener("abort", onAbort);
    }
  };
}
async function waitForProcessExit(proc) {
  return new Promise((resolve3, reject) => {
    proc.on("close", (code) => resolve3(code ?? 0));
    proc.on("error", (err) => reject(err));
  });
}
function truncateSSHError(stderr) {
  const trimmed = stderr.trim();
  if (!trimmed) return "exit code 255";
  const firstLine = trimmed.split("\n")[0];
  if (firstLine.length <= 200) return firstLine;
  return firstLine.slice(0, 197) + "...";
}
var SSHRuntime = class extends RemoteRuntime {
  constructor(config2, transport) {
    super();
    /** Cached resolved bgOutputDir (tilde expanded to absolute path) */
    this.resolvedBgOutputDir = null;
    // ===== RemoteRuntime abstract method implementations =====
    this.commandPrefix = "SSH";
    this.config = config2;
    this.transport = transport;
  }
  /**
   * Get resolved background output directory (tilde expanded), caching the result.
   * This ensures all background process paths are absolute from the start.
   * Public for use by BackgroundProcessExecutor.
   */
  async getBgOutputDir() {
    if (this.resolvedBgOutputDir !== null) {
      return this.resolvedBgOutputDir;
    }
    let dir = this.config.bgOutputDir ?? "/tmp/unix-bashes";
    if (dir === "~" || dir.startsWith("~/")) {
      const result = await execBuffered(this, 'echo "$HOME"', { cwd: "/", timeout: 10 });
      let home;
      if (result.exitCode === 0 && result.stdout.trim()) {
        home = result.stdout.trim();
      } else {
        log.warn(
          `SSHRuntime: Failed to resolve $HOME (exitCode=${result.exitCode}). Falling back to /tmp.`
        );
        home = "/tmp";
      }
      dir = dir === "~" ? home : `${home}/${dir.slice(2)}`;
    }
    this.resolvedBgOutputDir = dir;
    return this.resolvedBgOutputDir;
  }
  /** Create a PTY session using the underlying transport. */
  createPtySession(params) {
    return this.transport.createPtySession(params);
  }
  /** Get SSH configuration (for PTY terminal spawning). */
  getConfig() {
    return this.config;
  }
  getBasePath() {
    return this.config.srcBaseDir;
  }
  quoteForRemote(filePath) {
    return expandTildeForSSH(filePath);
  }
  cdCommand(cwd) {
    return cdCommandForSSH(cwd);
  }
  /**
   * Handle exit codes for SSH connection pool health tracking.
   */
  onExitCode(exitCode, _options, stderr) {
    if (this.transport.isConnectionFailure(exitCode, stderr)) {
      this.transport.reportFailure(truncateSSHError(stderr));
    } else {
      this.transport.markHealthy();
    }
  }
  async spawnRemoteProcess(fullCommand, options) {
    return this.transport.spawnRemoteProcess(fullCommand, {
      forcePTY: options.forcePTY,
      timeout: options.timeout,
      abortSignal: options.abortSignal
    });
  }
  /**
   * Override buildWriteCommand for SSH to handle symlinks and preserve permissions.
   */
  buildWriteCommand(quotedPath, quotedTempPath) {
    return `RESOLVED=$(readlink -f ${quotedPath} 2>/dev/null || echo ${quotedPath}) && PERMS=$(stat -c '%a' "$RESOLVED" 2>/dev/null || echo 600) && mkdir -p $(dirname "$RESOLVED") && cat > ${quotedTempPath} && chmod "$PERMS" ${quotedTempPath} && mv ${quotedTempPath} "$RESOLVED"`;
  }
  // ===== Runtime interface implementations =====
  async resolvePath(filePath) {
    const script = [
      `p=${shescape.quote(filePath)}`,
      'if [ "$p" = "~" ]; then',
      '  echo "$HOME"',
      'elif [ "${p#\\~/}" != "$p" ]; then',
      '  echo "$HOME/${p#\\~/}"',
      'elif [ "${p#/}" != "$p" ]; then',
      '  echo "$p"',
      "else",
      '  echo "$PWD/$p"',
      "fi"
    ].join("\n");
    const command = `bash -lc ${shescape.quote(script)}`;
    const abortController = createAbortController(1e4);
    try {
      const result = await execBuffered(this, command, {
        cwd: "/tmp",
        abortSignal: abortController.signal
      });
      if (abortController.didTimeout()) {
        throw new Error(`SSH command timed out after 10000ms: ${command}`);
      }
      if (result.exitCode !== 0) {
        const message = result.stderr || result.stdout || "Unknown error";
        throw new Error(`Failed to resolve SSH path: ${message}`);
      }
      return result.stdout.trim();
    } finally {
      abortController.dispose();
    }
  }
  getWorkspacePath(projectPath, workspaceName) {
    const projectName = getProjectName(projectPath);
    return path8.posix.join(this.config.srcBaseDir, projectName, workspaceName);
  }
  /**
   * Sync project to remote using git bundle
   *
   * Uses `git bundle` to create a packfile and clones it on the remote.
   *
   * Benefits over git archive:
   * - Creates a real git repository on remote (can run git commands)
   * - Better parity with git worktrees (full .git directory with metadata)
   * - Enables remote git operations (commit, branch, status, diff, etc.)
   * - Only tracked files in checkout (no node_modules, build artifacts)
   * - Includes full history for flexibility
   *
   * Benefits over rsync/scp:
   * - Much faster (only tracked files)
   * - No external dependencies (git is always available)
   * - Simpler implementation
   */
  async syncProjectToRemote(projectPath, workspacePath, initLogger, abortSignal) {
    const timestamp = Date.now();
    const remoteBundlePath = `~/.unix-bundle-${timestamp}.bundle`;
    await syncProjectViaGitBundle({
      projectPath,
      workspacePath,
      remoteTmpDir: "~",
      remoteBundlePath,
      exec: (command, options) => this.exec(command, options),
      quoteRemotePath: (path21) => this.quoteForRemote(path21),
      logOriginErrors: true,
      initLogger,
      abortSignal,
      cloneStep: "Cloning repository on remote...",
      createRemoteBundle: async ({ remoteBundlePath: remoteBundlePath2, initLogger: initLogger2, abortSignal: abortSignal2 }) => {
        await this.transport.acquireConnection({
          abortSignal: abortSignal2,
          onWait: (waitMs) => logSSHBackoffWait(initLogger2, waitMs)
        });
        if (abortSignal2?.aborted) {
          throw new Error("Bundle creation aborted");
        }
        const gitProc = spawn2("git", ["-C", projectPath, "bundle", "create", "-", "--all"], {
          stdio: ["ignore", "pipe", "pipe"],
          windowsHide: true
        });
        let stderr = "";
        gitProc.stderr?.on("data", (data) => {
          const chunk = data.toString();
          stderr += chunk;
          for (const line of chunk.split("\n").filter(Boolean)) {
            initLogger2.logStderr(line);
          }
        });
        const remoteAbortController = createAbortController(3e5, abortSignal2);
        const remoteStream = await this.exec(`cat > ${this.quoteForRemote(remoteBundlePath2)}`, {
          cwd: "~",
          abortSignal: remoteAbortController.signal
        });
        try {
          try {
            await pipeReadableToWebWritable(gitProc.stdout, remoteStream.stdin, abortSignal2);
          } catch (error) {
            gitProc.kill();
            throw error;
          }
          const [gitExitCode, remoteExitCode] = await Promise.all([
            waitForProcessExit(gitProc),
            remoteStream.exitCode
          ]);
          if (remoteAbortController.didTimeout()) {
            throw new Error(
              `SSH command timed out after 300000ms: cat > ${this.quoteForRemote(remoteBundlePath2)}`
            );
          }
          if (abortSignal2?.aborted) {
            throw new Error("Bundle creation aborted");
          }
          if (gitExitCode !== 0) {
            throw new Error(`Failed to create bundle: ${stderr}`);
          }
          if (remoteExitCode !== 0) {
            const remoteStderr = await streamToString2(remoteStream.stderr);
            throw new Error(`Failed to upload bundle: ${remoteStderr}`);
          }
        } finally {
          remoteAbortController.dispose();
        }
      }
    });
  }
  async createWorkspace(params) {
    try {
      const { projectPath, branchName, initLogger, abortSignal } = params;
      const workspacePath = this.getWorkspacePath(projectPath, branchName);
      initLogger.logStep("Preparing remote workspace...");
      try {
        const lastSlash = workspacePath.lastIndexOf("/");
        const parentDir = lastSlash > 0 ? workspacePath.substring(0, lastSlash) : "~";
        const expandedParentDir = expandTildeForSSH(parentDir);
        const parentDirCommand = `mkdir -p ${expandedParentDir}`;
        const mkdirStream = await this.exec(parentDirCommand, {
          cwd: "/tmp",
          timeout: 10,
          abortSignal
        });
        const mkdirExitCode = await mkdirStream.exitCode;
        if (mkdirExitCode !== 0) {
          const stderr = await streamToString2(mkdirStream.stderr);
          return {
            success: false,
            error: `Failed to prepare remote workspace: ${stderr}`
          };
        }
      } catch (error) {
        return {
          success: false,
          error: `Failed to prepare remote workspace: ${getErrorMessage3(error)}`
        };
      }
      initLogger.logStep("Remote workspace prepared");
      return {
        success: true,
        workspacePath
      };
    } catch (error) {
      return {
        success: false,
        error: getErrorMessage3(error)
      };
    }
  }
  async initWorkspace(params) {
    const {
      projectPath,
      branchName,
      trunkBranch,
      workspacePath,
      initLogger,
      abortSignal,
      env: env3,
      skipInitHook
    } = params;
    try {
      const workspacePathArg = expandTildeForSSH(workspacePath);
      let shouldSync = true;
      try {
        const dirCheck = await execBuffered(this, `test -d ${workspacePathArg}`, {
          cwd: "/tmp",
          timeout: 10,
          abortSignal
        });
        if (dirCheck.exitCode === 0) {
          const gitCheck = await execBuffered(
            this,
            `git -C ${workspacePathArg} rev-parse --is-inside-work-tree`,
            {
              cwd: "/tmp",
              timeout: 20,
              abortSignal
            }
          );
          shouldSync = gitCheck.exitCode !== 0;
        }
      } catch {
        shouldSync = true;
      }
      if (shouldSync) {
        initLogger.logStep("Syncing project files to remote...");
        const maxSyncAttempts = 3;
        for (let attempt = 1; attempt <= maxSyncAttempts; attempt++) {
          try {
            await this.syncProjectToRemote(projectPath, workspacePath, initLogger, abortSignal);
            break;
          } catch (error) {
            const errorMsg = getErrorMessage3(error);
            const isRetryable = errorMsg.includes("pack-objects died") || errorMsg.includes("Connection reset") || errorMsg.includes("Connection closed") || errorMsg.includes("Broken pipe");
            if (!isRetryable || attempt === maxSyncAttempts) {
              initLogger.logStderr(`Failed to sync project: ${errorMsg}`);
              initLogger.logComplete(-1);
              return {
                success: false,
                error: `Failed to sync project: ${errorMsg}`
              };
            }
            log.info(
              `Sync failed (attempt ${attempt}/${maxSyncAttempts}), will retry: ${errorMsg}`
            );
            try {
              const rmStream = await this.exec(`rm -rf ${workspacePathArg}`, {
                cwd: "~",
                timeout: 30
              });
              await rmStream.exitCode;
            } catch {
            }
            initLogger.logStep(
              `Sync failed, retrying (attempt ${attempt + 1}/${maxSyncAttempts})...`
            );
            await new Promise((r) => setTimeout(r, attempt * 1e3));
          }
        }
        initLogger.logStep("Files synced successfully");
      } else {
        initLogger.logStep("Remote workspace already contains a git repo; skipping sync");
      }
      const fetchedOrigin = await this.fetchOriginTrunk(
        workspacePath,
        trunkBranch,
        initLogger,
        abortSignal
      );
      const shouldUseOrigin = fetchedOrigin && await this.canFastForwardToOrigin(workspacePath, trunkBranch, initLogger, abortSignal);
      initLogger.logStep(`Checking out branch: ${branchName}`);
      const newBranchBase = shouldUseOrigin ? `origin/${trunkBranch}` : trunkBranch;
      const checkoutCmd = `git checkout ${shescape.quote(branchName)} 2>/dev/null || git checkout -b ${shescape.quote(branchName)} ${shescape.quote(newBranchBase)}`;
      const checkoutStream = await this.exec(checkoutCmd, {
        cwd: workspacePath,
        // Use the full workspace path for git operations
        timeout: 300,
        // 5 minutes for git checkout (can be slow on large repos)
        abortSignal
      });
      const [stdout, stderr, exitCode] = await Promise.all([
        streamToString2(checkoutStream.stdout),
        streamToString2(checkoutStream.stderr),
        checkoutStream.exitCode
      ]);
      if (exitCode !== 0) {
        const errorMsg = `Failed to checkout branch: ${stderr || stdout}`;
        initLogger.logStderr(errorMsg);
        initLogger.logComplete(-1);
        return {
          success: false,
          error: errorMsg
        };
      }
      initLogger.logStep("Branch checked out successfully");
      if (shouldUseOrigin) {
        await this.fastForwardToOrigin(workspacePath, trunkBranch, initLogger, abortSignal);
      }
      if (skipInitHook) {
        initLogger.logStep("Skipping .unix/init hook (disabled for this task)");
        initLogger.logComplete(0);
      } else {
        const hookExists = await checkInitHookExists(projectPath);
        if (hookExists) {
          const muxEnv = { ...env3, ...getUnixEnv(projectPath, "ssh", branchName) };
          const hookPath = expandTildeForSSH(`${workspacePath}/.unix/init`);
          await runInitHookOnRuntime(
            this,
            hookPath,
            workspacePath,
            muxEnv,
            initLogger,
            abortSignal
          );
        } else {
          initLogger.logComplete(0);
        }
      }
      return { success: true };
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(`Initialization failed: ${errorMsg}`);
      initLogger.logComplete(-1);
      return {
        success: false,
        error: errorMsg
      };
    }
  }
  /**
   * Fetch trunk branch from origin before checkout.
   * Returns true if fetch succeeded (origin is available for branching).
   */
  async fetchOriginTrunk(workspacePath, trunkBranch, initLogger, abortSignal) {
    try {
      initLogger.logStep(`Fetching latest from origin/${trunkBranch}...`);
      const fetchCmd = `git fetch origin ${shescape.quote(trunkBranch)}`;
      const fetchStream = await this.exec(fetchCmd, {
        cwd: workspacePath,
        timeout: 120,
        // 2 minutes for network operation
        abortSignal
      });
      const fetchExitCode = await fetchStream.exitCode;
      if (fetchExitCode !== 0) {
        const fetchStderr = await streamToString2(fetchStream.stderr);
        if (fetchStderr.includes("couldn't find remote ref")) {
          initLogger.logStep(`Branch "${trunkBranch}" not found on origin; using local state.`);
        } else {
          initLogger.logStderr(
            `Note: Could not fetch from origin (${fetchStderr}), using local branch state`
          );
        }
        return false;
      }
      initLogger.logStep("Fetched latest from origin");
      return true;
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(
        `Note: Could not fetch from origin (${errorMsg}), using local branch state`
      );
      return false;
    }
  }
  /**
   * Check if local trunk can fast-forward to origin/<trunk>.
   * Returns true if local is behind or equal to origin (safe to use origin).
   * Returns false if local is ahead or diverged (preserve local state).
   */
  async canFastForwardToOrigin(workspacePath, trunkBranch, initLogger, abortSignal) {
    try {
      const checkCmd = `git merge-base --is-ancestor ${shescape.quote(trunkBranch)} origin/${shescape.quote(trunkBranch)}`;
      const checkStream = await this.exec(checkCmd, {
        cwd: workspacePath,
        timeout: 30,
        abortSignal
      });
      const exitCode = await checkStream.exitCode;
      if (exitCode === 0) {
        return true;
      }
      initLogger.logStderr(
        `Note: Local ${trunkBranch} is ahead of or diverged from origin, using local state`
      );
      return false;
    } catch {
      return false;
    }
  }
  /**
   * Fast-forward merge to latest origin/<trunkBranch> after checkout.
   * Best-effort operation for existing branches that may be behind origin.
   */
  async fastForwardToOrigin(workspacePath, trunkBranch, initLogger, abortSignal) {
    try {
      initLogger.logStep("Fast-forward merging...");
      const mergeCmd = `git merge --ff-only origin/${shescape.quote(trunkBranch)}`;
      const mergeStream = await this.exec(mergeCmd, {
        cwd: workspacePath,
        timeout: 60,
        // 1 minute for fast-forward merge
        abortSignal
      });
      const [mergeStderr, mergeExitCode] = await Promise.all([
        streamToString2(mergeStream.stderr),
        mergeStream.exitCode
      ]);
      if (mergeExitCode !== 0) {
        initLogger.logStderr(
          `Note: Fast-forward skipped (${mergeStderr || "branches diverged"}), using local branch state`
        );
      } else {
        initLogger.logStep("Fast-forwarded to latest origin successfully");
      }
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(`Note: Fast-forward failed (${errorMsg}), using local branch state`);
    }
  }
  async renameWorkspace(projectPath, oldName, newName, abortSignal) {
    if (abortSignal?.aborted) {
      return { success: false, error: "Rename operation aborted" };
    }
    const oldPath = this.getWorkspacePath(projectPath, oldName);
    const newPath = this.getWorkspacePath(projectPath, newName);
    try {
      const expandedOldPath = expandTildeForSSH(oldPath);
      const expandedNewPath = expandTildeForSSH(newPath);
      const moveCommand = `mv ${expandedOldPath} ${expandedNewPath}`;
      const stream = await this.exec(moveCommand, {
        cwd: this.config.srcBaseDir,
        timeout: 30,
        abortSignal
      });
      await stream.stdin.abort();
      const exitCode = await stream.exitCode;
      if (exitCode !== 0) {
        const stderrReader = stream.stderr.getReader();
        const decoder = new TextDecoder();
        let stderr = "";
        try {
          while (true) {
            const { done, value: value2 } = await stderrReader.read();
            if (done) break;
            stderr += decoder.decode(value2, { stream: true });
          }
        } finally {
          stderrReader.releaseLock();
        }
        return {
          success: false,
          error: `Failed to rename directory: ${stderr.trim() || "Unknown error"}`
        };
      }
      return { success: true, oldPath, newPath };
    } catch (error) {
      return {
        success: false,
        error: `Failed to rename directory: ${getErrorMessage3(error)}`
      };
    }
  }
  async deleteWorkspace(projectPath, workspaceName, force, abortSignal) {
    if (abortSignal?.aborted) {
      return { success: false, error: "Delete operation aborted" };
    }
    const deletedPath = this.getWorkspacePath(projectPath, workspaceName);
    try {
      const checkScript = force ? (
        // When force=true, only check existence
        `test -d ${shescape.quote(deletedPath)} || exit 3`
      ) : (
        // When force=false, perform all safety checks
        `
            test -d ${shescape.quote(deletedPath)} || exit 3
            cd ${shescape.quote(deletedPath)} || exit 1
            git diff --quiet --exit-code && git diff --quiet --cached --exit-code || exit 1
            if git remote | grep -q .; then
              # First, check the original condition: any commits not in any remote
              unpushed=$(git log --branches --not --remotes --oneline)
              if [ -n "$unpushed" ]; then
                # Get current branch for better error messaging
                BRANCH=$(git rev-parse --abbrev-ref HEAD 2>/dev/null)

                # Get default branch (prefer main/master over origin/HEAD since origin/HEAD
                # might point to a feature branch in some setups)
                if git rev-parse --verify origin/main >/dev/null 2>&1; then
                  DEFAULT="main"
                elif git rev-parse --verify origin/master >/dev/null 2>&1; then
                  DEFAULT="master"
                else
                  # Fallback to origin/HEAD if main/master don't exist
                  DEFAULT=$(git symbolic-ref refs/remotes/origin/HEAD 2>/dev/null | sed 's@^refs/remotes/origin/@@')
                fi

                # Check for squash-merge: if all changed files match origin/$DEFAULT, content is merged
                if [ -n "$DEFAULT" ]; then
                  # Fetch latest to ensure we have current remote state
                  git fetch origin "$DEFAULT" --quiet 2>/dev/null || true

                  # Get merge-base between current branch and default
                  MERGE_BASE=$(git merge-base "origin/$DEFAULT" HEAD 2>/dev/null)
                  if [ -n "$MERGE_BASE" ]; then
                    # Get files changed on this branch since fork point
                    CHANGED_FILES=$(git diff --name-only "$MERGE_BASE" HEAD 2>/dev/null)

                    if [ -n "$CHANGED_FILES" ]; then
                      # Check if all changed files match what's in origin/$DEFAULT
                      ALL_MERGED=true
                      while IFS= read -r f; do
                        # Compare file content between HEAD and origin/$DEFAULT
                        # If file doesn't exist in one but exists in other, they differ
                        if ! git diff --quiet "HEAD:$f" "origin/$DEFAULT:$f" 2>/dev/null; then
                          ALL_MERGED=false
                          break
                        fi
                      done <<< "$CHANGED_FILES"

                      if $ALL_MERGED; then
                        # All changes are in default branch - safe to delete (squash-merge case)
                        exit 0
                      fi
                    else
                      # No changed files means nothing to merge - safe to delete
                      exit 0
                    fi
                  fi
                fi

                # If we get here, there are real unpushed changes
                # Show helpful output for debugging
                if [ -n "$BRANCH" ] && [ -n "$DEFAULT" ] && git show-branch "$BRANCH" "origin/$DEFAULT" >/dev/null 2>&1; then
                  echo "Branch status compared to origin/$DEFAULT:" >&2
                  echo "" >&2
                  git show-branch "$BRANCH" "origin/$DEFAULT" 2>&1 | head -20 >&2
                  echo "" >&2
                  echo "Note: Branch has changes not yet in origin/$DEFAULT." >&2
                else
                  # Fallback to just showing the commit list
                  echo "$unpushed" | head -10 >&2
                fi
                exit 2
              fi
            fi
            exit 0
          `
      );
      const checkStream = await this.exec(checkScript, {
        cwd: this.config.srcBaseDir,
        timeout: 10,
        abortSignal
      });
      await checkStream.stdin.abort();
      const checkExitCode = await checkStream.exitCode;
      if (checkExitCode === 3) {
        return { success: true, deletedPath };
      }
      if (checkExitCode === 1) {
        return {
          success: false,
          error: "Workspace contains uncommitted changes. Use force flag to delete anyway."
        };
      }
      if (checkExitCode === 2) {
        const stderr = await streamToString2(checkStream.stderr);
        const commitList = stderr.trim();
        const errorMsg = commitList ? `Workspace contains unpushed commits:

${commitList}` : "Workspace contains unpushed commits. Use force flag to delete anyway.";
        return {
          success: false,
          error: errorMsg
        };
      }
      if (checkExitCode !== 0) {
        const stderr = await streamToString2(checkStream.stderr);
        return {
          success: false,
          error: `Failed to check workspace state: ${stderr.trim() || `exit code ${checkExitCode}`}`
        };
      }
      const removeCommand = `rm -rf ${shescape.quote(deletedPath)}`;
      const stream = await this.exec(removeCommand, {
        cwd: this.config.srcBaseDir,
        timeout: 30,
        abortSignal
      });
      await stream.stdin.abort();
      const exitCode = await stream.exitCode;
      if (exitCode !== 0) {
        const stderr = await streamToString2(stream.stderr);
        return {
          success: false,
          error: `Failed to delete directory: ${stderr.trim() || "Unknown error"}`
        };
      }
      return { success: true, deletedPath };
    } catch (error) {
      return { success: false, error: `Failed to delete directory: ${getErrorMessage3(error)}` };
    }
  }
  async forkWorkspace(params) {
    const { projectPath, sourceWorkspaceName, newWorkspaceName, initLogger } = params;
    const sourceWorkspacePath = this.getWorkspacePath(projectPath, sourceWorkspaceName);
    const newWorkspacePath = this.getWorkspacePath(projectPath, newWorkspaceName);
    const sourceWorkspacePathArg = expandTildeForSSH(sourceWorkspacePath);
    const newWorkspacePathArg = expandTildeForSSH(newWorkspacePath);
    try {
      {
        const exists = await execBuffered(this, `test -e ${newWorkspacePathArg}`, {
          cwd: "/tmp",
          timeout: 10
        });
        if (exists.exitCode === 0) {
          return { success: false, error: `Workspace already exists at ${newWorkspacePath}` };
        }
      }
      initLogger.logStep("Detecting source workspace branch...");
      const branchResult = await execBuffered(
        this,
        `git -C ${sourceWorkspacePathArg} branch --show-current`,
        {
          cwd: "/tmp",
          timeout: 30
        }
      );
      const sourceBranch = branchResult.stdout.trim();
      if (branchResult.exitCode !== 0 || sourceBranch.length === 0) {
        return {
          success: false,
          error: "Failed to detect branch in source workspace"
        };
      }
      initLogger.logStep("Preparing remote workspace...");
      const parentDir = path8.posix.dirname(newWorkspacePath);
      const mkdirResult = await execBuffered(this, `mkdir -p ${expandTildeForSSH(parentDir)}`, {
        cwd: "/tmp",
        timeout: 10
      });
      if (mkdirResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to prepare remote workspace: ${mkdirResult.stderr || mkdirResult.stdout}`
        };
      }
      initLogger.logStep("Cloning workspace on remote...");
      const cloneResult = await execBuffered(
        this,
        `git clone --quiet ${sourceWorkspacePathArg} ${newWorkspacePathArg}`,
        {
          cwd: "/tmp",
          timeout: 300
        }
      );
      if (cloneResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to clone workspace: ${cloneResult.stderr || cloneResult.stdout}`
        };
      }
      initLogger.logStep("Creating local tracking branches...");
      try {
        await execBuffered(
          this,
          `cd ${newWorkspacePathArg} && for branch in $(git for-each-ref --format='%(refname:short)' refs/remotes/origin/ | grep -v 'origin/HEAD'); do localname=\${branch#origin/}; git show-ref --verify --quiet refs/heads/$localname || git branch $localname $branch; done`,
          {
            cwd: "/tmp",
            timeout: 30
          }
        );
      } catch {
      }
      try {
        const originResult = await execBuffered(
          this,
          `git -C ${sourceWorkspacePathArg} remote get-url origin 2>/dev/null || true`,
          {
            cwd: "/tmp",
            timeout: 10
          }
        );
        const originUrl = originResult.stdout.trim();
        if (originUrl.length > 0) {
          await execBuffered(
            this,
            `git -C ${newWorkspacePathArg} remote set-url origin ${shescape.quote(originUrl)}`,
            {
              cwd: "/tmp",
              timeout: 10
            }
          );
        } else {
          await execBuffered(
            this,
            `git -C ${newWorkspacePathArg} remote remove origin 2>/dev/null || true`,
            {
              cwd: "/tmp",
              timeout: 10
            }
          );
        }
      } catch {
      }
      initLogger.logStep(`Checking out branch: ${newWorkspaceName}`);
      const checkoutCmd = `git checkout ${shescape.quote(newWorkspaceName)} 2>/dev/null || git checkout -b ${shescape.quote(newWorkspaceName)} ${shescape.quote(sourceBranch)}`;
      const checkoutResult = await execBuffered(this, checkoutCmd, {
        cwd: newWorkspacePath,
        timeout: 120
      });
      if (checkoutResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to checkout forked branch: ${checkoutResult.stderr || checkoutResult.stdout}`
        };
      }
      return { success: true, workspacePath: newWorkspacePath, sourceBranch };
    } catch (error) {
      return { success: false, error: getErrorMessage3(error) };
    }
  }
};

// src/node/runtime/LatticeSSHRuntime.ts
import * as path9 from "path";
var LATTICE_NAME_REGEX = /^[a-zA-Z0-9]+(?:-[a-zA-Z0-9]+)*$/;
function toLatticeCompatibleName(name16) {
  return name16.replace(/_/g, "-").replace(/^-+|-+$/g, "").replace(/-{2,}/g, "-");
}
var LATTICE_INACTIVITY_THRESHOLD_MS = 5 * 60 * 1e3;
var LATTICE_ENSURE_READY_TIMEOUT_MS = 12e4;
var LATTICE_STATUS_POLL_INTERVAL_MS = 2e3;
var LatticeSSHRuntime = class extends SSHRuntime {
  constructor(config2, transport, latticeService) {
    if (!config2 || !latticeService || !transport) {
      throw new Error("LatticeSSHRuntime requires config, transport, and latticeService");
    }
    const baseConfig = {
      host: config2.host,
      srcBaseDir: config2.srcBaseDir,
      bgOutputDir: config2.bgOutputDir,
      identityFile: config2.identityFile,
      port: config2.port
    };
    super(baseConfig, transport);
    /**
     * Timestamp of last time we (a) successfully used the runtime or (b) decided not
     * to block the user (unknown Coder CLI error).
     * Used to avoid running expensive status checks on every message while still
     * catching auto-stopped workspaces after long inactivity.
     */
    this.lastActivityAtMs = 0;
    /**
     * Flags for WorkspaceService to customize create flow:
     * - deferredRuntimeAccess: skip srcBaseDir resolution (Coder host doesn't exist yet)
     * - configLevelCollisionDetection: use config-based collision check (can't reach host)
     */
    this.createFlags = {
      deferredRuntimeAccess: true,
      configLevelCollisionDetection: true
    };
    /** In-flight ensureReady promise to avoid duplicate start/wait sequences */
    this.ensureReadyPromise = null;
    this.latticeConfig = config2.lattice;
    this.latticeService = latticeService;
  }
  /**
   * Check if runtime is ready for use.
   *
   * Behavior:
   * - If creation failed during postCreateSetup(), fail fast.
   * - If workspace is running: return ready.
   * - If workspace is stopped: auto-start and wait (blocking, ~120s timeout).
   * - If workspace is stopping: poll until stopped, then start.
   * - Emits runtime-status events via statusSink for UX feedback.
   *
   * Concurrency: shares an in-flight promise to avoid duplicate start sequences.
   */
  async ensureReady(options) {
    const workspaceName = this.latticeConfig.workspaceName;
    if (!workspaceName) {
      return {
        ready: false,
        error: "Lattice workspace name not set",
        errorType: "runtime_not_ready"
      };
    }
    const now = Date.now();
    if (this.lastActivityAtMs !== 0 && now - this.lastActivityAtMs < LATTICE_INACTIVITY_THRESHOLD_MS) {
      return { ready: true };
    }
    if (this.ensureReadyPromise) {
      return this.ensureReadyPromise;
    }
    this.ensureReadyPromise = this.doEnsureReady(workspaceName, options);
    try {
      return await this.ensureReadyPromise;
    } finally {
      this.ensureReadyPromise = null;
    }
  }
  /**
   * Core ensureReady logic - called once (protected by ensureReadyPromise).
   *
   * Flow:
   * 1. Check status via `coder list` - short-circuit for "running" or "not_found"
   * 2. If "stopping"/"canceling": poll until it clears (coder ssh can't autostart during these)
   * 3. Run `coder ssh --wait=yes -- true` which handles everything else:
   *    - stopped: auto-starts, streams build logs, waits for startup scripts
   *    - starting/pending: waits for build completion + startup scripts
   */
  async doEnsureReady(workspaceName, options) {
    const statusSink = options?.statusSink;
    const signal = options?.signal;
    const startTime = Date.now();
    const emitStatus = (phase, detail) => {
      statusSink?.({ phase, runtimeType: "ssh", detail });
    };
    const isTimedOut = () => Date.now() - startTime > LATTICE_ENSURE_READY_TIMEOUT_MS;
    const remainingMs = () => Math.max(0, LATTICE_ENSURE_READY_TIMEOUT_MS - (Date.now() - startTime));
    emitStatus("checking");
    if (signal?.aborted) {
      emitStatus("error");
      return { ready: false, error: "Aborted", errorType: "runtime_start_failed" };
    }
    let statusResult = await this.latticeService.getWorkspaceStatus(workspaceName, {
      timeoutMs: Math.min(remainingMs(), 1e4),
      signal
    });
    if (statusResult.kind === "ok" && statusResult.status === "running") {
      this.lastActivityAtMs = Date.now();
      emitStatus("ready");
      return { ready: true };
    }
    if (statusResult.kind === "not_found") {
      emitStatus("error");
      return {
        ready: false,
        error: `Lattice workspace "${workspaceName}" not found`,
        errorType: "runtime_not_ready"
      };
    }
    if (statusResult.kind === "error") {
      if (signal?.aborted) {
        emitStatus("error");
        return { ready: false, error: "Aborted", errorType: "runtime_start_failed" };
      }
      log.debug("Lattice workspace status unknown, proceeding optimistically", {
        workspaceName,
        error: statusResult.error
      });
    }
    if (statusResult.kind === "ok" && (statusResult.status === "stopping" || statusResult.status === "canceling")) {
      emitStatus("waiting", "Waiting for Lattice workspace to stop...");
      while (statusResult.kind === "ok" && (statusResult.status === "stopping" || statusResult.status === "canceling") && !isTimedOut()) {
        if (signal?.aborted) {
          emitStatus("error");
          return { ready: false, error: "Aborted", errorType: "runtime_start_failed" };
        }
        await this.sleep(LATTICE_STATUS_POLL_INTERVAL_MS, signal);
        statusResult = await this.latticeService.getWorkspaceStatus(workspaceName, {
          timeoutMs: Math.min(remainingMs(), 1e4),
          signal
        });
        if (statusResult.kind === "ok" && statusResult.status === "running") {
          this.lastActivityAtMs = Date.now();
          emitStatus("ready");
          return { ready: true };
        }
        if (statusResult.kind === "not_found") {
          emitStatus("error");
          return {
            ready: false,
            error: `Lattice workspace "${workspaceName}" not found`,
            errorType: "runtime_not_ready"
          };
        }
      }
      if (isTimedOut()) {
        emitStatus("error");
        return {
          ready: false,
          error: "Lattice workspace is still stopping... Please retry shortly.",
          errorType: "runtime_start_failed"
        };
      }
    }
    emitStatus("starting", "Connecting to Lattice workspace...");
    log.debug("Connecting to Lattice workspace via SSH", { workspaceName });
    const controller = new AbortController();
    const checkInterval = setInterval(() => {
      if (isTimedOut() || signal?.aborted) {
        controller.abort();
        clearInterval(checkInterval);
      }
    }, 1e3);
    controller.signal.addEventListener("abort", () => clearInterval(checkInterval), {
      once: true
    });
    if (isTimedOut() || signal?.aborted) controller.abort();
    try {
      for await (const _line of this.latticeService.waitForStartupScripts(
        workspaceName,
        controller.signal
      )) {
      }
      this.lastActivityAtMs = Date.now();
      emitStatus("ready");
      return { ready: true };
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      emitStatus("error");
      if (isTimedOut()) {
        return {
          ready: false,
          error: "Lattice workspace start timed out",
          errorType: "runtime_start_failed"
        };
      }
      if (signal?.aborted) {
        return { ready: false, error: "Aborted", errorType: "runtime_start_failed" };
      }
      if (/not found|no access/i.test(errorMsg)) {
        return {
          ready: false,
          error: `Lattice workspace "${workspaceName}" not found`,
          errorType: "runtime_not_ready"
        };
      }
      return {
        ready: false,
        error: `Failed to connect to Lattice workspace: ${errorMsg}`,
        errorType: "runtime_start_failed"
      };
    } finally {
      clearInterval(checkInterval);
    }
  }
  /** Promise-based sleep helper */
  sleep(ms, abortSignal) {
    if (abortSignal?.aborted) {
      return Promise.resolve();
    }
    return new Promise((resolve3) => {
      const timeout = setTimeout(() => {
        abortSignal?.removeEventListener("abort", onAbort);
        resolve3();
      }, ms);
      const onAbort = () => {
        clearTimeout(timeout);
        abortSignal?.removeEventListener("abort", onAbort);
        resolve3();
      };
      abortSignal?.addEventListener("abort", onAbort, { once: true });
    });
  }
  /**
   * Finalize runtime config after collision handling.
   * Derives Lattice workspace name from branch name and computes SSH host.
   */
  finalizeConfig(finalBranchName, config2) {
    if (!isSSHRuntime(config2) || !config2.lattice) {
      return Promise.resolve(Ok(config2));
    }
    const latticeConf = config2.lattice;
    let workspaceName = latticeConf.workspaceName?.trim() ?? "";
    if (!latticeConf.existingWorkspace) {
      if (!workspaceName) {
        workspaceName = `unix-${finalBranchName}`;
      }
      workspaceName = toLatticeCompatibleName(workspaceName);
      if (!LATTICE_NAME_REGEX.test(workspaceName)) {
        return Promise.resolve(
          Err(
            `Workspace name "${finalBranchName}" cannot be converted to a valid Lattice name. Use only letters, numbers, and hyphens.`
          )
        );
      }
    } else {
      if (!workspaceName) {
        return Promise.resolve(Err("Lattice workspace name is required for existing workspaces"));
      }
    }
    if (!workspaceName) {
      return Promise.resolve(Err("Lattice workspace name is required"));
    }
    return Promise.resolve(
      Ok({
        ...config2,
        host: `${workspaceName}.lattice`,
        lattice: { ...latticeConf, workspaceName }
      })
    );
  }
  /**
   * Validate before persisting workspace metadata.
   * Checks if a Lattice workspace with this name already exists.
   */
  async validateBeforePersist(_finalBranchName, config2) {
    if (!isSSHRuntime(config2) || !config2.lattice) {
      return Ok(void 0);
    }
    if (config2.lattice.existingWorkspace) {
      return Ok(void 0);
    }
    const workspaceName = config2.lattice.workspaceName;
    if (!workspaceName) {
      return Ok(void 0);
    }
    const exists = await this.latticeService.workspaceExists(workspaceName);
    if (exists) {
      return Err(
        `A Lattice workspace named "${workspaceName}" already exists. Either switch to "Existing" mode to use it, delete/rename it in Coder, or choose a different unix workspace name.`
      );
    }
    return Ok(void 0);
  }
  /**
   * Create workspace (fast path only - no SSH needed).
   * The Lattice workspace may not exist yet, so we can't reach the SSH host.
   * Just compute the workspace path locally.
   */
  createWorkspace(params) {
    const workspacePath = this.getWorkspacePath(params.projectPath, params.directoryName);
    params.initLogger.logStep("Workspace path computed (Coder provisioning will follow)");
    return Promise.resolve({
      success: true,
      workspacePath
    });
  }
  /**
   * Delete workspace: removes SSH files AND deletes Lattice workspace (if Unix-managed).
   *
   * IMPORTANT: Only delete the Lattice workspace once we're confident unix will commit
   * the deletion. In the non-force path, WorkspaceService.remove() aborts and keeps
   * workspace metadata when runtime.deleteWorkspace() fails.
   */
  async deleteWorkspace(projectPath, workspaceName, force, abortSignal) {
    if (this.latticeConfig.existingWorkspace) {
      return super.deleteWorkspace(projectPath, workspaceName, force, abortSignal);
    }
    const latticeWorkspaceName = this.latticeConfig.workspaceName;
    if (!latticeWorkspaceName) {
      log.warn("Lattice workspace name not set, falling back to SSH-only deletion");
      return super.deleteWorkspace(projectPath, workspaceName, force, abortSignal);
    }
    const statusResult = await this.latticeService.getWorkspaceStatus(latticeWorkspaceName);
    if (statusResult.kind === "not_found") {
      log.debug("Lattice workspace already deleted, skipping SSH cleanup", { latticeWorkspaceName });
      return { success: true, deletedPath: this.getWorkspacePath(projectPath, workspaceName) };
    }
    if (statusResult.kind === "error") {
      log.warn("Could not check Lattice workspace status, proceeding with SSH cleanup", {
        latticeWorkspaceName,
        error: statusResult.error
      });
    }
    if (statusResult.kind === "ok") {
      if (statusResult.status === "deleted" || statusResult.status === "deleting") {
        log.debug("Lattice workspace is deleted/deleting, skipping SSH cleanup", {
          latticeWorkspaceName,
          status: statusResult.status
        });
        return { success: true, deletedPath: this.getWorkspacePath(projectPath, workspaceName) };
      }
    }
    const sshResult = await super.deleteWorkspace(projectPath, workspaceName, force, abortSignal);
    if (!sshResult.success && !force) {
      return sshResult;
    }
    try {
      log.debug(`Deleting Lattice workspace "${latticeWorkspaceName}"`);
      await this.latticeService.deleteWorkspace(latticeWorkspaceName);
    } catch (error) {
      const message = error instanceof Error ? error.message : String(error);
      log.error("Failed to delete Lattice workspace", {
        latticeWorkspaceName,
        error: message
      });
      if (sshResult.success) {
        return {
          success: false,
          error: `SSH delete succeeded, but failed to delete Lattice workspace: ${message}`
        };
      }
      return {
        success: false,
        error: `SSH delete failed: ${sshResult.error}; Coder delete also failed: ${message}`
      };
    }
    return sshResult;
  }
  /**
   * Fork workspace: delegates to SSHRuntime, but marks both source and fork
   * as existingWorkspace=true so neither can delete the shared Lattice workspace.
   *
   * IMPORTANT: Also updates this instance's latticeConfig so that if postCreateSetup
   * runs on this same runtime instance (for the forked workspace), it won't attempt
   * to create a new Lattice workspace.
   */
  async forkWorkspace(params) {
    const result = await super.forkWorkspace(params);
    if (!result.success) return result;
    const sharedCoderConfig = { ...this.latticeConfig, existingWorkspace: true };
    this.latticeConfig = sharedCoderConfig;
    const sshConfig = this.getConfig();
    const sharedRuntimeConfig = { type: "ssh", ...sshConfig, lattice: sharedCoderConfig };
    return {
      ...result,
      forkedRuntimeConfig: sharedRuntimeConfig,
      sourceRuntimeConfig: sharedRuntimeConfig
    };
  }
  /**
   * Post-create setup: provision Lattice workspace and configure SSH.
   * This runs after unix persists workspace metadata, so build logs stream to UI.
   */
  async postCreateSetup(params) {
    const { initLogger, abortSignal } = params;
    if (!this.latticeConfig.existingWorkspace) {
      const latticeWorkspaceName = this.latticeConfig.workspaceName;
      if (!latticeWorkspaceName) {
        throw new Error("Lattice workspace name is required (should be set by finalizeConfig)");
      }
      if (!this.latticeConfig.template) {
        throw new Error("Coder template is required for new workspaces");
      }
      initLogger.logStep(`Creating Lattice workspace "${latticeWorkspaceName}"...`);
      try {
        for await (const line of this.latticeService.createWorkspace(
          latticeWorkspaceName,
          this.latticeConfig.template,
          this.latticeConfig.preset,
          abortSignal,
          this.latticeConfig.templateOrg
        )) {
          initLogger.logStdout(line);
        }
        initLogger.logStep("Lattice workspace created successfully");
        initLogger.logStep("Waiting for startup scripts...");
        for await (const line of this.latticeService.waitForStartupScripts(
          latticeWorkspaceName,
          abortSignal
        )) {
          initLogger.logStdout(line);
        }
      } catch (error) {
        const errorMsg = error instanceof Error ? error.message : String(error);
        log.error("Failed to create Lattice workspace", { error, config: this.latticeConfig });
        initLogger.logStderr(`Failed to create Lattice workspace: ${errorMsg}`);
        throw new Error(`Failed to create Lattice workspace: ${errorMsg}`);
      }
    } else if (this.latticeConfig.workspaceName) {
      const workspaceName = this.latticeConfig.workspaceName;
      let status = await this.latticeService.getWorkspaceStatus(workspaceName, {
        signal: abortSignal
      });
      if (status.kind === "ok" && (status.status === "stopping" || status.status === "canceling")) {
        initLogger.logStep(`Waiting for Lattice workspace "${workspaceName}" to stop...`);
        while (status.kind === "ok" && (status.status === "stopping" || status.status === "canceling")) {
          if (abortSignal?.aborted) {
            throw new Error("Aborted while waiting for Lattice workspace to stop");
          }
          await this.sleep(LATTICE_STATUS_POLL_INTERVAL_MS, abortSignal);
          status = await this.latticeService.getWorkspaceStatus(workspaceName, {
            signal: abortSignal
          });
        }
      }
      initLogger.logStep(`Connecting to Lattice workspace "${workspaceName}"...`);
      try {
        for await (const line of this.latticeService.waitForStartupScripts(
          workspaceName,
          abortSignal
        )) {
          initLogger.logStdout(line);
        }
      } catch (error) {
        const errorMsg = error instanceof Error ? error.message : String(error);
        log.error("Failed waiting for Lattice workspace", { error, config: this.latticeConfig });
        initLogger.logStderr(`Failed connecting to Lattice workspace: ${errorMsg}`);
        throw new Error(`Failed connecting to Lattice workspace: ${errorMsg}`);
      }
    }
    initLogger.logStep("Configuring SSH for Coder...");
    try {
      await this.latticeService.ensureSSHConfig();
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      log.error("Failed to configure SSH for Coder", { error });
      initLogger.logStderr(`Failed to configure SSH: ${errorMsg}`);
      throw new Error(`Failed to configure SSH for Coder: ${errorMsg}`);
    }
    initLogger.logStep("Preparing workspace directory...");
    const parentDir = path9.posix.dirname(params.workspacePath);
    const mkdirResult = await execBuffered(this, `mkdir -p ${expandTildeForSSH(parentDir)}`, {
      cwd: "/tmp",
      timeout: 10,
      abortSignal
    });
    if (mkdirResult.exitCode !== 0) {
      const errorMsg = mkdirResult.stderr || mkdirResult.stdout || "Unknown error";
      log.error("Failed to create workspace parent directory", { parentDir, error: errorMsg });
      initLogger.logStderr(`Failed to prepare workspace directory: ${errorMsg}`);
      throw new Error(`Failed to prepare workspace directory: ${errorMsg}`);
    }
    this.lastActivityAtMs = Date.now();
  }
};

// src/node/runtime/transports/OpenSSHTransport.ts
import { spawn as spawn4 } from "child_process";

// src/node/runtime/ptySpawn.ts
function loadNodePty(runtimeType, preferElectronBuild) {
  const first = preferElectronBuild ? "node-pty" : "@lydell/node-pty";
  const second = preferElectronBuild ? "@lydell/node-pty" : "node-pty";
  try {
    const pty = __require(first);
    log.debug(`Using ${first} for ${runtimeType}`);
    return pty;
  } catch {
    try {
      const pty = __require(second);
      log.debug(`Using ${second} for ${runtimeType} (fallback)`);
      return pty;
    } catch (err) {
      log.error("Neither @lydell/node-pty nor node-pty available:", err);
      throw new Error(
        process.versions.electron ? `${runtimeType} terminals are not available. node-pty failed to load (likely due to Electron ABI version mismatch). Run 'make rebuild-native' to rebuild native modules.` : `${runtimeType} terminals are not available. No prebuilt binaries found for your platform. Supported: linux-x64, linux-arm64, darwin-x64, darwin-arm64, win32-x64.`
      );
    }
  }
}
function resolvePathEnv(env3, pathEnvOverride) {
  if (pathEnvOverride) {
    return pathEnvOverride;
  }
  return env3.PATH ?? env3.Path ?? (process.platform === "win32" ? void 0 : "/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin");
}
function spawnPtyProcess(request) {
  const pty = loadNodePty(request.runtimeLabel, request.preferElectronBuild);
  const mergedEnv = { ...process.env, ...request.env };
  const pathEnv = resolvePathEnv(mergedEnv, request.pathEnv);
  const env3 = {
    ...mergedEnv,
    TERM: "xterm-256color",
    ...pathEnv ? { PATH: pathEnv } : {}
  };
  try {
    return pty.spawn(request.command, request.args, {
      name: "xterm-256color",
      cols: request.cols,
      rows: request.rows,
      cwd: request.cwd,
      env: env3
    });
  } catch (err) {
    log.error(`[PTY] Failed to spawn ${request.runtimeLabel} terminal:`, err);
    const printableArgs = request.args.length > 0 ? ` ${request.args.join(" ")}` : "";
    const cmd = `${request.command}${printableArgs}`;
    const details = `cmd="${cmd}", cwd="${request.cwd}", platform="${process.platform}"`;
    const errMessage = err instanceof Error ? err.message : String(err);
    if (request.logLocalEnv) {
      log.error(`Local PTY spawn config: ${cmd} (cwd: ${request.cwd})`);
      log.error(`process.env.SHELL: ${process.env.SHELL ?? "undefined"}`);
      log.error(`process.env.PATH: ${process.env.PATH ?? process.env.Path ?? "undefined"}`);
    }
    throw new Error(`Failed to spawn ${request.runtimeLabel} terminal (${details}): ${errMessage}`);
  }
}

// src/node/runtime/sshConnectionPool.ts
import * as crypto2 from "crypto";
import * as path10 from "path";
import * as os3 from "os";
import { spawn as spawn3 } from "child_process";
var BACKOFF_SCHEDULE = [1, 2, 4, 7, 10];
function withJitter(seconds) {
  const jitterFactor = 0.8 + Math.random() * 0.4;
  return seconds * jitterFactor;
}
var HEALTHY_TTL_MS = 15 * 1e3;
var DEFAULT_PROBE_TIMEOUT_MS = 1e4;
var DEFAULT_MAX_WAIT_MS = 2 * 60 * 1e3;
async function sleepWithAbort(ms, abortSignal) {
  if (ms <= 0) return;
  if (abortSignal?.aborted) {
    throw new Error("Operation aborted");
  }
  await new Promise((resolve3, reject) => {
    const timer = setTimeout(() => {
      cleanup();
      resolve3();
    }, ms);
    const onAbort = () => {
      cleanup();
      reject(new Error("Operation aborted"));
    };
    const cleanup = () => {
      clearTimeout(timer);
      abortSignal?.removeEventListener("abort", onAbort);
    };
    abortSignal?.addEventListener("abort", onAbort);
  });
}
var SSHConnectionPool = class {
  constructor() {
    this.health = /* @__PURE__ */ new Map();
    this.inflight = /* @__PURE__ */ new Map();
  }
  async acquireConnection(config2, timeoutMsOrOptions = DEFAULT_PROBE_TIMEOUT_MS) {
    const options = typeof timeoutMsOrOptions === "number" ? { timeoutMs: timeoutMsOrOptions } : timeoutMsOrOptions ?? {};
    const timeoutMs = options.timeoutMs ?? DEFAULT_PROBE_TIMEOUT_MS;
    const sleep = options.sleep ?? sleepWithAbort;
    const maxWaitMs = options.maxWaitMs ?? DEFAULT_MAX_WAIT_MS;
    const shouldWait = maxWaitMs > 0;
    const key = makeConnectionKey(config2);
    const startTime = Date.now();
    while (true) {
      if (options.abortSignal?.aborted) {
        throw new Error("Operation aborted");
      }
      const health = this.health.get(key);
      if (health?.backoffUntil && health.backoffUntil > /* @__PURE__ */ new Date()) {
        const remainingMs = health.backoffUntil.getTime() - Date.now();
        const remainingSecs = Math.ceil(remainingMs / 1e3);
        if (!shouldWait) {
          throw new Error(
            `SSH connection to ${config2.host} is in backoff for ${remainingSecs}s. Last error: ${health.lastError ?? "unknown"}`
          );
        }
        const elapsedMs = Date.now() - startTime;
        const budgetMs = Math.max(0, maxWaitMs - elapsedMs);
        if (budgetMs <= 0) {
          throw new Error(
            `SSH connection to ${config2.host} did not become healthy within ${maxWaitMs}ms. Last error: ${health.lastError ?? "unknown"}`
          );
        }
        const waitMs = Math.min(remainingMs, budgetMs);
        options.onWait?.(waitMs);
        await sleep(waitMs, options.abortSignal);
        continue;
      }
      if (health?.status === "healthy") {
        const age = Date.now() - (health.lastSuccess?.getTime() ?? 0);
        if (age < HEALTHY_TTL_MS) {
          log.debug(`SSH connection to ${config2.host} is known healthy, skipping probe`);
          return;
        }
        log.debug(
          `SSH connection to ${config2.host} health is stale (${Math.round(age / 1e3)}s), re-probing`
        );
      }
      const existing = this.inflight.get(key);
      if (existing) {
        log.debug(`SSH connection to ${config2.host} has inflight probe, waiting...`);
        try {
          await existing;
          return;
        } catch (error) {
          if (!shouldWait) {
            throw error;
          }
          continue;
        }
      }
      log.debug(`SSH connection to ${config2.host} needs probe, starting health check`);
      const probe = this.probeConnection(config2, timeoutMs, key);
      this.inflight.set(key, probe);
      try {
        await probe;
        return;
      } catch (error) {
        if (!shouldWait) {
          throw error;
        }
        continue;
      } finally {
        this.inflight.delete(key);
      }
    }
  }
  /**
   * Get current health status for a connection
   */
  getConnectionHealth(config2) {
    const key = makeConnectionKey(config2);
    return this.health.get(key);
  }
  /**
   * Get deterministic controlPath for SSH config.
   */
  getControlPath(config2) {
    return getControlPath(config2);
  }
  /**
   * Reset backoff for a connection (e.g., after user intervention)
   */
  resetBackoff(config2) {
    const key = makeConnectionKey(config2);
    const health = this.health.get(key);
    if (health) {
      health.backoffUntil = void 0;
      health.consecutiveFailures = 0;
      health.status = "unknown";
      log.info(`Reset backoff for SSH connection to ${config2.host}`);
    }
  }
  /**
   * Mark connection as healthy.
   * Call after successful SSH operations to maintain health state.
   */
  markHealthy(config2) {
    const key = makeConnectionKey(config2);
    this.markHealthyByKey(key);
  }
  /**
   * Report a connection failure.
   * Call when SSH operations fail due to connection issues (not command failures).
   * This triggers backoff to prevent thundering herd on a failing host.
   */
  reportFailure(config2, error) {
    const key = makeConnectionKey(config2);
    this.markFailedByKey(key, error);
  }
  /**
   * Mark connection as healthy by key (internal use)
   */
  markHealthyByKey(key) {
    this.health.set(key, {
      status: "healthy",
      lastSuccess: /* @__PURE__ */ new Date(),
      consecutiveFailures: 0
    });
  }
  /**
   * Mark connection as failed (internal use after failed probe)
   */
  markFailedByKey(key, error) {
    const current = this.health.get(key);
    const failures = (current?.consecutiveFailures ?? 0) + 1;
    const backoffIndex = Math.min(failures - 1, BACKOFF_SCHEDULE.length - 1);
    const backoffSecs = withJitter(BACKOFF_SCHEDULE[backoffIndex]);
    this.health.set(key, {
      status: "unhealthy",
      lastFailure: /* @__PURE__ */ new Date(),
      lastError: error,
      backoffUntil: new Date(Date.now() + backoffSecs * 1e3),
      consecutiveFailures: failures
    });
    log.warn(
      `SSH connection failed (${failures} consecutive). Backoff for ${backoffSecs.toFixed(1)}s. Error: ${error}`
    );
  }
  /**
   * Probe connection health by running a simple command
   */
  async probeConnection(config2, timeoutMs, key) {
    const controlPath = getControlPath(config2);
    const args2 = ["-T"];
    if (config2.port) {
      args2.push("-p", config2.port.toString());
    }
    if (config2.identityFile) {
      args2.push("-i", config2.identityFile);
      args2.push("-o", "StrictHostKeyChecking=no");
      args2.push("-o", "UserKnownHostsFile=/dev/null");
      args2.push("-o", "LogLevel=ERROR");
    }
    args2.push("-o", "ControlMaster=auto");
    args2.push("-o", `ControlPath=${controlPath}`);
    args2.push("-o", "ControlPersist=60");
    const connectTimeout = Math.min(Math.ceil(timeoutMs / 1e3), 15);
    args2.push("-o", `ConnectTimeout=${connectTimeout}`);
    args2.push("-o", "ServerAliveInterval=5");
    args2.push("-o", "ServerAliveCountMax=2");
    args2.push(config2.host, "echo ok");
    log.debug(`SSH probe: ssh ${args2.join(" ")}`);
    return new Promise((resolve3, reject) => {
      const proc = spawn3("ssh", args2, { stdio: ["ignore", "pipe", "pipe"] });
      let stderr = "";
      proc.stderr.on("data", (data) => {
        stderr += data.toString();
      });
      let timedOut = false;
      const timeout = setTimeout(() => {
        timedOut = true;
        proc.kill("SIGKILL");
        const error = "SSH probe timed out";
        this.markFailedByKey(key, error);
        reject(new Error(error));
      }, timeoutMs);
      proc.on("close", (code) => {
        clearTimeout(timeout);
        if (timedOut) return;
        if (code === 0) {
          this.markHealthyByKey(key);
          log.debug(`SSH probe to ${config2.host} succeeded`);
          resolve3();
        } else {
          const error = stderr.trim() || `SSH probe failed with code ${code ?? "unknown"}`;
          this.markFailedByKey(key, error);
          reject(new Error(error));
        }
      });
      proc.on("error", (err) => {
        clearTimeout(timeout);
        const error = `SSH probe spawn error: ${err.message}`;
        this.markFailedByKey(key, error);
        reject(new Error(error));
      });
    });
  }
};
var sshConnectionPool = new SSHConnectionPool();
function getControlPath(config2) {
  const key = makeConnectionKey(config2);
  const hash = hashKey(key);
  return path10.join(os3.tmpdir(), `unix-ssh-${hash}`);
}
function makeConnectionKey(config2) {
  const parts = [
    os3.userInfo().username,
    // Include local user to prevent cross-user collisions
    config2.host,
    config2.port?.toString() ?? "22",
    config2.identityFile ?? "default"
  ];
  return parts.join(":");
}
function hashKey(key) {
  return crypto2.createHash("sha256").update(key).digest("hex").substring(0, 12);
}

// src/node/runtime/transports/OpenSSHTransport.ts
var OpenSSHTransport = class {
  constructor(config2) {
    this.config = config2;
    this.controlPath = getControlPath(config2);
  }
  isConnectionFailure(exitCode, _stderr) {
    return exitCode === 255;
  }
  getConfig() {
    return this.config;
  }
  markHealthy() {
    sshConnectionPool.markHealthy(this.config);
  }
  reportFailure(error) {
    sshConnectionPool.reportFailure(this.config, error);
  }
  async acquireConnection(options) {
    await sshConnectionPool.acquireConnection(this.config, {
      abortSignal: options?.abortSignal,
      timeoutMs: options?.timeoutMs,
      onWait: options?.onWait
    });
  }
  async spawnRemoteProcess(fullCommand, options) {
    await sshConnectionPool.acquireConnection(this.config, {
      abortSignal: options.abortSignal
    });
    const sshArgs = [options.forcePTY ? "-t" : "-T", ...this.buildSSHArgs()];
    const connectTimeout = options.timeout !== void 0 ? Math.min(Math.ceil(options.timeout), 15) : 15;
    sshArgs.push("-o", `ConnectTimeout=${connectTimeout}`);
    sshArgs.push("-o", "ServerAliveInterval=5");
    sshArgs.push("-o", "ServerAliveCountMax=2");
    sshArgs.push(this.config.host, fullCommand);
    log.debug(`SSH exec on ${this.config.host}`);
    const process3 = spawn4("ssh", sshArgs, {
      stdio: ["pipe", "pipe", "pipe"],
      windowsHide: true
    });
    return { process: process3 };
  }
  async createPtySession(params) {
    await sshConnectionPool.acquireConnection(this.config, { maxWaitMs: 0 });
    const args2 = [...this.buildSSHArgs()];
    args2.push("-o", "ConnectTimeout=15");
    args2.push("-o", "ServerAliveInterval=5");
    args2.push("-o", "ServerAliveCountMax=2");
    args2.push("-t");
    args2.push(this.config.host);
    const expandedPath = expandTildeForSSH(params.workspacePath);
    args2.push(`cd ${expandedPath} && exec $SHELL -i`);
    return spawnPtyProcess({
      runtimeLabel: "SSH",
      command: "ssh",
      args: args2,
      cwd: process.cwd(),
      cols: params.cols,
      rows: params.rows,
      preferElectronBuild: false
    });
  }
  buildSSHArgs() {
    const args2 = [];
    if (this.config.port) {
      args2.push("-p", this.config.port.toString());
    }
    if (this.config.identityFile) {
      args2.push("-i", this.config.identityFile);
      args2.push("-o", "StrictHostKeyChecking=no");
      args2.push("-o", "UserKnownHostsFile=/dev/null");
    }
    args2.push("-o", "LogLevel=FATAL");
    args2.push("-o", "ControlMaster=auto");
    args2.push("-o", `ControlPath=${this.controlPath}`);
    args2.push("-o", "ControlPersist=60");
    return args2;
  }
};

// src/node/runtime/transports/SSH2Transport.ts
import { EventEmitter } from "events";
import { PassThrough } from "stream";

// src/node/runtime/SSH2ConnectionPool.ts
import * as fs6 from "fs/promises";
import * as os5 from "os";
import * as path12 from "path";
import { spawn as spawn5 } from "child_process";
import { Duplex } from "stream";
import { Client } from "ssh2";

// src/node/runtime/sshConfigParser.ts
var import_ssh_config = __toESM(require_dist2());
import { spawnSync } from "child_process";
import * as fs5 from "fs/promises";
import * as os4 from "os";
import * as path11 from "path";
var DEFAULT_SSH_PORT = 22;
function getHomeDir2() {
  return process.env.USERPROFILE ?? os4.homedir();
}
function getDefaultUsername() {
  try {
    return os4.userInfo().username;
  } catch {
    return process.env.USER ?? process.env.USERNAME ?? "";
  }
}
function expandHomePath(value2, homeDir) {
  if (value2 === "~") {
    return homeDir;
  }
  if (value2.startsWith("~/") || value2.startsWith("~\\")) {
    return path11.join(homeDir, value2.slice(2));
  }
  return value2;
}
function normalizeIdentityFile(value2, homeDir) {
  const expanded = expandHomePath(value2, homeDir);
  if (path11.isAbsolute(expanded)) {
    return expanded;
  }
  return path11.join(homeDir, expanded);
}
function parseHostAndUser(host) {
  const trimmed = host.trim();
  const atIndex = trimmed.lastIndexOf("@");
  if (atIndex > 0) {
    const user = trimmed.slice(0, atIndex).trim();
    const hostname = trimmed.slice(atIndex + 1).trim();
    if (user && hostname) {
      return { host: hostname, user };
    }
  }
  return { host: trimmed };
}
function isParsedValueToken(value2) {
  return typeof value2 === "object" && value2 !== null && "val" in value2 && "separator" in value2;
}
function tokensToString(tokens) {
  return tokens.map(({ val, separator, quoted }) => {
    const rendered = quoted ? `"${val}"` : val;
    return `${separator}${rendered}`;
  }).join("").trimStart();
}
function getConfigValue(config2, key) {
  const match = Object.entries(config2).find(
    ([configKey]) => configKey.toLowerCase() === key.toLowerCase()
  );
  return match?.[1];
}
function toStringValue(value2) {
  if (typeof value2 === "string") {
    return value2;
  }
  if (Array.isArray(value2)) {
    const first = value2[0];
    if (typeof first === "string") {
      return first;
    }
    if (isParsedValueToken(first)) {
      return tokensToString(value2);
    }
  }
  return void 0;
}
function getCriteriaValue(criteria, key) {
  const match = Object.entries(criteria).find(
    ([criteriaKey]) => criteriaKey.toLowerCase() === key.toLowerCase()
  );
  return match?.[1];
}
function criteriaToString(value2) {
  if (typeof value2 === "string") {
    return value2;
  }
  if (Array.isArray(value2)) {
    return value2[0]?.val;
  }
  return void 0;
}
function criteriaToStringArray(value2) {
  if (typeof value2 === "string") {
    return [value2];
  }
  if (Array.isArray(value2)) {
    return value2.map(({ val }) => val);
  }
  return [];
}
function expandMatchExecTokens(command, hostName, user) {
  return command.replace(/%(%|h|r)/g, (_match, token) => {
    switch (token) {
      case "%":
        return "%";
      case "h":
        return hostName;
      case "r":
        return user ?? "";
      default:
        return _match;
    }
  });
}
function applyNegatedExecMatch(config2, hostName, user, computed) {
  if (getConfigValue(computed, "ProxyCommand")) {
    return;
  }
  for (const line of config2) {
    if (line.type !== import_ssh_config.default.DIRECTIVE || line.param !== "Match") {
      continue;
    }
    if (!("criteria" in line)) {
      continue;
    }
    const criteria = line.criteria;
    const hostCriterion = getCriteriaValue(criteria, "host");
    const negatedExec = getCriteriaValue(criteria, "!exec");
    if (!hostCriterion || !negatedExec) {
      continue;
    }
    const hostPatterns = criteriaToStringArray(hostCriterion);
    if (!(0, import_ssh_config.glob)(hostPatterns, hostName)) {
      continue;
    }
    const execCommand = criteriaToString(negatedExec);
    if (!execCommand) {
      continue;
    }
    const expandedCommand = expandMatchExecTokens(execCommand, hostName, user);
    const execResult = spawnSync(expandedCommand, { shell: true });
    if (execResult.status === 0) {
      continue;
    }
    const proxyLine = line.config.find(
      (subline) => subline.type === import_ssh_config.default.DIRECTIVE && subline.param.toLowerCase() === "proxycommand"
    );
    if (proxyLine?.type === import_ssh_config.default.DIRECTIVE) {
      computed.ProxyCommand = proxyLine.value;
      return;
    }
  }
}
function toStringArray(value2) {
  if (typeof value2 === "string") {
    return [value2];
  }
  if (Array.isArray(value2)) {
    const first = value2[0];
    if (typeof first === "string") {
      return value2;
    }
    if (isParsedValueToken(first)) {
      return [tokensToString(value2)];
    }
  }
  return [];
}
async function loadSSHConfig() {
  const homeDir = getHomeDir2();
  const configPath = path11.join(homeDir, ".ssh", "config");
  try {
    const content = await fs5.readFile(configPath, "utf8");
    const parsed = import_ssh_config.default.parse(content);
    return parsed;
  } catch (error) {
    if (error?.code !== "ENOENT") {
      log.debug("Failed to read SSH config", {
        configPath,
        error: error instanceof Error ? error.message : String(error)
      });
    }
    return null;
  }
}
async function resolveSSHConfig(host) {
  const { host: hostAlias, user: userOverride } = parseHostAndUser(host);
  const homeDir = getHomeDir2();
  const config2 = await loadSSHConfig();
  const computed = config2 ? userOverride ? config2.compute({ Host: hostAlias, User: userOverride }) : config2.compute(hostAlias) : {};
  const hostName = toStringValue(getConfigValue(computed, "HostName")) ?? hostAlias;
  const userFromConfig = toStringValue(getConfigValue(computed, "User"));
  if (config2) {
    const matchExecUser = userOverride ?? userFromConfig ?? getDefaultUsername();
    applyNegatedExecMatch(config2, hostName, matchExecUser, computed);
  }
  const portValue = toStringValue(getConfigValue(computed, "Port"));
  const identityValues = toStringArray(getConfigValue(computed, "IdentityFile"));
  const proxyCommandRaw = toStringValue(getConfigValue(computed, "ProxyCommand"));
  const port = portValue ? Number.parseInt(portValue, 10) : DEFAULT_SSH_PORT;
  const identityFiles = identityValues.map((value2) => normalizeIdentityFile(value2, homeDir));
  const proxyCommand = proxyCommandRaw && proxyCommandRaw.toLowerCase() !== "none" ? proxyCommandRaw.trim() : void 0;
  return {
    host: hostAlias,
    hostName,
    user: userOverride ?? userFromConfig,
    port: Number.isFinite(port) ? port : DEFAULT_SSH_PORT,
    identityFiles,
    proxyCommand
  };
}

// src/node/runtime/SSH2ConnectionPool.ts
var BACKOFF_SCHEDULE2 = [1, 2, 4, 7, 10];
var DEFAULT_CONNECT_TIMEOUT_MS = 1e4;
var DEFAULT_MAX_WAIT_MS2 = 2 * 60 * 1e3;
var IDLE_TIMEOUT_MS = 60 * 1e3;
function withJitter2(seconds) {
  const jitterFactor = 0.8 + Math.random() * 0.4;
  return seconds * jitterFactor;
}
async function sleepWithAbort2(ms, abortSignal) {
  if (ms <= 0) return;
  if (abortSignal?.aborted) {
    throw new Error("Operation aborted");
  }
  await new Promise((resolve3, reject) => {
    const timer = setTimeout(() => {
      cleanup();
      resolve3();
    }, ms);
    const onAbort = () => {
      cleanup();
      reject(new Error("Operation aborted"));
    };
    const cleanup = () => {
      clearTimeout(timer);
      abortSignal?.removeEventListener("abort", onAbort);
    };
    abortSignal?.addEventListener("abort", onAbort);
  });
}
function getAgentConfig() {
  if (process.env.SSH_AUTH_SOCK) {
    return process.env.SSH_AUTH_SOCK;
  }
  if (process.platform === "win32") {
    return "pageant";
  }
  return void 0;
}
function getDefaultUsername2() {
  try {
    return os5.userInfo().username;
  } catch {
    return process.env.USER ?? process.env.USERNAME ?? "unknown";
  }
}
var DEFAULT_IDENTITY_FILES = [
  "~/.ssh/id_rsa",
  "~/.ssh/id_ecdsa",
  "~/.ssh/id_ecdsa_sk",
  "~/.ssh/id_ed25519",
  "~/.ssh/id_ed25519_sk",
  "~/.ssh/id_dsa"
];
function expandLocalPath(value2) {
  if (value2 === "~") {
    return os5.homedir();
  }
  if (value2.startsWith("~/") || value2.startsWith("~\\")) {
    return path12.join(os5.homedir(), value2.slice(2));
  }
  if (!path12.isAbsolute(value2)) {
    return path12.join(os5.homedir(), value2);
  }
  return value2;
}
function makeConnectionKey2(config2) {
  const parts = [
    getDefaultUsername2(),
    config2.host,
    config2.port?.toString() ?? "22",
    config2.identityFile ?? "default"
  ];
  return parts.join(":");
}
function sanitizeProxyCommand(command, tokens) {
  return command.replace(/%(%|h|p|r)/g, (match, token) => {
    switch (token) {
      case "%":
        return "%";
      case "h":
        return tokens.host;
      case "p":
        return String(tokens.port);
      case "r":
        return tokens.user;
      default:
        return match;
    }
  });
}
function getProxyShellArgs(command) {
  if (process.platform === "win32") {
    return {
      command: process.env.COMSPEC ?? "cmd.exe",
      args: ["/d", "/s", "/c", command]
    };
  }
  return { command: "/bin/sh", args: ["-c", command] };
}
function spawnProxyCommand(command, tokens) {
  const substituted = sanitizeProxyCommand(command, tokens);
  const { command: shell, args: args2 } = getProxyShellArgs(substituted);
  const proc = spawn5(shell, args2, {
    stdio: ["pipe", "pipe", "pipe"],
    windowsHide: true
  });
  proc.stderr?.on("data", () => {
  });
  if (!proc.stdin || !proc.stdout) {
    throw new Error("ProxyCommand did not provide stdio streams");
  }
  const sock = Duplex.from({ writable: proc.stdin, readable: proc.stdout });
  return { sock, process: proc };
}
function isEncryptedKeyError(error) {
  if (!error) {
    return false;
  }
  const message = error instanceof Error ? error.message : typeof error === "string" ? error : "";
  return message.includes("Encrypted private key detected") || message.includes("Encrypted private OpenSSH key detected") || message.includes("Encrypted PPK private key detected") || message.includes("Cannot parse privateKey") && message.includes("ncrypted");
}
function isAuthFailure(error) {
  if (!error) {
    return false;
  }
  if (isEncryptedKeyError(error)) {
    return true;
  }
  if (typeof error === "object" && error !== null && "level" in error) {
    const level = error.level;
    if (level === "client-authentication") {
      return true;
    }
  }
  const message = error instanceof Error ? error.message : typeof error === "string" ? error : "";
  return message.includes("All configured authentication methods failed") || message.includes("Authentication failed") || message.includes("Authentication failure");
}
async function resolvePrivateKeys(identityFiles) {
  const keys = [];
  for (const file of identityFiles) {
    try {
      keys.push(await fs6.readFile(file));
    } catch {
    }
  }
  return keys;
}
var SSH2ConnectionPool = class {
  constructor() {
    this.health = /* @__PURE__ */ new Map();
    this.inflight = /* @__PURE__ */ new Map();
    this.connections = /* @__PURE__ */ new Map();
  }
  async acquireConnection(config2, options = {}) {
    const key = makeConnectionKey2(config2);
    const timeoutMs = options.timeoutMs ?? DEFAULT_CONNECT_TIMEOUT_MS;
    const sleep = options.sleep ?? sleepWithAbort2;
    const maxWaitMs = options.maxWaitMs ?? DEFAULT_MAX_WAIT_MS2;
    const shouldWait = maxWaitMs > 0;
    const startTime = Date.now();
    while (true) {
      if (options.abortSignal?.aborted) {
        throw new Error("Operation aborted");
      }
      const existing = this.connections.get(key);
      if (existing) {
        this.touchConnection(existing, key);
        this.markHealthy(config2);
        return existing;
      }
      const health = this.health.get(key);
      if (health?.backoffUntil && health.backoffUntil > /* @__PURE__ */ new Date()) {
        const remainingMs = health.backoffUntil.getTime() - Date.now();
        const remainingSecs = Math.ceil(remainingMs / 1e3);
        if (!shouldWait) {
          throw new Error(
            `SSH connection to ${config2.host} is in backoff for ${remainingSecs}s. Last error: ${health.lastError ?? "unknown"}`
          );
        }
        const elapsedMs = Date.now() - startTime;
        const budgetMs = Math.max(0, maxWaitMs - elapsedMs);
        if (budgetMs <= 0) {
          throw new Error(
            `SSH connection to ${config2.host} is in backoff and maxWaitMs exceeded. Last error: ${health.lastError ?? "unknown"}`
          );
        }
        const waitMs = Math.min(remainingMs, budgetMs);
        options.onWait?.(waitMs);
        await sleep(waitMs, options.abortSignal);
        continue;
      }
      let inflight = this.inflight.get(key);
      if (!inflight) {
        inflight = this.connect(config2, timeoutMs, options.abortSignal);
        this.inflight.set(key, inflight);
        void inflight.catch(() => {
        }).finally(() => this.inflight.delete(key));
      }
      try {
        const entry = await inflight;
        return entry;
      } catch (error) {
        if (!shouldWait) {
          throw error;
        }
        const elapsedMs = Date.now() - startTime;
        if (elapsedMs >= maxWaitMs) {
          throw error;
        }
      }
    }
  }
  markHealthy(config2) {
    const key = makeConnectionKey2(config2);
    const existing = this.health.get(key);
    this.health.set(key, {
      status: "healthy",
      lastSuccess: /* @__PURE__ */ new Date(),
      consecutiveFailures: 0,
      lastFailure: existing?.lastFailure,
      lastError: existing?.lastError
    });
  }
  reportFailure(config2, errorMessage) {
    const key = makeConnectionKey2(config2);
    const now = /* @__PURE__ */ new Date();
    const current = this.health.get(key);
    const failures = (current?.consecutiveFailures ?? 0) + 1;
    const backoffIndex = Math.min(failures - 1, BACKOFF_SCHEDULE2.length - 1);
    const backoffSeconds = withJitter2(BACKOFF_SCHEDULE2[backoffIndex]);
    this.health.set(key, {
      status: "unhealthy",
      lastFailure: now,
      lastError: errorMessage,
      consecutiveFailures: failures,
      backoffUntil: new Date(Date.now() + backoffSeconds * 1e3),
      lastSuccess: current?.lastSuccess
    });
  }
  /**
   * Update last activity time and reset idle timer.
   * Called on each acquireConnection() to keep active connections alive.
   */
  touchConnection(entry, key) {
    entry.lastActivityAt = Date.now();
    if (entry.idleTimer) {
      clearTimeout(entry.idleTimer);
    }
    entry.idleTimer = setTimeout(() => {
      this.closeIdleConnection(key, entry);
    }, IDLE_TIMEOUT_MS);
  }
  /**
   * Close a connection that has been idle for too long.
   */
  closeIdleConnection(key, entry) {
    if (this.connections.get(key) !== entry) {
      return;
    }
    this.connections.delete(key);
    try {
      entry.client.end();
    } catch {
    }
    if (entry.proxyProcess?.exitCode === null) {
      try {
        entry.proxyProcess.kill();
      } catch {
      }
    }
  }
  async connect(config2, timeoutMs, abortSignal) {
    const key = makeConnectionKey2(config2);
    try {
      const resolved = await resolveSSHConfig(config2.host);
      const resolvedConfig = {
        ...resolved,
        port: config2.port ?? resolved.port,
        identityFiles: config2.identityFile ? [expandLocalPath(config2.identityFile)] : resolved.identityFiles
      };
      const agent = getAgentConfig();
      const baseIdentityFiles = resolvedConfig.identityFiles.length > 0 ? resolvedConfig.identityFiles : [];
      const fallbackIdentityFiles = baseIdentityFiles.length > 0 ? baseIdentityFiles : DEFAULT_IDENTITY_FILES.map((file) => expandLocalPath(file));
      const username = resolvedConfig.user ?? getDefaultUsername2();
      const proxyTokens = {
        host: resolvedConfig.hostName,
        port: resolvedConfig.port,
        user: username
      };
      const attemptConnection = async (identityFiles, agentOverride) => {
        const resolvedConfigWithIdentities = {
          ...resolvedConfig,
          identityFiles
        };
        const readableKeys = await resolvePrivateKeys(resolvedConfigWithIdentities.identityFiles);
        const keysToTry = readableKeys.length > 0 ? readableKeys : [void 0];
        const connectWithKey = async (privateKey, reportAuthFailure) => {
          const proxy = resolvedConfigWithIdentities.proxyCommand ? spawnProxyCommand(resolvedConfigWithIdentities.proxyCommand, proxyTokens) : void 0;
          const client = new Client();
          const entry = {
            client,
            resolvedConfig: resolvedConfigWithIdentities,
            proxyProcess: proxy?.process,
            lastActivityAt: Date.now()
          };
          const cleanupProxy = () => {
            if (proxy?.process?.exitCode === null) {
              proxy.process.kill();
            }
          };
          const cleanupProxySocket = () => {
            if (proxy?.sock && !proxy.sock.destroyed) {
              proxy.sock.destroy();
            }
            cleanupProxy();
          };
          if (proxy) {
            const attach = (emitter, label) => {
              attachStreamErrorHandler(emitter, label, {
                logger: log,
                onIgnorable: cleanupProxySocket,
                onUnexpected: cleanupProxySocket
              });
            };
            attach(proxy.process, "ssh2-proxy-process");
            attach(proxy.sock, "ssh2-proxy-socket");
            if (proxy.process.stdin) {
              attach(proxy.process.stdin, "ssh2-proxy-stdin");
            }
            if (proxy.process.stdout) {
              attach(proxy.process.stdout, "ssh2-proxy-stdout");
            }
            if (proxy.process.stderr) {
              attach(proxy.process.stderr, "ssh2-proxy-stderr");
            }
          }
          const onClose = () => {
            if (entry.idleTimer) {
              clearTimeout(entry.idleTimer);
            }
            cleanupProxy();
            this.connections.delete(key);
          };
          client.on("close", onClose);
          client.on("end", onClose);
          client.on("error", (err) => {
            if (entry.idleTimer) {
              clearTimeout(entry.idleTimer);
            }
            if (!isAuthFailure(err) || reportAuthFailure) {
              this.reportFailure(config2, getErrorMessage3(err));
            }
            this.connections.delete(key);
            cleanupProxy();
          });
          await new Promise((resolve3, reject) => {
            const onReady = () => {
              cleanup();
              resolve3();
            };
            const onError2 = (err) => {
              cleanup();
              reject(err);
            };
            const onAbort = () => {
              cleanup();
              client.end();
              cleanupProxy();
              reject(new Error("Operation aborted"));
            };
            const cleanup = () => {
              client.off("ready", onReady);
              client.off("error", onError2);
              abortSignal?.removeEventListener("abort", onAbort);
            };
            client.on("ready", onReady);
            client.on("error", onError2);
            abortSignal?.addEventListener("abort", onAbort, { once: true });
            const connectOptions = {
              host: resolvedConfig.hostName,
              port: resolvedConfig.port,
              username,
              agent: agentOverride,
              sock: proxy?.sock,
              readyTimeout: timeoutMs,
              keepaliveInterval: 5e3,
              keepaliveCountMax: 2,
              ...privateKey ? { privateKey } : {}
            };
            client.connect(connectOptions);
          });
          if (abortSignal?.aborted) {
            client.end();
            throw new Error("Operation aborted");
          }
          this.markHealthy(config2);
          this.connections.set(key, entry);
          entry.idleTimer = setTimeout(() => {
            this.closeIdleConnection(key, entry);
          }, IDLE_TIMEOUT_MS);
          return entry;
        };
        for (const [index, privateKey] of keysToTry.entries()) {
          const isLastKey = index === keysToTry.length - 1;
          try {
            return await connectWithKey(privateKey, isLastKey);
          } catch (error) {
            if (!isAuthFailure(error) || isLastKey) {
              throw error;
            }
          }
        }
        throw new Error("SSH2 authentication failed");
      };
      const shouldTryAgentOnly = agent && baseIdentityFiles.length === 0;
      if (shouldTryAgentOnly) {
        try {
          return await attemptConnection([], agent);
        } catch (error) {
          if (!isAuthFailure(error)) {
            throw error;
          }
        }
      }
      const agentForFallback = shouldTryAgentOnly ? void 0 : agent;
      return await attemptConnection(fallbackIdentityFiles, agentForFallback);
    } catch (error) {
      this.reportFailure(config2, getErrorMessage3(error));
      throw error;
    }
  }
};
var ssh2ConnectionPool = new SSH2ConnectionPool();

// src/node/runtime/transports/SSH2Transport.ts
var SSH2ChildProcess = class extends EventEmitter {
  constructor(channel) {
    super();
    this.channel = channel;
    this.exitCode = null;
    this.signalCode = null;
    this.killed = false;
    this.pid = 0;
    const stdoutPipe = new PassThrough();
    const stderrPipe = new PassThrough();
    const stdinPipe = new PassThrough();
    channel.pipe(stdoutPipe);
    (channel.stderr ?? new PassThrough()).pipe(stderrPipe);
    stdinPipe.pipe(channel);
    this.stdout = stdoutPipe;
    this.stderr = stderrPipe;
    this.stdin = stdinPipe;
    let closeEventFired = false;
    let closeTimer = null;
    let closeEmitted = false;
    const emitClose = () => {
      if (closeEmitted) {
        return;
      }
      closeEmitted = true;
      if (closeTimer) {
        clearTimeout(closeTimer);
        closeTimer = null;
      }
      this.emit("close", this.exitCode ?? 0, this.signalCode);
    };
    channel.on("exit", (code, signal) => {
      this.exitCode = typeof code === "number" ? code : null;
      this.signalCode = typeof signal === "string" ? signal : null;
      if (closeEventFired) {
        emitClose();
      }
    });
    channel.on("close", (...args2) => {
      closeEventFired = true;
      const [code, signal] = args2;
      if (this.exitCode === null && typeof code === "number") {
        this.exitCode = code;
      }
      if (this.signalCode === null && typeof signal === "string") {
        this.signalCode = signal;
      }
      if (this.exitCode !== null || this.signalCode !== null) {
        emitClose();
        return;
      }
      closeTimer = setTimeout(() => emitClose(), 250);
      closeTimer.unref?.();
    });
    channel.on("error", (err) => {
      this.emit("error", err);
    });
  }
  kill(signal) {
    this.killed = true;
    try {
      if (signal && typeof this.channel.signal === "function") {
        this.channel.signal(signal);
      }
    } catch {
    }
    try {
      this.channel.close();
    } catch {
    }
    return true;
  }
};
var SSH2Pty = class {
  constructor(channel) {
    this.channel = channel;
    this.closed = false;
    this.channel.on("close", () => {
      this.closed = true;
    });
    const closeChannel = () => {
      this.closed = true;
      try {
        this.channel.close();
      } catch {
      }
    };
    attachStreamErrorHandler(this.channel, "ssh2-pty-channel", {
      logger: log,
      onIgnorable: closeChannel,
      onUnexpected: closeChannel
    });
    if (this.channel.stderr) {
      attachStreamErrorHandler(this.channel.stderr, "ssh2-pty-stderr", {
        logger: log,
        onIgnorable: closeChannel,
        onUnexpected: closeChannel
      });
    }
  }
  write(data) {
    if (this.closed || this.channel.destroyed || this.channel.writableEnded) {
      return;
    }
    try {
      this.channel.write(data);
    } catch (error) {
      if (isIgnorableStreamError(error)) {
        return;
      }
      const message = error instanceof Error ? error.message : String(error);
      const code = error && typeof error === "object" && "code" in error && typeof error.code === "string" ? error.code : void 0;
      log.warn("SSH2 PTY write failed", { code, message });
    }
  }
  resize(cols, rows) {
    this.channel.setWindow(rows, cols, 0, 0);
  }
  kill() {
    this.closed = true;
    this.channel.close();
  }
  onData(handler) {
    const onStdout = (data) => handler(data.toString());
    const onStderr = (data) => handler(data.toString());
    this.channel.on("data", onStdout);
    this.channel.stderr?.on("data", onStderr);
    return {
      dispose: () => {
        this.channel.off("data", onStdout);
        this.channel.stderr?.off("data", onStderr);
      }
    };
  }
  onExit(handler) {
    const onClose = (code) => {
      handler({ exitCode: typeof code === "number" ? code : 0 });
    };
    this.channel.on("close", onClose);
    return {
      dispose: () => {
        this.channel.off("close", onClose);
      }
    };
  }
};
var SSH2Transport = class {
  constructor(config2) {
    this.config = config2;
  }
  isConnectionFailure(_exitCode, _stderr) {
    return false;
  }
  getConfig() {
    return this.config;
  }
  markHealthy() {
    ssh2ConnectionPool.markHealthy(this.config);
  }
  reportFailure(error) {
    ssh2ConnectionPool.reportFailure(this.config, error);
  }
  async acquireConnection(options) {
    await ssh2ConnectionPool.acquireConnection(this.config, {
      abortSignal: options?.abortSignal,
      timeoutMs: options?.timeoutMs,
      onWait: options?.onWait
    });
  }
  async spawnRemoteProcess(fullCommand, options) {
    const connectTimeoutSec = options.timeout !== void 0 ? Math.min(Math.ceil(options.timeout), 15) : 15;
    let client;
    try {
      ({ client } = await ssh2ConnectionPool.acquireConnection(this.config, {
        abortSignal: options.abortSignal,
        timeoutMs: connectTimeoutSec * 1e3
      }));
    } catch (error) {
      throw new RuntimeError(
        `SSH2 connection failed: ${getErrorMessage3(error)}`,
        "network",
        error instanceof Error ? error : void 0
      );
    }
    try {
      const channel = await new Promise((resolve3, reject) => {
        const onExec = (err, stream) => {
          if (err) {
            reject(err);
            return;
          }
          if (!stream) {
            reject(new Error("SSH2 exec did not return a stream"));
            return;
          }
          resolve3(stream);
        };
        if (options.forcePTY) {
          client.exec(fullCommand, { pty: { term: "xterm-256color" } }, onExec);
        } else {
          client.exec(fullCommand, onExec);
        }
      });
      const process3 = new SSH2ChildProcess(channel);
      return { process: process3 };
    } catch (error) {
      ssh2ConnectionPool.reportFailure(this.config, getErrorMessage3(error));
      throw new RuntimeError(
        `SSH2 command failed: ${getErrorMessage3(error)}`,
        "network",
        error instanceof Error ? error : void 0
      );
    }
  }
  async createPtySession(params) {
    const { client } = await ssh2ConnectionPool.acquireConnection(this.config, { maxWaitMs: 0 });
    const channel = await new Promise((resolve3, reject) => {
      client.shell(
        {
          term: "xterm-256color",
          cols: params.cols,
          rows: params.rows
        },
        (err, stream) => {
          if (err) {
            reject(err);
            return;
          }
          if (!stream) {
            reject(new Error("SSH2 shell did not return a stream"));
            return;
          }
          resolve3(stream);
        }
      );
    });
    const expandedPath = expandTildeForSSH(params.workspacePath);
    channel.write(`cd ${expandedPath} || exit 1
`);
    return new SSH2Pty(channel);
  }
};

// src/node/runtime/transports/index.ts
function createSSHTransport(config2, useSSH2) {
  return useSSH2 ? new SSH2Transport(config2) : new OpenSSHTransport(config2);
}

// src/node/runtime/DockerRuntime.ts
import { spawn as spawn6, exec as exec2 } from "child_process";
import { createHash as createHash2 } from "crypto";
import * as path14 from "path";
import * as fs7 from "fs/promises";
import * as os7 from "os";

// src/node/runtime/credentialForwarding.ts
import { existsSync as existsSync3 } from "fs";
import * as fsPromises4 from "fs/promises";
import * as os6 from "os";
import * as path13 from "path";
function resolveSshAgentForwarding(targetSocketPath) {
  const hostSocketPath = process.platform === "darwin" ? "/run/host-services/ssh-auth.sock" : process.env.SSH_AUTH_SOCK;
  if (!hostSocketPath || !existsSync3(hostSocketPath)) {
    return null;
  }
  return { hostSocketPath, targetSocketPath };
}
function resolveGhToken(env3) {
  return env3?.GH_TOKEN ?? process.env.GH_TOKEN ?? null;
}
function getHostGitconfigPath() {
  return path13.join(os6.homedir(), ".gitconfig");
}
function hasHostGitconfig() {
  return existsSync3(getHostGitconfigPath());
}
async function readHostGitconfig() {
  const gitconfigPath = getHostGitconfigPath();
  if (!existsSync3(gitconfigPath)) {
    return null;
  }
  return fsPromises4.readFile(gitconfigPath);
}

// src/node/runtime/DockerRuntime.ts
var CONTAINER_SRC_DIR = "/src";
function runDockerCommand(command, timeoutMs = 3e4) {
  return new Promise((resolve3) => {
    let stdout = "";
    let stderr = "";
    let timedOut = false;
    const child = exec2(command);
    const timer = setTimeout(() => {
      timedOut = true;
      child.kill();
      resolve3({ exitCode: -1, stdout, stderr: "Command timed out" });
    }, timeoutMs);
    child.stdout?.on("data", (data) => {
      stdout += data.toString();
    });
    child.stderr?.on("data", (data) => {
      stderr += data.toString();
    });
    child.on("close", (code) => {
      clearTimeout(timer);
      if (timedOut) return;
      resolve3({ exitCode: code ?? -1, stdout, stderr });
    });
    child.on("error", (err) => {
      clearTimeout(timer);
      if (timedOut) return;
      resolve3({ exitCode: -1, stdout, stderr: err.message });
    });
  });
}
function runSpawnCommand(command, args2, timeoutMs = 3e4) {
  return new Promise((resolve3) => {
    let stdout = "";
    let stderr = "";
    let timedOut = false;
    const child = spawn6(command, args2);
    const timer = setTimeout(() => {
      timedOut = true;
      child.kill();
      resolve3({ exitCode: -1, stdout, stderr: "Command timed out" });
    }, timeoutMs);
    child.stdout?.on("data", (data) => {
      stdout += data.toString();
    });
    child.stderr?.on("data", (data) => {
      stderr += data.toString();
    });
    child.on("close", (code) => {
      clearTimeout(timer);
      if (timedOut) return;
      resolve3({ exitCode: code ?? -1, stdout, stderr });
    });
    child.on("error", (err) => {
      clearTimeout(timer);
      if (timedOut) return;
      resolve3({ exitCode: -1, stdout, stderr: err.message });
    });
  });
}
function buildCredentialArgs() {
  const args2 = [];
  const sshForwarding = resolveSshAgentForwarding("/ssh-agent");
  if (sshForwarding) {
    args2.push("-v", `${sshForwarding.hostSocketPath}:${sshForwarding.targetSocketPath}:ro`);
    args2.push("-e", `SSH_AUTH_SOCK=${sshForwarding.targetSocketPath}`);
  }
  const ghToken = resolveGhToken();
  if (ghToken) {
    args2.push("-e", `GH_TOKEN=${ghToken}`);
  }
  return args2;
}
function streamDockerRun(containerName, image, initLogger, options) {
  const { abortSignal, shareCredentials, timeoutMs = 6e5 } = options ?? {};
  return new Promise((resolve3) => {
    let stdout = "";
    let stderr = "";
    let resolved = false;
    const finish = (result) => {
      if (resolved) return;
      resolved = true;
      clearTimeout(timer);
      abortSignal?.removeEventListener("abort", abortHandler);
      resolve3(result);
    };
    const dockerArgs = ["run", "-d", "--name", containerName];
    if (shareCredentials) {
      dockerArgs.push(...buildCredentialArgs());
    }
    dockerArgs.push(image, "sleep", "infinity");
    const child = spawn6("docker", dockerArgs);
    const timer = setTimeout(() => {
      child.kill();
      void runDockerCommand(`docker rm -f ${containerName}`, 1e4);
      finish({ exitCode: -1, stdout, stderr: "Container creation timed out" });
    }, timeoutMs);
    const abortHandler = () => {
      child.kill();
      void runDockerCommand(`docker rm -f ${containerName}`, 1e4);
      finish({ exitCode: -1, stdout, stderr: "Aborted" });
    };
    abortSignal?.addEventListener("abort", abortHandler);
    child.stdout?.on("data", (data) => {
      const text2 = data.toString();
      stdout += text2;
    });
    child.stderr?.on("data", (data) => {
      const text2 = data.toString();
      stderr += text2;
      for (const line of text2.split("\n").filter((l) => l.trim())) {
        initLogger.logStdout(line);
      }
    });
    child.on("close", (code) => {
      finish({ exitCode: code ?? -1, stdout, stderr });
    });
    child.on("error", (err) => {
      finish({ exitCode: -1, stdout, stderr: err.message });
    });
  });
}
function sanitizeContainerName(name16) {
  return name16.replace(/[^a-zA-Z0-9_.-]/g, "-").replace(/^[^a-zA-Z0-9]+/, "").replace(/-+/g, "-");
}
function getContainerName(projectPath, workspaceName) {
  const projectName = getProjectName(projectPath);
  const hash = createHash2("sha256").update(`${projectPath}:${workspaceName}`).digest("hex").slice(0, 6);
  const base = sanitizeContainerName(`unix-${projectName}-${workspaceName}`).slice(0, 56);
  return `${base}-${hash}`;
}
var DockerRuntime = class extends RemoteRuntime {
  constructor(config2) {
    super();
    // ===== RemoteRuntime abstract method implementations =====
    this.commandPrefix = "Docker";
    this.config = config2;
    if (config2.containerName) {
      this.containerName = config2.containerName;
    }
  }
  /**
   * Get the container name (if set)
   */
  getContainerName() {
    return this.containerName;
  }
  /**
   * Get Docker image name
   */
  getImage() {
    return this.config.image;
  }
  getBasePath() {
    return CONTAINER_SRC_DIR;
  }
  quoteForRemote(filePath) {
    const home = this.containerHome ?? "/root";
    const expanded = filePath.startsWith("~/") ? `${home}/${filePath.slice(2)}` : filePath === "~" ? home : filePath;
    return shescape.quote(expanded);
  }
  cdCommand(cwd) {
    return `cd ${shescape.quote(cwd)}`;
  }
  spawnRemoteProcess(fullCommand, _options) {
    if (!this.containerName) {
      throw new RuntimeError(
        "Docker runtime not initialized with container name. For existing workspaces, pass containerName in config. For new workspaces, call createWorkspace first.",
        "exec"
      );
    }
    const dockerArgs = ["exec", "-i", this.containerName, "bash", "-c", fullCommand];
    const process3 = spawn6("docker", dockerArgs, {
      stdio: ["pipe", "pipe", "pipe"],
      windowsHide: true
    });
    return Promise.resolve({ process: process3 });
  }
  /**
   * Override buildWriteCommand to preserve symlinks and file permissions.
   *
   * This matches SSHRuntime behavior: write through the symlink to the final target,
   * while keeping the symlink itself intact.
   */
  buildWriteCommand(quotedPath, quotedTempPath) {
    return `RESOLVED=$(readlink -f ${quotedPath} 2>/dev/null || echo ${quotedPath}) && PERMS=$(stat -c '%a' "$RESOLVED" 2>/dev/null || echo 644) && mkdir -p $(dirname "$RESOLVED") && cat > ${quotedTempPath} && chmod "$PERMS" ${quotedTempPath} && mv ${quotedTempPath} "$RESOLVED"`;
  }
  // ===== Runtime interface implementations =====
  resolvePath(filePath) {
    const home = this.containerHome ?? "/root";
    if (filePath === "~") {
      return Promise.resolve(home);
    }
    if (filePath.startsWith("~/")) {
      return Promise.resolve(path14.posix.join(home, filePath.slice(2)));
    }
    return Promise.resolve(
      filePath.startsWith("/") ? filePath : path14.posix.join(CONTAINER_SRC_DIR, filePath)
    );
  }
  getWorkspacePath(_projectPath, _workspaceName) {
    return CONTAINER_SRC_DIR;
  }
  async createWorkspace(params) {
    const { projectPath, branchName } = params;
    const containerName = getContainerName(projectPath, branchName);
    const checkResult = await runDockerCommand(`docker inspect ${containerName}`, 1e4);
    if (checkResult.exitCode === 0) {
      return {
        success: false,
        error: `Workspace already exists: container ${containerName}`
      };
    }
    if (!checkResult.stderr.toLowerCase().includes("no such object")) {
      return {
        success: false,
        error: `Docker error: ${checkResult.stderr || checkResult.stdout || "unknown error"}`
      };
    }
    this.containerName = containerName;
    return {
      success: true,
      workspacePath: CONTAINER_SRC_DIR
    };
  }
  /**
   * Post-create setup: provision container OR detect fork and setup credentials.
   * Runs after unix persists workspace metadata so build logs stream to UI in real-time.
   *
   * Handles ALL environment setup:
   * - Fresh workspace: provisions container (create, sync, checkout, credentials)
   * - Fork: detects existing container, logs "from fork", sets up credentials
   * - Stale container: removes and re-provisions
   *
   * After this completes, the container is ready for initWorkspace() to run the hook.
   */
  async postCreateSetup(params) {
    const {
      projectPath,
      branchName,
      trunkBranch,
      workspacePath,
      initLogger,
      abortSignal,
      env: env3,
      skipInitHook
    } = params;
    if (!this.containerName) {
      throw new Error("Container not initialized. Call createWorkspace first.");
    }
    const containerName = this.containerName;
    const containerCheck = await this.checkExistingContainer(
      containerName,
      workspacePath,
      branchName
    );
    switch (containerCheck.action) {
      case "skip":
        initLogger.logStep(
          skipInitHook ? "Container already running (from fork), skipping init hook..." : "Container already running (from fork), running init hook..."
        );
        await this.setupCredentials(containerName, env3);
        return;
      case "cleanup":
        initLogger.logStep(containerCheck.reason);
        await runDockerCommand(`docker rm -f ${containerName}`, 1e4);
        break;
      case "create":
        break;
    }
    await this.provisionContainer({
      containerName,
      projectPath,
      workspacePath,
      branchName,
      trunkBranch,
      initLogger,
      abortSignal,
      env: env3
    });
  }
  /**
   * Initialize workspace by running .unix/init hook.
   * Assumes postCreateSetup() has already been called to provision/prepare the container.
   *
   * This method ONLY runs the hook - all container provisioning and credential setup
   * is handled by postCreateSetup().
   */
  async initWorkspace(params) {
    const { projectPath, branchName, workspacePath, initLogger, abortSignal, env: env3, skipInitHook } = params;
    try {
      if (!this.containerName) {
        return {
          success: false,
          error: "Container not initialized. Call createWorkspace first."
        };
      }
      if (skipInitHook) {
        initLogger.logStep("Skipping .unix/init hook (disabled for this task)");
        initLogger.logComplete(0);
        return { success: true };
      }
      const hookExists = await checkInitHookExists(projectPath);
      if (hookExists) {
        const muxEnv = { ...env3, ...getUnixEnv(projectPath, "docker", branchName) };
        const hookPath = `${workspacePath}/.unix/init`;
        await runInitHookOnRuntime(this, hookPath, workspacePath, muxEnv, initLogger, abortSignal);
      } else {
        initLogger.logComplete(0);
      }
      return { success: true };
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(`Initialization failed: ${errorMsg}`);
      initLogger.logComplete(-1);
      return {
        success: false,
        error: errorMsg
      };
    }
  }
  /**
   * Check if a container already exists and whether it's valid for reuse.
   * Returns action to take: skip setup, cleanup invalid container, or create new.
   */
  async checkExistingContainer(containerName, workspacePath, branchName) {
    const exists = await runDockerCommand(`docker inspect ${containerName}`, 1e4);
    if (exists.exitCode !== 0) return { action: "create" };
    const isRunning = await runDockerCommand(
      `docker inspect -f '{{.State.Running}}' ${containerName}`,
      1e4
    );
    if (isRunning.exitCode !== 0 || isRunning.stdout.trim() !== "true") {
      return { action: "cleanup", reason: "Removing stale container from previous attempt..." };
    }
    const gitCheck = await runDockerCommand(
      `docker exec ${containerName} test -d ${workspacePath}/.git`,
      5e3
    );
    if (gitCheck.exitCode !== 0) {
      return {
        action: "cleanup",
        reason: "Container exists but repo not initialized, recreating..."
      };
    }
    const branchCheck = await runDockerCommand(
      `docker exec ${containerName} git -C ${workspacePath} rev-parse --abbrev-ref HEAD`,
      5e3
    );
    if (branchCheck.exitCode !== 0 || branchCheck.stdout.trim() !== branchName) {
      return { action: "cleanup", reason: "Container exists but wrong branch, recreating..." };
    }
    return { action: "skip" };
  }
  /**
   * Copy gitconfig and configure gh CLI credential helper in container.
   * Called for both new containers and reused forked containers.
   */
  async setupCredentials(containerName, env3) {
    if (!this.config.shareCredentials) return;
    if (hasHostGitconfig()) {
      await runDockerCommand(
        `docker cp ${getHostGitconfigPath()} ${containerName}:/root/.gitconfig`,
        1e4
      );
    }
    const ghToken = resolveGhToken(env3);
    if (ghToken) {
      await runDockerCommand(
        `docker exec -e GH_TOKEN=${shescape.quote(ghToken)} ${containerName} sh -c 'command -v gh >/dev/null && gh auth setup-git || true'`,
        1e4
      );
    }
  }
  /**
   * Provision container: create, sync project, checkout branch.
   * Throws on error (does not call logComplete - caller handles that).
   * Used by postCreateSetup() for streaming logs before initWorkspace().
   */
  async provisionContainer(params) {
    const {
      containerName,
      projectPath,
      workspacePath,
      branchName,
      trunkBranch,
      initLogger,
      abortSignal,
      env: env3
    } = params;
    initLogger.logStep(`Creating container from ${this.config.image}...`);
    if (abortSignal?.aborted) {
      throw new Error("Workspace creation aborted");
    }
    const runResult = await streamDockerRun(containerName, this.config.image, initLogger, {
      abortSignal,
      shareCredentials: this.config.shareCredentials
    });
    if (runResult.exitCode !== 0) {
      await runDockerCommand(`docker rm -f ${containerName}`, 1e4);
      throw new Error(`Failed to create container: ${runResult.stderr}`);
    }
    const [uidResult, gidResult, homeResult] = await Promise.all([
      runDockerCommand(`docker exec ${containerName} id -u`, 5e3),
      runDockerCommand(`docker exec ${containerName} id -g`, 5e3),
      runDockerCommand(`docker exec ${containerName} sh -c 'echo $HOME'`, 5e3)
    ]);
    this.containerUid = uidResult.stdout.trim() || "0";
    this.containerGid = gidResult.stdout.trim() || "0";
    this.containerHome = homeResult.stdout.trim() || "/root";
    initLogger.logStep("Preparing workspace directory...");
    const mkdirResult = await runDockerCommand(
      `docker exec --user root ${containerName} sh -c 'mkdir -p ${CONTAINER_SRC_DIR} /var/unix/plans && chown ${this.containerUid}:${this.containerGid} ${CONTAINER_SRC_DIR} /var/unix /var/unix/plans'`,
      1e4
    );
    if (mkdirResult.exitCode !== 0) {
      await runDockerCommand(`docker rm -f ${containerName}`, 1e4);
      throw new Error(`Failed to create workspace directory: ${mkdirResult.stderr}`);
    }
    initLogger.logStep("Container ready");
    await this.setupCredentials(containerName, env3);
    initLogger.logStep("Syncing project files to container...");
    try {
      await this.syncProjectToContainer(
        projectPath,
        containerName,
        workspacePath,
        initLogger,
        abortSignal
      );
    } catch (error) {
      await runDockerCommand(`docker rm -f ${containerName}`, 1e4);
      throw new Error(`Failed to sync project: ${getErrorMessage3(error)}`);
    }
    initLogger.logStep("Files synced successfully");
    initLogger.logStep(`Checking out branch: ${branchName}`);
    const checkoutCmd = `git checkout ${shescape.quote(branchName)} 2>/dev/null || git checkout -b ${shescape.quote(branchName)} ${shescape.quote(trunkBranch)}`;
    const checkoutStream = await this.exec(checkoutCmd, {
      cwd: workspacePath,
      timeout: 300,
      abortSignal
    });
    const [stdout, stderr, exitCode] = await Promise.all([
      streamToString2(checkoutStream.stdout),
      streamToString2(checkoutStream.stderr),
      checkoutStream.exitCode
    ]);
    if (exitCode !== 0) {
      await runDockerCommand(`docker rm -f ${containerName}`, 1e4);
      throw new Error(`Failed to checkout branch: ${stderr || stdout}`);
    }
    initLogger.logStep("Branch checked out successfully");
  }
  async syncProjectToContainer(projectPath, containerName, workspacePath, initLogger, abortSignal) {
    const timestamp = Date.now();
    const bundleFilename = `unix-bundle-${timestamp}.bundle`;
    const remoteBundlePath = `/tmp/${bundleFilename}`;
    const localBundlePath = path14.join(os7.tmpdir(), bundleFilename);
    await syncProjectViaGitBundle({
      projectPath,
      workspacePath,
      remoteTmpDir: "/tmp",
      remoteBundlePath,
      exec: (command, options) => this.exec(command, options),
      quoteRemotePath: (path21) => this.quoteForRemote(path21),
      initLogger,
      abortSignal,
      cloneStep: "Cloning repository in container...",
      createRemoteBundle: async ({ remoteBundlePath: remoteBundlePath2, initLogger: initLogger2, abortSignal: abortSignal2 }) => {
        try {
          if (abortSignal2?.aborted) {
            throw new Error("Sync operation aborted before starting");
          }
          const bundleResult = await runDockerCommand(
            `git -C "${projectPath}" bundle create "${localBundlePath}" --all`,
            3e5
          );
          if (bundleResult.exitCode !== 0) {
            throw new Error(`Failed to create bundle: ${bundleResult.stderr}`);
          }
          initLogger2.logStep("Copying bundle to container...");
          const copyResult = await runDockerCommand(
            `docker cp "${localBundlePath}" ${containerName}:${remoteBundlePath2}`,
            3e5
          );
          if (copyResult.exitCode !== 0) {
            throw new Error(`Failed to copy bundle: ${copyResult.stderr}`);
          }
          return {
            cleanupLocal: async () => {
              await runDockerCommand(`rm -f "${localBundlePath}"`, 5e3);
            }
          };
        } catch (error) {
          await runDockerCommand(`rm -f "${localBundlePath}"`, 5e3);
          throw error;
        }
      }
    });
  }
  // eslint-disable-next-line @typescript-eslint/require-await
  async renameWorkspace(_projectPath, _oldName, _newName, _abortSignal) {
    return {
      success: false,
      error: "Renaming Docker workspaces is not supported. Create a new workspace and delete the old one."
    };
  }
  async deleteWorkspace(projectPath, workspaceName, force, abortSignal) {
    if (abortSignal?.aborted) {
      return { success: false, error: "Delete operation aborted" };
    }
    const containerName = getContainerName(projectPath, workspaceName);
    const deletedPath = CONTAINER_SRC_DIR;
    try {
      const inspectResult = await runDockerCommand(`docker inspect ${containerName}`, 1e4);
      if (inspectResult.exitCode !== 0) {
        if (inspectResult.stderr.toLowerCase().includes("no such object")) {
          return { success: true, deletedPath };
        }
        return {
          success: false,
          error: `Docker error: ${inspectResult.stderr || inspectResult.stdout || "unknown error"}`
        };
      }
      if (!force) {
        const wasRunning = await runDockerCommand(
          `docker inspect -f '{{.State.Running}}' ${containerName}`,
          1e4
        );
        const containerWasRunning = wasRunning.exitCode === 0 && wasRunning.stdout.trim() === "true";
        const startResult = await runDockerCommand(`docker start ${containerName}`, 3e4);
        if (startResult.exitCode !== 0) {
        } else {
          const stopIfWeStartedIt = async () => {
            if (!containerWasRunning) {
              await runDockerCommand(`docker stop ${containerName}`, 1e4);
            }
          };
          const checkResult = await runDockerCommand(
            `docker exec ${containerName} bash -c 'cd ${CONTAINER_SRC_DIR} && git diff --quiet --exit-code && git diff --quiet --cached --exit-code'`,
            1e4
          );
          if (checkResult.exitCode !== 0) {
            await stopIfWeStartedIt();
            return {
              success: false,
              error: "Workspace contains uncommitted changes. Use force flag to delete anyway."
            };
          }
          const hasRemotes = await runDockerCommand(
            `docker exec ${containerName} bash -c 'cd ${CONTAINER_SRC_DIR} && git remote | grep -q .'`,
            1e4
          );
          if (hasRemotes.exitCode === 0) {
            const unpushedResult = await runDockerCommand(
              `docker exec ${containerName} bash -c 'cd ${CONTAINER_SRC_DIR} && git log --branches --not --remotes --oneline'`,
              1e4
            );
            if (unpushedResult.exitCode === 0 && unpushedResult.stdout.trim()) {
              await stopIfWeStartedIt();
              return {
                success: false,
                error: `Workspace contains unpushed commits:

${unpushedResult.stdout.trim()}`
              };
            }
          }
        }
      }
      const rmResult = await runDockerCommand(`docker rm -f ${containerName}`, 3e4);
      if (rmResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to remove container: ${rmResult.stderr}`
        };
      }
      return { success: true, deletedPath };
    } catch (error) {
      return { success: false, error: `Failed to delete workspace: ${getErrorMessage3(error)}` };
    }
  }
  async forkWorkspace(params) {
    const { projectPath, sourceWorkspaceName, newWorkspaceName, initLogger } = params;
    const srcContainerName = getContainerName(projectPath, sourceWorkspaceName);
    const destContainerName = getContainerName(projectPath, newWorkspaceName);
    const hostTempPath = path14.join(os7.tmpdir(), `unix-fork-${Date.now()}.bundle`);
    const containerBundlePath = "/tmp/fork.bundle";
    let destContainerCreated = false;
    let forkSucceeded = false;
    try {
      const srcCheck = await runDockerCommand(`docker inspect ${srcContainerName}`, 1e4);
      if (srcCheck.exitCode !== 0) {
        return {
          success: false,
          error: `Source workspace container not found: ${srcContainerName}`
        };
      }
      initLogger.logStep("Detecting source workspace branch...");
      const branchResult = await runDockerCommand(
        `docker exec ${srcContainerName} git -C ${CONTAINER_SRC_DIR} branch --show-current`,
        3e4
      );
      const sourceBranch = branchResult.stdout.trim();
      if (branchResult.exitCode !== 0 || sourceBranch.length === 0) {
        return {
          success: false,
          error: "Failed to detect branch in source workspace (detached HEAD?)"
        };
      }
      initLogger.logStep("Creating git bundle from source...");
      const bundleResult = await runDockerCommand(
        `docker exec ${srcContainerName} git -C ${CONTAINER_SRC_DIR} bundle create ${containerBundlePath} --all`,
        3e5
      );
      if (bundleResult.exitCode !== 0) {
        return { success: false, error: `Failed to create git bundle: ${bundleResult.stderr}` };
      }
      initLogger.logStep("Copying bundle from source container...");
      const cpOutResult = await runDockerCommand(
        `docker cp ${srcContainerName}:${containerBundlePath} ${shescape.quote(hostTempPath)}`,
        3e5
      );
      if (cpOutResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to copy bundle from source: ${cpOutResult.stderr}`
        };
      }
      initLogger.logStep(`Creating container: ${destContainerName}...`);
      const dockerArgs = ["run", "-d", "--name", destContainerName];
      if (this.config.shareCredentials) {
        dockerArgs.push(...buildCredentialArgs());
      }
      dockerArgs.push(this.config.image, "sleep", "infinity");
      const runResult = await runSpawnCommand("docker", dockerArgs, 6e4);
      if (runResult.exitCode !== 0) {
        if (runResult.stderr.includes("already in use")) {
          return {
            success: false,
            error: `Workspace already exists: container ${destContainerName}`
          };
        }
        return { success: false, error: `Failed to create container: ${runResult.stderr}` };
      }
      destContainerCreated = true;
      const [uidResult, gidResult, homeResult] = await Promise.all([
        runDockerCommand(`docker exec ${destContainerName} id -u`, 5e3),
        runDockerCommand(`docker exec ${destContainerName} id -g`, 5e3),
        runDockerCommand(`docker exec ${destContainerName} sh -c 'echo $HOME'`, 5e3)
      ]);
      const destUid = uidResult.stdout.trim() || "0";
      const destGid = gidResult.stdout.trim() || "0";
      const destHome = homeResult.stdout.trim() || "/root";
      const mkdirResult = await runDockerCommand(
        `docker exec --user root ${destContainerName} sh -c 'mkdir -p ${CONTAINER_SRC_DIR} /var/unix/plans && chown ${destUid}:${destGid} ${CONTAINER_SRC_DIR} /var/unix /var/unix/plans'`,
        1e4
      );
      if (mkdirResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to prepare workspace directory: ${mkdirResult.stderr}`
        };
      }
      initLogger.logStep("Copying bundle to destination container...");
      const cpInResult = await runDockerCommand(
        `docker cp ${shescape.quote(hostTempPath)} ${destContainerName}:${containerBundlePath}`,
        3e5
      );
      if (cpInResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to copy bundle to destination: ${cpInResult.stderr}`
        };
      }
      initLogger.logStep("Cloning repository in destination...");
      const cloneResult = await runDockerCommand(
        `docker exec ${destContainerName} git clone ${containerBundlePath} ${CONTAINER_SRC_DIR}`,
        3e5
      );
      if (cloneResult.exitCode !== 0) {
        return { success: false, error: `Failed to clone from bundle: ${cloneResult.stderr}` };
      }
      await runDockerCommand(
        `docker exec --user root ${destContainerName} chown -R ${destUid}:${destGid} ${CONTAINER_SRC_DIR}`,
        3e4
      );
      this.containerUid = destUid;
      this.containerGid = destGid;
      this.containerHome = destHome;
      initLogger.logStep("Creating local tracking branches...");
      try {
        const remotesResult = await runDockerCommand(
          `docker exec ${destContainerName} git -C ${CONTAINER_SRC_DIR} branch -r`,
          3e4
        );
        if (remotesResult.exitCode === 0) {
          const remotes = remotesResult.stdout.split("\n").map((b) => b.trim()).filter((b) => b.startsWith("origin/") && !b.includes("HEAD"));
          for (const remote of remotes) {
            const localName = remote.replace("origin/", "");
            await runDockerCommand(
              `docker exec ${destContainerName} git -C ${CONTAINER_SRC_DIR} branch ${shescape.quote(localName)} ${shescape.quote(remote)} 2>/dev/null || true`,
              1e4
            );
          }
        }
      } catch {
      }
      try {
        const originResult = await runDockerCommand(
          `docker exec ${srcContainerName} git -C ${CONTAINER_SRC_DIR} remote get-url origin 2>/dev/null || true`,
          1e4
        );
        const originUrl = originResult.stdout.trim();
        if (originUrl.length > 0) {
          await runDockerCommand(
            `docker exec ${destContainerName} git -C ${CONTAINER_SRC_DIR} remote set-url origin ${shescape.quote(originUrl)}`,
            1e4
          );
        } else {
          await runDockerCommand(
            `docker exec ${destContainerName} git -C ${CONTAINER_SRC_DIR} remote remove origin 2>/dev/null || true`,
            1e4
          );
        }
      } catch {
      }
      initLogger.logStep(`Checking out branch: ${newWorkspaceName}`);
      const checkoutCmd = `git checkout ${shescape.quote(newWorkspaceName)} 2>/dev/null || git checkout -b ${shescape.quote(newWorkspaceName)} ${shescape.quote(sourceBranch)}`;
      const checkoutResult = await runDockerCommand(
        `docker exec ${destContainerName} bash -c ${shescape.quote(`cd ${CONTAINER_SRC_DIR} && ${checkoutCmd}`)}`,
        12e4
      );
      if (checkoutResult.exitCode !== 0) {
        return {
          success: false,
          error: `Failed to checkout forked branch: ${checkoutResult.stderr || checkoutResult.stdout}`
        };
      }
      initLogger.logStep("Fork completed successfully");
      forkSucceeded = true;
      this.containerName = destContainerName;
      return { success: true, workspacePath: CONTAINER_SRC_DIR, sourceBranch };
    } catch (error) {
      return { success: false, error: getErrorMessage3(error) };
    } finally {
      await runDockerCommand(
        `docker exec ${srcContainerName} rm -f ${containerBundlePath}`,
        5e3
      ).catch(() => {
      });
      if (destContainerCreated) {
        await runDockerCommand(
          `docker exec ${destContainerName} rm -f ${containerBundlePath}`,
          5e3
        ).catch(() => {
        });
        if (!forkSucceeded) {
          await runDockerCommand(`docker rm -f ${destContainerName}`, 1e4).catch(() => {
          });
        }
      }
      await fs7.unlink(hostTempPath).catch(() => {
      });
    }
  }
  /**
   * Ensure the Docker container is running.
   * `docker start` is idempotent - succeeds if already running, starts if stopped,
   * and waits if container is in a transitional state (starting/restarting).
   *
   * Returns typed error for retry decisions:
   * - runtime_not_ready: container missing or permanent failure
   * - runtime_start_failed: transient failure (daemon issue, etc.)
   */
  async ensureReady() {
    if (!this.containerName) {
      return {
        ready: false,
        error: "Container name not set",
        errorType: "runtime_not_ready"
      };
    }
    const result = await runDockerCommand(`docker start ${this.containerName}`, 3e4);
    if (result.exitCode !== 0) {
      const stderr = result.stderr || "Failed to start container";
      const isContainerMissing = stderr.includes("No such container") || stderr.includes("not found");
      return {
        ready: false,
        error: stderr,
        errorType: isContainerMissing ? "runtime_not_ready" : "runtime_start_failed"
      };
    }
    if (!this.containerHome) {
      const [uidResult, gidResult, homeResult] = await Promise.all([
        runDockerCommand(`docker exec ${this.containerName} id -u`, 5e3),
        runDockerCommand(`docker exec ${this.containerName} id -g`, 5e3),
        runDockerCommand(`docker exec ${this.containerName} sh -c 'echo $HOME'`, 5e3)
      ]);
      this.containerUid = uidResult.stdout.trim() || "0";
      this.containerGid = gidResult.stdout.trim() || "0";
      this.containerHome = homeResult.stdout.trim() || "/root";
    }
    return { ready: true };
  }
  /**
   * Docker uses /var/unix instead of ~/.unix because:
   * - /root has 700 permissions, inaccessible to VS Code Dev Containers (non-root user)
   * - /var/unix is world-readable by default
   */
  getUnixHome() {
    return "/var/unix";
  }
};

// src/node/runtime/DevcontainerRuntime.ts
import { spawn as spawn8 } from "child_process";
import * as path15 from "path";
import { Readable as Readable3, Writable as Writable2 } from "stream";

// src/node/runtime/devcontainerCli.ts
import { spawn as spawn7 } from "child_process";
function isRecord(value2) {
  return typeof value2 === "object" && value2 !== null;
}
function isDevcontainerUpOutcome(value2) {
  return value2 === "success" || value2 === "error";
}
function isDevcontainerUpResult(value2) {
  if (!isRecord(value2)) return false;
  return isDevcontainerUpOutcome(value2.outcome);
}
function extractDevcontainerLogText(value2) {
  const text2 = typeof value2.text === "string" ? value2.text : void 0;
  if (text2) {
    const level = typeof value2.level === "number" ? value2.level : 0;
    const channel = typeof value2.channel === "string" ? value2.channel : "";
    const type2 = typeof value2.type === "string" ? value2.type : "";
    const isError = channel === "error" || type2 === "error";
    if (level >= 2 || isError) {
      return text2;
    }
    return null;
  }
  const name16 = typeof value2.name === "string" ? value2.name : void 0;
  if (name16) {
    return name16;
  }
  return null;
}
function parseJsonLine(line) {
  try {
    return JSON.parse(line);
  } catch {
    return null;
  }
}
function parseDevcontainerStdoutLine(line) {
  const trimmed = line.trim();
  if (!trimmed) return null;
  if (!trimmed.startsWith("{")) {
    return { kind: "raw", text: line };
  }
  const parsed = parseJsonLine(trimmed);
  if (!parsed) {
    return { kind: "raw", text: line };
  }
  if (isDevcontainerUpResult(parsed)) {
    return { kind: "result", result: parsed };
  }
  if (isRecord(parsed)) {
    const text2 = extractDevcontainerLogText(parsed);
    if (text2) {
      return { kind: "log", text: text2 };
    }
  }
  return null;
}
function formatDevcontainerUpError(result, stderrSummary) {
  const messageParts = [result.message, result.description].filter(
    (value2) => typeof value2 === "string" && value2.trim().length > 0
  );
  if (messageParts.length > 0) {
    return `devcontainer up failed: ${messageParts.join(" - ")}`;
  }
  if (stderrSummary && stderrSummary.trim().length > 0) {
    return `devcontainer up failed: ${stderrSummary.trim()}`;
  }
  return "devcontainer up failed";
}
function shouldCleanupDevcontainer(result) {
  return result.outcome === "error" && typeof result.containerId === "string" && result.containerId.trim().length > 0;
}
var SENSITIVE_REMOTE_ENV_KEYS = /* @__PURE__ */ new Set([
  "GH_TOKEN",
  "GITHUB_TOKEN",
  "GH_ENTERPRISE_TOKEN",
  "GITHUB_ENTERPRISE_TOKEN"
]);
function redactRemoteEnvArgs(args2) {
  const redacted = [...args2];
  for (let i = 0; i < redacted.length - 1; i += 1) {
    if (redacted[i] !== "--remote-env") continue;
    const entry = redacted[i + 1] ?? "";
    const [key] = entry.split("=");
    if (SENSITIVE_REMOTE_ENV_KEYS.has(key)) {
      redacted[i + 1] = `${key}=<redacted>`;
    }
  }
  return redacted;
}
var DEFAULT_UP_TIMEOUT_MS = 30 * 60 * 1e3;
var MAX_STDERR_BUFFER_LENGTH = 8e3;
var DEFAULT_CLEANUP_TIMEOUT_MS = 6e4;
async function removeDevcontainerContainer(containerId) {
  await new Promise((resolve3) => {
    const proc = spawn7("docker", ["rm", "-f", containerId], {
      stdio: ["ignore", "pipe", "pipe"],
      timeout: DEFAULT_CLEANUP_TIMEOUT_MS
    });
    proc.on("error", () => {
      resolve3();
    });
    proc.on("close", () => {
      resolve3();
    });
  });
}
var VERSION_CHECK_TIMEOUT_MS = 1e4;
async function checkDevcontainerCliVersion() {
  return new Promise((resolve3) => {
    const proc = spawn7("devcontainer", ["--version"], {
      stdio: ["ignore", "pipe", "pipe"],
      timeout: VERSION_CHECK_TIMEOUT_MS
    });
    let stdout = "";
    proc.stdout?.on("data", (data) => {
      stdout += data.toString();
    });
    proc.on("error", () => {
      resolve3(null);
    });
    proc.on("close", (code) => {
      if (code === 0 && stdout.trim()) {
        resolve3({ available: true, version: stdout.trim() });
      } else {
        resolve3(null);
      }
    });
  });
}
async function devcontainerUp(options) {
  const {
    workspaceFolder,
    configPath,
    initLogger,
    abortSignal,
    additionalMounts,
    remoteEnv,
    timeoutMs = DEFAULT_UP_TIMEOUT_MS
  } = options;
  const baseArgs = ["up", "--log-format", "json", "--workspace-folder", workspaceFolder];
  if (configPath) {
    baseArgs.push("--config", configPath);
  }
  if (additionalMounts) {
    for (const mount of additionalMounts) {
      baseArgs.push("--mount", mount);
    }
  }
  if (remoteEnv) {
    for (const [key, value2] of Object.entries(remoteEnv)) {
      baseArgs.push("--remote-env", `${key}=${value2}`);
    }
  }
  const runUp = (args2) => {
    const logArgs = redactRemoteEnvArgs(args2);
    initLogger.logStep(`Running: devcontainer ${logArgs.join(" ")}`);
    return new Promise((resolve3, reject) => {
      const proc = spawn7("devcontainer", args2, {
        stdio: ["ignore", "pipe", "pipe"],
        timeout: timeoutMs,
        cwd: workspaceFolder
      });
      let settled = false;
      let lastResultLine = null;
      let stderrBuffer = "";
      let timeoutId;
      const settleSuccess = (result) => {
        if (settled) return;
        settled = true;
        if (timeoutId) clearTimeout(timeoutId);
        resolve3(result);
      };
      const appendStderrSummary = (text2) => {
        if (stderrBuffer.length >= MAX_STDERR_BUFFER_LENGTH) return;
        const next = `${text2}
`;
        stderrBuffer = (stderrBuffer + next).slice(0, MAX_STDERR_BUFFER_LENGTH);
      };
      const settleError = (error) => {
        if (settled) return;
        settled = true;
        if (timeoutId) clearTimeout(timeoutId);
        reject(error);
      };
      const stdoutLineBuffer = new LineBuffer((line) => {
        const parsed = parseDevcontainerStdoutLine(line);
        if (!parsed) return;
        if (parsed.kind === "result") {
          lastResultLine = parsed.result;
          return;
        }
        if (parsed.kind === "log") {
          initLogger.logStdout(parsed.text);
          return;
        }
        initLogger.logStdout(parsed.text);
      });
      const stderrLineBuffer = new LineBuffer((line) => {
        const parsed = parseDevcontainerStdoutLine(line);
        if (parsed?.kind === "result") {
          lastResultLine ??= parsed.result;
          return;
        }
        const summaryText = parsed ? parsed.text : line;
        appendStderrSummary(summaryText);
        if (!parsed) return;
        initLogger.logStdout(parsed.text);
      });
      proc.stdout?.on("data", (data) => {
        stdoutLineBuffer.append(data.toString());
      });
      proc.stderr?.on("data", (data) => {
        stderrLineBuffer.append(data.toString());
      });
      const abortHandler = () => {
        proc.kill("SIGTERM");
        settleError(new Error("devcontainer up aborted"));
      };
      if (timeoutMs && timeoutMs > 0) {
        timeoutId = setTimeout(() => {
          proc.kill("SIGTERM");
          settleError(new Error(`devcontainer up timed out after ${timeoutMs}ms`));
        }, timeoutMs);
      }
      abortSignal?.addEventListener("abort", abortHandler);
      const finalizeError = async (message, result) => {
        if (result && shouldCleanupDevcontainer(result)) {
          try {
            await removeDevcontainerContainer(result.containerId ?? "");
          } catch (cleanupError) {
            log.debug("Failed to remove devcontainer container", {
              cleanupError,
              containerId: result.containerId
            });
          }
        }
        settleError(new Error(message));
      };
      proc.on("error", (err) => {
        abortSignal?.removeEventListener("abort", abortHandler);
        stdoutLineBuffer.flush();
        stderrLineBuffer.flush();
        settleError(new Error(`devcontainer up failed: ${getErrorMessage3(err)}`));
      });
      proc.on("close", (code) => {
        const handleClose = async () => {
          abortSignal?.removeEventListener("abort", abortHandler);
          stdoutLineBuffer.flush();
          stderrLineBuffer.flush();
          if (settled) return;
          const stderrSummary = stderrBuffer.trim();
          if (lastResultLine) {
            if (lastResultLine.outcome === "success") {
              if (!lastResultLine.containerId || !lastResultLine.remoteUser || !lastResultLine.remoteWorkspaceFolder) {
                await finalizeError(
                  "devcontainer up output missing required fields",
                  lastResultLine
                );
                return;
              }
              settleSuccess({
                containerId: lastResultLine.containerId,
                remoteUser: lastResultLine.remoteUser,
                remoteWorkspaceFolder: lastResultLine.remoteWorkspaceFolder
              });
              return;
            }
            await finalizeError(
              formatDevcontainerUpError(lastResultLine, stderrSummary),
              lastResultLine
            );
            return;
          }
          if (code !== 0) {
            const suffix2 = stderrSummary.length > 0 ? `: ${stderrSummary}` : "";
            settleError(new Error(`devcontainer up exited with code ${String(code)}${suffix2}`));
            return;
          }
          const suffix = stderrSummary.length > 0 ? `: ${stderrSummary}` : "";
          settleError(new Error(`devcontainer up did not produce result output${suffix}`));
        };
        void handleClose();
      });
    });
  };
  return runUp(baseArgs);
}
async function getDevcontainerContainerId(workspaceFolder, _configPath, timeoutMs = 1e4) {
  const labelValue = workspaceFolder;
  return new Promise((resolve3) => {
    const proc = spawn7(
      "docker",
      ["ps", "-q", "--filter", `label=devcontainer.local_folder=${labelValue}`],
      {
        stdio: ["ignore", "pipe", "pipe"],
        timeout: timeoutMs
      }
    );
    let stdout = "";
    proc.stdout?.on("data", (data) => {
      stdout += data.toString();
    });
    proc.on("error", () => {
      resolve3(null);
    });
    proc.on("close", (code) => {
      if (code === 0 && stdout.trim()) {
        resolve3(stdout.trim().split("\n")[0]);
      } else {
        resolve3(null);
      }
    });
  });
}
async function devcontainerDown(workspaceFolder, _configPath, timeoutMs = 6e4) {
  const containerId = await getDevcontainerContainerId(workspaceFolder);
  if (!containerId) {
    return;
  }
  return new Promise((resolve3) => {
    const proc = spawn7("docker", ["rm", "-f", containerId], {
      stdio: ["ignore", "pipe", "pipe"],
      timeout: timeoutMs
    });
    proc.on("error", () => {
      resolve3();
    });
    proc.on("close", () => {
      resolve3();
    });
  });
}

// src/node/utils/pathUtils.ts
function stripTrailingSlashes(inputPath) {
  return inputPath.replace(/[/\\]+$/, "");
}

// src/node/runtime/DevcontainerRuntime.ts
var DevcontainerRuntime = class extends LocalBaseRuntime {
  constructor(options) {
    super();
    this.createFlags = {
      deferredRuntimeAccess: true
    };
    this.srcBaseDir = options.srcBaseDir;
    this.worktreeManager = new WorktreeManager(options.srcBaseDir);
    this.configPath = options.configPath;
    this.shareCredentials = options.shareCredentials ?? false;
  }
  buildCredentialForwarding(env3) {
    const additionalMounts = [];
    const remoteEnv = {};
    if (!this.shareCredentials) {
      return { additionalMounts, remoteEnv };
    }
    const sshForwarding = resolveSshAgentForwarding("/tmp/ssh-agent.sock");
    if (sshForwarding) {
      additionalMounts.push(
        `type=bind,source=${sshForwarding.hostSocketPath},target=${sshForwarding.targetSocketPath}`
      );
      remoteEnv.SSH_AUTH_SOCK = sshForwarding.targetSocketPath;
    }
    const ghToken = resolveGhToken(env3);
    if (ghToken) {
      remoteEnv.GH_TOKEN = ghToken;
    }
    return { additionalMounts, remoteEnv };
  }
  mapContainerPathToHost(containerPath) {
    if (!this.remoteWorkspaceFolder || !this.currentWorkspacePath) return null;
    const remoteRoot = this.remoteWorkspaceFolder.replace(/\/+$/, "");
    if (containerPath !== remoteRoot && !containerPath.startsWith(`${remoteRoot}/`)) return null;
    const suffix = containerPath.slice(remoteRoot.length).replace(/^\/+/, "");
    return suffix.length === 0 ? this.currentWorkspacePath : path15.join(this.currentWorkspacePath, suffix);
  }
  getContainerBasePath() {
    return this.remoteWorkspaceFolder ?? "/";
  }
  resolveHostPathForMounted(filePath) {
    if (this.currentWorkspacePath) {
      const normalizedFilePath = filePath.replaceAll("\\", "/");
      const normalizedHostRoot = stripTrailingSlashes(
        this.currentWorkspacePath.replaceAll("\\", "/")
      );
      if (normalizedFilePath === normalizedHostRoot || normalizedFilePath.startsWith(`${normalizedHostRoot}/`)) {
        return filePath;
      }
    }
    return this.mapContainerPathToHost(filePath);
  }
  quoteForContainer(filePath) {
    if (filePath === "~" || filePath.startsWith("~/")) {
      return expandTildeForSSH(filePath);
    }
    return shescape.quote(filePath);
  }
  /**
   * Expand tilde in file paths for container operations.
   * Returns unexpanded path when container user is unknown (before ensureReady).
   * Callers must check for unexpanded tilde and handle appropriately.
   */
  expandTildeForContainer(filePath) {
    if (filePath === "~" || filePath.startsWith("~/")) {
      if (this.remoteHomeDir) {
        return filePath === "~" ? this.remoteHomeDir : this.remoteHomeDir + filePath.slice(1);
      }
      if (this.remoteUser !== void 0) {
        const homeDir = this.remoteUser === "root" ? "/root" : `/home/${this.remoteUser}`;
        return filePath === "~" ? homeDir : homeDir + filePath.slice(1);
      }
      return filePath;
    }
    return filePath;
  }
  /**
   * Check if a path contains unexpanded tilde (container user unknown).
   */
  hasUnexpandedTilde(filePath) {
    return filePath === "~" || filePath.startsWith("~/");
  }
  async setupCredentials(env3) {
    if (!this.shareCredentials) return;
    const gitconfigContents = await readHostGitconfig();
    if (gitconfigContents) {
      const stream = await this.exec('cat > "$HOME/.gitconfig"', {
        cwd: this.getContainerBasePath(),
        timeout: 30
      });
      const writer = stream.stdin.getWriter();
      try {
        await writer.write(gitconfigContents);
      } finally {
        writer.releaseLock();
      }
      await stream.stdin.close();
      const exitCode = await stream.exitCode;
      if (exitCode !== 0) {
        const stderr = await streamToString2(stream.stderr);
        throw new RuntimeError(`Failed to copy gitconfig: ${stderr}`, "file_io");
      }
    }
    const ghToken = resolveGhToken(env3);
    if (ghToken) {
      const stream = await this.exec("command -v gh >/dev/null && gh auth setup-git || true", {
        cwd: this.getContainerBasePath(),
        timeout: 30,
        env: { GH_TOKEN: ghToken }
      });
      await stream.stdin.close();
      await stream.exitCode;
    }
  }
  async fetchRemoteHome() {
    if (!this.currentWorkspacePath) return;
    try {
      const stream = await this.exec('printf "%s" "$HOME"', {
        cwd: this.remoteWorkspaceFolder ?? "/",
        timeout: 10
      });
      await stream.stdin.close();
      const stdout = await streamToString2(stream.stdout);
      const exitCode = await stream.exitCode;
      if (exitCode === 0 && stdout.trim()) {
        this.remoteHomeDir = stdout.trim();
      }
    } catch {
    }
  }
  readFileViaExec(filePath, abortSignal) {
    return new ReadableStream({
      start: async (controller) => {
        try {
          const stream = await this.exec(`cat ${this.quoteForContainer(filePath)}`, {
            cwd: this.getContainerBasePath(),
            timeout: 300,
            abortSignal
          });
          const reader = stream.stdout.getReader();
          const exitCodePromise = stream.exitCode;
          while (true) {
            const { done, value: value2 } = await reader.read();
            if (done) break;
            controller.enqueue(value2);
          }
          const code = await exitCodePromise;
          if (code !== 0) {
            const stderr = await streamToString2(stream.stderr);
            throw new RuntimeError(`Failed to read file ${filePath}: ${stderr}`, "file_io");
          }
          controller.close();
        } catch (err) {
          if (err instanceof RuntimeError) {
            controller.error(err);
          } else {
            controller.error(
              new RuntimeError(
                `Failed to read file ${filePath}: ${err instanceof Error ? err.message : String(err)}`,
                "file_io",
                err instanceof Error ? err : void 0
              )
            );
          }
        }
      }
    });
  }
  writeFileViaExec(filePath, abortSignal) {
    const quotedPath = this.quoteForContainer(filePath);
    const tempPath = `${filePath}.tmp.${Date.now()}`;
    const quotedTempPath = this.quoteForContainer(tempPath);
    const writeCommand = `mkdir -p $(dirname ${quotedPath}) && cat > ${quotedTempPath} && mv ${quotedTempPath} ${quotedPath}`;
    let execPromise = null;
    const getExecStream = () => {
      execPromise ??= this.exec(writeCommand, {
        cwd: this.getContainerBasePath(),
        timeout: 300,
        abortSignal
      });
      return execPromise;
    };
    return new WritableStream({
      write: async (chunk) => {
        const stream = await getExecStream();
        const writer = stream.stdin.getWriter();
        try {
          await writer.write(chunk);
        } finally {
          writer.releaseLock();
        }
      },
      close: async () => {
        const stream = await getExecStream();
        await stream.stdin.close();
        const exitCode = await stream.exitCode;
        if (exitCode !== 0) {
          const stderr = await streamToString2(stream.stderr);
          throw new RuntimeError(`Failed to write file ${filePath}: ${stderr}`, "file_io");
        }
      },
      abort: async (reason) => {
        const stream = await getExecStream();
        await stream.stdin.abort();
        throw new RuntimeError(`Failed to write file ${filePath}: ${String(reason)}`, "file_io");
      }
    });
  }
  async ensureDirViaExec(dirPath) {
    const stream = await this.exec(`mkdir -p ${this.quoteForContainer(dirPath)}`, {
      cwd: "/",
      timeout: 10
    });
    await stream.stdin.close();
    const [stdout, stderr, exitCode] = await Promise.all([
      streamToString2(stream.stdout),
      streamToString2(stream.stderr),
      stream.exitCode
    ]);
    if (exitCode !== 0) {
      const extra = stderr.trim() || stdout.trim();
      throw new RuntimeError(
        `Failed to create directory ${dirPath}: exit code ${exitCode}${extra ? `: ${extra}` : ""}`,
        "file_io"
      );
    }
  }
  async statViaExec(filePath, abortSignal) {
    const stream = await this.exec(`stat -c '%s %Y %F' ${this.quoteForContainer(filePath)}`, {
      cwd: this.getContainerBasePath(),
      timeout: 10,
      abortSignal
    });
    const [stdout, stderr, exitCode] = await Promise.all([
      streamToString2(stream.stdout),
      streamToString2(stream.stderr),
      stream.exitCode
    ]);
    if (exitCode !== 0) {
      throw new RuntimeError(`Failed to stat ${filePath}: ${stderr}`, "file_io");
    }
    const parts = stdout.trim().split(" ");
    if (parts.length < 3) {
      throw new RuntimeError(`Failed to parse stat output for ${filePath}: ${stdout}`, "file_io");
    }
    const size = parseInt(parts[0], 10);
    const mtime = parseInt(parts[1], 10);
    const fileType = parts.slice(2).join(" ");
    return {
      size,
      modifiedTime: new Date(mtime * 1e3),
      isDirectory: fileType === "directory"
    };
  }
  mapHostPathToContainer(hostPath) {
    if (!this.remoteWorkspaceFolder || !this.currentWorkspacePath) return null;
    const normalizedHostPath = hostPath.replaceAll("\\", "/");
    const hostRoot = this.currentWorkspacePath.replaceAll("\\", "/").replace(/\/+$/, "");
    if (normalizedHostPath !== hostRoot && !normalizedHostPath.startsWith(`${hostRoot}/`))
      return null;
    const suffix = normalizedHostPath.slice(hostRoot.length).replace(/^\/+/, "");
    return suffix.length === 0 ? this.remoteWorkspaceFolder : path15.posix.join(this.remoteWorkspaceFolder, suffix);
  }
  /**
   * Resolve cwd for container exec, filtering out unmappable host paths.
   * Only uses options.cwd if it looks like a valid container path (POSIX absolute, no Windows drive letters).
   */
  resolveContainerCwd(optionsCwd, workspaceFolder) {
    if (optionsCwd && this.looksLikeContainerPath(optionsCwd)) {
      return optionsCwd;
    }
    return this.remoteWorkspaceFolder ?? workspaceFolder;
  }
  /**
   * Check if a path looks like a valid container path (POSIX absolute, no Windows artifacts).
   */
  looksLikeContainerPath(p) {
    if (/^[A-Za-z]:/.test(p)) return false;
    if (p.includes("\\")) return false;
    return p.startsWith("/");
  }
  getWorkspacePath(projectPath, workspaceName) {
    return this.worktreeManager.getWorkspacePath(projectPath, workspaceName);
  }
  async createWorkspace(params) {
    return this.worktreeManager.createWorkspace({
      projectPath: params.projectPath,
      branchName: params.branchName,
      trunkBranch: params.trunkBranch,
      initLogger: params.initLogger
    });
  }
  /**
   * Build and start the devcontainer after workspace creation.
   * This runs `devcontainer up` which builds the image and starts the container.
   */
  async postCreateSetup(params) {
    const { workspacePath, initLogger, abortSignal, env: env3 } = params;
    initLogger.logStep("Building devcontainer...");
    this.lastCredentialEnv = env3;
    const { additionalMounts, remoteEnv } = this.buildCredentialForwarding(env3);
    try {
      const result = await devcontainerUp({
        workspaceFolder: workspacePath,
        configPath: this.configPath,
        initLogger,
        abortSignal,
        additionalMounts: additionalMounts.length > 0 ? additionalMounts : void 0,
        remoteEnv: Object.keys(remoteEnv).length > 0 ? remoteEnv : void 0
      });
      this.remoteWorkspaceFolder = result.remoteWorkspaceFolder;
      this.remoteUser = result.remoteUser;
      this.currentWorkspacePath = workspacePath;
      await this.fetchRemoteHome();
      await this.setupCredentials(env3);
      initLogger.logStep("Devcontainer ready");
    } catch (error) {
      throw new Error(`Failed to start devcontainer: ${getErrorMessage3(error)}`);
    }
  }
  /**
   * Run .unix/init hook inside the devcontainer.
   */
  async initWorkspace(params) {
    const { projectPath, branchName, workspacePath, initLogger, env: env3 } = params;
    try {
      const hookExists = await checkInitHookExists(workspacePath);
      if (hookExists) {
        const muxEnv = { ...env3, ...getUnixEnv(projectPath, "devcontainer", branchName) };
        const containerWorkspacePath = this.remoteWorkspaceFolder ?? workspacePath;
        const hookPath = `${containerWorkspacePath}/.unix/init`;
        await runInitHookOnRuntime(this, hookPath, containerWorkspacePath, muxEnv, initLogger);
      } else {
        initLogger.logComplete(0);
      }
      return { success: true };
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      initLogger.logStderr(`Initialization failed: ${errorMsg}`);
      initLogger.logComplete(-1);
      return {
        success: false,
        error: errorMsg
      };
    }
  }
  /**
   * Execute a command inside the devcontainer.
   * Overrides LocalBaseRuntime.exec() to use `devcontainer exec`.
   */
  exec(command, options) {
    const startTime = performance.now();
    if (options.abortSignal?.aborted) {
      throw new RuntimeError("Operation aborted before execution", "exec");
    }
    const workspaceFolder = this.currentWorkspacePath;
    if (!workspaceFolder) {
      throw new RuntimeError("Devcontainer not initialized. Call ensureReady() first.", "exec");
    }
    const args2 = ["exec", "--workspace-folder", workspaceFolder];
    if (this.configPath) {
      args2.push("--config", this.configPath);
    }
    const envVars = { ...options.env, ...NON_INTERACTIVE_ENV_VARS };
    for (const [key, value2] of Object.entries(envVars)) {
      args2.push("--remote-env", `${key}=${value2}`);
    }
    const mappedCwd = options.cwd ? this.mapHostPathToContainer(options.cwd) : null;
    const cwd = mappedCwd ?? this.resolveContainerCwd(options.cwd, workspaceFolder);
    const fullCommand = `cd ${JSON.stringify(cwd)} && ${command}`;
    args2.push("--", "bash", "-c", fullCommand);
    const childProcess = spawn8("devcontainer", args2, {
      stdio: ["pipe", "pipe", "pipe"],
      detached: true,
      windowsHide: true,
      cwd: workspaceFolder
    });
    const disposable = new DisposableProcess(childProcess);
    const stdout = Readable3.toWeb(childProcess.stdout);
    const stderr = Readable3.toWeb(childProcess.stderr);
    const stdin = Writable2.toWeb(childProcess.stdin);
    let timedOut = false;
    let aborted = false;
    const exitCode = new Promise((resolve3, reject) => {
      childProcess.on("exit", (code) => {
        if (childProcess.pid !== void 0) {
          killProcessTree(childProcess.pid);
        }
        if (aborted || options.abortSignal?.aborted) {
          resolve3(EXIT_CODE_ABORTED);
          return;
        }
        if (timedOut) {
          resolve3(EXIT_CODE_TIMEOUT);
          return;
        }
        resolve3(code ?? 0);
      });
      childProcess.on("error", (err) => {
        reject(
          new RuntimeError(`Failed to execute devcontainer exec: ${err.message}`, "exec", err)
        );
      });
    });
    const duration = exitCode.then(() => performance.now() - startTime);
    void exitCode.catch(() => void 0);
    void duration.catch(() => void 0);
    let timeoutId;
    if (options.timeout && options.timeout > 0) {
      timeoutId = setTimeout(() => {
        timedOut = true;
        disposable[Symbol.dispose]();
      }, options.timeout * 1e3);
      void exitCode.finally(() => {
        if (timeoutId) clearTimeout(timeoutId);
      });
    }
    const abortHandler = () => {
      aborted = true;
      disposable[Symbol.dispose]();
    };
    options.abortSignal?.addEventListener("abort", abortHandler);
    void exitCode.finally(() => {
      options.abortSignal?.removeEventListener("abort", abortHandler);
    });
    return Promise.resolve({
      stdout,
      stderr,
      stdin,
      exitCode,
      duration
    });
  }
  readFile(filePath, abortSignal) {
    const hostPath = this.resolveHostPathForMounted(filePath);
    if (hostPath) {
      return super.readFile(hostPath, abortSignal);
    }
    return this.readFileViaExec(filePath, abortSignal);
  }
  writeFile(filePath, abortSignal) {
    const hostPath = this.resolveHostPathForMounted(filePath);
    if (hostPath) {
      return super.writeFile(hostPath, abortSignal);
    }
    return this.writeFileViaExec(filePath, abortSignal);
  }
  async stat(filePath) {
    const hostPath = this.resolveHostPathForMounted(filePath);
    if (hostPath) {
      return super.stat(hostPath);
    }
    return this.statViaExec(filePath);
  }
  async ensureDir(dirPath) {
    const hostPath = this.resolveHostPathForMounted(dirPath);
    if (hostPath) {
      return super.ensureDir(hostPath);
    }
    return this.ensureDirViaExec(dirPath);
  }
  async resolvePath(filePath) {
    let expanded = this.expandTildeForContainer(filePath);
    if (this.hasUnexpandedTilde(expanded)) {
      await this.fetchRemoteHome();
      if (this.remoteHomeDir) {
        expanded = filePath === "~" ? this.remoteHomeDir : this.remoteHomeDir + filePath.slice(1);
      } else {
        throw new RuntimeError(
          `Failed to resolve path ${filePath}: container home directory unavailable`,
          "exec"
        );
      }
    }
    if (!expanded.startsWith("/")) {
      const basePath = this.remoteWorkspaceFolder ?? "/";
      return path15.posix.resolve(basePath, expanded);
    }
    return path15.posix.resolve(expanded);
  }
  tempDir() {
    const workspaceRoot = this.remoteWorkspaceFolder ?? this.currentWorkspacePath;
    if (!workspaceRoot) {
      return super.tempDir();
    }
    const tmpPath = this.remoteWorkspaceFolder ? path15.posix.join(workspaceRoot, ".unix", "tmp") : path15.join(workspaceRoot, ".unix", "tmp");
    return Promise.resolve(tmpPath);
  }
  /**
   * Ensure the devcontainer is ready for operations.
   * Runs `devcontainer up` which starts the container if stopped,
   * or rebuilds if the container was deleted.
   */
  async ensureReady(options) {
    if (!this.currentWorkspacePath) {
      return {
        ready: false,
        error: "Workspace path not set. Call postCreateSetup() first.",
        errorType: "runtime_not_ready"
      };
    }
    const statusSink = options?.statusSink;
    statusSink?.({ phase: "checking", runtimeType: "devcontainer" });
    try {
      statusSink?.({
        phase: "starting",
        runtimeType: "devcontainer",
        detail: "Starting devcontainer..."
      });
      const silentLogger = {
        logStep: (_message) => {
        },
        logStdout: (_line) => {
        },
        logStderr: (line) => log.debug("devcontainer up stderr:", { line }),
        logComplete: (_exitCode) => {
        }
      };
      const { additionalMounts, remoteEnv } = this.buildCredentialForwarding(
        this.lastCredentialEnv
      );
      const result = await devcontainerUp({
        workspaceFolder: this.currentWorkspacePath,
        configPath: this.configPath,
        initLogger: silentLogger,
        abortSignal: options?.signal,
        additionalMounts: additionalMounts.length > 0 ? additionalMounts : void 0,
        remoteEnv: Object.keys(remoteEnv).length > 0 ? remoteEnv : void 0
      });
      this.remoteWorkspaceFolder = result.remoteWorkspaceFolder;
      this.remoteUser = result.remoteUser;
      await this.fetchRemoteHome();
      await this.setupCredentials(this.lastCredentialEnv);
      statusSink?.({ phase: "ready", runtimeType: "devcontainer" });
      return { ready: true };
    } catch (error) {
      const errorMsg = getErrorMessage3(error);
      statusSink?.({ phase: "error", runtimeType: "devcontainer", detail: errorMsg });
      return {
        ready: false,
        error: errorMsg,
        errorType: "runtime_not_ready"
      };
    }
  }
  async renameWorkspace(projectPath, oldName, newName, _abortSignal) {
    const oldPath = this.getWorkspacePath(projectPath, oldName);
    await devcontainerDown(oldPath, this.configPath);
    const result = await this.worktreeManager.renameWorkspace(projectPath, oldName, newName);
    if (result.success) {
      if (this.currentWorkspacePath === oldPath) {
        this.currentWorkspacePath = result.newPath;
      }
    }
    return result;
  }
  async deleteWorkspace(projectPath, workspaceName, force, _abortSignal) {
    const workspacePath = this.getWorkspacePath(projectPath, workspaceName);
    try {
      await devcontainerDown(workspacePath, this.configPath);
    } catch (error) {
      log.debug("devcontainerDown failed (container may not exist):", { error });
    }
    return this.worktreeManager.deleteWorkspace(projectPath, workspaceName, force);
  }
  async forkWorkspace(params) {
    return this.worktreeManager.forkWorkspace(params);
  }
  /**
   * Set the current workspace path for exec operations.
   * Called by workspaceService when switching to an existing workspace.
   */
  setCurrentWorkspacePath(workspacePath) {
    this.currentWorkspacePath = workspacePath;
  }
  /**
   * Get the remote workspace folder path (inside container).
   */
  getRemoteWorkspaceFolder() {
    return this.remoteWorkspaceFolder;
  }
};

// src/common/utils/runtimeCompatibility.ts
function isIncompatibleRuntimeConfig(config2) {
  if (!config2) {
    return false;
  }
  return !RuntimeModeSchema.safeParse(config2.type).success;
}

// src/node/config.ts
var import_write_file_atomic = __toESM(require_lib());
import * as fs8 from "fs";
import * as path16 from "path";
import * as crypto3 from "crypto";
import * as jsonc from "jsonc-parser";

// src/common/utils/assert.ts
var AssertionError = class extends Error {
  constructor(message) {
    super(message ?? "Assertion failed");
    this.name = "AssertionError";
  }
};
function assert(condition, message) {
  if (!condition) {
    throw new AssertionError(message);
  }
}
var assert_default = assert;

// src/common/types/thinking.ts
var THINKING_LEVELS = ["off", "low", "medium", "high", "xhigh"];
function isThinkingLevel(value2) {
  return typeof value2 === "string" && THINKING_LEVELS.includes(value2);
}
function coerceThinkingLevel(value2) {
  return isThinkingLevel(value2) ? value2 : void 0;
}

// src/common/types/tasks.ts
var TASK_SETTINGS_LIMITS = {
  maxParallelAgentTasks: { min: 1, max: 10, default: 3 },
  maxTaskNestingDepth: { min: 1, max: 5, default: 3 }
};
var SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS = {
  bashOutputCompactionMinLines: { min: 0, max: 1e3, default: 10 },
  bashOutputCompactionMinTotalBytes: { min: 0, max: 16 * 1024, default: 4 * 1024 },
  bashOutputCompactionMaxKeptLines: { min: 1, max: 1e3, default: 40 },
  bashOutputCompactionTimeoutMs: { min: 1e3, max: 12e4, default: 5e3 }
};
var DEFAULT_TASK_SETTINGS = {
  maxParallelAgentTasks: TASK_SETTINGS_LIMITS.maxParallelAgentTasks.default,
  maxTaskNestingDepth: TASK_SETTINGS_LIMITS.maxTaskNestingDepth.default,
  proposePlanImplementReplacesChatHistory: false,
  bashOutputCompactionMinLines: SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinLines.default,
  bashOutputCompactionMinTotalBytes: SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinTotalBytes.default,
  bashOutputCompactionMaxKeptLines: SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMaxKeptLines.default,
  bashOutputCompactionTimeoutMs: SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionTimeoutMs.default,
  bashOutputCompactionHeuristicFallback: true
};
function normalizeSubagentAiDefaults(raw) {
  const record = raw && typeof raw === "object" ? raw : {};
  const result = {};
  for (const [agentTypeRaw, entryRaw] of Object.entries(record)) {
    const agentType = agentTypeRaw.trim().toLowerCase();
    if (!agentType) continue;
    if (agentType === "exec") continue;
    if (!entryRaw || typeof entryRaw !== "object") continue;
    const entry = entryRaw;
    const modelString = typeof entry.modelString === "string" && entry.modelString.trim().length > 0 ? entry.modelString.trim() : void 0;
    const thinkingLevel = coerceThinkingLevel(entry.thinkingLevel);
    if (!modelString && !thinkingLevel) {
      continue;
    }
    result[agentType] = { modelString, thinkingLevel };
  }
  return result;
}
function clampInt(value2, fallback, min, max) {
  if (typeof value2 !== "number" || !Number.isFinite(value2)) {
    return fallback;
  }
  const rounded = Math.floor(value2);
  if (rounded < min) return min;
  if (rounded > max) return max;
  return rounded;
}
function normalizeTaskSettings(raw) {
  const record = raw && typeof raw === "object" ? raw : {};
  const maxParallelAgentTasks = clampInt(
    record.maxParallelAgentTasks,
    DEFAULT_TASK_SETTINGS.maxParallelAgentTasks,
    TASK_SETTINGS_LIMITS.maxParallelAgentTasks.min,
    TASK_SETTINGS_LIMITS.maxParallelAgentTasks.max
  );
  const maxTaskNestingDepth = clampInt(
    record.maxTaskNestingDepth,
    DEFAULT_TASK_SETTINGS.maxTaskNestingDepth,
    TASK_SETTINGS_LIMITS.maxTaskNestingDepth.min,
    TASK_SETTINGS_LIMITS.maxTaskNestingDepth.max
  );
  const proposePlanImplementReplacesChatHistory = typeof record.proposePlanImplementReplacesChatHistory === "boolean" ? record.proposePlanImplementReplacesChatHistory : DEFAULT_TASK_SETTINGS.proposePlanImplementReplacesChatHistory ?? false;
  const bashOutputCompactionMinLines = clampInt(
    record.bashOutputCompactionMinLines,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinLines.default,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinLines.min,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinLines.max
  );
  const bashOutputCompactionMinTotalBytes = clampInt(
    record.bashOutputCompactionMinTotalBytes,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinTotalBytes.default,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinTotalBytes.min,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMinTotalBytes.max
  );
  const bashOutputCompactionMaxKeptLines = clampInt(
    record.bashOutputCompactionMaxKeptLines,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMaxKeptLines.default,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMaxKeptLines.min,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionMaxKeptLines.max
  );
  const bashOutputCompactionTimeoutMsRaw = clampInt(
    record.bashOutputCompactionTimeoutMs,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionTimeoutMs.default,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionTimeoutMs.min,
    SYSTEM1_BASH_OUTPUT_COMPACTION_LIMITS.bashOutputCompactionTimeoutMs.max
  );
  const bashOutputCompactionHeuristicFallback = typeof record.bashOutputCompactionHeuristicFallback === "boolean" ? record.bashOutputCompactionHeuristicFallback : DEFAULT_TASK_SETTINGS.bashOutputCompactionHeuristicFallback ?? true;
  const bashOutputCompactionTimeoutMs = Math.floor(bashOutputCompactionTimeoutMsRaw / 1e3) * 1e3;
  const result = {
    maxParallelAgentTasks,
    maxTaskNestingDepth,
    proposePlanImplementReplacesChatHistory,
    bashOutputCompactionMinLines,
    bashOutputCompactionMinTotalBytes,
    bashOutputCompactionMaxKeptLines,
    bashOutputCompactionTimeoutMs,
    bashOutputCompactionHeuristicFallback
  };
  assert_default(
    Number.isInteger(maxParallelAgentTasks),
    "normalizeTaskSettings: maxParallelAgentTasks must be an integer"
  );
  assert_default(
    Number.isInteger(maxTaskNestingDepth),
    "normalizeTaskSettings: maxTaskNestingDepth must be an integer"
  );
  assert_default(
    typeof proposePlanImplementReplacesChatHistory === "boolean",
    "normalizeTaskSettings: proposePlanImplementReplacesChatHistory must be a boolean"
  );
  assert_default(
    Number.isInteger(bashOutputCompactionMinLines),
    "normalizeTaskSettings: bashOutputCompactionMinLines must be an integer"
  );
  assert_default(
    Number.isInteger(bashOutputCompactionMinTotalBytes),
    "normalizeTaskSettings: bashOutputCompactionMinTotalBytes must be an integer"
  );
  assert_default(
    Number.isInteger(bashOutputCompactionMaxKeptLines),
    "normalizeTaskSettings: bashOutputCompactionMaxKeptLines must be an integer"
  );
  assert_default(
    Number.isInteger(bashOutputCompactionTimeoutMs),
    "normalizeTaskSettings: bashOutputCompactionTimeoutMs must be an integer"
  );
  assert_default(
    typeof bashOutputCompactionHeuristicFallback === "boolean",
    "normalizeTaskSettings: bashOutputCompactionHeuristicFallback must be a boolean"
  );
  assert_default(
    bashOutputCompactionTimeoutMs % 1e3 === 0,
    "normalizeTaskSettings: bashOutputCompactionTimeoutMs must be a whole number of seconds"
  );
  return result;
}

// src/common/types/keybind.ts
function hasModifierKeybind(keybind) {
  return [keybind.ctrl, keybind.shift, keybind.alt, keybind.meta].some((v) => v === true);
}
function normalizeKeybind(raw) {
  if (!raw || typeof raw !== "object") {
    return void 0;
  }
  const record = raw;
  const rawKey = typeof record.key === "string" ? record.key : "";
  const key = rawKey === " " ? rawKey : rawKey.trim();
  if (!key) {
    return void 0;
  }
  const allowShift = typeof record.allowShift === "boolean" ? record.allowShift : void 0;
  const ctrl = typeof record.ctrl === "boolean" ? record.ctrl : void 0;
  const shift = typeof record.shift === "boolean" ? record.shift : void 0;
  const alt = typeof record.alt === "boolean" ? record.alt : void 0;
  const meta = typeof record.meta === "boolean" ? record.meta : void 0;
  const macCtrlBehavior = record.macCtrlBehavior === "either" || record.macCtrlBehavior === "command" || record.macCtrlBehavior === "control" ? record.macCtrlBehavior : void 0;
  const result = {
    key,
    allowShift,
    ctrl,
    shift,
    alt,
    meta,
    macCtrlBehavior
  };
  assert_default(typeof result.key === "string" && result.key.length > 0, "Keybind.key must be non-empty");
  return result;
}

// src/common/types/uiLayouts.ts
var DEFAULT_LAYOUT_PRESETS_CONFIG = {
  version: 2,
  slots: []
};
function isLayoutSlotNumber(value2) {
  return typeof value2 === "number" && Number.isInteger(value2) && value2 >= 1;
}
function normalizeOptionalNonEmptyString(value2) {
  if (typeof value2 !== "string") {
    return void 0;
  }
  const trimmed = value2.trim();
  return trimmed ? trimmed : void 0;
}
function normalizeRightSidebarWidthPreset(raw) {
  if (!raw || typeof raw !== "object") {
    return { mode: "px", value: 400 };
  }
  const record = raw;
  const mode = record.mode;
  if (mode === "fraction") {
    const value3 = typeof record.value === "number" && Number.isFinite(record.value) ? record.value : 0.3;
    const clamped2 = Math.min(0.9, Math.max(0.1, value3));
    return { mode: "fraction", value: clamped2 };
  }
  const value2 = typeof record.value === "number" && Number.isFinite(record.value) ? record.value : 400;
  const rounded = Math.floor(value2);
  const clamped = Math.min(1200, Math.max(300, rounded));
  return { mode: "px", value: clamped };
}
function isPresetTabType(value2) {
  if (typeof value2 !== "string") return false;
  if (value2 === "costs" || value2 === "review" || value2 === "explorer" || value2 === "stats") {
    return true;
  }
  return value2.startsWith("terminal_new:") && value2.length > "terminal_new:".length;
}
function isLayoutNode(value2) {
  if (!value2 || typeof value2 !== "object") return false;
  const v = value2;
  if (v.type === "tabset") {
    return typeof v.id === "string" && Array.isArray(v.tabs) && v.tabs.every((t) => isPresetTabType(t)) && isPresetTabType(v.activeTab);
  }
  if (v.type === "split") {
    if (typeof v.id !== "string") return false;
    if (v.direction !== "horizontal" && v.direction !== "vertical") return false;
    if (!Array.isArray(v.sizes) || v.sizes.length !== 2) return false;
    if (typeof v.sizes[0] !== "number" || typeof v.sizes[1] !== "number") return false;
    if (!Array.isArray(v.children) || v.children.length !== 2) return false;
    return isLayoutNode(v.children[0]) && isLayoutNode(v.children[1]);
  }
  return false;
}
function findTabset(root, tabsetId) {
  if (root.type === "tabset") {
    return root.id === tabsetId ? root : null;
  }
  return findTabset(root.children[0], tabsetId) ?? findTabset(root.children[1], tabsetId);
}
function isRightSidebarLayoutPresetState(value2) {
  if (!value2 || typeof value2 !== "object") return false;
  const v = value2;
  if (v.version !== 1) return false;
  if (typeof v.nextId !== "number") return false;
  if (typeof v.focusedTabsetId !== "string") return false;
  if (!isLayoutNode(v.root)) return false;
  return findTabset(v.root, v.focusedTabsetId) !== null;
}
function normalizeLayoutSlot(raw) {
  if (!raw || typeof raw !== "object") {
    return void 0;
  }
  const record = raw;
  if (!isLayoutSlotNumber(record.slot)) {
    return void 0;
  }
  const preset = normalizeLayoutPreset(record.preset);
  const keybindOverrideRaw = normalizeKeybind(record.keybindOverride);
  const keybindOverride = keybindOverrideRaw ? hasModifierKeybind(keybindOverrideRaw) ? keybindOverrideRaw : void 0 : void 0;
  if (!preset && !keybindOverride) {
    return void 0;
  }
  return {
    slot: record.slot,
    preset: preset ?? void 0,
    keybindOverride
  };
}
function normalizeLayoutSlotV1(raw) {
  if (!raw || typeof raw !== "object") {
    return void 0;
  }
  const record = raw;
  if (!isLayoutSlotNumber(record.slot)) {
    return void 0;
  }
  const presetId = normalizeOptionalNonEmptyString(record.presetId);
  const keybindOverrideRaw = normalizeKeybind(record.keybindOverride);
  const keybindOverride = keybindOverrideRaw ? hasModifierKeybind(keybindOverrideRaw) ? keybindOverrideRaw : void 0 : void 0;
  if (!presetId && !keybindOverride) {
    return void 0;
  }
  return {
    slot: record.slot,
    presetId,
    keybindOverride
  };
}
function normalizeLayoutPreset(raw) {
  if (!raw || typeof raw !== "object") {
    return void 0;
  }
  const record = raw;
  const id = normalizeOptionalNonEmptyString(record.id);
  const name16 = normalizeOptionalNonEmptyString(record.name);
  if (!id || !name16) {
    return void 0;
  }
  const leftSidebarCollapsed = typeof record.leftSidebarCollapsed === "boolean" ? record.leftSidebarCollapsed : false;
  if (!record.rightSidebar || typeof record.rightSidebar !== "object") {
    return void 0;
  }
  const rightSidebarRecord = record.rightSidebar;
  const collapsed = typeof rightSidebarRecord.collapsed === "boolean" ? rightSidebarRecord.collapsed : false;
  const width = normalizeRightSidebarWidthPreset(rightSidebarRecord.width);
  const layoutRaw = rightSidebarRecord.layout;
  if (!isRightSidebarLayoutPresetState(layoutRaw)) {
    return void 0;
  }
  const layout = layoutRaw;
  return {
    id,
    name: name16,
    leftSidebarCollapsed,
    rightSidebar: {
      collapsed,
      width,
      layout
    }
  };
}
function normalizeLayoutPresetsConfig(raw) {
  if (!raw || typeof raw !== "object") {
    return DEFAULT_LAYOUT_PRESETS_CONFIG;
  }
  const record = raw;
  if (record.version === 2) {
    return normalizeLayoutPresetsConfigV2(record);
  }
  if (record.version === 1) {
    return migrateLayoutPresetsConfigV1(record);
  }
  return DEFAULT_LAYOUT_PRESETS_CONFIG;
}
function normalizeLayoutPresetsConfigV2(record) {
  const slotsArray = Array.isArray(record.slots) ? record.slots : [];
  const slotsByNumber = /* @__PURE__ */ new Map();
  for (const entry of slotsArray) {
    const slot = normalizeLayoutSlot(entry);
    if (!slot) continue;
    slotsByNumber.set(slot.slot, slot);
  }
  const slots = Array.from(slotsByNumber.values()).sort((a, b) => a.slot - b.slot);
  const result = {
    version: 2,
    slots
  };
  assert_default(result.version === 2, "normalizeLayoutPresetsConfig: version must be 2");
  assert_default(Array.isArray(result.slots), "normalizeLayoutPresetsConfig: slots must be an array");
  return result;
}
function migrateLayoutPresetsConfigV1(record) {
  const presetsArray = Array.isArray(record.presets) ? record.presets : [];
  const presetsById = /* @__PURE__ */ new Map();
  for (const entry of presetsArray) {
    const preset = normalizeLayoutPreset(entry);
    if (!preset) continue;
    presetsById.set(preset.id, preset);
  }
  const slotsArray = Array.isArray(record.slots) ? record.slots : [];
  const slotsByNumber = /* @__PURE__ */ new Map();
  for (const entry of slotsArray) {
    const slot = normalizeLayoutSlotV1(entry);
    if (!slot) continue;
    const preset = slot.presetId ? presetsById.get(slot.presetId) : void 0;
    if (!preset && !slot.keybindOverride) {
      continue;
    }
    slotsByNumber.set(slot.slot, {
      slot: slot.slot,
      preset,
      keybindOverride: slot.keybindOverride
    });
  }
  const slots = Array.from(slotsByNumber.values()).sort((a, b) => a.slot - b.slot);
  const result = {
    version: 2,
    slots
  };
  assert_default(result.version === 2, "migrateLayoutPresetsConfigV1: version must be 2");
  assert_default(Array.isArray(result.slots), "migrateLayoutPresetsConfigV1: slots must be an array");
  return result;
}
function isLayoutPresetsConfigEmpty(value2) {
  assert_default(value2.version === 2, "isLayoutPresetsConfigEmpty: version must be 2");
  for (const slot of value2.slots) {
    if (slot.preset || slot.keybindOverride) {
      return false;
    }
  }
  return true;
}

// src/common/types/agentAiDefaults.ts
function normalizeAgentAiDefaults(raw) {
  const record = raw && typeof raw === "object" ? raw : {};
  const result = {};
  for (const [agentIdRaw, entryRaw] of Object.entries(record)) {
    const agentId = agentIdRaw.trim().toLowerCase();
    if (!agentId) continue;
    if (!AgentIdSchema.safeParse(agentId).success) continue;
    if (!entryRaw || typeof entryRaw !== "object") continue;
    const entry = entryRaw;
    const modelString = typeof entry.modelString === "string" && entry.modelString.trim().length > 0 ? entry.modelString.trim() : void 0;
    const thinkingLevel = coerceThinkingLevel(entry.thinkingLevel);
    if (!modelString && !thinkingLevel) {
      continue;
    }
    result[agentId] = { modelString, thinkingLevel };
  }
  return result;
}

// src/common/constants/workspace.ts
var DEFAULT_RUNTIME_CONFIG = {
  type: "worktree",
  srcBaseDir: "~/.unix/src"
};

// src/common/utils/paths.ts
function isWindowsPlatform2() {
  if (typeof navigator !== "undefined" && navigator.platform) {
    return navigator.platform.toLowerCase().includes("win");
  }
  return false;
}
function getSeparator2() {
  return isWindowsPlatform2() ? "\\" : "/";
}
var PlatformPaths2 = class {
  /**
   * Get the appropriate path separator for the current platform
   */
  static get separator() {
    return getSeparator2();
  }
  /**
   * Extract basename from path (OS-aware)
   *
   * @param filePath - Path to extract basename from
   * @returns The final component of the path
   *
   * @example
   * // Unix
   * basename("/home/user/project") // => "project"
   *
   * // Windows
   * basename("C:\\Users\\user\\project") // => "project"
   */
  static basename(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return filePath;
    }
    const lastSlash = isWindowsPlatform2() ? Math.max(filePath.lastIndexOf("/"), filePath.lastIndexOf("\\")) : filePath.lastIndexOf("/");
    if (lastSlash === -1) {
      return filePath;
    }
    return filePath.slice(lastSlash + 1);
  }
  /**
   * Split path into components (OS-aware)
   *
   * @param filePath - Path to parse
   * @returns Object with root, segments, and basename
   *
   * @example
   * // Unix
   * parse("/home/user/project") // => { root: "/", segments: ["home", "user"], basename: "project" }
   *
   * // Windows
   * parse("C:\\Users\\user\\project") // => { root: "C:\\", segments: ["Users", "user"], basename: "project" }
   */
  static parse(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return { root: "", segments: [], basename: filePath };
    }
    const original = filePath;
    let root = "";
    let dir = "";
    let base = "";
    const lastSlash = isWindowsPlatform2() ? Math.max(original.lastIndexOf("/"), original.lastIndexOf("\\")) : original.lastIndexOf("/");
    if (lastSlash === -1) {
      base = original;
      dir = "";
    } else {
      base = original.slice(lastSlash + 1);
      dir = original.slice(0, lastSlash);
    }
    if (isWindowsPlatform2()) {
      const driveMatch = /^[A-Za-z]:[\\/]/.exec(original);
      if (driveMatch) {
        root = driveMatch[0];
        if (dir.startsWith(root)) {
          dir = dir.slice(root.length);
        }
      } else if (original.startsWith("\\\\")) {
        root = "\\\\";
        if (dir.startsWith(root)) {
          dir = dir.slice(root.length);
        }
      }
      if (!root && original.startsWith("/")) {
        root = "/";
        if (dir.startsWith(root)) {
          dir = dir.slice(root.length);
        }
      }
    } else if (original.startsWith("/")) {
      root = "/";
      if (dir.startsWith(root)) {
        dir = dir.slice(root.length);
      }
    }
    const separatorRegex = isWindowsPlatform2() ? /[\\/]+/ : /\/+/;
    const segments = dir ? dir.split(separatorRegex).filter(Boolean) : [];
    return {
      root,
      segments,
      basename: base
    };
  }
  /**
   * Format path for display with fish-style abbreviation (OS-aware)
   * Abbreviates all directory components except the last one to their first letter
   *
   * @param filePath - Path to abbreviate
   * @returns Abbreviated path
   *
   * @example
   * // Unix
   * abbreviate("/home/user/Projects/unix") // => "/h/u/P/unix"
   *
   * // Windows
   * abbreviate("C:\\Users\\john\\Documents\\project") // => "C:\\U\\j\\D\\project"
   */
  static abbreviate(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return filePath;
    }
    const { root, segments, basename } = this.parse(filePath);
    const abbreviated = segments.map((seg) => seg.length > 0 ? seg[0] : seg);
    if (!root && abbreviated.length === 0) {
      return basename;
    }
    const sep = isWindowsPlatform2() ? filePath.includes("\\") ? "\\" : "/" : "/";
    const joined = [...abbreviated, basename].filter(Boolean).join(sep);
    if (!root) {
      return joined;
    }
    const rootEndsWithSep = root.endsWith("\\") || root.endsWith("/");
    return rootEndsWithSep ? root + joined : root + sep + joined;
  }
  /**
   * Split an abbreviated path into directory path and basename
   *
   * @param filePath - Abbreviated path
   * @returns Object with dirPath (including trailing separator) and basename
   *
   * @example
   * splitAbbreviated("/h/u/P/unix") // => { dirPath: "/h/u/P/", basename: "unix" }
   */
  static splitAbbreviated(filePath) {
    if (!filePath || typeof filePath !== "string") {
      return { dirPath: "", basename: filePath };
    }
    const sep = isWindowsPlatform2() ? filePath.includes("\\") ? "\\" : "/" : "/";
    const lastSlash = filePath.lastIndexOf(sep);
    if (lastSlash === -1) {
      return { dirPath: "", basename: filePath };
    }
    return {
      dirPath: filePath.slice(0, lastSlash + 1),
      basename: filePath.slice(lastSlash + 1)
    };
  }
  /**
   * NOTE: Home expansion and formatting helpers are main-only.
   * Use './paths.main' for expandHome/formatHome in Node contexts.
   */
  /**
   * Get project name from path (OS-aware)
   * Extracts the final directory name from a project path
   *
   * @param projectPath - Path to the project
   * @returns Project name (final directory component)
   *
   * @example
   * getProjectName("/home/user/projects/unix") // => "unix"
   * getProjectName("C:\\Users\\john\\projects\\unix") // => "unix"
   */
  static getProjectName(projectPath) {
    return this.basename(projectPath) || "unknown";
  }
};

// src/node/config.ts
function parseOptionalNonEmptyString(value2) {
  if (typeof value2 !== "string") {
    return void 0;
  }
  const trimmed = value2.trim();
  return trimmed ? trimmed : void 0;
}
function parseOptionalEnvBoolean(value2) {
  if (typeof value2 !== "string") {
    return void 0;
  }
  const normalized = value2.trim().toLowerCase();
  if (!normalized) {
    return void 0;
  }
  if (normalized === "1" || normalized === "true" || normalized === "yes" || normalized === "on") {
    return true;
  }
  if (normalized === "0" || normalized === "false" || normalized === "no" || normalized === "off") {
    return false;
  }
  return void 0;
}
function parseOptionalBoolean(value2) {
  return typeof value2 === "boolean" ? value2 : void 0;
}
function parseOptionalPort(value2) {
  if (typeof value2 !== "number" || !Number.isFinite(value2) || !Number.isInteger(value2)) {
    return void 0;
  }
  if (value2 < 0 || value2 > 65535) {
    return void 0;
  }
  return value2;
}
var Config = class {
  constructor(rootDir) {
    this.rootDir = rootDir ?? getUnixHome();
    this.sessionsDir = path16.join(this.rootDir, "sessions");
    this.srcDir = path16.join(this.rootDir, "src");
    this.configFile = path16.join(this.rootDir, "config.json");
    this.providersFile = path16.join(this.rootDir, "providers.jsonc");
    this.secretsFile = path16.join(this.rootDir, "secrets.json");
  }
  loadConfigOrDefault() {
    try {
      if (fs8.existsSync(this.configFile)) {
        const data = fs8.readFileSync(this.configFile, "utf-8");
        const parsed = JSON.parse(data);
        if (parsed.projects && Array.isArray(parsed.projects)) {
          const rawPairs = parsed.projects;
          const normalizedPairs = rawPairs.filter(([projectPath]) => {
            if (!projectPath || typeof projectPath !== "string") {
              log.warn("Filtering out project with invalid path", { projectPath });
              return false;
            }
            return true;
          }).map(([projectPath, projectConfig]) => {
            return [stripTrailingSlashes(projectPath), projectConfig];
          });
          const projectsMap = new Map(normalizedPairs);
          const taskSettings = normalizeTaskSettings(parsed.taskSettings);
          const legacySubagentAiDefaults = normalizeSubagentAiDefaults(parsed.subagentAiDefaults);
          const agentAiDefaults = parsed.agentAiDefaults !== void 0 ? normalizeAgentAiDefaults(parsed.agentAiDefaults) : normalizeAgentAiDefaults(legacySubagentAiDefaults);
          const layoutPresetsRaw = normalizeLayoutPresetsConfig(parsed.layoutPresets);
          const layoutPresets = isLayoutPresetsConfigEmpty(layoutPresetsRaw) ? void 0 : layoutPresetsRaw;
          return {
            projects: projectsMap,
            apiServerBindHost: parseOptionalNonEmptyString(parsed.apiServerBindHost),
            apiServerServeWebUi: parseOptionalBoolean(parsed.apiServerServeWebUi) ? true : void 0,
            apiServerPort: parseOptionalPort(parsed.apiServerPort),
            mdnsAdvertisementEnabled: parseOptionalBoolean(parsed.mdnsAdvertisementEnabled),
            mdnsServiceName: parseOptionalNonEmptyString(parsed.mdnsServiceName),
            serverSshHost: parsed.serverSshHost,
            viewedSplashScreens: parsed.viewedSplashScreens,
            layoutPresets,
            taskSettings,
            agentAiDefaults,
            // Legacy fields are still parsed and returned for downgrade compatibility.
            subagentAiDefaults: legacySubagentAiDefaults,
            featureFlagOverrides: parsed.featureFlagOverrides,
            useSSH2Transport: parseOptionalBoolean(parsed.useSSH2Transport)
          };
        }
      }
    } catch (error) {
      log.error("Error loading config:", error);
    }
    return {
      projects: /* @__PURE__ */ new Map(),
      taskSettings: DEFAULT_TASK_SETTINGS,
      agentAiDefaults: {},
      subagentAiDefaults: {}
    };
  }
  async saveConfig(config2) {
    try {
      if (!fs8.existsSync(this.rootDir)) {
        fs8.mkdirSync(this.rootDir, { recursive: true });
      }
      const data = {
        projects: Array.from(config2.projects.entries()),
        taskSettings: config2.taskSettings ?? DEFAULT_TASK_SETTINGS
      };
      const apiServerBindHost = parseOptionalNonEmptyString(config2.apiServerBindHost);
      if (apiServerBindHost) {
        data.apiServerBindHost = apiServerBindHost;
      }
      const apiServerServeWebUi = parseOptionalBoolean(config2.apiServerServeWebUi);
      if (apiServerServeWebUi) {
        data.apiServerServeWebUi = true;
      }
      const apiServerPort = parseOptionalPort(config2.apiServerPort);
      if (apiServerPort !== void 0) {
        data.apiServerPort = apiServerPort;
      }
      const mdnsAdvertisementEnabled = parseOptionalBoolean(config2.mdnsAdvertisementEnabled);
      if (mdnsAdvertisementEnabled !== void 0) {
        data.mdnsAdvertisementEnabled = mdnsAdvertisementEnabled;
      }
      const mdnsServiceName = parseOptionalNonEmptyString(config2.mdnsServiceName);
      if (mdnsServiceName) {
        data.mdnsServiceName = mdnsServiceName;
      }
      if (config2.serverSshHost) {
        data.serverSshHost = config2.serverSshHost;
      }
      if (config2.featureFlagOverrides) {
        data.featureFlagOverrides = config2.featureFlagOverrides;
      }
      if (config2.layoutPresets) {
        const normalized = normalizeLayoutPresetsConfig(config2.layoutPresets);
        if (!isLayoutPresetsConfigEmpty(normalized)) {
          data.layoutPresets = normalized;
        }
      }
      if (config2.viewedSplashScreens) {
        data.viewedSplashScreens = config2.viewedSplashScreens;
      }
      if (config2.agentAiDefaults && Object.keys(config2.agentAiDefaults).length > 0) {
        data.agentAiDefaults = config2.agentAiDefaults;
        const legacySubagent = {};
        for (const [id, entry] of Object.entries(config2.agentAiDefaults)) {
          if (id === "plan" || id === "exec" || id === "compact") continue;
          legacySubagent[id] = entry;
        }
        if (Object.keys(legacySubagent).length > 0) {
          data.subagentAiDefaults = legacySubagent;
        }
      } else {
        if (config2.subagentAiDefaults && Object.keys(config2.subagentAiDefaults).length > 0) {
          data.subagentAiDefaults = config2.subagentAiDefaults;
        }
      }
      if (config2.useSSH2Transport !== void 0) {
        data.useSSH2Transport = config2.useSSH2Transport;
      }
      await (0, import_write_file_atomic.default)(this.configFile, JSON.stringify(data, null, 2), "utf-8");
    } catch (error) {
      log.error("Error saving config:", error);
    }
  }
  /**
   * Edit config atomically using a transformation function
   * @param fn Function that takes current config and returns modified config
   */
  async editConfig(fn) {
    const config2 = this.loadConfigOrDefault();
    const newConfig = fn(config2);
    await this.saveConfig(newConfig);
  }
  /**
   * Cross-client feature flag overrides (shared via ~/.unix/config.json).
   */
  getFeatureFlagOverride(flagKey) {
    const config2 = this.loadConfigOrDefault();
    const override = config2.featureFlagOverrides?.[flagKey];
    if (override === "on" || override === "off" || override === "default") {
      return override;
    }
    return "default";
  }
  async setFeatureFlagOverride(flagKey, override) {
    await this.editConfig((config2) => {
      const next = { ...config2.featureFlagOverrides ?? {} };
      if (override === "default") {
        delete next[flagKey];
      } else {
        next[flagKey] = override;
      }
      config2.featureFlagOverrides = Object.keys(next).length > 0 ? next : void 0;
      return config2;
    });
  }
  /**
   * mDNS advertisement enablement.
   *
   * - true: attempt to advertise (will warn if the API server is loopback-only)
   * - false: never advertise
   * - undefined: "auto" (advertise only when the API server is LAN-reachable)
   */
  getMdnsAdvertisementEnabled() {
    const envOverride = parseOptionalEnvBoolean(process.env.UNIX_MDNS_ADVERTISE);
    if (envOverride !== void 0) {
      return envOverride;
    }
    const config2 = this.loadConfigOrDefault();
    return config2.mdnsAdvertisementEnabled;
  }
  /** Optional DNS-SD service instance name override. */
  getMdnsServiceName() {
    const envName = parseOptionalNonEmptyString(process.env.UNIX_MDNS_SERVICE_NAME);
    if (envName) {
      return envName;
    }
    const config2 = this.loadConfigOrDefault();
    return config2.mdnsServiceName;
  }
  /**
   * Get the configured SSH hostname for this server (used for editor deep links in browser mode).
   */
  getServerSshHost() {
    const config2 = this.loadConfigOrDefault();
    return config2.serverSshHost;
  }
  getProjectName(projectPath) {
    return PlatformPaths2.getProjectName(projectPath);
  }
  /**
   * Generate a stable unique workspace ID.
   * Uses 10 random hex characters for readability while maintaining uniqueness.
   *
   * Example: "a1b2c3d4e5"
   */
  generateStableId() {
    return crypto3.randomBytes(5).toString("hex");
  }
  /**
   * DEPRECATED: Generate legacy workspace ID from project and workspace paths.
   * This method is used only for legacy workspace migration to look up old workspaces.
   * New workspaces use generateStableId() which returns a random stable ID.
   *
   * DO NOT use this method or its format to construct workspace IDs anywhere in the codebase.
   * Workspace IDs are backend implementation details and must only come from backend operations.
   */
  generateLegacyId(projectPath, workspacePath) {
    const projectBasename = this.getProjectName(projectPath);
    const workspaceBasename = PlatformPaths2.basename(workspacePath);
    return `${projectBasename}-${workspaceBasename}`;
  }
  /**
   * Get the workspace directory path for a given directory name.
   * The directory name is the workspace name (branch name).
   */
  /**
   * Add paths to WorkspaceMetadata to create FrontendWorkspaceMetadata.
   * Helper to avoid duplicating path computation logic.
   */
  addPathsToMetadata(metadata, workspacePath, _projectPath) {
    const result = {
      ...metadata,
      namedWorkspacePath: workspacePath
    };
    if (isIncompatibleRuntimeConfig(metadata.runtimeConfig)) {
      result.incompatibleRuntime = "This workspace was created with a newer version ofunix. Please upgrade unix to use this workspace.";
    }
    return result;
  }
  /**
   * Find a workspace path and project path by workspace ID
   * @returns Object with workspace and project paths, or null if not found
   */
  findWorkspace(workspaceId) {
    const config2 = this.loadConfigOrDefault();
    for (const [projectPath, project] of config2.projects) {
      for (const workspace2 of project.workspaces) {
        if (workspace2.id === workspaceId) {
          return { workspacePath: workspace2.path, projectPath };
        }
        if (!workspace2.id) {
          const workspaceBasename = workspace2.path.split("/").pop() ?? workspace2.path.split("\\").pop() ?? "unknown";
          const metadataPath = path16.join(this.getSessionDir(workspaceBasename), "metadata.json");
          if (fs8.existsSync(metadataPath)) {
            try {
              const data = fs8.readFileSync(metadataPath, "utf-8");
              const metadata = JSON.parse(data);
              if (metadata.id === workspaceId) {
                return { workspacePath: workspace2.path, projectPath };
              }
            } catch {
            }
          }
          const legacyId = this.generateLegacyId(projectPath, workspace2.path);
          if (legacyId === workspaceId) {
            return { workspacePath: workspace2.path, projectPath };
          }
        }
      }
    }
    return null;
  }
  /**
   * Workspace Path Architecture:
   *
   * Workspace paths are computed on-demand from projectPath + workspace name using
   * config.getWorkspacePath(projectPath, directoryName). This ensures a single source of truth.
   *
   * - Worktree directory name: uses workspace.name (the branch name)
   * - Workspace ID: stable random identifier for identity and sessions (not used for directories)
   *
   * Backend: Uses getWorkspacePath(metadata.projectPath, metadata.name) for workspace directory paths
   * Frontend: Gets enriched metadata with paths via IPC (FrontendWorkspaceMetadata)
   *
   * WorkspaceMetadata.workspacePath is deprecated and will be removed. Use computed
   * paths from getWorkspacePath() or getWorkspacePaths() instead.
   */
  /**
   * Get the session directory for a specific workspace
   */
  getSessionDir(workspaceId) {
    return path16.join(this.sessionsDir, workspaceId);
  }
  /**
   * Get all workspace metadata by loading config and metadata files.
   *
   * Returns FrontendWorkspaceMetadata with paths already computed.
   * This eliminates the need for separate "enrichment" - paths are computed
   * once during the loop when we already have all the necessary data.
   *
   * NEW BEHAVIOR: Config is the primary source of truth
   * - If workspace has id/name/createdAt in config, use those directly
   * - If workspace only has path, fall back to reading metadata.json
   * - Migrate old workspaces by copying metadata from files to config
   *
   * This centralizes workspace metadata in config.json and eliminates the need
   * for scattered metadata.json files (kept for backward compat with older versions).
   *
   * GUARANTEE: Every workspace returned will have a createdAt timestamp.
   * If missing from config or legacy metadata, a new timestamp is assigned and
   * saved to config for subsequent loads.
   */
  async getAllWorkspaceMetadata() {
    const config2 = this.loadConfigOrDefault();
    const workspaceMetadata = [];
    let configModified = false;
    for (const [projectPath, projectConfig] of config2.projects) {
      if (!projectPath) {
        log.warn("Skipping project with empty path in config", {
          workspaceCount: projectConfig.workspaces?.length ?? 0
        });
        continue;
      }
      const projectName = this.getProjectName(projectPath);
      for (const workspace2 of projectConfig.workspaces) {
        const workspaceBasename = workspace2.path.split("/").pop() ?? workspace2.path.split("\\").pop() ?? "unknown";
        try {
          if (workspace2.id && workspace2.name) {
            const metadata = {
              id: workspace2.id,
              name: workspace2.name,
              title: workspace2.title,
              projectName,
              projectPath,
              // GUARANTEE: All workspaces must have createdAt (assign now if missing)
              createdAt: workspace2.createdAt ?? (/* @__PURE__ */ new Date()).toISOString(),
              // GUARANTEE: All workspaces must have runtimeConfig (apply default if missing)
              runtimeConfig: workspace2.runtimeConfig ?? DEFAULT_RUNTIME_CONFIG,
              aiSettings: workspace2.aiSettings,
              aiSettingsByAgent: workspace2.aiSettingsByAgent ?? (workspace2.aiSettings ? {
                plan: workspace2.aiSettings,
                exec: workspace2.aiSettings
              } : void 0),
              parentWorkspaceId: workspace2.parentWorkspaceId,
              agentType: workspace2.agentType,
              taskStatus: workspace2.taskStatus,
              reportedAt: workspace2.reportedAt,
              taskModelString: workspace2.taskModelString,
              taskThinkingLevel: workspace2.taskThinkingLevel,
              taskPrompt: workspace2.taskPrompt,
              taskTrunkBranch: workspace2.taskTrunkBranch,
              archivedAt: workspace2.archivedAt,
              unarchivedAt: workspace2.unarchivedAt,
              sectionId: workspace2.sectionId
            };
            if (!workspace2.createdAt) {
              workspace2.createdAt = metadata.createdAt;
              configModified = true;
            }
            if (!workspace2.aiSettingsByAgent) {
              const derived = workspace2.aiSettings ? {
                plan: workspace2.aiSettings,
                exec: workspace2.aiSettings
              } : void 0;
              if (derived) {
                workspace2.aiSettingsByAgent = derived;
                configModified = true;
              }
            }
            if (!workspace2.runtimeConfig) {
              workspace2.runtimeConfig = metadata.runtimeConfig;
              configModified = true;
            }
            if (metadata.runtimeConfig?.type === "docker" && !metadata.runtimeConfig.containerName) {
              metadata.runtimeConfig = {
                ...metadata.runtimeConfig,
                containerName: getContainerName(projectPath, metadata.name)
              };
            }
            workspaceMetadata.push(this.addPathsToMetadata(metadata, workspace2.path, projectPath));
            continue;
          }
          const legacyId = this.generateLegacyId(projectPath, workspace2.path);
          const metadataPath = path16.join(this.getSessionDir(legacyId), "metadata.json");
          let metadataFound = false;
          if (fs8.existsSync(metadataPath)) {
            const data = fs8.readFileSync(metadataPath, "utf-8");
            const metadata = JSON.parse(data);
            if (!metadata.name) metadata.name = workspaceBasename;
            if (!metadata.projectPath) metadata.projectPath = projectPath;
            if (!metadata.projectName) metadata.projectName = projectName;
            metadata.createdAt ??= (/* @__PURE__ */ new Date()).toISOString();
            metadata.runtimeConfig ??= DEFAULT_RUNTIME_CONFIG;
            metadata.aiSettingsByAgent ??= workspace2.aiSettingsByAgent ?? (workspace2.aiSettings ? {
              plan: workspace2.aiSettings,
              exec: workspace2.aiSettings
            } : void 0);
            metadata.aiSettings ??= workspace2.aiSettings;
            metadata.parentWorkspaceId ??= workspace2.parentWorkspaceId;
            metadata.agentType ??= workspace2.agentType;
            metadata.taskStatus ??= workspace2.taskStatus;
            metadata.reportedAt ??= workspace2.reportedAt;
            metadata.taskModelString ??= workspace2.taskModelString;
            metadata.taskThinkingLevel ??= workspace2.taskThinkingLevel;
            metadata.taskPrompt ??= workspace2.taskPrompt;
            metadata.taskTrunkBranch ??= workspace2.taskTrunkBranch;
            metadata.archivedAt ??= workspace2.archivedAt;
            metadata.unarchivedAt ??= workspace2.unarchivedAt;
            metadata.sectionId ??= workspace2.sectionId;
            if (!workspace2.aiSettingsByAgent && metadata.aiSettingsByAgent) {
              workspace2.aiSettingsByAgent = metadata.aiSettingsByAgent;
              configModified = true;
            }
            workspace2.id = metadata.id;
            workspace2.name = metadata.name;
            workspace2.createdAt = metadata.createdAt;
            workspace2.runtimeConfig = metadata.runtimeConfig;
            configModified = true;
            workspaceMetadata.push(this.addPathsToMetadata(metadata, workspace2.path, projectPath));
            metadataFound = true;
          }
          if (!metadataFound) {
            const legacyId2 = this.generateLegacyId(projectPath, workspace2.path);
            const metadata = {
              id: legacyId2,
              name: workspaceBasename,
              projectName,
              projectPath,
              // GUARANTEE: All workspaces must have createdAt
              createdAt: (/* @__PURE__ */ new Date()).toISOString(),
              // GUARANTEE: All workspaces must have runtimeConfig
              runtimeConfig: DEFAULT_RUNTIME_CONFIG,
              aiSettings: workspace2.aiSettings,
              aiSettingsByAgent: workspace2.aiSettingsByAgent ?? (workspace2.aiSettings ? {
                plan: workspace2.aiSettings,
                exec: workspace2.aiSettings
              } : void 0),
              parentWorkspaceId: workspace2.parentWorkspaceId,
              agentType: workspace2.agentType,
              taskStatus: workspace2.taskStatus,
              reportedAt: workspace2.reportedAt,
              taskModelString: workspace2.taskModelString,
              taskThinkingLevel: workspace2.taskThinkingLevel,
              taskPrompt: workspace2.taskPrompt,
              taskTrunkBranch: workspace2.taskTrunkBranch,
              archivedAt: workspace2.archivedAt,
              unarchivedAt: workspace2.unarchivedAt,
              sectionId: workspace2.sectionId
            };
            workspace2.id = metadata.id;
            workspace2.name = metadata.name;
            workspace2.createdAt = metadata.createdAt;
            workspace2.runtimeConfig = metadata.runtimeConfig;
            configModified = true;
            workspaceMetadata.push(this.addPathsToMetadata(metadata, workspace2.path, projectPath));
          }
        } catch (error) {
          log.error(`Failed to load/migrate workspace metadata:`, error);
          const legacyId = this.generateLegacyId(projectPath, workspace2.path);
          const metadata = {
            id: legacyId,
            name: workspaceBasename,
            projectName,
            projectPath,
            // GUARANTEE: All workspaces must have createdAt (even in error cases)
            createdAt: (/* @__PURE__ */ new Date()).toISOString(),
            // GUARANTEE: All workspaces must have runtimeConfig (even in error cases)
            runtimeConfig: DEFAULT_RUNTIME_CONFIG,
            aiSettings: workspace2.aiSettings,
            aiSettingsByAgent: workspace2.aiSettingsByAgent ?? (workspace2.aiSettings ? {
              plan: workspace2.aiSettings,
              exec: workspace2.aiSettings
            } : void 0),
            parentWorkspaceId: workspace2.parentWorkspaceId,
            agentType: workspace2.agentType,
            taskStatus: workspace2.taskStatus,
            reportedAt: workspace2.reportedAt,
            taskModelString: workspace2.taskModelString,
            taskThinkingLevel: workspace2.taskThinkingLevel,
            taskPrompt: workspace2.taskPrompt,
            taskTrunkBranch: workspace2.taskTrunkBranch,
            sectionId: workspace2.sectionId
          };
          workspaceMetadata.push(this.addPathsToMetadata(metadata, workspace2.path, projectPath));
        }
      }
    }
    if (configModified) {
      await this.saveConfig(config2);
    }
    return workspaceMetadata;
  }
  /**
   * Add a workspace to config.json (single source of truth for workspace metadata).
   * Creates project entry if it doesn't exist.
   *
   * @param projectPath Absolute path to the project
   * @param metadata Workspace metadata to save
   */
  async addWorkspace(projectPath, metadata) {
    await this.editConfig((config2) => {
      let project = config2.projects.get(projectPath);
      if (!project) {
        project = { workspaces: [] };
        config2.projects.set(projectPath, project);
      }
      const existingIndex = project.workspaces.findIndex((w) => w.id === metadata.id);
      const projectName = this.getProjectName(projectPath);
      const workspacePath = metadata.namedWorkspacePath ?? path16.join(this.srcDir, projectName, metadata.name);
      const workspaceEntry = {
        path: workspacePath,
        id: metadata.id,
        name: metadata.name,
        createdAt: metadata.createdAt,
        runtimeConfig: metadata.runtimeConfig
      };
      if (existingIndex >= 0) {
        project.workspaces[existingIndex] = workspaceEntry;
      } else {
        project.workspaces.push(workspaceEntry);
      }
      return config2;
    });
  }
  /**
   * Remove a workspace from config.json
   *
   * @param workspaceId ID of the workspace to remove
   */
  async removeWorkspace(workspaceId) {
    await this.editConfig((config2) => {
      let workspaceFound = false;
      for (const [_projectPath, project] of config2.projects) {
        const index = project.workspaces.findIndex((w) => w.id === workspaceId);
        if (index !== -1) {
          project.workspaces.splice(index, 1);
          workspaceFound = true;
        }
      }
      if (!workspaceFound) {
        log.warn(`Workspace ${workspaceId} not found in config during removal`);
      }
      return config2;
    });
  }
  /**
   * Update workspace metadata fields (e.g., regenerate missing title/branch)
   * Used to fix incomplete metadata after errors or restarts
   */
  async updateWorkspaceMetadata(workspaceId, updates) {
    await this.editConfig((config2) => {
      for (const [_projectPath, projectConfig] of config2.projects) {
        const workspace2 = projectConfig.workspaces.find((w) => w.id === workspaceId);
        if (workspace2) {
          if (updates.name !== void 0) workspace2.name = updates.name;
          if (updates.runtimeConfig !== void 0) workspace2.runtimeConfig = updates.runtimeConfig;
          return config2;
        }
      }
      throw new Error(`Workspace ${workspaceId} not found in config`);
    });
  }
  /**
   * Load providers configuration from JSONC file
   * Supports comments in JSONC format
   */
  loadProvidersConfig() {
    try {
      if (fs8.existsSync(this.providersFile)) {
        const data = fs8.readFileSync(this.providersFile, "utf-8");
        return jsonc.parse(data);
      }
    } catch (error) {
      log.error("Error loading providers config:", error);
    }
    return null;
  }
  /**
   * Save providers configuration to JSONC file
   * @param config The providers configuration to save
   */
  saveProvidersConfig(config2) {
    try {
      if (!fs8.existsSync(this.rootDir)) {
        fs8.mkdirSync(this.rootDir, { recursive: true });
      }
      const jsonString = JSON.stringify(config2, null, 2);
      const contentWithComments = `// Providers configuration for unix
// Configure your AI providers here
// Example:
// {
//   "anthropic": {
//     "apiKey": "sk-ant-..."
//   },
//   "openai": {
//     "apiKey": "sk-..."
//   },
//   "xai": {
//     "apiKey": "sk-xai-..."
//   },
//   "ollama": {
//     "baseUrl": "http://localhost:11434/api"  // Optional - only needed for remote/custom URL
//   }
// }
${jsonString}`;
      fs8.writeFileSync(this.providersFile, contentWithComments);
    } catch (error) {
      log.error("Error saving providers config:", error);
      throw error;
    }
  }
  /**
   * Load secrets configuration from JSON file
   * Returns empty config if file doesn't exist
   */
  loadSecretsConfig() {
    try {
      if (fs8.existsSync(this.secretsFile)) {
        const data = fs8.readFileSync(this.secretsFile, "utf-8");
        return JSON.parse(data);
      }
    } catch (error) {
      log.error("Error loading secrets config:", error);
    }
    return {};
  }
  /**
   * Save secrets configuration to JSON file
   * @param config The secrets configuration to save
   */
  async saveSecretsConfig(config2) {
    try {
      if (!fs8.existsSync(this.rootDir)) {
        fs8.mkdirSync(this.rootDir, { recursive: true });
      }
      await (0, import_write_file_atomic.default)(this.secretsFile, JSON.stringify(config2, null, 2), "utf-8");
    } catch (error) {
      log.error("Error saving secrets config:", error);
      throw error;
    }
  }
  /**
   * Get secrets for a specific project
   * @param projectPath The path to the project
   * @returns Array of secrets for the project, or empty array if none
   */
  getProjectSecrets(projectPath) {
    const config2 = this.loadSecretsConfig();
    return config2[projectPath] ?? [];
  }
  /**
   * Update secrets for a specific project
   * @param projectPath The path to the project
   * @param secrets The secrets to save for the project
   */
  async updateProjectSecrets(projectPath, secrets) {
    const config2 = this.loadSecretsConfig();
    config2[projectPath] = secrets;
    await this.saveSecretsConfig(config2);
  }
};
var defaultConfig = new Config();

// src/node/runtime/devcontainerConfigs.ts
import * as fs9 from "fs/promises";
import * as path17 from "path";
function formatDevcontainerLabel(configPath) {
  if (configPath === ".devcontainer.json") {
    return "Default (.devcontainer.json)";
  }
  if (configPath === ".devcontainer/devcontainer.json") {
    return "Default (.devcontainer/devcontainer.json)";
  }
  const normalized = configPath.replace(/\\/g, "/");
  const match = /^\.devcontainer\/([^/]+)\/devcontainer\.json$/.exec(normalized);
  if (match?.[1]) {
    return `${match[1]} (${normalized})`;
  }
  return normalized;
}
function buildDevcontainerConfigInfo(configs) {
  return configs.map((configPath) => ({
    path: configPath,
    label: formatDevcontainerLabel(configPath)
  }));
}
async function scanDevcontainerConfigs(projectPath) {
  const configs = [];
  const locations = [".devcontainer.json", ".devcontainer/devcontainer.json"];
  for (const loc of locations) {
    try {
      await fs9.access(path17.join(projectPath, loc));
      configs.push(loc);
    } catch {
    }
  }
  try {
    const devcontainerDir = path17.join(projectPath, ".devcontainer");
    const entries = await fs9.readdir(devcontainerDir, { withFileTypes: true });
    for (const entry of entries) {
      if (entry.isDirectory()) {
        const configPath = path17.join(".devcontainer", entry.name, "devcontainer.json");
        try {
          await fs9.access(path17.join(projectPath, configPath));
          configs.push(configPath);
        } catch {
        }
      }
    }
  } catch {
  }
  return configs;
}

// src/node/runtime/runtimeFactory.ts
var globalLatticeService;
function shouldUseSSH2Runtime() {
  if (process.platform === "win32") {
    return true;
  }
  const config2 = new Config();
  return config2.loadConfigOrDefault().useSSH2Transport ?? false;
}
var IncompatibleRuntimeError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "IncompatibleRuntimeError";
  }
};
function createRuntime(config2, options) {
  if (isIncompatibleRuntimeConfig(config2)) {
    throw new IncompatibleRuntimeError(
      `This workspace uses a runtime configuration from a newer version ofunix. Please upgrade unix to use this workspace.`
    );
  }
  switch (config2.type) {
    case "local":
      if (hasSrcBaseDir(config2)) {
        return new WorktreeRuntime(config2.srcBaseDir);
      }
      if (!options?.projectPath) {
        throw new Error(
          "LocalRuntime requires projectPath in options for project-dir config (type: 'local' without srcBaseDir)"
        );
      }
      return new LocalRuntime(options.projectPath);
    case "worktree":
      return new WorktreeRuntime(config2.srcBaseDir);
    case "ssh": {
      const sshConfig = {
        host: config2.host,
        srcBaseDir: config2.srcBaseDir,
        bgOutputDir: config2.bgOutputDir,
        identityFile: config2.identityFile,
        port: config2.port
      };
      const useSSH2 = shouldUseSSH2Runtime();
      const transport = createSSHTransport(sshConfig, useSSH2);
      const latticeService = options?.latticeService ?? globalLatticeService;
      if (config2.lattice) {
        if (!latticeService) {
          throw new Error("Lattice runtime requested but LatticeService is not initialized");
        }
        return new LatticeSSHRuntime({ ...sshConfig, lattice: config2.lattice }, transport, latticeService);
      }
      return new SSHRuntime(sshConfig, transport);
    }
    case "docker": {
      const containerName = options?.projectPath && options?.workspaceName ? getContainerName(options.projectPath, options.workspaceName) : config2.containerName;
      return new DockerRuntime({
        image: config2.image,
        containerName,
        shareCredentials: config2.shareCredentials
      });
    }
    case "devcontainer": {
      const runtime = new DevcontainerRuntime({
        srcBaseDir: new Config().srcDir,
        configPath: config2.configPath,
        shareCredentials: config2.shareCredentials
      });
      if (options?.projectPath && options?.workspaceName) {
        runtime.setCurrentWorkspacePath(
          runtime.getWorkspacePath(options.projectPath, options.workspaceName)
        );
      }
      return runtime;
    }
    default: {
      const unknownConfig = config2;
      throw new Error(`Unknown runtime type: ${unknownConfig.type ?? "undefined"}`);
    }
  }
}
async function isGitRepository(projectPath) {
  try {
    const gitPath = path18.join(projectPath, ".git");
    const stat3 = await fs10.stat(gitPath);
    return stat3.isDirectory() || stat3.isFile();
  } catch {
    return false;
  }
}
async function isDockerAvailable() {
  let timeoutHandle;
  try {
    var _stack = [];
    try {
      const proc = __using(_stack, execAsync("docker info"));
      const timeout = new Promise((_2, reject) => {
        timeoutHandle = setTimeout(() => reject(new Error("timeout")), 5e3);
      });
      await Promise.race([proc.result, timeout]);
      return true;
    } catch (_) {
      var _error = _, _hasError = true;
    } finally {
      __callDispose(_stack, _error, _hasError);
    }
  } catch {
    return false;
  } finally {
    if (timeoutHandle) clearTimeout(timeoutHandle);
  }
}
async function checkRuntimeAvailability(projectPath) {
  const [isGit, dockerAvailable, devcontainerCliInfo, devcontainerConfigs] = await Promise.all([
    isGitRepository(projectPath),
    isDockerAvailable(),
    checkDevcontainerCliVersion(),
    scanDevcontainerConfigs(projectPath)
  ]);
  const devcontainerConfigInfo = buildDevcontainerConfigInfo(devcontainerConfigs);
  const gitRequiredReason = "Requires git repository";
  let devcontainerAvailability;
  if (!isGit) {
    devcontainerAvailability = { available: false, reason: gitRequiredReason };
  } else if (!devcontainerCliInfo) {
    devcontainerAvailability = {
      available: false,
      reason: "Dev Container CLI not installed. Run: npm install -g @devcontainers/cli"
    };
  } else if (!dockerAvailable) {
    devcontainerAvailability = { available: false, reason: "Docker daemon not running" };
  } else if (devcontainerConfigInfo.length === 0) {
    devcontainerAvailability = { available: false, reason: "No devcontainer.json found" };
  } else {
    devcontainerAvailability = {
      available: true,
      configs: devcontainerConfigInfo,
      cliVersion: devcontainerCliInfo.version
    };
  }
  return {
    local: { available: true },
    worktree: isGit ? { available: true } : { available: false, reason: gitRequiredReason },
    ssh: isGit ? { available: true } : { available: false, reason: gitRequiredReason },
    docker: !isGit ? { available: false, reason: gitRequiredReason } : !dockerAvailable ? { available: false, reason: "Docker daemon not running" } : { available: true },
    devcontainer: devcontainerAvailability
  };
}

// src/node/runtime/runtimeHelpers.ts
function createRuntimeForWorkspace(metadata) {
  return createRuntime(metadata.runtimeConfig, {
    projectPath: metadata.projectPath,
    workspaceName: metadata.name
  });
}

// src/common/types/secrets.ts
function secretsToRecord(secrets) {
  const record = {};
  for (const secret of secrets) {
    record[secret.key] = secret.value;
  }
  return record;
}

// src/common/telemetry/utils.ts
function roundToBase2(value2) {
  if (value2 <= 0) return 0;
  return Math.pow(2, Math.ceil(Math.log2(value2)));
}

// src/common/utils/asyncEventIterator.ts
function createAsyncEventQueue() {
  const queue = [];
  let resolveNext = null;
  let ended = false;
  const push = (value2) => {
    if (ended) return;
    if (resolveNext) {
      const resolve3 = resolveNext;
      resolveNext = null;
      resolve3(value2);
    } else {
      queue.push(value2);
    }
  };
  async function* iterate() {
    while (!ended) {
      if (queue.length > 0) {
        yield queue.shift();
      } else {
        yield await new Promise((resolve3) => {
          resolveNext = resolve3;
        });
      }
    }
  }
  const end = () => {
    ended = true;
    if (resolveNext) {
      resolveNext(void 0);
    }
  };
  return { push, iterate, end };
}

// src/node/services/agentSkills/agentSkillsService.ts
import * as fs11 from "node:fs/promises";

// src/node/services/tools/fileCommon.ts
var MAX_FILE_SIZE = 1024 * 1024;
function validateFileSize(stats) {
  if (stats.size > MAX_FILE_SIZE) {
    const sizeMB = (stats.size / (1024 * 1024)).toFixed(2);
    const maxMB = (MAX_FILE_SIZE / (1024 * 1024)).toFixed(2);
    return {
      error: `File is too large (${sizeMB}MB). The maximum file size for file operations is ${maxMB}MB. Please use system tools like grep, sed, awk, or split the file into smaller chunks.`
    };
  }
  return null;
}

// src/node/services/agentSkills/parseSkillMarkdown.ts
var import_yaml = __toESM(require_dist3());
var AgentSkillParseError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "AgentSkillParseError";
  }
};
function normalizeNewlines(input) {
  return input.replace(/\r\n/g, "\n").replace(/\r/g, "\n");
}
function stripUtf8Bom(input) {
  return input.startsWith("\uFEFF") ? input.slice(1) : input;
}
function assertObject(value2, message) {
  if (!value2 || typeof value2 !== "object" || Array.isArray(value2)) {
    throw new AgentSkillParseError(message);
  }
}
function formatZodIssues(issues) {
  return issues.map((issue) => {
    const issuePath = issue.path.length > 0 ? issue.path.map((part) => String(part)).join(".") : "<root>";
    return `${issuePath}: ${issue.message}`;
  }).join("; ");
}
function parseSkillMarkdown(input) {
  if (input.byteSize > MAX_FILE_SIZE) {
    const sizeMB = (input.byteSize / (1024 * 1024)).toFixed(2);
    const maxMB = (MAX_FILE_SIZE / (1024 * 1024)).toFixed(2);
    throw new AgentSkillParseError(
      `SKILL.md is too large (${sizeMB}MB). Maximum supported size is ${maxMB}MB.`
    );
  }
  const content = normalizeNewlines(stripUtf8Bom(input.content));
  if (!content.startsWith("---")) {
    throw new AgentSkillParseError("SKILL.md must start with YAML frontmatter delimited by '---'.");
  }
  const lines = content.split("\n");
  if ((lines[0] ?? "").trim() !== "---") {
    throw new AgentSkillParseError("SKILL.md frontmatter start delimiter must be exactly '---'.");
  }
  const endIndex = lines.findIndex((line, idx) => idx > 0 && line.trim() === "---");
  if (endIndex === -1) {
    throw new AgentSkillParseError("SKILL.md frontmatter is missing the closing '---' delimiter.");
  }
  const yamlText = lines.slice(1, endIndex).join("\n");
  const body = lines.slice(endIndex + 1).join("\n");
  let raw;
  try {
    raw = import_yaml.default.parse(yamlText);
  } catch (err) {
    const message = err instanceof Error ? err.message : String(err);
    throw new AgentSkillParseError(`Failed to parse SKILL.md YAML frontmatter: ${message}`);
  }
  assertObject(raw, "SKILL.md YAML frontmatter must be a mapping/object.");
  const parsed = AgentSkillFrontmatterSchema.safeParse(raw);
  if (!parsed.success) {
    throw new AgentSkillParseError(
      `Invalid SKILL.md frontmatter: ${formatZodIssues(parsed.error.issues)}`
    );
  }
  if (input.directoryName && parsed.data.name !== input.directoryName) {
    throw new AgentSkillParseError(
      `SKILL.md frontmatter.name '${parsed.data.name}' must match directory name '${input.directoryName}'.`
    );
  }
  return { frontmatter: parsed.data, body };
}

// src/node/services/agentSkills/builtInSkillContent.generated.ts
var BUILTIN_SKILL_FILES = {
  init: {
    "SKILL.md": [
      "---",
      "name: init",
      "description: Bootstrap an AGENTS.md file in a new or existing project",
      "---",
      "",
      "<system>",
      "Use your tools to create or improve an AGENTS.md file in the root of the workspace which will serve as a contribution guide for AI agents.",
      "If an AGENTS.md file already exists, focus on additive improvement (preserve intent and useful information; refine, extend, and reorganize as needed) rather than replacing it wholesale.",
      "Inspect the workspace layout, code, documentation and git history to ensure correctness and accuracy.",
      "",
      "Ensure the following preamble exists at the top of the file before any other sections. Do not include the surrounding code fence backticks; only include the text.",
      "",
      "```md",
      "You are an experienced, pragmatic software engineering AI agent. Do not over-engineer a solution when a simple one is possible. Keep edits minimal. If you want an exception to ANY rule, you MUST stop and get permission first.",
      "```",
      "",
      "Recommended sections:",
      "",
      "- Project Overview (mandatory)",
      "  - Basic details about the project (e.g., high-level overview and goals).",
      "  - Technology choices (e.g., languages, databases, frameworks, libraries, build tools).",
      "- Reference (mandatory)",
      "  - List important code files.",
      "  - List important directories and basic code structure tips.",
      "  - Project architecture.",
      "- Essential commands (mandatory)",
      "  - build",
      "  - format",
      "  - lint",
      "  - test",
      "  - clean",
      "  - development server",
      "  - other _important_ scripts (use `find -type f -name '*.sh'` or similar)",
      "- Patterns (optional)",
      "  - List any important or uncommon patterns (compared to other similar codebases), with examples (e.g., how to authorize an HTTP request).",
      "  - List any important workflows and their steps (e.g., how to make a database migration).",
      "  - Testing patterns.",
      "- Anti-patterns (optional)",
      "  - Search git history and comments to find recurring mistakes or forbidden patterns.",
      "  - List each pattern and its reason.",
      "- Code style (optional)",
      "  - Style guide to follow (with link).",
      "- Commit and Pull Request Guidelines (mandatory)",
      "  - Required steps for validating changes before committing.",
      "  - Commit message conventions (read `git log`, or use `type: message` by default).",
      "  - Pull request description requirements.",
      "",
      "You can add other sections if they are necessary.",
      "If the information required for mandatory sections isn't available due to the workspace being empty or sparse, add TODO text in its place.",
      "Optional sections should be scrapped if the information is too thin.",
      "",
      "Some investigation tips:",
      "",
      "- Read existing lint configs, tsconfig, and CI workflows to find any style or layout rules.",
      `- Search for "TODO", "HACK", "FIXME", "don't", "never", "always" in comments.`,
      "- Examine test files for patterns.",
      "- Read PR templates and issue templates if they exist.",
      "- Check for existing CONTRIBUTING.md, CODE_OF_CONDUCT.md, or similar documentation files.",
      "",
      "Some writing tips:",
      "",
      `- Each "do X" should have a corresponding "don't Y" where applicable.`,
      "- Commands should be easily copy-pastable and tested.",
      "- Terms or phrases specific to this project should be explained on first use.",
      "- Anything that is against the norm should be explicitly highlighted and called out.",
      "",
      "Above all things:",
      "",
      "- The document must be clear and concise. Simple projects should need less than 400 words, but larger and more mature codebases will likely need 700+. Prioritize completeness over brevity.",
      "- Don't include useless fluff.",
      "- The document must be in Markdown format and use headings for structure.",
      "- Give examples where necessary or helpful (commands, directory paths, naming patterns).",
      "- Explanations and examples must be correct and specific to this codebase.",
      "- Maintain a professional, instructional tone.",
      "",
      "If the workspace is empty or sparse, ask the user for more information. Avoid hallucinating important decisions. You can provide suggestions to the user for language/technology/tool choices, but always respect the user's decision.",
      "",
      "- Project description and goals.",
      "- Language(s).",
      "- Technologies (database?), frameworks, libraries.",
      "- Tools.",
      "- Any other questions as you deem necessary.",
      "",
      "For empty or sparse workspaces ONLY, when finished writing/updating AGENTS.md, ask the user if they would like you to do the following:",
      "",
      "- initialize git IF it's not already set up (e.g., `git init`, `git remote add`, etc.)",
      "- write a concise README.md file",
      "- generate the bare minimum project scaffolding (e.g., initializing the package manager, writing a minimal build tool config)",
      "  </system>",
      ""
    ].join("\n")
  },
  "unix-docs": {
    "SKILL.md": [
      "---",
      "name: unix-docs",
      "description: Index + offline snapshot of unix documentation (progressive disclosure).",
      "---",
      "",
      "# unix docs",
      "",
      "This built-in skill helps the agent answer questions about **unix** (Coding Agent Multiplexer) without dumping the entire docs into context.",
      "",
      "## How to use",
      "",
      "### Prefer: read the bundled docs snapshot (recommended)",
      "",
      "This skill bundles an **offline snapshot of the unix docs** under `references/docs/`.",
      "",
      "Why prefer the bundled snapshot?",
      "",
      "1. The docs tree below is guaranteed to match what\u2019s embedded.",
      "2. It\u2019s more likely to match *your installed unix version* (the live site may be ahead).",
      "",
      "To read a specific page:",
      "",
      "```ts",
      "agent_skill_read_file({",
      '  name: "unix-docs",',
      '  filePath: "references/docs/config/models.mdx",',
      "});",
      "```",
      "",
      "### Fallback: bundled docs",
      "",
      "If the bundled docs don't mention something, refer to the local documentation in the `docs/` directory.",
      "",
      "#### Docs tree (auto-generated)",
      "",
      "Use this index to find a page's:",
      "",
      "- **Docs route** (for `web_fetch`)",
      "- **Embedded file path** (for `agent_skill_read_file`)",
      "",
      "<!-- BEGIN DOCS_TREE -->",
      "- **Documentation**",
      "  - **Getting Started**",
      "    - Introduction (`/`) \u2192 `references/docs/index.mdx`",
      "    - Install (`/install`) \u2192 `references/docs/install.mdx` \u2014 Download and install Unix for macOS, Linux, and Windows",
      "    - **Models**",
      "      - Models (`/config/models`) \u2192 `references/docs/config/models.mdx` \u2014 Select and configure AI models in Unix",
      "      - Providers (`/config/providers`) \u2192 `references/docs/config/providers.mdx` \u2014 Configure API keys and settings for AI providers",
      "    - Why Parallelize? (`/getting-started/why-parallelize`) \u2192 `references/docs/getting-started/why-parallelize.mdx` \u2014 Use cases for running multiple AI agents in parallel",
      "    - Unix Codes (`/getting-started/unix-codes`) \u2192 `references/docs/getting-started/unix-codes.mdx` \u2014 Redeem free LLM token credits for evaluating Unix",
      "    - CLI (`/reference/cli`) \u2192 `references/docs/reference/cli.mdx` \u2014 Run one-off agent tasks from the command line with `unix run`",
      "  - **Workspaces**",
      "    - Workspaces (`/workspaces`) \u2192 `references/docs/workspaces/index.mdx` \u2014 Isolated development environments for parallel agent work",
      "    - Forking Workspaces (`/workspaces/fork`) \u2192 `references/docs/workspaces/fork.mdx` \u2014 Clone workspaces with conversation history to explore alternatives",
      "    - Message Sharing (`/workspaces/sharing`) \u2192 `references/docs/workspaces/sharing.mdx` \u2014 Share encrypted messages with cryptographic signatures via Unix",
      "    - **Compaction**",
      "      - Compaction (`/workspaces/compaction`) \u2192 `references/docs/workspaces/compaction/index.mdx` \u2014 Managing conversation context size with compaction",
      "      - Manual Compaction (`/workspaces/compaction/manual`) \u2192 `references/docs/workspaces/compaction/manual.mdx` \u2014 Commands for manually managing conversation context",
      "      - Automatic Compaction (`/workspaces/compaction/automatic`) \u2192 `references/docs/workspaces/compaction/automatic.mdx` \u2014 Let Unix automatically compact your conversations based on usage or idle time",
      "      - Customization (`/workspaces/compaction/customization`) \u2192 `references/docs/workspaces/compaction/customization.mdx` \u2014 Customize the compaction system prompt",
      "    - **Runtimes**",
      "      - Runtimes (`/runtime`) \u2192 `references/docs/runtime/index.mdx` \u2014 Configure where and how Unix executes agent workspaces",
      "      - Local Runtime (`/runtime/local`) \u2192 `references/docs/runtime/local.mdx` \u2014 Run agents directly in your project directory",
      "      - Worktree Runtime (`/runtime/worktree`) \u2192 `references/docs/runtime/worktree.mdx` \u2014 Isolated git worktree environments for parallel agent work",
      "      - SSH Runtime (`/runtime/ssh`) \u2192 `references/docs/runtime/ssh.mdx` \u2014 Run agents on remote hosts over SSH for security and performance",
      "      - Coder Runtime (`/runtime/coder`) \u2192 `references/docs/runtime/lattice.mdx` \u2014 Run agents on Lattice workspaces",
      "      - Docker Runtime (`/runtime/docker`) \u2192 `references/docs/runtime/docker.mdx` \u2014 Run agents in isolated Docker containers",
      "      - Dev Container Runtime (`/runtime/devcontainer`) \u2192 `references/docs/runtime/devcontainer.mdx` \u2014 Run agents in containers defined by devcontainer.json",
      "    - **Hooks**",
      "      - Init Hooks (`/hooks/init`) \u2192 `references/docs/hooks/init.mdx` \u2014 Run setup commands automatically when creating new workspaces",
      "      - Tool Hooks (`/hooks/tools`) \u2192 `references/docs/hooks/tools.mdx` \u2014 Block dangerous commands, lint after edits, and set up your environment",
      "      - Environment Variables (`/hooks/environment-variables`) \u2192 `references/docs/hooks/environment-variables.mdx` \u2014 Environment variables available in agent bash commands and hooks",
      "  - **Agents**",
      "    - Agents (`/agents`) \u2192 `references/docs/agents/index.mdx` \u2014 Define custom agents (modes + subagents) with Markdown files",
      "    - Instruction Files (`/agents/instruction-files`) \u2192 `references/docs/agents/instruction-files.mdx` \u2014 Configure agent behavior with AGENTS.md files",
      "    - Agent Skills (`/agents/agent-skills`) \u2192 `references/docs/agents/agent-skills.mdx` \u2014 Share reusable workflows and references with skills",
      "    - Plan Mode (`/agents/plan-mode`) \u2192 `references/docs/agents/plan-mode.mdx` \u2014 Review and collaborate on plans before execution",
      "    - System Prompt (`/agents/system-prompt`) \u2192 `references/docs/agents/system-prompt.mdx` \u2014 How Unix constructs the system prompt for AI models",
      "    - Prompting Tips (`/agents/prompting-tips`) \u2192 `references/docs/agents/prompting-tips.mdx` \u2014 Tips and tricks for getting the most out of your AI agents",
      "  - **Configuration**",
      "    - MCP Servers (`/config/mcp-servers`) \u2192 `references/docs/config/mcp-servers.mdx` \u2014 Extend agent capabilities with Model Context Protocol servers",
      "    - Project Secrets (`/config/project-secrets`) \u2192 `references/docs/config/project-secrets.mdx` \u2014 Manage environment variables and API keys for your projects",
      "    - Agentic Git Identity (`/config/agentic-git-identity`) \u2192 `references/docs/config/agentic-git-identity.mdx` \u2014 Configure a separate Git identity for AI-generated commits",
      "    - Keyboard Shortcuts (`/config/keybinds`) \u2192 `references/docs/config/keybinds.mdx` \u2014 Complete keyboard shortcut reference for Unix",
      "    - Notifications (`/config/notifications`) \u2192 `references/docs/config/notifications.mdx` \u2014 Configure how agents notify you about important events",
      "    - Vim Mode (`/config/vim-mode`) \u2192 `references/docs/config/vim-mode.mdx` \u2014 Vim-style editing in the Unix chat input",
      "  - **Guides**",
      "    - GitHub Actions (`/guides/github-actions`) \u2192 `references/docs/guides/github-actions.mdx` \u2014 Automate your workflows with unix run in GitHub Actions",
      "    - Agentic Git Identity (`/config/agentic-git-identity`) \u2192 `references/docs/config/agentic-git-identity.mdx` \u2014 Configure a separate Git identity for AI-generated commits",
      "    - Prompting Tips (`/agents/prompting-tips`) \u2192 `references/docs/agents/prompting-tips.mdx` \u2014 Tips and tricks for getting the most out of your AI agents",
      "  - **Integrations**",
      "    - VS Code Extension (`/integrations/vscode-extension`) \u2192 `references/docs/integrations/vscode-extension.mdx` \u2014 Pair Unix workspaces with VS Code and Cursor editors",
      "  - **Reference**",
      "    - Telemetry (`/reference/telemetry`) \u2192 `references/docs/reference/telemetry.mdx` \u2014 What Unix collects, what it doesn\u2019t, and how to disable it",
      "    - Storybook (`/reference/storybook`) \u2192 `references/docs/reference/storybook.mdx` \u2014 Develop and test Unix UI states in isolation",
      "    - Terminal Benchmarking (`/reference/benchmarking`) \u2192 `references/docs/reference/benchmarking.mdx` \u2014 Run Terminal-Bench benchmarks with the Unix adapter",
      "    - AGENTS.md (`/AGENTS`) \u2192 `references/docs/AGENTS.md` \u2014 Agent instructions for AI assistants working on the Unix codebase",
      "<!-- END DOCS_TREE -->",
      "",
      "1. Read the docs navigation (source of truth for which pages exist):",
      "",
      "```ts",
      'agent_skill_read_file({ name: "unix-docs", filePath: "references/docs/docs.json" });',
      "```",
      "",
      "2. Read a specific page by path (mirrors `docs/` in the unix repo):",
      "",
      "- `/agents` \u2192 `references/docs/agents/index.mdx`",
      "- `/config/models` \u2192 `references/docs/config/models.mdx`",
      "- `/runtime` \u2192 `references/docs/runtime/index.mdx`",
      "",
      "```ts",
      "agent_skill_read_file({",
      '  name: "unix-docs",',
      '  filePath: "references/docs/config/models.mdx",',
      "});",
      "```",
      "",
      "Notes:",
      "",
      "- Many pages are `.mdx`; some are `.../index.mdx`.",
      "- Images are not embedded; you may see `/img/...` references.",
      "",
      "## When to use",
      "",
      "Use this skill when the user asks how unix works (workspaces, runtimes, agents, models, hooks, keybinds, etc.).",
      "",
      "## About",
      "",
      "DEV OS - parallel agentic workspace for internal use.",
      ""
    ].join("\n")
  }
};

// src/node/services/agentSkills/builtInSkillDefinitions.ts
var BUILT_IN_SOURCES = Object.entries(BUILTIN_SKILL_FILES).map(
  ([name16, files]) => ({ name: name16, files })
);
var cachedPackages = null;
function parseBuiltIns() {
  return BUILT_IN_SOURCES.map(({ name: name16, files }) => {
    const content = files["SKILL.md"];
    if (content === void 0) {
      throw new Error(`Built-in skill '${name16}' is missing SKILL.md`);
    }
    const parsed = parseSkillMarkdown({
      content,
      byteSize: Buffer.byteLength(content, "utf8"),
      directoryName: name16
    });
    return {
      scope: "built-in",
      directoryName: name16,
      frontmatter: parsed.frontmatter,
      body: parsed.body.trim()
    };
  });
}
function getBuiltInSkillDefinitions() {
  cachedPackages ??= parseBuiltIns();
  return cachedPackages;
}
function getBuiltInSkillDescriptors() {
  return getBuiltInSkillDefinitions().map((pkg) => ({
    name: pkg.frontmatter.name,
    description: pkg.frontmatter.description,
    scope: pkg.scope
  }));
}
function getBuiltInSkillByName(name16) {
  return getBuiltInSkillDefinitions().find((pkg) => pkg.frontmatter.name === name16);
}

// src/node/services/agentSkills/agentSkillsService.ts
var GLOBAL_SKILLS_ROOT = "~/.unix/skills";
function getDefaultAgentSkillsRoots(runtime, workspacePath) {
  if (!workspacePath) {
    throw new Error("getDefaultAgentSkillsRoots: workspacePath is required");
  }
  return {
    projectRoot: runtime.normalizePath(".unix/skills", workspacePath),
    globalRoot: GLOBAL_SKILLS_ROOT
  };
}
function formatError(error) {
  return error instanceof Error ? error.message : String(error);
}
async function listSkillDirectoriesFromLocalFs(root) {
  try {
    const entries = await fs11.readdir(root, { withFileTypes: true });
    return entries.filter((entry) => entry.isDirectory()).map((entry) => entry.name);
  } catch {
    return [];
  }
}
async function listSkillDirectoriesFromRuntime(runtime, root, options) {
  if (!options.cwd) {
    throw new Error("listSkillDirectoriesFromRuntime: options.cwd is required");
  }
  const quotedRoot = shellQuote(root);
  const command = `if [ -d ${quotedRoot} ]; then find ${quotedRoot} -mindepth 1 -maxdepth 1 -type d -exec basename {} \\; ; fi`;
  const result = await execBuffered(runtime, command, { cwd: options.cwd, timeout: 10 });
  if (result.exitCode !== 0) {
    log.warn(`Failed to read skills directory ${root}: ${result.stderr || result.stdout}`);
    return [];
  }
  return result.stdout.split("\n").map((line) => line.trim()).filter(Boolean);
}
async function readSkillDescriptorFromDir(runtime, skillDir, directoryName, scope) {
  const skillFilePath = runtime.normalizePath("SKILL.md", skillDir);
  let stat3;
  try {
    stat3 = await runtime.stat(skillFilePath);
  } catch {
    return null;
  }
  if (stat3.isDirectory) {
    return null;
  }
  const sizeValidation = validateFileSize(stat3);
  if (sizeValidation) {
    log.warn(`Skipping skill '${directoryName}' (${scope}): ${sizeValidation.error}`);
    return null;
  }
  let content;
  try {
    content = await readFileString(runtime, skillFilePath);
  } catch (err) {
    log.warn(`Failed to read SKILL.md for ${directoryName}: ${formatError(err)}`);
    return null;
  }
  try {
    const parsed = parseSkillMarkdown({
      content,
      byteSize: stat3.size,
      directoryName
    });
    const descriptor = {
      name: parsed.frontmatter.name,
      description: parsed.frontmatter.description,
      scope
    };
    const validated = AgentSkillDescriptorSchema.safeParse(descriptor);
    if (!validated.success) {
      log.warn(`Invalid agent skill descriptor for ${directoryName}: ${validated.error.message}`);
      return null;
    }
    return validated.data;
  } catch (err) {
    const message = err instanceof AgentSkillParseError ? err.message : formatError(err);
    log.warn(`Skipping invalid skill '${directoryName}' (${scope}): ${message}`);
    return null;
  }
}
async function discoverAgentSkills(runtime, workspacePath, options) {
  if (!workspacePath) {
    throw new Error("discoverAgentSkills: workspacePath is required");
  }
  const roots = options?.roots ?? getDefaultAgentSkillsRoots(runtime, workspacePath);
  const byName = /* @__PURE__ */ new Map();
  const scans = [
    { scope: "project", root: roots.projectRoot },
    { scope: "global", root: roots.globalRoot }
  ];
  for (const scan of scans) {
    let resolvedRoot;
    try {
      resolvedRoot = await runtime.resolvePath(scan.root);
    } catch (err) {
      log.warn(`Failed to resolve skills root ${scan.root}: ${formatError(err)}`);
      continue;
    }
    const directoryNames = runtime instanceof SSHRuntime ? await listSkillDirectoriesFromRuntime(runtime, resolvedRoot, { cwd: workspacePath }) : await listSkillDirectoriesFromLocalFs(resolvedRoot);
    for (const directoryNameRaw of directoryNames) {
      const nameParsed = SkillNameSchema.safeParse(directoryNameRaw);
      if (!nameParsed.success) {
        log.warn(`Skipping invalid skill directory name '${directoryNameRaw}' in ${resolvedRoot}`);
        continue;
      }
      const directoryName = nameParsed.data;
      if (scan.scope === "global" && byName.has(directoryName)) {
        continue;
      }
      const skillDir = runtime.normalizePath(directoryName, resolvedRoot);
      const descriptor = await readSkillDescriptorFromDir(
        runtime,
        skillDir,
        directoryName,
        scan.scope
      );
      if (!descriptor) continue;
      byName.set(descriptor.name, descriptor);
    }
  }
  for (const builtIn of getBuiltInSkillDescriptors()) {
    if (!byName.has(builtIn.name)) {
      byName.set(builtIn.name, builtIn);
    }
  }
  return Array.from(byName.values()).sort((a, b) => a.name.localeCompare(b.name));
}
async function readAgentSkillFromDir(runtime, skillDir, directoryName, scope) {
  const skillFilePath = runtime.normalizePath("SKILL.md", skillDir);
  const stat3 = await runtime.stat(skillFilePath);
  if (stat3.isDirectory) {
    throw new Error(`SKILL.md is not a file: ${skillFilePath}`);
  }
  const sizeValidation = validateFileSize(stat3);
  if (sizeValidation) {
    throw new Error(sizeValidation.error);
  }
  const content = await readFileString(runtime, skillFilePath);
  const parsed = parseSkillMarkdown({
    content,
    byteSize: stat3.size,
    directoryName
  });
  const pkg = {
    scope,
    directoryName,
    frontmatter: parsed.frontmatter,
    body: parsed.body
  };
  const validated = AgentSkillPackageSchema.safeParse(pkg);
  if (!validated.success) {
    throw new Error(
      `Invalid agent skill package for '${directoryName}': ${validated.error.message}`
    );
  }
  return {
    package: validated.data,
    skillDir
  };
}
async function readAgentSkill(runtime, workspacePath, name16, options) {
  if (!workspacePath) {
    throw new Error("readAgentSkill: workspacePath is required");
  }
  const roots = options?.roots ?? getDefaultAgentSkillsRoots(runtime, workspacePath);
  const candidates = [
    { scope: "project", root: roots.projectRoot },
    { scope: "global", root: roots.globalRoot }
  ];
  for (const candidate of candidates) {
    let resolvedRoot;
    try {
      resolvedRoot = await runtime.resolvePath(candidate.root);
    } catch {
      continue;
    }
    const skillDir = runtime.normalizePath(name16, resolvedRoot);
    try {
      const stat3 = await runtime.stat(skillDir);
      if (!stat3.isDirectory) continue;
      return await readAgentSkillFromDir(runtime, skillDir, name16, candidate.scope);
    } catch {
      continue;
    }
  }
  const builtIn = getBuiltInSkillByName(name16);
  if (builtIn) {
    return {
      package: builtIn,
      // Built-in skills don't have a real skillDir on disk.
      // agent_skill_read_file handles built-in skills specially; this is a sentinel value.
      skillDir: `<built-in:${name16}>`
    };
  }
  throw new Error(`Agent skill not found: ${name16}`);
}

// src/node/services/agentDefinitions/agentDefinitionsService.ts
import * as fs12 from "node:fs/promises";
import * as path19 from "node:path";

// src/node/services/agentDefinitions/parseAgentDefinitionMarkdown.ts
var import_yaml2 = __toESM(require_dist3());
var AgentDefinitionParseError = class extends Error {
  constructor(message) {
    super(message);
    this.name = "AgentDefinitionParseError";
  }
};
function normalizeNewlines2(input) {
  return input.replace(/\r\n/g, "\n").replace(/\r/g, "\n");
}
function stripUtf8Bom2(input) {
  return input.startsWith("\uFEFF") ? input.slice(1) : input;
}
function assertObject2(value2, message) {
  if (!value2 || typeof value2 !== "object" || Array.isArray(value2)) {
    throw new AgentDefinitionParseError(message);
  }
}
function formatZodIssues2(issues) {
  return issues.map((issue) => {
    const issuePath = issue.path.length > 0 ? issue.path.map((part) => String(part)).join(".") : "<root>";
    return `${issuePath}: ${issue.message}`;
  }).join("; ");
}
function parseAgentDefinitionMarkdown(input) {
  if (input.byteSize > MAX_FILE_SIZE) {
    const sizeMB = (input.byteSize / (1024 * 1024)).toFixed(2);
    const maxMB = (MAX_FILE_SIZE / (1024 * 1024)).toFixed(2);
    throw new AgentDefinitionParseError(
      `Agent definition is too large (${sizeMB}MB). Maximum supported size is ${maxMB}MB.`
    );
  }
  const content = normalizeNewlines2(stripUtf8Bom2(input.content));
  if (!content.startsWith("---")) {
    throw new AgentDefinitionParseError(
      "Agent definition must start with YAML frontmatter delimited by '---'."
    );
  }
  const lines = content.split("\n");
  if ((lines[0] ?? "").trim() !== "---") {
    throw new AgentDefinitionParseError(
      "Agent definition frontmatter start delimiter must be exactly '---'."
    );
  }
  const endIndex = lines.findIndex((line, idx) => idx > 0 && line.trim() === "---");
  if (endIndex === -1) {
    throw new AgentDefinitionParseError(
      "Agent definition frontmatter is missing the closing '---' delimiter."
    );
  }
  const yamlText = lines.slice(1, endIndex).join("\n");
  const body = lines.slice(endIndex + 1).join("\n");
  let raw;
  try {
    raw = import_yaml2.default.parse(yamlText);
  } catch (err) {
    const message = err instanceof Error ? err.message : String(err);
    throw new AgentDefinitionParseError(`Failed to parse YAML frontmatter: ${message}`);
  }
  assertObject2(raw, "Agent definition YAML frontmatter must be a mapping/object.");
  const parsed = AgentDefinitionFrontmatterSchema.safeParse(raw);
  if (!parsed.success) {
    throw new AgentDefinitionParseError(
      `Invalid agent definition frontmatter: ${formatZodIssues2(parsed.error.issues)}`
    );
  }
  return { frontmatter: parsed.data, body };
}

// src/node/services/agentDefinitions/builtInAgentContent.generated.ts
var BUILTIN_AGENT_CONTENT = {
  "compact": "---\nname: Compact\ndescription: History compaction (internal)\nui:\n  hidden: true\nsubagent:\n  runnable: false\n---\n\nYou are running a compaction/summarization pass. Your task is to write a concise summary of the conversation so far.\n\nIMPORTANT:\n\n- You have NO tools available. Do not attempt to call any tools or output JSON.\n- Simply write the summary as plain text prose.\n- Follow the user's instructions for what to include in the summary.\n",
  "exec": "---\nname: Exec\ndescription: Implement changes in the repository\nui:\n  color: var(--color-exec-mode)\nsubagent:\n  runnable: true\n  append_prompt: |\n    If you are running as a sub-agent in a child workspace:\n\n    - When you have a final answer, call agent_report exactly once.\n    - Do not call task/task_await/task_list/task_terminate (subagent recursion is disabled).\n    - Do not call propose_plan.\ntools:\n  add:\n    # Allow all tools by default (includes MCP tools which have dynamic names)\n    # Use tools.remove in child agents to restrict specific tools\n    - .*\n  remove:\n    # Exec mode doesn't use planning tools\n    - propose_plan\n    - ask_user_question\n    # Internal-only tools\n    - system1_keep_ranges\n---\n\nYou are in Exec mode.\n\n- Make minimal, correct, reviewable changes that match existing codebase patterns.\n- Prefer targeted commands and checks (typecheck/tests) when feasible.\n- Treat as a standing order: keep running checks and addressing failures until they pass or a blocker outside your control arises.\n",
  "explore": "---\nname: Explore\ndescription: Read-only repository exploration\nbase: exec\nui:\n  hidden: true\nsubagent:\n  runnable: true\n  skip_init_hook: true\n  append_prompt: |\n    You are an Explore sub-agent running inside a child workspace.\n\n    - Explore the repository to answer the prompt using read-only investigation.\n    - Return concise, actionable findings (paths, symbols, callsites, and facts).\n    - When you have a final answer, call agent_report exactly once.\n    - Do not call agent_report until you have completed the assigned task.\ntools:\n  # Remove editing and task tools from exec base (read-only agent)\n  remove:\n    - file_edit_.*\n    - task\n    - task_.*\n    - agent_skill_read\n    - agent_skill_read_file\n---\n\nYou are in Explore mode (read-only).\n\n=== CRITICAL: READ-ONLY MODE - NO FILE MODIFICATIONS ===\n\n- You MUST NOT create, edit, delete, move, or copy files.\n- You MUST NOT create temporary files anywhere (including /tmp).\n- You MUST NOT use redirect operators (>, >>, |) or heredocs to write to files.\n- You MUST NOT run commands that change system state (rm, mv, cp, mkdir, touch, git add/commit, installs, etc.).\n- Prefer `file_read` for reading file contents (supports offset/limit paging).\n- Use bash only for read-only operations (rg, ls, git diff/show/log, etc.), or when you need piping/processing.\n",
  "plan": '---\nname: Plan\ndescription: Create a plan before coding\nui:\n  color: var(--color-plan-mode)\nsubagent:\n  runnable: false\ntools:\n  add:\n    # Allow all tools by default (includes MCP tools which have dynamic names)\n    # Use tools.remove in child agents to restrict specific tools\n    - .*\n  # Note: file_edit_* tools ARE available but restricted to plan file only at runtime\n  # Note: task tools ARE enabled - Plan delegates to Explore sub-agents\n---\n\nYou are in Plan Mode.\n\n- Every response MUST produce or update a plan\u2014no exceptions.\n- Simple requests deserve simple plans; a straightforward task might only need a few bullet points. Match plan complexity to the problem.\n- Keep the plan scannable; put long rationale in `<details>/<summary>` blocks.\n- Plans must be **self-contained**: include enough context, goals, constraints, and the core "why" so a new assistant can implement without needing the prior chat.\n- When Plan Mode is requested, assume the user wants the actual completed plan; do not merely describe how you would devise one.\n\n## Investigation step (required)\n\nBefore proposing a plan, identify what you must verify and use the best available tools\n(`file_read` for local file contents, search, or user questions). Do not guess. Investigation can be\ndone directly; sub-agents are optional.\n\nPrefer `file_read` over `bash cat` when reading files (including the plan file): long bash output may\nbe compacted, which can hide the middle of a document. Use `file_read` with offset/limit to page\nthrough larger files.\n\n## Plan format\n\n- Context/Why: Briefly restate the request, goals, and the rationale or user impact so the\n  plan stands alone for a fresh implementer.\n- Evidence: List sources consulted (file paths, tool outputs, or user-provided info) and\n  why they are sufficient. If evidence is missing, still produce a minimal plan and add a\n  Questions section listing what you need to proceed.\n\nDetailed plan mode instructions (plan file path, sub-agent delegation, propose_plan workflow) are provided separately.\n',
  "system1_bash": '---\nname: System1 Bash\ndescription: Fast bash-output filtering (internal)\nui:\n  hidden: true\nsubagent:\n  runnable: false\ntools:\n  add:\n    - system1_keep_ranges\n---\n\nYou are a fast bash-output filtering assistant.\n\nYou will be given:\n\n- `maxKeptLines` (budget)\n- `Display name` (optional): a short intent label for the command\n- `Bash script`\n- `Numbered output`\n\nGiven the numbered output, decide which lines to keep so the user sees the most relevant information.\n\nIMPORTANT:\n\n- You MUST call `system1_keep_ranges` exactly once.\n- Do NOT output markdown or prose. Only the tool call (with valid JSON arguments).\n\nRules:\n\n- Line numbers are 1-based indices into the numbered output.\n- Use the `Display name` and `Bash script` as intent hints.\n- If intent is exploration/listing/search (e.g. `ls`, `find`, `rg`, `grep`, `git status`), prioritize keeping\n  representative file paths/matches and any summary/counts (not just errors).\n- If intent is build/test/logs, prefer errors, stack traces, failing test summaries, and actionable warnings.\n- If the script already narrows output to a slice (e.g. `head`, `tail`, `sed -n` line ranges), avoid extra\n  denoising: prefer keeping most/all lines within the budget.\n- Never filter out git merge conflict markers (`<<<<<<<`, `|||||||`, `=======`, `>>>>>>>`). If the command is searching for these markers (e.g. `rg`/`grep`), do not keep only representative matches; keep all matches within the budget.\n- Prefer omitting tool-generated advisory blocks (especially git lines starting with `hint:`) that only suggest\n  next-step commands or point to docs/help. Keep the underlying `error:`/`fatal:`/`CONFLICT` lines, file paths,\n  and conflict markers instead.\n- Exception: keep `hint:` blocks when the script is explicitly searching for them (e.g. `rg \'^hint:\'`) or when\n  the hint is the only clue explaining a blocking state.\n- Prefer high signal density: keep ranges tight around important lines plus minimal surrounding context.\n- Merge adjacent/overlapping ranges only when the lines between are also informative. Do NOT add noise just\n  to reduce range count; it\'s OK to return many ranges when denoising (e.g., > 8).\n- Denoise aggressively: omit duplicate/redundant lines and repeated messages with the same meaning\n  (e.g., repeated progress, retries, or identical stack traces). If the same error repeats, keep only\n  the most informative instance plus minimal surrounding context.\n- If there are many similar warnings/errors, keep only a few representative examples (prefer those\n  with file paths/line numbers) plus any summary/count.\n- Always keep at least 1 line if any output exists.\n- Choose ranges that keep at most `maxKeptLines` lines total (the caller may truncate).\n\nExample:\n\n- Numbered output:\n  - 0001| building...\n  - 0002| ERROR: expected X, got Y\n  - 0003| at path/to/file.ts:12:3\n  - 0004| done\n- Tool call:\n  - system1_keep_ranges({"keep_ranges":[{"start":2,"end":3,"reason":"error"}]})\n',
  "unix": "---\nname: Unix\ndescription: Configure unix global behavior (system workspace)\nui:\n  hidden: true\nsubagent:\n  runnable: false\ntools:\n  add:\n    - unix_global_agents_read\n    - unix_global_agents_write\n    - ask_user_question\n---\n\nYou are the **Unix system assistant**.\n\nYour job is to help the user configure unix globally by editing the unix-wide instructions file:\n\n- `~/.unix/AGENTS.md`\n\n## Safety rules\n\n- You do **not** have access to arbitrary filesystem tools.\n- You do **not** have access to project secrets.\n- Before writing `~/.unix/AGENTS.md`, you must:\n  1) Read the current file (`unix_global_agents_read`).\n  2) Propose the exact change (show the new content or a concise diff).\n  3) Ask for explicit confirmation via `ask_user_question`.\n  4) Only then call `unix_global_agents_write` with `confirm: true`.\n\nIf the user declines, do not write anything.\n"
};

// src/node/services/agentDefinitions/builtInAgentDefinitions.ts
var BUILT_IN_SOURCES2 = [
  { id: "exec", content: BUILTIN_AGENT_CONTENT.exec },
  { id: "plan", content: BUILTIN_AGENT_CONTENT.plan },
  { id: "compact", content: BUILTIN_AGENT_CONTENT.compact },
  { id: "explore", content: BUILTIN_AGENT_CONTENT.explore },
  { id: "system1_bash", content: BUILTIN_AGENT_CONTENT.system1_bash },
  { id: "unix", content: BUILTIN_AGENT_CONTENT.unix }
];
var cachedPackages2 = null;
function parseBuiltIns2() {
  return BUILT_IN_SOURCES2.map(({ id, content }) => {
    const parsed = parseAgentDefinitionMarkdown({
      content,
      byteSize: Buffer.byteLength(content, "utf8")
    });
    return {
      id,
      scope: "built-in",
      frontmatter: parsed.frontmatter,
      body: parsed.body.trim()
    };
  });
}
function getBuiltInAgentDefinitions() {
  cachedPackages2 ??= parseBuiltIns2();
  return cachedPackages2;
}

// src/node/services/agentDefinitions/agentDefinitionsService.ts
var MAX_INHERITANCE_DEPTH = 10;
function agentVisitKey(id, scope) {
  return `${id}:${scope}`;
}
function computeBaseSkipScope(baseId, currentId, currentScope) {
  return baseId === currentId ? currentScope : void 0;
}
var GLOBAL_AGENTS_ROOT = "~/.unix/agents";
function resolveUiSelectable(ui) {
  if (!ui) {
    return true;
  }
  if (typeof ui.hidden === "boolean") {
    return !ui.hidden;
  }
  if (typeof ui.selectable === "boolean") {
    return ui.selectable;
  }
  return true;
}
function resolveUiDisabled(ui) {
  return ui?.disabled === true;
}
function getDefaultAgentDefinitionsRoots(runtime, workspacePath) {
  if (!workspacePath) {
    throw new Error("getDefaultAgentDefinitionsRoots: workspacePath is required");
  }
  return {
    projectRoot: runtime.normalizePath(".unix/agents", workspacePath),
    globalRoot: GLOBAL_AGENTS_ROOT
  };
}
function formatError2(error) {
  return error instanceof Error ? error.message : String(error);
}
async function listAgentFilesFromLocalFs(root) {
  try {
    const entries = await fs12.readdir(root, { withFileTypes: true });
    return entries.filter((entry) => entry.isFile() && entry.name.toLowerCase().endsWith(".md")).map((entry) => entry.name);
  } catch {
    return [];
  }
}
async function listAgentFilesFromRuntime(runtime, root, options) {
  if (!options.cwd) {
    throw new Error("listAgentFilesFromRuntime: options.cwd is required");
  }
  const quotedRoot = shellQuote(root);
  const command = `if [ -d ${quotedRoot} ]; then find ${quotedRoot} -mindepth 1 -maxdepth 1 -type f -name '*.md' -exec basename {} \\; ; fi`;
  const result = await execBuffered(runtime, command, { cwd: options.cwd, timeout: 10 });
  if (result.exitCode !== 0) {
    log.warn(`Failed to read agents directory ${root}: ${result.stderr || result.stdout}`);
    return [];
  }
  return result.stdout.split("\n").map((line) => line.trim()).filter(Boolean);
}
function getAgentIdFromFilename(filename) {
  const parsed = path19.parse(filename);
  if (parsed.ext.toLowerCase() !== ".md") {
    return null;
  }
  const idRaw = parsed.name.trim().toLowerCase();
  const idParsed = AgentIdSchema.safeParse(idRaw);
  if (!idParsed.success) {
    return null;
  }
  return idParsed.data;
}
async function readAgentDescriptorFromFileWithDisabled(runtime, filePath, agentId, scope) {
  let stat3;
  try {
    stat3 = await runtime.stat(filePath);
  } catch {
    return null;
  }
  if (stat3.isDirectory) {
    return null;
  }
  const sizeValidation = validateFileSize(stat3);
  if (sizeValidation) {
    log.warn(`Skipping agent '${agentId}' (${scope}): ${sizeValidation.error}`);
    return null;
  }
  let content;
  try {
    content = await readFileString(runtime, filePath);
  } catch (err) {
    log.warn(`Failed to read agent definition ${filePath}: ${formatError2(err)}`);
    return null;
  }
  try {
    const parsed = parseAgentDefinitionMarkdown({ content, byteSize: stat3.size });
    const uiSelectable = resolveUiSelectable(parsed.frontmatter.ui);
    const uiColor = parsed.frontmatter.ui?.color;
    const subagentRunnable = parsed.frontmatter.subagent?.runnable ?? false;
    const disabled = resolveUiDisabled(parsed.frontmatter.ui);
    const descriptor = {
      id: agentId,
      scope,
      name: parsed.frontmatter.name,
      description: parsed.frontmatter.description,
      uiSelectable,
      uiColor,
      subagentRunnable,
      base: parsed.frontmatter.base,
      aiDefaults: parsed.frontmatter.ai,
      tools: parsed.frontmatter.tools
    };
    const validated = AgentDefinitionDescriptorSchema.safeParse(descriptor);
    if (!validated.success) {
      log.warn(`Invalid agent definition descriptor for ${agentId}: ${validated.error.message}`);
      return null;
    }
    return { descriptor: validated.data, disabled };
  } catch (err) {
    const message = err instanceof AgentDefinitionParseError ? err.message : formatError2(err);
    log.warn(`Skipping invalid agent definition '${agentId}' (${scope}): ${message}`);
    return null;
  }
}
async function discoverAgentDefinitions(runtime, workspacePath, options) {
  if (!workspacePath) {
    throw new Error("discoverAgentDefinitions: workspacePath is required");
  }
  const roots = options?.roots ?? getDefaultAgentDefinitionsRoots(runtime, workspacePath);
  const byId = /* @__PURE__ */ new Map();
  for (const pkg of getBuiltInAgentDefinitions()) {
    const uiSelectable = resolveUiSelectable(pkg.frontmatter.ui);
    const uiColor = pkg.frontmatter.ui?.color;
    const subagentRunnable = pkg.frontmatter.subagent?.runnable ?? false;
    const disabled = resolveUiDisabled(pkg.frontmatter.ui);
    byId.set(pkg.id, {
      descriptor: {
        id: pkg.id,
        scope: "built-in",
        name: pkg.frontmatter.name,
        description: pkg.frontmatter.description,
        uiSelectable,
        uiColor,
        subagentRunnable,
        base: pkg.frontmatter.base,
        aiDefaults: pkg.frontmatter.ai,
        tools: pkg.frontmatter.tools
      },
      disabled
    });
  }
  const scans = [
    { scope: "global", root: roots.globalRoot },
    { scope: "project", root: roots.projectRoot }
  ];
  for (const scan of scans) {
    let resolvedRoot;
    try {
      resolvedRoot = await runtime.resolvePath(scan.root);
    } catch (err) {
      log.warn(`Failed to resolve agents root ${scan.root}: ${formatError2(err)}`);
      continue;
    }
    const filenames = runtime instanceof SSHRuntime ? await listAgentFilesFromRuntime(runtime, resolvedRoot, { cwd: workspacePath }) : await listAgentFilesFromLocalFs(resolvedRoot);
    for (const filename of filenames) {
      const agentId = getAgentIdFromFilename(filename);
      if (!agentId) {
        log.warn(`Skipping invalid agent filename '${filename}' in ${resolvedRoot}`);
        continue;
      }
      const filePath = runtime.normalizePath(filename, resolvedRoot);
      const result = await readAgentDescriptorFromFileWithDisabled(
        runtime,
        filePath,
        agentId,
        scan.scope
      );
      if (!result) continue;
      byId.set(agentId, result);
    }
  }
  return Array.from(byId.values()).filter((entry) => !entry.disabled).map((entry) => entry.descriptor).sort((a, b) => a.name.localeCompare(b.name));
}
var SCOPE_PRIORITY = ["project", "global", "built-in"];
async function readAgentDefinition(runtime, workspacePath, agentId, options) {
  if (!workspacePath) {
    throw new Error("readAgentDefinition: workspacePath is required");
  }
  const roots = options?.roots ?? getDefaultAgentDefinitionsRoots(runtime, workspacePath);
  const skipScopesAbove = options?.skipScopesAbove;
  const skipScopes = /* @__PURE__ */ new Set();
  if (skipScopesAbove) {
    const skipIndex = SCOPE_PRIORITY.indexOf(skipScopesAbove);
    if (skipIndex !== -1) {
      for (let i = 0; i <= skipIndex; i++) {
        skipScopes.add(SCOPE_PRIORITY[i]);
      }
    }
  }
  const candidates = [
    { scope: "project", root: roots.projectRoot },
    { scope: "global", root: roots.globalRoot }
  ];
  for (const candidate of candidates) {
    if (skipScopes.has(candidate.scope)) {
      continue;
    }
    let resolvedRoot;
    try {
      resolvedRoot = await runtime.resolvePath(candidate.root);
    } catch {
      continue;
    }
    const filePath = runtime.normalizePath(`${agentId}.md`, resolvedRoot);
    try {
      const stat3 = await runtime.stat(filePath);
      if (stat3.isDirectory) {
        continue;
      }
      const sizeValidation = validateFileSize(stat3);
      if (sizeValidation) {
        throw new Error(sizeValidation.error);
      }
      const content = await readFileString(runtime, filePath);
      const parsed = parseAgentDefinitionMarkdown({ content, byteSize: stat3.size });
      const pkg = {
        id: agentId,
        scope: candidate.scope,
        frontmatter: parsed.frontmatter,
        body: parsed.body
      };
      const validated = AgentDefinitionPackageSchema.safeParse(pkg);
      if (!validated.success) {
        throw new Error(
          `Invalid agent definition package for '${agentId}' (${candidate.scope}): ${validated.error.message}`
        );
      }
      return validated.data;
    } catch {
      continue;
    }
  }
  if (!skipScopes.has("built-in")) {
    const builtIn = getBuiltInAgentDefinitions().find((pkg) => pkg.id === agentId);
    if (builtIn) {
      const validated = AgentDefinitionPackageSchema.safeParse(builtIn);
      if (!validated.success) {
        throw new Error(
          `Invalid built-in agent definition '${agentId}': ${validated.error.message}`
        );
      }
      return validated.data;
    }
  }
  throw new Error(`Agent definition not found: ${agentId}`);
}

// src/node/services/agentDefinitions/resolveAgentInheritanceChain.ts
async function resolveAgentInheritanceChain(options) {
  const { runtime, workspacePath, agentId, agentDefinition, workspaceId } = options;
  const maxDepth = options.maxDepth ?? MAX_INHERITANCE_DEPTH;
  const agentsForInheritance = [];
  const seenPackages = /* @__PURE__ */ new Set();
  let currentAgentId = agentId;
  let currentDefinition = agentDefinition;
  for (let depth = 0; depth < maxDepth; depth++) {
    const visitKey = agentVisitKey(currentDefinition.id, currentDefinition.scope);
    if (seenPackages.has(visitKey)) {
      log.warn("Agent definition base chain has a cycle; stopping resolution", {
        workspaceId,
        agentId,
        currentAgentId,
        scope: currentDefinition.scope
      });
      break;
    }
    seenPackages.add(visitKey);
    agentsForInheritance.push({
      id: currentAgentId,
      base: currentDefinition.frontmatter.base,
      tools: currentDefinition.frontmatter.tools,
      uiColor: currentDefinition.frontmatter.ui?.color
    });
    const baseId = currentDefinition.frontmatter.base;
    if (!baseId) {
      break;
    }
    const skipScopesAbove = computeBaseSkipScope(baseId, currentAgentId, currentDefinition.scope);
    currentAgentId = baseId;
    try {
      currentDefinition = await readAgentDefinition(runtime, workspacePath, baseId, {
        skipScopesAbove
      });
    } catch (error) {
      log.warn("Failed to load base agent definition; stopping inheritance resolution", {
        workspaceId,
        agentId,
        baseId,
        error: error instanceof Error ? error.message : String(error)
      });
      break;
    }
  }
  return agentsForInheritance;
}

// src/common/utils/archive.ts
function isWorkspaceArchived(archivedAt, unarchivedAt) {
  if (!archivedAt) return false;
  if (!unarchivedAt) return true;
  return new Date(archivedAt).getTime() > new Date(unarchivedAt).getTime();
}

// src/node/orpc/router.ts
async function resolveAgentDiscoveryContext(context, input) {
  if (!input.projectPath && !input.workspaceId) {
    throw new Error("Either projectPath or workspaceId must be provided");
  }
  if (input.workspaceId) {
    const metadataResult = await context.aiService.getWorkspaceMetadata(input.workspaceId);
    if (!metadataResult.success) {
      throw new Error(metadataResult.error);
    }
    const metadata = metadataResult.data;
    const runtime2 = createRuntimeForWorkspace(metadata);
    const discoveryPath = input.disableWorkspaceAgents ? metadata.projectPath : runtime2.getWorkspacePath(metadata.projectPath, metadata.name);
    return { runtime: runtime2, discoveryPath };
  }
  const runtime = createRuntime(
    { type: "local", srcBaseDir: context.config.srcDir },
    { projectPath: input.projectPath }
  );
  return { runtime, discoveryPath: input.projectPath };
}
var router = (authToken) => {
  const t = os.$context().use(createAuthMiddleware(authToken));
  return t.router({
    tokenizer: {
      countTokens: t.input(tokenizer.countTokens.input).output(tokenizer.countTokens.output).handler(async ({ context, input }) => {
        return context.tokenizerService.countTokens(input.model, input.text);
      }),
      countTokensBatch: t.input(tokenizer.countTokensBatch.input).output(tokenizer.countTokensBatch.output).handler(async ({ context, input }) => {
        return context.tokenizerService.countTokensBatch(input.model, input.texts);
      }),
      calculateStats: t.input(tokenizer.calculateStats.input).output(tokenizer.calculateStats.output).handler(async ({ context, input }) => {
        return context.tokenizerService.calculateStats(
          input.workspaceId,
          input.messages,
          input.model
        );
      })
    },
    splashScreens: {
      getViewedSplashScreens: t.input(splashScreens.getViewedSplashScreens.input).output(splashScreens.getViewedSplashScreens.output).handler(({ context }) => {
        const config2 = context.config.loadConfigOrDefault();
        return config2.viewedSplashScreens ?? [];
      }),
      markSplashScreenViewed: t.input(splashScreens.markSplashScreenViewed.input).output(splashScreens.markSplashScreenViewed.output).handler(async ({ context, input }) => {
        await context.config.editConfig((config2) => {
          const viewed = config2.viewedSplashScreens ?? [];
          if (!viewed.includes(input.splashId)) {
            viewed.push(input.splashId);
          }
          return {
            ...config2,
            viewedSplashScreens: viewed
          };
        });
      })
    },
    server: {
      getLaunchProject: t.input(server.getLaunchProject.input).output(server.getLaunchProject.output).handler(async ({ context }) => {
        return context.serverService.getLaunchProject();
      }),
      getSshHost: t.input(server.getSshHost.input).output(server.getSshHost.output).handler(({ context }) => {
        return context.serverService.getSshHost() ?? null;
      }),
      setSshHost: t.input(server.setSshHost.input).output(server.setSshHost.output).handler(async ({ context, input }) => {
        context.serverService.setSshHost(input.sshHost ?? void 0);
        await context.config.editConfig((config2) => ({
          ...config2,
          serverSshHost: input.sshHost ?? void 0
        }));
      }),
      getApiServerStatus: t.input(server.getApiServerStatus.input).output(server.getApiServerStatus.output).handler(({ context }) => {
        const config2 = context.config.loadConfigOrDefault();
        const configuredBindHost = config2.apiServerBindHost ?? null;
        const configuredServeWebUi = config2.apiServerServeWebUi === true;
        const configuredPort = config2.apiServerPort ?? null;
        const info = context.serverService.getServerInfo();
        return {
          running: info !== null,
          baseUrl: info?.baseUrl ?? null,
          bindHost: info?.bindHost ?? null,
          port: info?.port ?? null,
          networkBaseUrls: info?.networkBaseUrls ?? [],
          token: info?.token ?? null,
          configuredBindHost,
          configuredPort,
          configuredServeWebUi
        };
      }),
      setApiServerSettings: t.input(server.setApiServerSettings.input).output(server.setApiServerSettings.output).handler(async ({ context, input }) => {
        const prevConfig = context.config.loadConfigOrDefault();
        const prevBindHost = prevConfig.apiServerBindHost;
        const prevServeWebUi = prevConfig.apiServerServeWebUi;
        const prevPort = prevConfig.apiServerPort;
        const wasRunning = context.serverService.isServerRunning();
        const bindHost = input.bindHost?.trim() ? input.bindHost.trim() : void 0;
        const serveWebUi = input.serveWebUi === void 0 ? prevServeWebUi : input.serveWebUi === true ? true : void 0;
        const port = input.port === null || input.port === 0 ? void 0 : input.port;
        if (wasRunning) {
          await context.serverService.stopServer();
        }
        await context.config.editConfig((config2) => {
          config2.apiServerServeWebUi = serveWebUi;
          config2.apiServerBindHost = bindHost;
          config2.apiServerPort = port;
          return config2;
        });
        if (process.env.UNIX_NO_API_SERVER !== "1") {
          const authToken2 = context.serverService.getApiAuthToken();
          if (!authToken2) {
            throw new Error("API server auth token not initialized");
          }
          const envPort = process.env.UNIX_SERVER_PORT ? Number.parseInt(process.env.UNIX_SERVER_PORT, 10) : void 0;
          const portToUse = envPort ?? port ?? 0;
          const hostToUse = bindHost ?? "127.0.0.1";
          try {
            await context.serverService.startServer({
              unixHome: context.config.rootDir,
              context,
              authToken: authToken2,
              serveStatic: serveWebUi === true,
              host: hostToUse,
              port: portToUse
            });
          } catch (error) {
            await context.config.editConfig((config2) => {
              config2.apiServerServeWebUi = prevServeWebUi;
              config2.apiServerBindHost = prevBindHost;
              config2.apiServerPort = prevPort;
              return config2;
            });
            if (wasRunning) {
              const portToRestore = envPort ?? prevPort ?? 0;
              const hostToRestore = prevBindHost ?? "127.0.0.1";
              try {
                await context.serverService.startServer({
                  unixHome: context.config.rootDir,
                  context,
                  serveStatic: prevServeWebUi === true,
                  authToken: authToken2,
                  host: hostToRestore,
                  port: portToRestore
                });
              } catch {
              }
            }
            throw error;
          }
        }
        const nextConfig = context.config.loadConfigOrDefault();
        const configuredBindHost = nextConfig.apiServerBindHost ?? null;
        const configuredServeWebUi = nextConfig.apiServerServeWebUi === true;
        const configuredPort = nextConfig.apiServerPort ?? null;
        const info = context.serverService.getServerInfo();
        return {
          running: info !== null,
          baseUrl: info?.baseUrl ?? null,
          bindHost: info?.bindHost ?? null,
          port: info?.port ?? null,
          networkBaseUrls: info?.networkBaseUrls ?? [],
          token: info?.token ?? null,
          configuredBindHost,
          configuredPort,
          configuredServeWebUi
        };
      })
    },
    features: {
      getStatsTabState: t.input(features.getStatsTabState.input).output(features.getStatsTabState.output).handler(async ({ context }) => {
        const state = await context.featureFlagService.getStatsTabState();
        context.sessionTimingService.setStatsTabState(state);
        return state;
      }),
      setStatsTabOverride: t.input(features.setStatsTabOverride.input).output(features.setStatsTabOverride.output).handler(async ({ context, input }) => {
        const state = await context.featureFlagService.setStatsTabOverride(input.override);
        context.sessionTimingService.setStatsTabState(state);
        return state;
      })
    },
    config: {
      getConfig: t.input(config.getConfig.input).output(config.getConfig.output).handler(({ context }) => {
        const config2 = context.config.loadConfigOrDefault();
        return {
          taskSettings: config2.taskSettings ?? DEFAULT_TASK_SETTINGS,
          agentAiDefaults: config2.agentAiDefaults ?? {},
          // Legacy fields (downgrade compatibility)
          subagentAiDefaults: config2.subagentAiDefaults ?? {}
        };
      }),
      updateAgentAiDefaults: t.input(config.updateAgentAiDefaults.input).output(config.updateAgentAiDefaults.output).handler(async ({ context, input }) => {
        await context.config.editConfig((config2) => {
          const normalized = normalizeAgentAiDefaults(input.agentAiDefaults);
          const legacySubagentDefaultsRaw = {};
          for (const [agentType, entry] of Object.entries(normalized)) {
            if (agentType === "plan" || agentType === "exec" || agentType === "compact") {
              continue;
            }
            legacySubagentDefaultsRaw[agentType] = entry;
          }
          const legacySubagentDefaults = normalizeSubagentAiDefaults(legacySubagentDefaultsRaw);
          return {
            ...config2,
            agentAiDefaults: Object.keys(normalized).length > 0 ? normalized : void 0,
            // Legacy fields (downgrade compatibility)
            subagentAiDefaults: Object.keys(legacySubagentDefaults).length > 0 ? legacySubagentDefaults : void 0
          };
        });
      }),
      saveConfig: t.input(config.saveConfig.input).output(config.saveConfig.output).handler(async ({ context, input }) => {
        await context.config.editConfig((config2) => {
          const normalizedTaskSettings = normalizeTaskSettings(input.taskSettings);
          const result = { ...config2, taskSettings: normalizedTaskSettings };
          if (input.agentAiDefaults !== void 0) {
            const normalized = normalizeAgentAiDefaults(input.agentAiDefaults);
            result.agentAiDefaults = Object.keys(normalized).length > 0 ? normalized : void 0;
            if (input.subagentAiDefaults === void 0) {
              const legacySubagentDefaultsRaw = {};
              for (const [agentType, entry] of Object.entries(normalized)) {
                if (agentType === "plan" || agentType === "exec" || agentType === "compact") {
                  continue;
                }
                legacySubagentDefaultsRaw[agentType] = entry;
              }
              const legacySubagentDefaults = normalizeSubagentAiDefaults(legacySubagentDefaultsRaw);
              result.subagentAiDefaults = Object.keys(legacySubagentDefaults).length > 0 ? legacySubagentDefaults : void 0;
            }
          }
          if (input.subagentAiDefaults !== void 0) {
            const normalizedDefaults = normalizeSubagentAiDefaults(input.subagentAiDefaults);
            result.subagentAiDefaults = Object.keys(normalizedDefaults).length > 0 ? normalizedDefaults : void 0;
            const previousLegacy = config2.subagentAiDefaults ?? {};
            const nextAgentAiDefaults = {
              ...result.agentAiDefaults ?? config2.agentAiDefaults ?? {}
            };
            for (const legacyAgentType of Object.keys(previousLegacy)) {
              if (legacyAgentType === "plan" || legacyAgentType === "exec" || legacyAgentType === "compact") {
                continue;
              }
              if (!(legacyAgentType in normalizedDefaults)) {
                delete nextAgentAiDefaults[legacyAgentType];
              }
            }
            for (const [agentType, entry] of Object.entries(normalizedDefaults)) {
              if (agentType === "plan" || agentType === "exec" || agentType === "compact")
                continue;
              nextAgentAiDefaults[agentType] = entry;
            }
            const normalizedAgent = normalizeAgentAiDefaults(nextAgentAiDefaults);
            result.agentAiDefaults = Object.keys(normalizedAgent).length > 0 ? normalizedAgent : void 0;
          }
          return result;
        });
        await context.taskService.maybeStartQueuedTasks();
      })
    },
    uiLayouts: {
      getAll: t.input(uiLayouts.getAll.input).output(uiLayouts.getAll.output).handler(({ context }) => {
        const config2 = context.config.loadConfigOrDefault();
        return config2.layoutPresets ?? DEFAULT_LAYOUT_PRESETS_CONFIG;
      }),
      saveAll: t.input(uiLayouts.saveAll.input).output(uiLayouts.saveAll.output).handler(async ({ context, input }) => {
        await context.config.editConfig((config2) => {
          const normalized = normalizeLayoutPresetsConfig(input.layoutPresets);
          return {
            ...config2,
            layoutPresets: isLayoutPresetsConfigEmpty(normalized) ? void 0 : normalized
          };
        });
      })
    },
    agents: {
      list: t.input(agents.list.input).output(agents.list.output).handler(async ({ context, input }) => {
        if (input.workspaceId) {
          await context.aiService.waitForInit(input.workspaceId);
        }
        const { runtime, discoveryPath } = await resolveAgentDiscoveryContext(context, input);
        const descriptors = await discoverAgentDefinitions(runtime, discoveryPath);
        return Promise.all(
          descriptors.map(async (descriptor) => {
            try {
              const pkg = await readAgentDefinition(runtime, discoveryPath, descriptor.id);
              const chain = await resolveAgentInheritanceChain({
                runtime,
                workspacePath: discoveryPath,
                agentId: descriptor.id,
                agentDefinition: pkg,
                workspaceId: input.workspaceId ?? ""
                // for logging only
              });
              const resolvedUiColor = chain.find((entry) => entry.uiColor)?.uiColor;
              return {
                ...descriptor,
                uiColor: descriptor.uiColor ?? resolvedUiColor
              };
            } catch {
              return descriptor;
            }
          })
        );
      }),
      get: t.input(agents.get.input).output(agents.get.output).handler(async ({ context, input }) => {
        if (input.workspaceId) {
          await context.aiService.waitForInit(input.workspaceId);
        }
        const { runtime, discoveryPath } = await resolveAgentDiscoveryContext(context, input);
        return readAgentDefinition(runtime, discoveryPath, input.agentId);
      })
    },
    agentSkills: {
      list: t.input(agentSkills.list.input).output(agentSkills.list.output).handler(async ({ context, input }) => {
        if (input.workspaceId) {
          await context.aiService.waitForInit(input.workspaceId);
        }
        const { runtime, discoveryPath } = await resolveAgentDiscoveryContext(context, input);
        return discoverAgentSkills(runtime, discoveryPath);
      }),
      get: t.input(agentSkills.get.input).output(agentSkills.get.output).handler(async ({ context, input }) => {
        if (input.workspaceId) {
          await context.aiService.waitForInit(input.workspaceId);
        }
        const { runtime, discoveryPath } = await resolveAgentDiscoveryContext(context, input);
        const result = await readAgentSkill(runtime, discoveryPath, input.skillName);
        return result.package;
      })
    },
    providers: {
      list: t.input(providers.list.input).output(providers.list.output).handler(({ context }) => context.providerService.list()),
      getConfig: t.input(providers.getConfig.input).output(providers.getConfig.output).handler(({ context }) => context.providerService.getConfig()),
      setProviderConfig: t.input(providers.setProviderConfig.input).output(providers.setProviderConfig.output).handler(
        ({ context, input }) => context.providerService.setConfig(input.provider, input.keyPath, input.value)
      ),
      setModels: t.input(providers.setModels.input).output(providers.setModels.output).handler(
        ({ context, input }) => context.providerService.setModels(input.provider, input.models)
      ),
      onConfigChanged: t.input(providers.onConfigChanged.input).output(providers.onConfigChanged.output).handler(async function* ({ context }) {
        let resolveNext = null;
        let pendingNotification = false;
        let ended = false;
        const push = () => {
          if (ended) return;
          if (resolveNext) {
            const resolve3 = resolveNext;
            resolveNext = null;
            resolve3();
          } else {
            pendingNotification = true;
          }
        };
        const unsubscribe = context.providerService.onConfigChanged(push);
        try {
          while (!ended) {
            if (pendingNotification) {
              pendingNotification = false;
              yield void 0;
              continue;
            }
            await new Promise((resolve3) => {
              resolveNext = resolve3;
            });
            yield void 0;
          }
        } finally {
          ended = true;
          unsubscribe();
        }
      })
    },
    general: {
      listDirectory: t.input(general.listDirectory.input).output(general.listDirectory.output).handler(async ({ context, input }) => {
        return context.projectService.listDirectory(input.path);
      }),
      createDirectory: t.input(general.createDirectory.input).output(general.createDirectory.output).handler(async ({ context, input }) => {
        return context.projectService.createDirectory(input.path);
      }),
      ping: t.input(general.ping.input).output(general.ping.output).handler(({ input }) => {
        return `Pong: ${input}`;
      }),
      tick: t.input(general.tick.input).output(general.tick.output).handler(async function* ({ input }) {
        for (let i = 1; i <= input.count; i++) {
          yield { tick: i, timestamp: Date.now() };
          if (i < input.count) {
            await new Promise((r) => setTimeout(r, input.intervalMs));
          }
        }
      }),
      openInEditor: t.input(general.openInEditor.input).output(general.openInEditor.output).handler(async ({ context, input }) => {
        return context.editorService.openInEditor(
          input.workspaceId,
          input.targetPath,
          input.editorConfig
        );
      })
    },
    projects: {
      list: t.input(projects.list.input).output(projects.list.output).handler(({ context }) => {
        return context.projectService.list();
      }),
      create: t.input(projects.create.input).output(projects.create.output).handler(async ({ context, input }) => {
        return context.projectService.create(input.projectPath);
      }),
      pickDirectory: t.input(projects.pickDirectory.input).output(projects.pickDirectory.output).handler(async ({ context }) => {
        return context.projectService.pickDirectory();
      }),
      getFileCompletions: t.input(projects.getFileCompletions.input).output(projects.getFileCompletions.output).handler(async ({ context, input }) => {
        return context.projectService.getFileCompletions(
          input.projectPath,
          input.query,
          input.limit
        );
      }),
      runtimeAvailability: t.input(projects.runtimeAvailability.input).output(projects.runtimeAvailability.output).handler(async ({ input }) => {
        return checkRuntimeAvailability(input.projectPath);
      }),
      listBranches: t.input(projects.listBranches.input).output(projects.listBranches.output).handler(async ({ context, input }) => {
        return context.projectService.listBranches(input.projectPath);
      }),
      gitInit: t.input(projects.gitInit.input).output(projects.gitInit.output).handler(async ({ context, input }) => {
        return context.projectService.gitInit(input.projectPath);
      }),
      remove: t.input(projects.remove.input).output(projects.remove.output).handler(async ({ context, input }) => {
        return context.projectService.remove(input.projectPath);
      }),
      secrets: {
        get: t.input(projects.secrets.get.input).output(projects.secrets.get.output).handler(({ context, input }) => {
          return context.projectService.getSecrets(input.projectPath);
        }),
        update: t.input(projects.secrets.update.input).output(projects.secrets.update.output).handler(async ({ context, input }) => {
          return context.projectService.updateSecrets(input.projectPath, input.secrets);
        })
      },
      mcp: {
        list: t.input(projects.mcp.list.input).output(projects.mcp.list.output).handler(({ context, input }) => context.mcpConfigService.listServers(input.projectPath)),
        add: t.input(projects.mcp.add.input).output(projects.mcp.add.output).handler(async ({ context, input }) => {
          const existing = await context.mcpConfigService.listServers(input.projectPath);
          const existingServer = existing[input.name];
          const transport = input.transport ?? "stdio";
          const hasHeaders = Boolean(input.headers && Object.keys(input.headers).length > 0);
          const usesSecretHeaders = Boolean(
            input.headers && Object.values(input.headers).some(
              (v) => typeof v === "object" && v !== null && "secret" in v
            )
          );
          const action = (() => {
            if (!existingServer) {
              return "add";
            }
            if (existingServer.transport !== "stdio" && transport !== "stdio" && existingServer.transport === transport && existingServer.url === input.url && JSON.stringify(existingServer.headers ?? {}) !== JSON.stringify(input.headers ?? {})) {
              return "set_headers";
            }
            return "edit";
          })();
          const result = await context.mcpConfigService.addServer(input.projectPath, input.name, {
            transport,
            command: input.command,
            url: input.url,
            headers: input.headers
          });
          if (result.success) {
            context.telemetryService.capture({
              event: "mcp_server_config_changed",
              properties: {
                action,
                transport,
                has_headers: hasHeaders,
                uses_secret_headers: usesSecretHeaders
              }
            });
          }
          return result;
        }),
        remove: t.input(projects.mcp.remove.input).output(projects.mcp.remove.output).handler(async ({ context, input }) => {
          const existing = await context.mcpConfigService.listServers(input.projectPath);
          const server2 = existing[input.name];
          const result = await context.mcpConfigService.removeServer(
            input.projectPath,
            input.name
          );
          if (result.success && server2) {
            const hasHeaders = server2.transport !== "stdio" && Boolean(server2.headers && Object.keys(server2.headers).length > 0);
            const usesSecretHeaders = server2.transport !== "stdio" && Boolean(
              server2.headers && Object.values(server2.headers).some(
                (v) => typeof v === "object" && v !== null && "secret" in v
              )
            );
            context.telemetryService.capture({
              event: "mcp_server_config_changed",
              properties: {
                action: "remove",
                transport: server2.transport,
                has_headers: hasHeaders,
                uses_secret_headers: usesSecretHeaders
              }
            });
          }
          return result;
        }),
        test: t.input(projects.mcp.test.input).output(projects.mcp.test.output).handler(async ({ context, input }) => {
          const start = Date.now();
          const secrets = secretsToRecord(context.projectService.getSecrets(input.projectPath));
          const configuredTransport = input.name ? (await context.mcpConfigService.listServers(input.projectPath))[input.name]?.transport : void 0;
          const transport = configuredTransport ?? (input.command ? "stdio" : input.transport ?? "auto");
          const result = await context.mcpServerManager.test({
            projectPath: input.projectPath,
            name: input.name,
            command: input.command,
            transport: input.transport,
            url: input.url,
            headers: input.headers,
            projectSecrets: secrets
          });
          const durationMs = Date.now() - start;
          const categorizeError = (error) => {
            const lower = error.toLowerCase();
            if (lower.includes("timed out")) {
              return "timeout";
            }
            if (lower.includes("econnrefused") || lower.includes("econnreset") || lower.includes("enotfound") || lower.includes("ehostunreach")) {
              return "connect";
            }
            if (/\b(400|401|403|404|405|500|502|503)\b/.test(lower)) {
              return "http_status";
            }
            return "unknown";
          };
          context.telemetryService.capture({
            event: "mcp_server_tested",
            properties: {
              transport,
              success: result.success,
              duration_ms_b2: roundToBase2(durationMs),
              ...result.success ? {} : { error_category: categorizeError(result.error) }
            }
          });
          return result;
        }),
        setEnabled: t.input(projects.mcp.setEnabled.input).output(projects.mcp.setEnabled.output).handler(async ({ context, input }) => {
          const existing = await context.mcpConfigService.listServers(input.projectPath);
          const server2 = existing[input.name];
          const result = await context.mcpConfigService.setServerEnabled(
            input.projectPath,
            input.name,
            input.enabled
          );
          if (result.success && server2) {
            const hasHeaders = server2.transport !== "stdio" && Boolean(server2.headers && Object.keys(server2.headers).length > 0);
            const usesSecretHeaders = server2.transport !== "stdio" && Boolean(
              server2.headers && Object.values(server2.headers).some(
                (v) => typeof v === "object" && v !== null && "secret" in v
              )
            );
            context.telemetryService.capture({
              event: "mcp_server_config_changed",
              properties: {
                action: input.enabled ? "enable" : "disable",
                transport: server2.transport,
                has_headers: hasHeaders,
                uses_secret_headers: usesSecretHeaders
              }
            });
          }
          return result;
        }),
        setToolAllowlist: t.input(projects.mcp.setToolAllowlist.input).output(projects.mcp.setToolAllowlist.output).handler(async ({ context, input }) => {
          const existing = await context.mcpConfigService.listServers(input.projectPath);
          const server2 = existing[input.name];
          const result = await context.mcpConfigService.setToolAllowlist(
            input.projectPath,
            input.name,
            input.toolAllowlist
          );
          if (result.success && server2) {
            const hasHeaders = server2.transport !== "stdio" && Boolean(server2.headers && Object.keys(server2.headers).length > 0);
            const usesSecretHeaders = server2.transport !== "stdio" && Boolean(
              server2.headers && Object.values(server2.headers).some(
                (v) => typeof v === "object" && v !== null && "secret" in v
              )
            );
            context.telemetryService.capture({
              event: "mcp_server_config_changed",
              properties: {
                action: "set_tool_allowlist",
                transport: server2.transport,
                has_headers: hasHeaders,
                uses_secret_headers: usesSecretHeaders,
                tool_allowlist_size_b2: roundToBase2(input.toolAllowlist.length)
              }
            });
          }
          return result;
        })
      },
      idleCompaction: {
        get: t.input(projects.idleCompaction.get.input).output(projects.idleCompaction.get.output).handler(({ context, input }) => ({
          hours: context.projectService.getIdleCompactionHours(input.projectPath)
        })),
        set: t.input(projects.idleCompaction.set.input).output(projects.idleCompaction.set.output).handler(
          ({ context, input }) => context.projectService.setIdleCompactionHours(input.projectPath, input.hours)
        )
      },
      sections: {
        list: t.input(projects.sections.list.input).output(projects.sections.list.output).handler(({ context, input }) => context.projectService.listSections(input.projectPath)),
        create: t.input(projects.sections.create.input).output(projects.sections.create.output).handler(
          ({ context, input }) => context.projectService.createSection(input.projectPath, input.name, input.color)
        ),
        update: t.input(projects.sections.update.input).output(projects.sections.update.output).handler(
          ({ context, input }) => context.projectService.updateSection(input.projectPath, input.sectionId, {
            name: input.name,
            color: input.color
          })
        ),
        remove: t.input(projects.sections.remove.input).output(projects.sections.remove.output).handler(
          ({ context, input }) => context.projectService.removeSection(input.projectPath, input.sectionId)
        ),
        reorder: t.input(projects.sections.reorder.input).output(projects.sections.reorder.output).handler(
          ({ context, input }) => context.projectService.reorderSections(input.projectPath, input.sectionIds)
        ),
        assignWorkspace: t.input(projects.sections.assignWorkspace.input).output(projects.sections.assignWorkspace.output).handler(async ({ context, input }) => {
          const result = await context.projectService.assignWorkspaceToSection(
            input.projectPath,
            input.workspaceId,
            input.sectionId
          );
          if (result.success) {
            await context.workspaceService.refreshAndEmitMetadata(input.workspaceId);
          }
          return result;
        })
      }
    },
    nameGeneration: {
      generate: t.input(nameGeneration.generate.input).output(nameGeneration.generate.output).handler(async ({ context, input }) => {
        const model = await selectModelForNameGeneration(
          context.aiService,
          input.preferredModels,
          input.userModel
        );
        if (!model) {
          return {
            success: false,
            error: {
              type: "unknown",
              raw: "No model available for name generation."
            }
          };
        }
        const result = await generateWorkspaceIdentity(input.message, model, context.aiService);
        if (!result.success) {
          return result;
        }
        return {
          success: true,
          data: { name: result.data.name, title: result.data.title, modelUsed: model }
        };
      })
    },
    lattice: {
      getInfo: t.input(lattice.getInfo.input).output(lattice.getInfo.output).handler(async ({ context }) => {
        return context.latticeService.getLatticeInfo();
      }),
      listTemplates: t.input(lattice.listTemplates.input).output(lattice.listTemplates.output).handler(async ({ context }) => {
        return context.latticeService.listTemplates();
      }),
      listPresets: t.input(lattice.listPresets.input).output(lattice.listPresets.output).handler(async ({ context, input }) => {
        return context.latticeService.listPresets(input.template, input.org);
      }),
      listWorkspaces: t.input(lattice.listWorkspaces.input).output(lattice.listWorkspaces.output).handler(async ({ context }) => {
        return context.latticeService.listWorkspaces();
      })
    },
    workspace: {
      list: t.input(workspace.list.input).output(workspace.list.output).handler(async ({ context, input }) => {
        const allWorkspaces = await context.workspaceService.list();
        if (input?.archived) {
          return allWorkspaces.filter((w) => isWorkspaceArchived(w.archivedAt, w.unarchivedAt));
        }
        return allWorkspaces.filter((w) => !isWorkspaceArchived(w.archivedAt, w.unarchivedAt));
      }),
      create: t.input(workspace.create.input).output(workspace.create.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.create(
          input.projectPath,
          input.branchName,
          input.trunkBranch,
          input.title,
          input.runtimeConfig,
          input.sectionId
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, metadata: result.data.metadata };
      }),
      remove: t.input(workspace.remove.input).output(workspace.remove.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.remove(
          input.workspaceId,
          input.options?.force
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true };
      }),
      updateAgentAISettings: t.input(workspace.updateAgentAISettings.input).output(workspace.updateAgentAISettings.output).handler(async ({ context, input }) => {
        return context.workspaceService.updateAgentAISettings(
          input.workspaceId,
          input.agentId,
          input.aiSettings
        );
      }),
      rename: t.input(workspace.rename.input).output(workspace.rename.output).handler(async ({ context, input }) => {
        return context.workspaceService.rename(input.workspaceId, input.newName);
      }),
      updateModeAISettings: t.input(workspace.updateModeAISettings.input).output(workspace.updateModeAISettings.output).handler(async ({ context, input }) => {
        return context.workspaceService.updateModeAISettings(
          input.workspaceId,
          input.mode,
          input.aiSettings
        );
      }),
      updateTitle: t.input(workspace.updateTitle.input).output(workspace.updateTitle.output).handler(async ({ context, input }) => {
        return context.workspaceService.updateTitle(input.workspaceId, input.title);
      }),
      archive: t.input(workspace.archive.input).output(workspace.archive.output).handler(async ({ context, input }) => {
        return context.workspaceService.archive(input.workspaceId);
      }),
      unarchive: t.input(workspace.unarchive.input).output(workspace.unarchive.output).handler(async ({ context, input }) => {
        return context.workspaceService.unarchive(input.workspaceId);
      }),
      fork: t.input(workspace.fork.input).output(workspace.fork.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.fork(
          input.sourceWorkspaceId,
          input.newName
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return {
          success: true,
          metadata: result.data.metadata,
          projectPath: result.data.projectPath
        };
      }),
      sendMessage: t.input(workspace.sendMessage.input).output(workspace.sendMessage.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.sendMessage(
          input.workspaceId,
          input.message,
          input.options
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: {} };
      }),
      answerAskUserQuestion: t.input(workspace.answerAskUserQuestion.input).output(workspace.answerAskUserQuestion.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.answerAskUserQuestion(
          input.workspaceId,
          input.toolCallId,
          input.answers
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: void 0 };
      }),
      resumeStream: t.input(workspace.resumeStream.input).output(workspace.resumeStream.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.resumeStream(
          input.workspaceId,
          input.options
        );
        if (!result.success) {
          const error = typeof result.error === "string" ? { type: "unknown", raw: result.error } : result.error;
          return { success: false, error };
        }
        return { success: true, data: void 0 };
      }),
      interruptStream: t.input(workspace.interruptStream.input).output(workspace.interruptStream.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.interruptStream(
          input.workspaceId,
          input.options
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: void 0 };
      }),
      clearQueue: t.input(workspace.clearQueue.input).output(workspace.clearQueue.output).handler(({ context, input }) => {
        const result = context.workspaceService.clearQueue(input.workspaceId);
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: void 0 };
      }),
      truncateHistory: t.input(workspace.truncateHistory.input).output(workspace.truncateHistory.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.truncateHistory(
          input.workspaceId,
          input.percentage
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: void 0 };
      }),
      replaceChatHistory: t.input(workspace.replaceChatHistory.input).output(workspace.replaceChatHistory.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.replaceHistory(
          input.workspaceId,
          input.summaryMessage,
          { deletePlanFile: input.deletePlanFile }
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: void 0 };
      }),
      getDevcontainerInfo: t.input(workspace.getDevcontainerInfo.input).output(workspace.getDevcontainerInfo.output).handler(async ({ context, input }) => {
        return context.workspaceService.getDevcontainerInfo(input.workspaceId);
      }),
      getInfo: t.input(workspace.getInfo.input).output(workspace.getInfo.output).handler(async ({ context, input }) => {
        return context.workspaceService.getInfo(input.workspaceId);
      }),
      getLastLlmRequest: t.input(workspace.getLastLlmRequest.input).output(workspace.getLastLlmRequest.output).handler(({ context, input }) => {
        return context.aiService.debugGetLastLlmRequest(input.workspaceId);
      }),
      getFullReplay: t.input(workspace.getFullReplay.input).output(workspace.getFullReplay.output).handler(async ({ context, input }) => {
        return context.workspaceService.getFullReplay(input.workspaceId);
      }),
      executeBash: t.input(workspace.executeBash.input).output(workspace.executeBash.output).handler(async ({ context, input }) => {
        const result = await context.workspaceService.executeBash(
          input.workspaceId,
          input.script,
          input.options
        );
        if (!result.success) {
          return { success: false, error: result.error };
        }
        return { success: true, data: result.data };
      }),
      getFileCompletions: t.input(workspace.getFileCompletions.input).output(workspace.getFileCompletions.output).handler(async ({ context, input }) => {
        return context.workspaceService.getFileCompletions(
          input.workspaceId,
          input.query,
          input.limit
        );
      }),
      onChat: t.input(workspace.onChat.input).output(workspace.onChat.output).handler(async function* ({ context, input }) {
        const session = context.workspaceService.getOrCreateSession(input.workspaceId);
        const { push, iterate, end } = createAsyncMessageQueue();
        const unsubscribe = session.onChatEvent(({ message }) => {
          push(message);
        });
        await session.replayHistory(({ message }) => {
          push(message);
        });
        const HEARTBEAT_INTERVAL_MS = 5e3;
        const heartbeatInterval = setInterval(() => {
          push({ type: "heartbeat" });
        }, HEARTBEAT_INTERVAL_MS);
        try {
          yield* iterate();
        } finally {
          clearInterval(heartbeatInterval);
          end();
          unsubscribe();
        }
      }),
      onMetadata: t.input(workspace.onMetadata.input).output(workspace.onMetadata.output).handler(async function* ({ context }) {
        const service = context.workspaceService;
        let resolveNext = null;
        const queue = [];
        let ended = false;
        const push = (event) => {
          if (ended) return;
          if (resolveNext) {
            const resolve3 = resolveNext;
            resolveNext = null;
            resolve3(event);
          } else {
            queue.push(event);
          }
        };
        const onMetadata = (event) => {
          push(event);
        };
        service.on("metadata", onMetadata);
        try {
          while (!ended) {
            if (queue.length > 0) {
              yield queue.shift();
            } else {
              const event = await new Promise((resolve3) => {
                resolveNext = resolve3;
              });
              yield event;
            }
          }
        } finally {
          ended = true;
          service.off("metadata", onMetadata);
        }
      }),
      activity: {
        list: t.input(workspace.activity.list.input).output(workspace.activity.list.output).handler(async ({ context }) => {
          return context.workspaceService.getActivityList();
        }),
        subscribe: t.input(workspace.activity.subscribe.input).output(workspace.activity.subscribe.output).handler(async function* ({ context }) {
          const service = context.workspaceService;
          let resolveNext = null;
          const queue = [];
          let ended = false;
          const push = (event) => {
            if (ended) return;
            if (resolveNext) {
              const resolve3 = resolveNext;
              resolveNext = null;
              resolve3(event);
            } else {
              queue.push(event);
            }
          };
          const onActivity = (event) => {
            push(event);
          };
          service.on("activity", onActivity);
          try {
            while (!ended) {
              if (queue.length > 0) {
                yield queue.shift();
              } else {
                const event = await new Promise((resolve3) => {
                  resolveNext = resolve3;
                });
                yield event;
              }
            }
          } finally {
            ended = true;
            service.off("activity", onActivity);
          }
        })
      },
      getPlanContent: t.input(workspace.getPlanContent.input).output(workspace.getPlanContent.output).handler(async ({ context, input }) => {
        const metadata = await context.workspaceService.getInfo(input.workspaceId);
        if (!metadata) {
          return { success: false, error: `Workspace not found: ${input.workspaceId}` };
        }
        const runtime = createRuntimeForWorkspace(metadata);
        const result = await readPlanFile(
          runtime,
          metadata.name,
          metadata.projectName,
          input.workspaceId
        );
        if (!result.exists) {
          return { success: false, error: `Plan file not found at ${result.path}` };
        }
        return { success: true, data: { content: result.content, path: result.path } };
      }),
      backgroundBashes: {
        subscribe: t.input(workspace.backgroundBashes.subscribe.input).output(workspace.backgroundBashes.subscribe.output).handler(async function* ({ context, input }) {
          const service = context.workspaceService;
          const { workspaceId } = input;
          const getState = async () => ({
            processes: await service.listBackgroundProcesses(workspaceId),
            foregroundToolCallIds: service.getForegroundToolCallIds(workspaceId)
          });
          const queue = createAsyncEventQueue();
          const onChange = (changedWorkspaceId) => {
            if (changedWorkspaceId === workspaceId) {
              void getState().then(queue.push);
            }
          };
          service.onBackgroundBashChange(onChange);
          try {
            yield await getState();
            yield* queue.iterate();
          } finally {
            queue.end();
            service.offBackgroundBashChange(onChange);
          }
        }),
        terminate: t.input(workspace.backgroundBashes.terminate.input).output(workspace.backgroundBashes.terminate.output).handler(async ({ context, input }) => {
          const result = await context.workspaceService.terminateBackgroundProcess(
            input.workspaceId,
            input.processId
          );
          if (!result.success) {
            return { success: false, error: result.error };
          }
          return { success: true, data: void 0 };
        }),
        sendToBackground: t.input(workspace.backgroundBashes.sendToBackground.input).output(workspace.backgroundBashes.sendToBackground.output).handler(({ context, input }) => {
          const result = context.workspaceService.sendToBackground(input.toolCallId);
          if (!result.success) {
            return { success: false, error: result.error };
          }
          return { success: true, data: void 0 };
        }),
        getOutput: t.input(workspace.backgroundBashes.getOutput.input).output(workspace.backgroundBashes.getOutput.output).handler(async ({ context, input }) => {
          const result = await context.workspaceService.getBackgroundProcessOutput(
            input.workspaceId,
            input.processId,
            { fromOffset: input.fromOffset, tailBytes: input.tailBytes }
          );
          if (!result.success) {
            return { success: false, error: result.error };
          }
          return { success: true, data: result.data };
        })
      },
      getPostCompactionState: t.input(workspace.getPostCompactionState.input).output(workspace.getPostCompactionState.output).handler(({ context, input }) => {
        return context.workspaceService.getPostCompactionState(input.workspaceId);
      }),
      setPostCompactionExclusion: t.input(workspace.setPostCompactionExclusion.input).output(workspace.setPostCompactionExclusion.output).handler(async ({ context, input }) => {
        return context.workspaceService.setPostCompactionExclusion(
          input.workspaceId,
          input.itemId,
          input.excluded
        );
      }),
      getSessionUsage: t.input(workspace.getSessionUsage.input).output(workspace.getSessionUsage.output).handler(async ({ context, input }) => {
        return context.sessionUsageService.getSessionUsage(input.workspaceId);
      }),
      getSessionUsageBatch: t.input(workspace.getSessionUsageBatch.input).output(workspace.getSessionUsageBatch.output).handler(async ({ context, input }) => {
        return context.sessionUsageService.getSessionUsageBatch(input.workspaceIds);
      }),
      stats: {
        subscribe: t.input(workspace.stats.subscribe.input).output(workspace.stats.subscribe.output).handler(async function* ({ context, input }) {
          const workspaceId = input.workspaceId;
          context.sessionTimingService.addSubscriber(workspaceId);
          const queue = createAsyncEventQueue();
          let pending = Promise.resolve();
          const enqueueSnapshot = () => {
            pending = pending.then(async () => {
              queue.push(await context.sessionTimingService.getSnapshot(workspaceId));
            });
          };
          const onChange = (changedWorkspaceId) => {
            if (changedWorkspaceId !== workspaceId) {
              return;
            }
            enqueueSnapshot();
          };
          context.sessionTimingService.onStatsChange(onChange);
          try {
            queue.push(await context.sessionTimingService.getSnapshot(workspaceId));
            yield* queue.iterate();
          } finally {
            queue.end();
            context.sessionTimingService.offStatsChange(onChange);
            context.sessionTimingService.removeSubscriber(workspaceId);
          }
        }),
        clear: t.input(workspace.stats.clear.input).output(workspace.stats.clear.output).handler(async ({ context, input }) => {
          try {
            await context.sessionTimingService.clearTimingFile(input.workspaceId);
            return { success: true, data: void 0 };
          } catch (error) {
            const message = error instanceof Error ? error.message : String(error);
            return { success: false, error: message };
          }
        })
      },
      mcp: {
        get: t.input(workspace.mcp.get.input).output(workspace.mcp.get.output).handler(async ({ context, input }) => {
          try {
            return await context.workspaceMcpOverridesService.getOverridesForWorkspace(
              input.workspaceId
            );
          } catch {
            return {};
          }
        }),
        set: t.input(workspace.mcp.set.input).output(workspace.mcp.set.output).handler(async ({ context, input }) => {
          try {
            await context.workspaceMcpOverridesService.setOverridesForWorkspace(
              input.workspaceId,
              input.overrides
            );
            return { success: true, data: void 0 };
          } catch (error) {
            const message = error instanceof Error ? error.message : String(error);
            return { success: false, error: message };
          }
        })
      }
    },
    tasks: {
      create: t.input(tasks.create.input).output(tasks.create.output).handler(({ context, input }) => {
        const thinkingLevel = input.thinkingLevel === "off" || input.thinkingLevel === "low" || input.thinkingLevel === "medium" || input.thinkingLevel === "high" || input.thinkingLevel === "xhigh" ? input.thinkingLevel : void 0;
        return context.taskService.create({
          parentWorkspaceId: input.parentWorkspaceId,
          kind: input.kind,
          agentId: input.agentId,
          agentType: input.agentType,
          prompt: input.prompt,
          title: input.title,
          modelString: input.modelString,
          thinkingLevel
        });
      })
    },
    window: {
      setTitle: t.input(window2.setTitle.input).output(window2.setTitle.output).handler(({ context, input }) => {
        return context.windowService.setTitle(input.title);
      })
    },
    terminal: {
      create: t.input(terminal.create.input).output(terminal.create.output).handler(async ({ context, input }) => {
        return context.terminalService.create(input);
      }),
      close: t.input(terminal.close.input).output(terminal.close.output).handler(({ context, input }) => {
        return context.terminalService.close(input.sessionId);
      }),
      resize: t.input(terminal.resize.input).output(terminal.resize.output).handler(({ context, input }) => {
        return context.terminalService.resize(input);
      }),
      sendInput: t.input(terminal.sendInput.input).output(terminal.sendInput.output).handler(({ context, input }) => {
        context.terminalService.sendInput(input.sessionId, input.data);
      }),
      onOutput: t.input(terminal.onOutput.input).output(terminal.onOutput.output).handler(async function* ({ context, input }) {
        let resolveNext = null;
        const queue = [];
        let ended = false;
        const push = (data) => {
          if (ended) return;
          if (resolveNext) {
            const resolve3 = resolveNext;
            resolveNext = null;
            resolve3(data);
          } else {
            queue.push(data);
          }
        };
        const unsubscribe = context.terminalService.onOutput(input.sessionId, push);
        try {
          while (!ended) {
            if (queue.length > 0) {
              yield queue.shift();
            } else {
              const data = await new Promise((resolve3) => {
                resolveNext = resolve3;
              });
              yield data;
            }
          }
        } finally {
          ended = true;
          unsubscribe();
        }
      }),
      attach: t.input(terminal.attach.input).output(terminal.attach.output).handler(async function* ({ context, input }) {
        let resolveNext = null;
        const queue = [];
        let ended = false;
        const push = (msg) => {
          if (ended) return;
          if (resolveNext) {
            const resolve3 = resolveNext;
            resolveNext = null;
            resolve3(msg);
          } else {
            queue.push(msg);
          }
        };
        const unsubscribe = context.terminalService.onOutput(input.sessionId, (data) => {
          push({ type: "output", data });
        });
        try {
          const screenState = context.terminalService.getScreenState(input.sessionId);
          yield { type: "screenState", data: screenState };
          while (!ended) {
            if (queue.length > 0) {
              yield queue.shift();
            } else {
              const msg = await new Promise((resolve3) => {
                resolveNext = resolve3;
              });
              yield msg;
            }
          }
        } finally {
          ended = true;
          unsubscribe();
        }
      }),
      onExit: t.input(terminal.onExit.input).output(terminal.onExit.output).handler(async function* ({ context, input }) {
        let resolveNext = null;
        const queue = [];
        let ended = false;
        const push = (code) => {
          if (ended) return;
          if (resolveNext) {
            const resolve3 = resolveNext;
            resolveNext = null;
            resolve3(code);
          } else {
            queue.push(code);
          }
        };
        const unsubscribe = context.terminalService.onExit(input.sessionId, push);
        try {
          while (!ended) {
            if (queue.length > 0) {
              yield queue.shift();
              break;
            } else {
              const code = await new Promise((resolve3) => {
                resolveNext = resolve3;
              });
              yield code;
              break;
            }
          }
        } finally {
          ended = true;
          unsubscribe();
        }
      }),
      openWindow: t.input(terminal.openWindow.input).output(terminal.openWindow.output).handler(async ({ context, input }) => {
        return context.terminalService.openWindow(input.workspaceId, input.sessionId);
      }),
      closeWindow: t.input(terminal.closeWindow.input).output(terminal.closeWindow.output).handler(({ context, input }) => {
        return context.terminalService.closeWindow(input.workspaceId);
      }),
      listSessions: t.input(terminal.listSessions.input).output(terminal.listSessions.output).handler(({ context, input }) => {
        return context.terminalService.getWorkspaceSessionIds(input.workspaceId);
      }),
      openNative: t.input(terminal.openNative.input).output(terminal.openNative.output).handler(async ({ context, input }) => {
        return context.terminalService.openNative(input.workspaceId);
      })
    },
    update: {
      check: t.input(update.check.input).output(update.check.output).handler(async ({ context }) => {
        return context.updateService.check();
      }),
      download: t.input(update.download.input).output(update.download.output).handler(async ({ context }) => {
        return context.updateService.download();
      }),
      install: t.input(update.install.input).output(update.install.output).handler(({ context }) => {
        return context.updateService.install();
      }),
      onStatus: t.input(update.onStatus.input).output(update.onStatus.output).handler(async function* ({ context }) {
        const queue = createAsyncEventQueue();
        const unsubscribe = context.updateService.onStatus(queue.push);
        try {
          yield* queue.iterate();
        } finally {
          queue.end();
          unsubscribe();
        }
      })
    },
    menu: {
      onOpenSettings: t.input(menu.onOpenSettings.input).output(menu.onOpenSettings.output).handler(async function* ({ context }) {
        const queue = createAsyncEventQueue();
        const unsubscribe = context.menuEventService.onOpenSettings(() => queue.push(true));
        try {
          for await (const _ of queue.iterate()) {
            yield void 0;
          }
        } finally {
          queue.end();
          unsubscribe();
        }
      })
    },
    voice: {
      transcribe: t.input(voice.transcribe.input).output(voice.transcribe.output).handler(async ({ context, input }) => {
        return context.voiceService.transcribe(input.audioBase64);
      })
    },
    experiments: {
      getAll: t.input(experiments.getAll.input).output(experiments.getAll.output).handler(({ context }) => {
        return context.experimentsService.getAll();
      }),
      reload: t.input(experiments.reload.input).output(experiments.reload.output).handler(async ({ context }) => {
        await context.experimentsService.refreshAll();
      })
    },
    debug: {
      triggerStreamError: t.input(debug.triggerStreamError.input).output(debug.triggerStreamError.output).handler(({ context, input }) => {
        return context.workspaceService.debugTriggerStreamError(
          input.workspaceId,
          input.errorMessage
        );
      })
    },
    telemetry: {
      track: t.input(telemetry.track.input).output(telemetry.track.output).handler(({ context, input }) => {
        context.telemetryService.capture(input);
      }),
      status: t.input(telemetry.status.input).output(telemetry.status.output).handler(({ context }) => {
        return {
          enabled: context.telemetryService.isEnabled(),
          explicit: context.telemetryService.isExplicitlyDisabled()
        };
      })
    },
    signing: {
      capabilities: t.input(signing.capabilities.input).output(signing.capabilities.output).handler(async ({ context }) => {
        return context.signingService.getCapabilities();
      }),
      signMessage: t.input(signing.signMessage.input).output(signing.signMessage.output).handler(({ context, input }) => {
        return context.signingService.signMessage(input.content);
      }),
      clearIdentityCache: t.input(signing.clearIdentityCache.input).output(signing.clearIdentityCache.output).handler(({ context }) => {
        context.signingService.clearIdentityCache();
        return { success: true };
      })
    }
  });
};

// node_modules/@orpc/client/dist/adapters/fetch/index.mjs
init_dist();

// node_modules/@orpc/standard-server-fetch/dist/index.mjs
init_dist();
init_dist2();
function toEventIterator(stream, options = {}) {
  const eventStream = stream?.pipeThrough(new TextDecoderStream()).pipeThrough(new EventDecoderStream());
  const reader = eventStream?.getReader();
  let span;
  let isCancelled = false;
  return new AsyncIteratorClass(async () => {
    span ??= startSpan("consume_event_iterator_stream");
    try {
      while (true) {
        if (reader === void 0) {
          return { done: true, value: void 0 };
        }
        const { done, value: value2 } = await runInSpanContext(span, () => reader.read());
        if (done) {
          if (isCancelled) {
            throw new AbortError("Stream was cancelled");
          }
          return { done: true, value: void 0 };
        }
        switch (value2.event) {
          case "message": {
            let message = parseEmptyableJSON(value2.data);
            if (isTypescriptObject(message)) {
              message = withEventMeta(message, value2);
            }
            span?.addEvent("message");
            return { done: false, value: message };
          }
          case "error": {
            let error = new ErrorEvent({
              data: parseEmptyableJSON(value2.data)
            });
            error = withEventMeta(error, value2);
            span?.addEvent("error");
            throw error;
          }
          case "done": {
            let done2 = parseEmptyableJSON(value2.data);
            if (isTypescriptObject(done2)) {
              done2 = withEventMeta(done2, value2);
            }
            span?.addEvent("done");
            return { done: true, value: done2 };
          }
          default: {
            span?.addEvent("maybe_keepalive");
          }
        }
      }
    } catch (e) {
      if (!(e instanceof ErrorEvent)) {
        setSpanError(span, e, options);
      }
      throw e;
    }
  }, async (reason) => {
    try {
      if (reason !== "next") {
        isCancelled = true;
        span?.addEvent("cancelled");
      }
      await runInSpanContext(span, () => reader?.cancel());
    } catch (e) {
      setSpanError(span, e, options);
      throw e;
    } finally {
      span?.end();
    }
  });
}
function toEventStream(iterator, options = {}) {
  const keepAliveEnabled = options.eventIteratorKeepAliveEnabled ?? true;
  const keepAliveInterval = options.eventIteratorKeepAliveInterval ?? 5e3;
  const keepAliveComment = options.eventIteratorKeepAliveComment ?? "";
  const initialCommentEnabled = options.eventIteratorInitialCommentEnabled ?? true;
  const initialComment = options.eventIteratorInitialComment ?? "";
  let cancelled = false;
  let timeout;
  let span;
  const stream = new ReadableStream({
    start(controller) {
      span = startSpan("stream_event_iterator");
      if (initialCommentEnabled) {
        controller.enqueue(encodeEventMessage({
          comments: [initialComment]
        }));
      }
    },
    async pull(controller) {
      try {
        if (keepAliveEnabled) {
          timeout = setInterval(() => {
            controller.enqueue(encodeEventMessage({
              comments: [keepAliveComment]
            }));
            span?.addEvent("keepalive");
          }, keepAliveInterval);
        }
        const value2 = await runInSpanContext(span, () => iterator.next());
        clearInterval(timeout);
        if (cancelled) {
          return;
        }
        const meta = getEventMeta(value2.value);
        if (!value2.done || value2.value !== void 0 || meta !== void 0) {
          const event = value2.done ? "done" : "message";
          controller.enqueue(encodeEventMessage({
            ...meta,
            event,
            data: stringifyJSON(value2.value)
          }));
          span?.addEvent(event);
        }
        if (value2.done) {
          controller.close();
          span?.end();
        }
      } catch (err) {
        clearInterval(timeout);
        if (cancelled) {
          return;
        }
        if (err instanceof ErrorEvent) {
          controller.enqueue(encodeEventMessage({
            ...getEventMeta(err),
            event: "error",
            data: stringifyJSON(err.data)
          }));
          span?.addEvent("error");
          controller.close();
        } else {
          setSpanError(span, err);
          controller.error(err);
        }
        span?.end();
      }
    },
    async cancel() {
      try {
        cancelled = true;
        clearInterval(timeout);
        span?.addEvent("cancelled");
        await runInSpanContext(span, () => iterator.return?.());
      } catch (e) {
        setSpanError(span, e);
        throw e;
      } finally {
        span?.end();
      }
    }
  }).pipeThrough(new TextEncoderStream());
  return stream;
}
function toStandardBody(re2, options = {}) {
  return runWithSpan(
    { name: "parse_standard_body", signal: options.signal },
    async () => {
      const contentDisposition = re2.headers.get("content-disposition");
      if (typeof contentDisposition === "string") {
        const fileName = getFilenameFromContentDisposition(contentDisposition) ?? "blob";
        const blob2 = await re2.blob();
        return new File([blob2], fileName, {
          type: blob2.type
        });
      }
      const contentType = re2.headers.get("content-type");
      if (!contentType || contentType.startsWith("application/json")) {
        const text2 = await re2.text();
        return parseEmptyableJSON(text2);
      }
      if (contentType.startsWith("multipart/form-data")) {
        return await re2.formData();
      }
      if (contentType.startsWith("application/x-www-form-urlencoded")) {
        const text2 = await re2.text();
        return new URLSearchParams(text2);
      }
      if (contentType.startsWith("text/event-stream")) {
        return toEventIterator(re2.body, options);
      }
      if (contentType.startsWith("text/plain")) {
        return await re2.text();
      }
      const blob = await re2.blob();
      return new File([blob], "blob", {
        type: blob.type
      });
    }
  );
}
function toFetchBody(body, headers, options = {}) {
  const currentContentDisposition = headers.get("content-disposition");
  headers.delete("content-type");
  headers.delete("content-disposition");
  if (body === void 0) {
    return void 0;
  }
  if (body instanceof Blob) {
    headers.set("content-type", body.type);
    headers.set("content-length", body.size.toString());
    headers.set(
      "content-disposition",
      currentContentDisposition ?? generateContentDisposition(body instanceof File ? body.name : "blob")
    );
    return body;
  }
  if (body instanceof FormData) {
    return body;
  }
  if (body instanceof URLSearchParams) {
    return body;
  }
  if (isAsyncIteratorObject(body)) {
    headers.set("content-type", "text/event-stream");
    return toEventStream(body, options);
  }
  headers.set("content-type", "application/json");
  return stringifyJSON(body);
}
function toStandardHeaders(headers, standardHeaders = {}) {
  headers.forEach((value2, key) => {
    if (Array.isArray(standardHeaders[key])) {
      standardHeaders[key].push(value2);
    } else if (standardHeaders[key] !== void 0) {
      standardHeaders[key] = [standardHeaders[key], value2];
    } else {
      standardHeaders[key] = value2;
    }
  });
  return standardHeaders;
}
function toFetchHeaders(headers, fetchHeaders = new Headers()) {
  for (const [key, value2] of Object.entries(headers)) {
    if (Array.isArray(value2)) {
      for (const v of value2) {
        fetchHeaders.append(key, v);
      }
    } else if (value2 !== void 0) {
      fetchHeaders.append(key, value2);
    }
  }
  return fetchHeaders;
}
function toFetchRequest(request, options = {}) {
  const headers = toFetchHeaders(request.headers);
  const body = toFetchBody(request.body, headers, options);
  return new Request(request.url, {
    signal: request.signal,
    method: request.method,
    headers,
    body
  });
}
function toStandardLazyResponse(response, options = {}) {
  return {
    body: once(() => toStandardBody(response, options)),
    status: response.status,
    get headers() {
      const headers = toStandardHeaders(response.headers);
      Object.defineProperty(this, "headers", { value: headers, writable: true });
      return headers;
    },
    set headers(value2) {
      Object.defineProperty(this, "headers", { value: value2, writable: true });
    }
  };
}

// node_modules/@orpc/client/dist/shared/client.EX0cvH1U.mjs
init_dist();
init_dist2();
init_client_J7pEE4Uw();
init_client_BLtwTQUg();
var CompositeStandardLinkPlugin = class {
  plugins;
  constructor(plugins = []) {
    this.plugins = [...plugins].sort((a, b) => (a.order ?? 0) - (b.order ?? 0));
  }
  init(options) {
    for (const plugin of this.plugins) {
      plugin.init?.(options);
    }
  }
};
var StandardLink = class {
  constructor(codec, sender, options = {}) {
    this.codec = codec;
    this.sender = sender;
    const plugin = new CompositeStandardLinkPlugin(options.plugins);
    plugin.init(options);
    this.interceptors = toArray(options.interceptors);
    this.clientInterceptors = toArray(options.clientInterceptors);
  }
  interceptors;
  clientInterceptors;
  call(path21, input, options) {
    return runWithSpan(
      { name: `${ORPC_NAME}.${path21.join("/")}`, signal: options.signal },
      (span) => {
        span?.setAttribute("rpc.system", ORPC_NAME);
        span?.setAttribute("rpc.method", path21.join("."));
        if (isAsyncIteratorObject(input)) {
          input = asyncIteratorWithSpan(
            { name: "consume_event_iterator_input", signal: options.signal },
            input
          );
        }
        return intercept(this.interceptors, { ...options, path: path21, input }, async ({ path: path22, input: input2, ...options2 }) => {
          const otelConfig = getGlobalOtelConfig();
          let otelContext;
          const currentSpan = otelConfig?.trace.getActiveSpan() ?? span;
          if (currentSpan && otelConfig) {
            otelContext = otelConfig?.trace.setSpan(otelConfig.context.active(), currentSpan);
          }
          const request = await runWithSpan(
            { name: "encode_request", context: otelContext },
            () => this.codec.encode(path22, input2, options2)
          );
          const response = await intercept(
            this.clientInterceptors,
            { ...options2, input: input2, path: path22, request },
            ({ input: input3, path: path32, request: request2, ...options3 }) => {
              return runWithSpan(
                { name: "send_request", signal: options3.signal, context: otelContext },
                () => this.sender.call(request2, options3, path32, input3)
              );
            }
          );
          const output = await runWithSpan(
            { name: "decode_response", context: otelContext },
            () => this.codec.decode(response, options2, path22, input2)
          );
          if (isAsyncIteratorObject(output)) {
            return asyncIteratorWithSpan(
              { name: "consume_event_iterator_output", signal: options2.signal },
              output
            );
          }
          return output;
        });
      }
    );
  }
};
var STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES = {
  BIGINT: 0,
  DATE: 1,
  NAN: 2,
  UNDEFINED: 3,
  URL: 4,
  REGEXP: 5,
  SET: 6,
  MAP: 7
};
var StandardRPCJsonSerializer = class {
  customSerializers;
  constructor(options = {}) {
    this.customSerializers = options.customJsonSerializers ?? [];
    if (this.customSerializers.length !== new Set(this.customSerializers.map((custom) => custom.type)).size) {
      throw new Error("Custom serializer type must be unique.");
    }
  }
  serialize(data, segments = [], meta = [], maps = [], blobs = []) {
    for (const custom of this.customSerializers) {
      if (custom.condition(data)) {
        const result = this.serialize(custom.serialize(data), segments, meta, maps, blobs);
        meta.push([custom.type, ...segments]);
        return result;
      }
    }
    if (data instanceof Blob) {
      maps.push(segments);
      blobs.push(data);
      return [data, meta, maps, blobs];
    }
    if (typeof data === "bigint") {
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.BIGINT, ...segments]);
      return [data.toString(), meta, maps, blobs];
    }
    if (data instanceof Date) {
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.DATE, ...segments]);
      if (Number.isNaN(data.getTime())) {
        return [null, meta, maps, blobs];
      }
      return [data.toISOString(), meta, maps, blobs];
    }
    if (Number.isNaN(data)) {
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.NAN, ...segments]);
      return [null, meta, maps, blobs];
    }
    if (data instanceof URL) {
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.URL, ...segments]);
      return [data.toString(), meta, maps, blobs];
    }
    if (data instanceof RegExp) {
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.REGEXP, ...segments]);
      return [data.toString(), meta, maps, blobs];
    }
    if (data instanceof Set) {
      const result = this.serialize(Array.from(data), segments, meta, maps, blobs);
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.SET, ...segments]);
      return result;
    }
    if (data instanceof Map) {
      const result = this.serialize(Array.from(data.entries()), segments, meta, maps, blobs);
      meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.MAP, ...segments]);
      return result;
    }
    if (Array.isArray(data)) {
      const json = data.map((v, i) => {
        if (v === void 0) {
          meta.push([STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.UNDEFINED, ...segments, i]);
          return v;
        }
        return this.serialize(v, [...segments, i], meta, maps, blobs)[0];
      });
      return [json, meta, maps, blobs];
    }
    if (isObject(data)) {
      const json = {};
      for (const k in data) {
        if (k === "toJSON" && typeof data[k] === "function") {
          continue;
        }
        json[k] = this.serialize(data[k], [...segments, k], meta, maps, blobs)[0];
      }
      return [json, meta, maps, blobs];
    }
    return [data, meta, maps, blobs];
  }
  deserialize(json, meta, maps, getBlob) {
    const ref = { data: json };
    if (maps && getBlob) {
      maps.forEach((segments, i) => {
        let currentRef = ref;
        let preSegment = "data";
        segments.forEach((segment) => {
          currentRef = currentRef[preSegment];
          preSegment = segment;
        });
        currentRef[preSegment] = getBlob(i);
      });
    }
    for (const item of meta) {
      const type2 = item[0];
      let currentRef = ref;
      let preSegment = "data";
      for (let i = 1; i < item.length; i++) {
        currentRef = currentRef[preSegment];
        preSegment = item[i];
      }
      for (const custom of this.customSerializers) {
        if (custom.type === type2) {
          currentRef[preSegment] = custom.deserialize(currentRef[preSegment]);
          break;
        }
      }
      switch (type2) {
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.BIGINT:
          currentRef[preSegment] = BigInt(currentRef[preSegment]);
          break;
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.DATE:
          currentRef[preSegment] = new Date(currentRef[preSegment] ?? "Invalid Date");
          break;
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.NAN:
          currentRef[preSegment] = Number.NaN;
          break;
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.UNDEFINED:
          currentRef[preSegment] = void 0;
          break;
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.URL:
          currentRef[preSegment] = new URL(currentRef[preSegment]);
          break;
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.REGEXP: {
          const [, pattern, flags] = currentRef[preSegment].match(/^\/(.*)\/([a-z]*)$/);
          currentRef[preSegment] = new RegExp(pattern, flags);
          break;
        }
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.SET:
          currentRef[preSegment] = new Set(currentRef[preSegment]);
          break;
        case STANDARD_RPC_JSON_SERIALIZER_BUILT_IN_TYPES.MAP:
          currentRef[preSegment] = new Map(currentRef[preSegment]);
          break;
      }
    }
    return ref.data;
  }
};
function toHttpPath(path21) {
  return `/${path21.map(encodeURIComponent).join("/")}`;
}
function toStandardHeaders2(headers) {
  if (typeof headers.forEach === "function") {
    return toStandardHeaders(headers);
  }
  return headers;
}
function getMalformedResponseErrorCode(status) {
  return Object.entries(COMMON_ORPC_ERROR_DEFS).find(([, def]) => def.status === status)?.[0] ?? "MALFORMED_ORPC_ERROR_RESPONSE";
}
var StandardRPCLinkCodec = class {
  constructor(serializer, options) {
    this.serializer = serializer;
    this.baseUrl = options.url;
    this.maxUrlLength = options.maxUrlLength ?? 2083;
    this.fallbackMethod = options.fallbackMethod ?? "POST";
    this.expectedMethod = options.method ?? this.fallbackMethod;
    this.headers = options.headers ?? {};
  }
  baseUrl;
  maxUrlLength;
  fallbackMethod;
  expectedMethod;
  headers;
  async encode(path21, input, options) {
    let headers = toStandardHeaders2(await value(this.headers, options, path21, input));
    if (options.lastEventId !== void 0) {
      headers = mergeStandardHeaders(headers, { "last-event-id": options.lastEventId });
    }
    const expectedMethod = await value(this.expectedMethod, options, path21, input);
    const baseUrl = await value(this.baseUrl, options, path21, input);
    const url = new URL(baseUrl);
    url.pathname = `${url.pathname.replace(/\/$/, "")}${toHttpPath(path21)}`;
    const serialized = this.serializer.serialize(input);
    if (expectedMethod === "GET" && !(serialized instanceof FormData) && !isAsyncIteratorObject(serialized)) {
      const maxUrlLength = await value(this.maxUrlLength, options, path21, input);
      const getUrl = new URL(url);
      getUrl.searchParams.append("data", stringifyJSON(serialized));
      if (getUrl.toString().length <= maxUrlLength) {
        return {
          body: void 0,
          method: expectedMethod,
          headers,
          url: getUrl,
          signal: options.signal
        };
      }
    }
    return {
      url,
      method: expectedMethod === "GET" ? this.fallbackMethod : expectedMethod,
      headers,
      body: serialized,
      signal: options.signal
    };
  }
  async decode(response) {
    const isOk = !isORPCErrorStatus(response.status);
    const deserialized = await (async () => {
      let isBodyOk = false;
      try {
        const body = await response.body();
        isBodyOk = true;
        return this.serializer.deserialize(body);
      } catch (error) {
        if (!isBodyOk) {
          throw new Error("Cannot parse response body, please check the response body and content-type.", {
            cause: error
          });
        }
        throw new Error("Invalid RPC response format.", {
          cause: error
        });
      }
    })();
    if (!isOk) {
      if (isORPCErrorJson(deserialized)) {
        throw createORPCErrorFromJson(deserialized);
      }
      throw new ORPCError(getMalformedResponseErrorCode(response.status), {
        status: response.status,
        data: { ...response, body: deserialized }
      });
    }
    return deserialized;
  }
};
var StandardRPCSerializer = class {
  constructor(jsonSerializer) {
    this.jsonSerializer = jsonSerializer;
  }
  serialize(data) {
    if (isAsyncIteratorObject(data)) {
      return mapEventIterator(data, {
        value: async (value2) => this.#serialize(value2, false),
        error: async (e) => {
          return new ErrorEvent({
            data: this.#serialize(toORPCError(e).toJSON(), false),
            cause: e
          });
        }
      });
    }
    return this.#serialize(data, true);
  }
  #serialize(data, enableFormData) {
    const [json, meta_, maps, blobs] = this.jsonSerializer.serialize(data);
    const meta = meta_.length === 0 ? void 0 : meta_;
    if (!enableFormData || blobs.length === 0) {
      return {
        json,
        meta
      };
    }
    const form = new FormData();
    form.set("data", stringifyJSON({ json, meta, maps }));
    blobs.forEach((blob, i) => {
      form.set(i.toString(), blob);
    });
    return form;
  }
  deserialize(data) {
    if (isAsyncIteratorObject(data)) {
      return mapEventIterator(data, {
        value: async (value2) => this.#deserialize(value2),
        error: async (e) => {
          if (!(e instanceof ErrorEvent)) {
            return e;
          }
          const deserialized = this.#deserialize(e.data);
          if (isORPCErrorJson(deserialized)) {
            return createORPCErrorFromJson(deserialized, { cause: e });
          }
          return new ErrorEvent({
            data: deserialized,
            cause: e
          });
        }
      });
    }
    return this.#deserialize(data);
  }
  #deserialize(data) {
    if (data === void 0) {
      return void 0;
    }
    if (!(data instanceof FormData)) {
      return this.jsonSerializer.deserialize(data.json, data.meta ?? []);
    }
    const serialized = JSON.parse(data.get("data"));
    return this.jsonSerializer.deserialize(
      serialized.json,
      serialized.meta ?? [],
      serialized.maps,
      (i) => data.get(i.toString())
    );
  }
};
var StandardRPCLink = class extends StandardLink {
  constructor(linkClient, options) {
    const jsonSerializer = new StandardRPCJsonSerializer(options);
    const serializer = new StandardRPCSerializer(jsonSerializer);
    const linkCodec = new StandardRPCLinkCodec(serializer, options);
    super(linkCodec, linkClient, options);
  }
};

// node_modules/@orpc/client/dist/adapters/fetch/index.mjs
init_dist2();
init_client_J7pEE4Uw();
init_client_BLtwTQUg();
var CompositeLinkFetchPlugin = class extends CompositeStandardLinkPlugin {
  initRuntimeAdapter(options) {
    for (const plugin of this.plugins) {
      plugin.initRuntimeAdapter?.(options);
    }
  }
};
var LinkFetchClient = class {
  fetch;
  toFetchRequestOptions;
  adapterInterceptors;
  constructor(options) {
    const plugin = new CompositeLinkFetchPlugin(options.plugins);
    plugin.initRuntimeAdapter(options);
    this.fetch = options.fetch ?? globalThis.fetch.bind(globalThis);
    this.toFetchRequestOptions = options;
    this.adapterInterceptors = toArray(options.adapterInterceptors);
  }
  async call(standardRequest, options, path21, input) {
    const request = toFetchRequest(standardRequest, this.toFetchRequestOptions);
    const fetchResponse = await intercept(
      this.adapterInterceptors,
      { ...options, request, path: path21, input, init: { redirect: "manual" } },
      ({ request: request2, path: path22, input: input2, init, ...options2 }) => this.fetch(request2, init, options2, path22, input2)
    );
    const lazyResponse = toStandardLazyResponse(fetchResponse, { signal: request.signal });
    return lazyResponse;
  }
};
var RPCLink = class extends StandardRPCLink {
  constructor(options) {
    const linkClient = new LinkFetchClient(options);
    super(linkClient, options);
  }
};

// src/cli/proxifyOrpc.ts
init_dist3();
init_dist5();
import { z as z29 } from "zod";
var emptyObjectSchema = z29.object({});
function isZod4Like(value2) {
  if (typeof value2 !== "object" || value2 === null) return false;
  const v = value2;
  return v.def !== void 0 && typeof v.def === "object" || v._def !== void 0 && typeof v._def === "object";
}
function isVoidOrUndefinedSchema(schema) {
  if (!isZod4Like(schema)) return false;
  const def = getDef(schema);
  return def?.type === "void" || def?.type === "undefined";
}
function isEmptyObject(value2) {
  return typeof value2 === "object" && value2 !== null && !Array.isArray(value2) && Object.keys(value2).length === 0;
}
function getDef(schema) {
  return schema.def ?? schema._def;
}
function unwrapSchema(schema) {
  let current = schema;
  let currentDef = getDef(current);
  while (currentDef && (currentDef.type === "optional" || currentDef.type === "nullable" || currentDef.type === "default") && currentDef.innerType) {
    current = currentDef.innerType;
    currentDef = getDef(current);
  }
  return current;
}
function isOptionalField(schema) {
  const def = getDef(schema);
  return def?.type === "optional" || def?.type === "default";
}
function detectCommonDiscriminator(options) {
  const commonFields = ["type", "kind", "tag", "variant"];
  for (const fieldName of commonFields) {
    let allHaveLiteral = true;
    for (const option of options) {
      if (!isZod4Like(option)) {
        allHaveLiteral = false;
        break;
      }
      const optDef = getDef(option);
      if (optDef?.type !== "object" || !optDef.shape) {
        allHaveLiteral = false;
        break;
      }
      const field = optDef.shape[fieldName];
      if (!field || !isZod4Like(field)) {
        allHaveLiteral = false;
        break;
      }
      const fieldDef = getDef(field);
      if (fieldDef?.type !== "literal") {
        allHaveLiteral = false;
        break;
      }
    }
    if (allHaveLiteral) {
      return fieldName;
    }
  }
  return void 0;
}
function describeZodType(schema, indent = 0) {
  if (!isZod4Like(schema)) return "unknown";
  const unwrapped = unwrapSchema(schema);
  const def = getDef(unwrapped);
  if (!def) return "unknown";
  const type2 = def.type;
  switch (type2) {
    case "string":
      return "string";
    case "number":
      return "number";
    case "boolean":
      return "boolean";
    case "literal":
      if (def.values && def.values.length > 0) {
        return JSON.stringify(def.values[0]);
      }
      if (def.value !== void 0) {
        return JSON.stringify(def.value);
      }
      return "literal";
    case "enum":
      if (def.entries) {
        return Object.values(def.entries).map((v) => JSON.stringify(v)).join("|");
      }
      return "enum";
    case "array":
      if (def.element && isZod4Like(def.element)) {
        const elemUnwrapped = unwrapSchema(def.element);
        const elemDef = getDef(elemUnwrapped);
        if (elemDef?.type === "object" && typeof elemDef.shape === "object") {
          const childFields = describeObjectFieldsHierarchical(elemUnwrapped, indent + 1);
          return `Array of:
${childFields}`;
        }
        if (elemDef?.type === "union") {
          const elemDesc = describeZodType(elemUnwrapped, indent);
          if (elemDesc.startsWith("One of:")) {
            return `Array of ${elemDesc}`;
          }
        }
        return `${describeZodType(def.element, indent)}[]`;
      }
      return "array";
    case "optional":
    case "nullable":
    case "default":
      if (def.innerType) {
        return describeZodType(def.innerType, indent);
      }
      return "unknown";
    case "union":
      if (def.options && Array.isArray(def.options)) {
        const variants = def.options.map((o) => describeZodType(o, indent)).filter((v) => v !== void 0 && v !== null);
        if (variants.length === 0) return "union";
        const allPrimitive = variants.every((v) => !v.includes("\n"));
        if (allPrimitive) {
          return variants.join("|");
        }
        const indentStr = "    ".repeat(indent + 1);
        const discriminator = def.discriminator ?? detectCommonDiscriminator(def.options);
        const formattedVariants = def.options.map((option, i) => {
          const variantDesc = variants[i];
          if (!variantDesc) return "";
          let label = `Variant ${i + 1}`;
          if (discriminator && isZod4Like(option)) {
            const optDef = getDef(option);
            if (optDef?.type === "object" && optDef.shape) {
              const discField = optDef.shape[discriminator];
              if (discField && isZod4Like(discField)) {
                const discDef = getDef(discField);
                if (discDef?.type === "literal") {
                  const val = discDef.values?.[0] ?? discDef.value;
                  if (val !== void 0) label = `${discriminator}=${JSON.stringify(val)}`;
                }
              }
            }
          }
          if (variantDesc.startsWith("\n")) {
            return `${indentStr}${label}:${variantDesc}`;
          }
          return `${indentStr}${label}: ${variantDesc}`;
        }).filter(Boolean);
        return `One of:
${formattedVariants.join("\n")}`;
      }
      return "union";
    case "object":
      if (typeof def.shape === "object") {
        const childFields = describeObjectFieldsHierarchical(unwrapped, indent + 1);
        return `
${childFields}`;
      }
      return "object";
    case "any":
      return "any";
    case "unknown":
      return "unknown";
    case "record":
      return "object";
    default:
      return type2 ?? "unknown";
  }
}
function describeObjectFieldsHierarchical(schema, indent) {
  const def = getDef(schema);
  if (!def || typeof def.shape !== "object") return `${"    ".repeat(indent)}- object`;
  const shape = def.shape;
  const lines = [];
  const indentStr = "    ".repeat(indent);
  for (const [key, fieldSchema] of Object.entries(shape)) {
    if (!isZod4Like(fieldSchema)) continue;
    const isOpt = isOptionalField(fieldSchema);
    const optMark = isOpt ? "?" : "";
    const fieldType = describeZodType(fieldSchema, indent);
    if (!fieldType) {
      lines.push(`${indentStr}- ${key}${optMark}: unknown`);
      continue;
    }
    if (fieldType.startsWith("\n")) {
      lines.push(`${indentStr}- ${key}${optMark}:${fieldType}`);
    } else if (fieldType.startsWith("Array of:\n")) {
      lines.push(`${indentStr}- ${key}${optMark}: ${fieldType}`);
    } else {
      lines.push(`${indentStr}- ${key}${optMark}: ${fieldType}`);
    }
  }
  return lines.join("\n");
}
function describeZodObjectFields(schema) {
  const def = getDef(schema);
  if (!def || typeof def.shape !== "object") return "object";
  const shape = def.shape;
  const requiredLines = [];
  const optionalLines = [];
  for (const [key, fieldSchema] of Object.entries(shape)) {
    if (!isZod4Like(fieldSchema)) continue;
    const isOpt = isOptionalField(fieldSchema);
    const optMark = isOpt ? "?" : "";
    const fieldType = describeZodType(fieldSchema, 1);
    let entry;
    if (fieldType.startsWith("\n")) {
      entry = `- ${key}${optMark}:${fieldType}`;
    } else if (fieldType.startsWith("Array of:\n") || fieldType.startsWith("Array of One of:\n")) {
      entry = `- ${key}${optMark}: ${fieldType}`;
    } else {
      entry = `- ${key}${optMark}: ${fieldType}`;
    }
    if (isOpt) {
      optionalLines.push(entry);
    } else {
      requiredLines.push(entry);
    }
  }
  const parts = [];
  if (requiredLines.length > 0) {
    parts.push(`Required:
${requiredLines.join("\n")}`);
  }
  if (optionalLines.length > 0) {
    parts.push(`Optional:
${optionalLines.join("\n")}`);
  }
  const content = parts.join("\n") || "object";
  const baseIndent = "      ";
  const indentedContent = content.split("\n").map((line) => baseIndent + line).join("\n");
  return "\n" + indentedContent;
}
function enhanceInputSchema(schema) {
  if (!isZod4Like(schema)) return schema;
  const def = getDef(schema);
  if (def?.type === "void" || def?.type === "undefined") {
    return emptyObjectSchema;
  }
  if (def?.type !== "object" || typeof def.shape !== "object") {
    return schema;
  }
  const shape = def.shape;
  let hasEnhancements = false;
  const enhancedShape = {};
  for (const [key, fieldSchema] of Object.entries(shape)) {
    if (!isZod4Like(fieldSchema)) {
      enhancedShape[key] = fieldSchema;
      continue;
    }
    if (fieldSchema.description || typeof fieldSchema.describe !== "function") {
      enhancedShape[key] = fieldSchema;
      continue;
    }
    let innerSchema = fieldSchema;
    let innerDef = getDef(fieldSchema);
    while (innerDef && (innerDef.type === "optional" || innerDef.type === "default") && innerDef.innerType) {
      innerSchema = innerDef.innerType;
      innerDef = getDef(innerSchema);
    }
    const innerType = innerDef?.type;
    if (innerType === "object" && typeof innerDef?.shape === "object") {
      const desc = describeZodObjectFields(innerSchema);
      const isOptional2 = getDef(fieldSchema)?.type === "optional";
      const replacement = isOptional2 ? z29.any().optional().describe(desc) : z29.any().describe(desc);
      enhancedShape[key] = replacement;
      hasEnhancements = true;
    } else if (innerType === "union" || innerType === "array") {
      const desc = describeZodType(innerSchema, 0);
      if (desc.includes("\n")) {
        const baseIndent = "      ";
        const indentedDesc = desc.split("\n").map((line) => baseIndent + line).join("\n");
        const isOptional2 = getDef(fieldSchema)?.type === "optional";
        const replacement = isOptional2 ? z29.any().optional().describe("\n" + indentedDesc) : z29.any().describe("\n" + indentedDesc);
        enhancedShape[key] = replacement;
        hasEnhancements = true;
      } else {
        enhancedShape[key] = fieldSchema;
      }
    } else {
      enhancedShape[key] = fieldSchema;
    }
  }
  if (!hasEnhancements) return schema;
  const enhancedDef = { ...def, shape: enhancedShape };
  const enhanced = {
    ...schema,
    def: enhancedDef,
    _def: enhancedDef
  };
  const originalZod = schema._zod;
  if (originalZod) {
    enhanced._zod = {
      ...originalZod,
      def: enhancedDef
      // toJSONSchema reads shape from _zod.def
    };
  }
  return enhanced;
}
function proxifyOrpc(router2, options) {
  const createClient = () => {
    const link = new RPCLink({
      url: `${options.baseUrl}/orpc`,
      headers: options.authToken ? { Authorization: `Bearer ${options.authToken}` } : void 0
    });
    return createORPCClient(link);
  };
  return createRouterProxy(
    router2,
    createClient,
    []
  );
}
function createRouterProxy(router2, createClient, path21) {
  const result = {};
  for (const [key, value2] of Object.entries(router2)) {
    const newPath = [...path21, key];
    if (isProcedure(value2)) {
      result[key] = createProcedureProxy(
        value2,
        createClient,
        newPath
      );
    } else if (typeof value2 === "object" && value2 !== null && !Array.isArray(value2)) {
      result[key] = createRouterProxy(value2, createClient, newPath);
    }
  }
  return result;
}
function createProcedureProxy(procedure, createClient, path21) {
  const originalDef = procedure["~orpc"];
  const originalInputSchema = originalDef.inputSchema;
  const isVoidInput = isVoidOrUndefinedSchema(originalInputSchema);
  const enhancedInputSchema = enhanceInputSchema(originalInputSchema);
  const getClientMethod = () => {
    const client = createClient();
    let method = client;
    for (const segment of path21) {
      method = method[segment];
    }
    return method;
  };
  const proxy = {
    "~orpc": {
      ...originalDef,
      // Use enhanced schema for CLI help generation
      inputSchema: enhancedInputSchema,
      // Keep the original middlewares empty for the proxy - we don't need them
      // since the server will run its own middleware chain
      middlewares: [],
      // The handler that will be called by @orpc/server's `call()` function
      // eslint-disable-next-line @typescript-eslint/no-explicit-any
      handler: async (opts) => {
        const clientMethod = getClientMethod();
        const input = isVoidInput && isEmptyObject(opts.input) ? void 0 : opts.input;
        return clientMethod(input);
      }
    }
  };
  return proxy;
}

// src/node/services/serverLockfile.ts
import * as fs13 from "fs/promises";
import * as path20 from "path";
import { z as z30 } from "zod";
var ServerLockDataSchema = z30.object({
  pid: z30.number(),
  /** Base URL for HTTP API (e.g., "http://localhost:3000" or "https://my.box.com/unix") */
  baseUrl: z30.url(),
  token: z30.string(),
  startedAt: z30.string(),
  /** Bind host/interface the server is listening on (e.g. "127.0.0.1" or "0.0.0.0") */
  bindHost: z30.string().optional(),
  /** The port the server is listening on */
  port: z30.number().int().min(0).max(65535).optional(),
  /** Additional base URLs that are reachable from other devices (LAN/VPN) */
  networkBaseUrls: z30.array(z30.url()).optional()
});
var ServerLockfile = class {
  constructor(unixHome) {
    this.lockPath = path20.join(unixHome, "server.lock");
  }
  /**
   * Acquire the lockfile with the given baseUrl and token.
   * Writes atomically with 0600 permissions (owner read/write only).
   */
  async acquire(baseUrl, token, extra) {
    const bindHost = extra?.bindHost?.trim() ? extra.bindHost.trim() : void 0;
    const port = typeof extra?.port === "number" && Number.isInteger(extra.port) && extra.port >= 0 && extra.port <= 65535 ? extra.port : void 0;
    const data = {
      pid: process.pid,
      baseUrl,
      token,
      startedAt: (/* @__PURE__ */ new Date()).toISOString(),
      bindHost,
      port,
      networkBaseUrls: extra?.networkBaseUrls?.length ? extra.networkBaseUrls : void 0
    };
    const dir = path20.dirname(this.lockPath);
    try {
      await fs13.access(dir);
    } catch {
      await fs13.mkdir(dir, { recursive: true });
    }
    const tempPath = `${this.lockPath}.${process.pid}.tmp`;
    await fs13.writeFile(tempPath, JSON.stringify(data, null, 2), {
      mode: 384
      // Owner read/write only
    });
    await fs13.rename(tempPath, this.lockPath);
  }
  /**
   * Read the lockfile and validate it.
   * Returns null if the lockfile doesn't exist or is stale (dead PID).
   */
  async read() {
    try {
      await fs13.access(this.lockPath);
      const content = await fs13.readFile(this.lockPath, "utf-8");
      const data = ServerLockDataSchema.parse(JSON.parse(content));
      if (!this.isProcessAlive(data.pid)) {
        await this.release();
        return null;
      }
      return data;
    } catch {
      return null;
    }
  }
  /**
   * Release the lockfile by deleting it.
   */
  async release() {
    try {
      await fs13.unlink(this.lockPath);
    } catch {
    }
  }
  /**
   * Check if a process with the given PID is still running.
   * Uses signal 0 which tests existence without actually sending a signal.
   */
  isProcessAlive(pid) {
    try {
      process.kill(pid, 0);
      return true;
    } catch {
      return false;
    }
  }
  /**
   * Get the path to the lockfile (for testing/debugging).
   */
  getLockPath() {
    return this.lockPath;
  }
};

// src/cli/argv.ts
function detectCliEnvironment(versions = process.versions, defaultApp = process.defaultApp) {
  const isElectron = "electron" in versions;
  const isPackagedElectron = isElectron && !defaultApp;
  const firstArgIndex = isPackagedElectron ? 1 : 2;
  return { isElectron, isPackagedElectron, firstArgIndex };
}
function getArgsAfterSplice(argv = process.argv, env3 = detectCliEnvironment()) {
  return argv.slice(env3.firstArgIndex);
}

// src/cli/api.ts
var args = getArgsAfterSplice();
async function discoverServer() {
  if (process.env.UNIX_SERVER_URL) {
    return {
      baseUrl: process.env.UNIX_SERVER_URL,
      authToken: process.env.UNIX_SERVER_AUTH_TOKEN
    };
  }
  try {
    const lockfile = new ServerLockfile(getUnixHome());
    const data = await lockfile.read();
    if (data) {
      return {
        baseUrl: data.baseUrl,
        authToken: data.token
      };
    }
  } catch {
  }
  return {
    baseUrl: "http://localhost:3000",
    authToken: process.env.UNIX_SERVER_AUTH_TOKEN
  };
}
(async () => {
  const { baseUrl, authToken } = await discoverServer();
  const proxiedRouter = proxifyOrpc(router(), { baseUrl, authToken });
  const { run } = createCli({
    router: proxiedRouter,
    name: "unix api",
    description: "Interact with the unix API via a running server"
  });
  try {
    await run({ argv: args });
  } catch (error) {
    if (error instanceof Error && error.constructor.name === "FailedToExitError") {
      return;
    }
    throw error;
  }
})();
/*! Bundled license information:

imurmurhash/imurmurhash.js:
  (**
   * @preserve
   * JS Implementation of incremental MurmurHash3 (r150) (as of May 10, 2013)
   *
   * @author <a href="mailto:jensyt@gmail.com">Jens Taylor</a>
   * @see http://github.com/homebrewing/brauhaus-diff
   * @author <a href="mailto:gary.court@gmail.com">Gary Court</a>
   * @see http://github.com/garycourt/murmurhash-js
   * @author <a href="mailto:aappleby@gmail.com">Austin Appleby</a>
   * @see http://sites.google.com/site/murmurhash/
   *)
*/
